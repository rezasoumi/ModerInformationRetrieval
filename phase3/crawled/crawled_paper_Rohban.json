[
    {
        "id": "0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf",
        "title": "Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl",
        "abstract": "The 2018 Data Science Bowl attracted 3,891 teams worldwide to make the first attempt to build a segmentation method that could be applied to any two-dimensional light microscopy image of stained nuclei across experiments, with no human interaction. Segmenting the nuclei of cells in microscopy images is often the first step in the quantitative analysis of imaging data for biological and biomedical applications. Many bioimage analysis tools can segment nuclei in images but need to be selected and configured for every experiment. The 2018 Data Science Bowl attracted 3,891 teams worldwide to make the first attempt to build a segmentation method that could be applied to any two-dimensional light microscopy image of stained nuclei across experiments, with no human interaction. Top participants in the challenge succeeded in this task, developing deep-learning-based models that identified cell nuclei across many image types and experimental conditions without the need to manually adjust segmentation parameters. This represents an important step toward configuration-free bioimage analysis software tools.The 2018 Data Science Bowl challenged competitors to develop an accurate tool for segmenting stained nuclei from diverse light microscopy images. The winners deployed innovative deep-learning strategies to realize configuration-free segmentation.",
        "publication_year": "2019",
        "authors": [
            "Juan C. Caicedo",
            "A. Goodman",
            "Kyle W. Karhohs",
            "B. Cimini",
            "Jeanelle Ackerman",
            "Marzieh Haghighi",
            "Cherkeng Heng",
            "T. Becker",
            "M. Doan",
            "C. McQuin",
            "M. Rohban",
            "Shantanu Singh",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Biology",
            "Physics",
            "Computer Science"
        ],
        "citation_count": "324",
        "reference_count": "55",
        "references": [
            "/paper/Boundary-Sensitive-Loss-Function-With-Location-for-Du-Guan/8ab76eba8c98c302def3e2d3bedea1e00b371add",
            "/paper/A-Two-stage-Refinement-Network-for-Nuclei-in-Images-Jian-Kamata/fbf097f626a02b2c49947e003f80915aab08147a",
            "/paper/A-general-deep-learning-framework-for-neuron-based-Wu-Souedet/0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
            "/paper/Neuroplastic-graph-attention-networks-for-nuclei-in-Alon-Zhou/b6d233e5a2c14e958c19cf1fc5d0a87531889f8f",
            "/paper/X-Net%3A-a-dual-encoding%E2%80%93decoding-method-in-medical-Li-Wang/9a2ce0b25d3a0f82eae38a0d1e8064d710aa11d0",
            "/paper/FANet%3A-A-Feedback-Attention-Network-for-Improved-Tomar-Jha/81c35b12898c7f46115547b70f628f966ed73c50",
            "/paper/CPP-Net%3A-Context-Aware-Polygon-Proposal-Network-for-Chen-Ding/02a3042552b70feb47f3dca08806f8ce82f35b84",
            "/paper/nucleAIzer%3A-A-Parameter-free-Deep-Learning-for-Hollandi-Szkalisity/0a78085721f70d82c1284c124c3137bb7c2b34e7",
            "/paper/EG-TransUNet%3A-a-transformer-based-U-Net-with-and-Pan-Liu/4a6bf17538ded4eae48629728ee17adebb688094",
            "/paper/Evaluation-of-Deep-Learning-Topcoders-Method-for-in-Wu-Souedet/056806e5ba9f2b39cbe86b529c325998c3bdd016",
            "/paper/Comprehensive-review-anonymous/dc90e115e348908891a4e990242e726b3d4e8b15",
            "/paper/Deep-learning-for-cellular-image-analysis-Moen-Bannon/48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852",
            "/paper/Author-Correction%3A-U-Net%3A-deep-learning-for-cell-Falk-Mai/1294067d8237497b6cd3ee8731c3636215981de3",
            "/paper/A-deep-learning-framework-for-nucleus-segmentation-Hollandi-Szkalisity/a1af04fa0a581a9f134a734363b1786ab2c355b7",
            "/paper/U-Net%3A-deep-learning-for-cell-counting%2C-detection%2C-Falk-Mai/779b489971775507fe6a39d98c52c4df56d9cce1",
            "/paper/Object%E2%80%90Oriented-Segmentation-of-Cell-Nuclei-in-Koyuncu-Cetin-Atalay/31a27c6500b6652d7ecc055c9b08457ad90128c1",
            "/paper/CellProfiler-3.0%3A-Next-generation-image-processing-McQuin-Goodman/713e881b5c3134debf934026edf6f0ba3cb42c3c",
            "/paper/On-the-Effect-of-Inter-observer-Variability-for-a-Jungo-Meier/0878ad6d3692c27eed44cc76b64662d228b4cf1e",
            "/paper/Evaluation-of-Deep-Learning-Strategies-for-Nucleus-Caicedo-Roth/c89bfd998b0a6c656010b629814ab0cad3cff72e",
            "/paper/Comparison-of-Different-Classifiers-with-Active-to-Wen-Kur%C3%A7/c26e4b47660692e500ad5afb5225e62b58b2e411"
        ]
    },
    {
        "id": "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
        "title": "Multiresolution Knowledge Distillation for Anomaly Detection",
        "abstract": "This work proposes to use the \"distillation\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle anomaly detection and localization. Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the \"distillation\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks\u2019 intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert\u2019s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.",
        "publication_year": "2020",
        "authors": [
            "Mohammadreza Salehi",
            "Niousha Sadjadi",
            "Soroosh Baselizadeh",
            "M. Rohban",
            "H. Rabiee"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "136",
        "reference_count": "58",
        "references": [
            "/paper/A-Unified-Model-for-Multi-class-Anomaly-Detection-You-Cui/0e8446c00ed21c19f62d71ab208a7b3601671766",
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/Pull-%26-Push%3A-Leveraging-Differential-Knowledge-for-Zhou-He/2013f18832e0fb11c7aaf1f4f8da453aebda488c",
            "/paper/Asymmetric-Distillation-Post-Segmentation-Method-Xing-Li/61840de4d9610558d510cfcf32986e93511a4cef",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/Prototypical-Residual-Networks-for-Anomaly-and-Zhang-Wu/ac62ed8a9b77d613189b63004f4a5d4c5cc082fe",
            "/paper/Multiresolution-Feature-Guidance-Based-Transformer-Yan-Chen/f48d6b404932c23b701d01d7f7382384103b0bd6",
            "/paper/An-Improved-Reverse-Distillation-Model-for-Anomaly-Nguyen-Bach/205a1c89058ea55fe536c6484a62213d1d0f0160",
            "/paper/Simple-Adaptive-Projection-with-Pretrained-Features-Gui/854c92e791ca2d81fec787736866b892b73b87f6",
            "/paper/MTHM%3A-Self-Supervised-Multitask-Anomaly-Detection-Zhang-Wang/a4b4b63968260f142b0b5a10d8868f18d6930f4c",
            "/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "/paper/Fully-Convolutional-Neural-Network-for-Fast-Anomaly-Sabokrou-Fayyaz/8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6",
            "/paper/Anomaly-Detection-with-Robust-Deep-Autoencoders-Zhou-Paffenroth/2b75ba7f75170b73d913c515cc0deefef6c88f5f",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/Iterative-energy-based-projection-on-a-normal-data-Dehaene-Frigo/d9d7ab13ce305ccee309c989a2341d72b1252070"
        ]
    },
    {
        "id": "1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5",
        "title": "Data-analysis strategies for image-based cell profiling",
        "abstract": "The steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images are introduced and techniques that have proven useful in each stage of the data analysis process are recommended on the basis of the experience of 20 laboratories worldwide that are refining their image- based cell-profiling methodologies. Image-based cell profiling is a high-throughput strategy for the quantification of phenotypic differences among a variety of cell populations. It paves the way to studying biological systems on a large scale by using chemical and genetic perturbations. The general workflow for this technology involves image acquisition with high-throughput microscopy systems and subsequent image processing and analysis. Here, we introduce the steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images. We recommend techniques that have proven useful in each stage of the data analysis process, on the basis of the experience of 20 laboratories worldwide that are refining their image-based cell-profiling methodologies in pursuit of biological discovery. The recommended techniques cover alternatives that may suit various biological goals, experimental designs, and laboratories' preferences.",
        "publication_year": "2017",
        "authors": [
            "Juan C. Caicedo",
            "Sam Cooper",
            "Florian Heigwer",
            "Scott Warchal",
            "P. Qiu",
            "Csaba Molnar",
            "A. Vasilevich",
            "Joseph D Barry",
            "Harmanjit Singh Bansal",
            "Oren Z. Kraus",
            "Mathias Wawer",
            "L. Paavolainen",
            "M. Herrmann",
            "M. Rohban",
            "Jane Hung",
            "H. Hennig",
            "J. Concannon",
            "Ian Smith",
            "P. Clemons",
            "Shantanu Singh",
            "P. Rees",
            "P. Horv\u00e1th",
            "Roger G. Linington",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "435",
        "reference_count": "152",
        "references": [
            "/paper/Image-based-cell-profiling-enhancement-via-data-Rezvani-Bigverdi/4d0506d3e7f5dd23e1620cf8c48650bf1552bd3e",
            "/paper/Phenotypic-Image-Analysis-Software-Tools-for-and-Smith-Piccinini/069c15e8891c9260d9545d0f82b8a08145044482",
            "/paper/Assessing-the-performance-of-the-Cell-Painting-Jamali-Tromans-Coia/dbe577b3cdc30f0f1b264a86affc9db96c6065a7",
            "/paper/Data-cleaning-for-image-based-profiling-enhancement-Rezvani-Bigverdi/0591de4af9853d4fd6225e73568b669d69c5f8a8",
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/Image-based-profiling%3A-a-powerful-and-challenging-Way-Spitzer/0b1bde9d681580b807d5da5933cfc6920fa922fc",
            "/paper/Single-cell-image-analysis-to-explore-cell-to-cell-U%C5%A1aj-Yeung/a8f057a67b17ed18eecdff46a4f15e4e6e2e3863",
            "/paper/Image-based-cell-phenotyping-with-deep-learning.-Pratapa-Doron/8f8a0de72c285f10bd3af311899026193eda632e",
            "/paper/A-statistical-framework-for-high-content-phenotypic-Pearson-Kremb/f091d0da11f8a4a2ed44e10fd34c6e76d8cd5456",
            "/paper/Multi-modal-image-cytometry-approach-From-dynamic-Husna-Gascoigne/047d1a132c24aca4b3dc9bad12b752c615b78f95",
            "/paper/Comparison-of-Methods-for-Image-Based-Profiling-of-Ljosa-Caie/929a490198770abcb8c123d68a59384879b69adb",
            "/paper/Applications-in-image-based-profiling-of-Caicedo-Singh/29c736eb38861ecf346ce49eedf163c03974566b",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0",
            "/paper/High-Content-Screening-for-Quantitative-Cell-U%C5%A1aj-Styles/e5c33c8df40dd55cb3068b759a30f76bbd8b9933",
            "/paper/Microscopy-Based-High-Content-Screening-Boutros-Heigwer/aa0875ccc516862edc0b6bd2181ee27ce882933d",
            "/paper/CellProfiler%3A-image-analysis-software-for-and-cell-Carpenter-Jones/a2e75b7d9727b7ea7cefb4060d93ac75813e3c48",
            "/paper/Rapid-analysis-and-exploration-of-fluorescence-Pavie-Rajaram/8db554d7e597000f5a0e13712ef0cb3299c05187",
            "/paper/Image-based-multivariate-profiling-of-drug-from-Loo-Wu/bfc8a8724b36cd2b1d068d1f997400e74791a68d",
            "/paper/Large%E2%80%90scale-image%E2%80%90based-screening-and-profiling-of-Bougen-Zhukov-Loh/8a7ce466e8f119f033aeace4210cc348ed62520b",
            "/paper/Machine-Learning-Improves-the-Precision-and-of-Horv%C3%A1th-Wild/669832b732a20ccbdbb81c22393f4bc8f9371dbc"
        ]
    },
    {
        "id": "0e16a10560b4f7d5f891b932c79d1b2005407acf",
        "title": "Minimax Optimal Sparse Signal Recovery With Poisson Statistics",
        "abstract": "This work derives a minimax matching lower bound on the mean-squared error of the maximum likelihood decoder and shows that the constrained ML decoder is minimax optimal for this regime. We are motivated by problems that arise in a number of applications such as Online Marketing and Explosives detection, where the observations are usually modeled using Poisson statistics. We model each observation as a Poisson random variable whose mean is a sparse linear superposition of known patterns. Unlike many conventional problems observations here are not identically distributed since they are associated with different sensing modalities. We analyze the performance of a maximum likelihood (ML) decoder, which for our Poisson setting involves a non-linear optimization but yet is computationally tractable. We derive fundamental sample complexity bounds for sparse recovery when the measurements are contaminated with Poisson noise. In contrast to the least-squares linear regression setting with Gaussian noise, we observe that in addition to sparsity, the scale of the parameters also fundamentally impacts l2 error in the Poisson setting. We show that our upper bounds are tight under suitable regularity conditions. Specifically, we derive a minimax matching lower bound on the mean-squared error and show that our constrained ML decoder is minimax optimal for this regime.",
        "publication_year": "2015",
        "authors": [
            "M. Rohban",
            "Venkatesh Saligrama",
            "Delaram Motamed Vaziri"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "15",
        "reference_count": "25",
        "references": [
            "/paper/Variance-stabilization-based-compressive-inversion-Bohra-Garg/f7ec3c2396844cb7f60649be7c059f206d8c3b46",
            "/paper/Reconstruction-Error-Bounds-for-Compressed-Sensing-Garg-Rajwade/b9dc8c417fb660a705c538ba16b22d199dd9c1d4",
            "/paper/Two-penalized-estimators-based-on-variance-for-with-Rajwade-Gurumoorthy/9e35901cbd1c258e99a2d119c666d8f1f0c62c88",
            "/paper/Using-an-Information-Theoretic-Metric-for-Recovery-Patil-Gurumoorthy/90d5988e60124db3e2221b90e2560d99790e7daf",
            "/paper/Performance-bounds-for-Poisson-compressed-sensing-Garg-Rajwade/c0ff008fe0ea97f117d200b702be481a073fbae8",
            "/paper/Reconstruction-Error-Bounds-for-Compressed-Sensing-Patil-Rajwade/f0737ce218f93f5252fe2c7978e33fead964dbc3",
            "/paper/Sparse-parametric-estimation-of-Poisson-processes-Moore-Davenport/a2c7b7db0ef5994cc43fb550880406c595d14d5f",
            "/paper/A-Data-Dependent-Weighted-LASSO-Under-Poisson-Noise-Hunt-Reynaud-Bouret/bc0aef148b8ec2f3dbdced4686b1ad094a2f0789",
            "/paper/Analyzing-cross-validation-in-compressed-sensing-Rajasekaran-Rajwade/e8e1b2d7917c22b01d0528d6d6159564cc284cfd",
            "/paper/Estimation-of-Poisson-Arrival-Processes-Under-Moore-Davenport/9e46ff3d4b13b099fb6281a7d74f2777c238f038",
            "/paper/Sparse-signal-recovery-under-Poisson-statistics-Motamedvaziri-Rohban/3ecba59e99a4cd5f146270debc5ef8d214697c77",
            "/paper/Compressed-Sensing-Performance-Bounds-Under-Poisson-Raginsky-Willett/51ff6cfb98eec39da52035d87f329cf9e89462e6",
            "/paper/Sparse-signal-recovery-with-exponential-family-Rish-Grabarnik/1ed22f981940b25d3ceac8846153b3521e8cae7b",
            "/paper/Information-Theoretic-Bounds-for-Compressed-Sensing-Aeron-Saligrama/46dfa751eade5e60ab16b51496a9c764bced2322",
            "/paper/Performance-Bounds-for-Expander-Based-Compressed-in-Raginsky-Jafarpour/e4d56ec1be5603ddb2cd5b9264e365a19dbd5217",
            "/paper/Sparse-signal-recovery-under-poisson-statistics-for-Motamedvaziri-Rohban/8f4f9faa26027f8eae4474d90f6d31c0749acd49",
            "/paper/A-unified-framework-for-high-dimensional-analysis-Negahban-Ravikumar/5f56320c5979faeab78dbd9ddb7db755ba4550f3",
            "/paper/Reconstruction-From-Anisotropic-Random-Measurements-Rudelson-Zhou/e716688ddc25dcc8871ef04c7f864063949aa8b9",
            "/paper/THE-LASSO-UNDER-POISSON-LIKE-HETEROSCEDASTICITY-Jia-Rohe/fe09efb519b26d59c64c715c4efcbe752dc933be",
            "/paper/Asymptotic-Behavior-of-Likelihood-Methods-for-when-Portnoy/046d550f95db0dae9aa26b34c31cb502b5b72983"
        ]
    },
    {
        "id": "10b219619e88931fabb674037bbb633682775136",
        "title": "ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection",
        "abstract": "Semantic Scholar extracted view of \"ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection\" by Mohammadreza Salehi et al.",
        "publication_year": "2020",
        "authors": [
            "Mohammadreza Salehi",
            "Atrin Arya",
            "Barbod Pajoum",
            "Mohammad Otoofi",
            "Amirreza Shaeiri",
            "M. Rohban",
            "H. Rabiee"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "32",
        "reference_count": "49",
        "references": [
            "/paper/Puzzle-AE%3A-Novelty-Detection-in-Images-through-Salehi-Eftekhar/38ca689c2f916c648ea3ecb1043facbc4bea0d4f",
            "/paper/Ano-Graph%3A-Learning-Normal-Scene-Contextual-Graphs-PourReza-Salehi/12ebe64bf81b85b2331875895bd3a2b5978dabd8",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/An-Experimental-Study-of-Semantic-Continuity-for-Wu-Sang/027c44214e34f06bfd82625c393ddc73cf4ae760",
            "/paper/One-Class-Classification%3A-A-Survey-Perera-Oza/bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6",
            "/paper/Robust-Semi-Supervised-Anomaly-Detection-via-Noise-Barker-Bhowmik/69244cd6455392f7eb0dec90119d5c689ee6f1ba",
            "/paper/Hierarchical-Semi-Supervised-Contrastive-Learning-Wang-Zhan/5e5ae3d3439151cd7a026aadb8da9eab16a7b7a7",
            "/paper/Future-frame-prediction-based-on-generative-network-Li-Li/32c82fa3e438521d010e7c7b95a7c01d61f2ceff",
            "/paper/A-Unified-Survey-on-Anomaly%2C-Novelty%2C-Open-Set%2C-and-Salehi-Mirzaei/8b153cc2c7f5ea9f307f12ea945a5e9196ee5c52",
            "/paper/Adversarially-Robust-One-Class-Novelty-Detection-Lo-Oza/4093d9e59f0be07b709d1157aab7fa2d0e41689b",
            "/paper/Generative-Probabilistic-Novelty-Detection-with-Pidhorskyi-Almohsen/70f9968a356d840040a1c9207906f60376dc6bd4",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Towards-Deep-Learning-Models-Resistant-to-Attacks-Madry-Makelov/7aa38b85fa8cba64d6a4010543f6695dbf5f1386",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/Memorizing-Normality-to-Detect-Anomaly%3A-Deep-for-Gong-Liu/d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "/paper/OCGAN%3A-One-Class-Novelty-Detection-Using-GANs-With-Perera-Nallapati/599fd051c9438011ec5b581983c89e8922b4a5e6",
            "/paper/Latent-Space-Autoregression-for-Novelty-Detection-Abati-Porrello/5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d",
            "/paper/Anomaly-Detection-with-Robust-Deep-Autoencoders-Zhou-Paffenroth/2b75ba7f75170b73d913c515cc0deefef6c88f5f",
            "/paper/Exploring-the-Landscape-of-Spatial-Robustness-Engstrom-Tran/0314e777333a63aca5735ea136c74e113aa8801d"
        ]
    },
    {
        "id": "8ab76eba8c98c302def3e2d3bedea1e00b371add",
        "title": "Boundary-Sensitive Loss Function With Location Constraint for Hard Region Segmentation",
        "abstract": "Compared to the second-best method tested, this method improves performance on hard regions in terms of Dice similarity coefficient (DSC) and 95% Hausdorff distance (95%HD) of up to 4.17% and 73% respectively and achieves the best overall segmentation performance. In computer-aided diagnosis and treatment planning, accurate segmentation of medical images plays an essential role, especially for some hard regions including boundaries, small objects and background interference. However, existing segmentation loss functions including distribution-, region- and boundary-based losses cannot achieve satisfactory performances on these hard regions. In this paper, a boundary-sensitive loss function with location constraint is proposed for hard region segmentation in medical images, which provides three advantages: i) our Boundary-Sensitive loss (BS-loss) can automatically pay more attention to the hard-to-segment boundaries (e.g., thin structures and blurred boundaries), thus obtaining finer object boundaries; ii) BS-loss also can adjust its attention to small objects during training to segment them more accurately; and iii) our location constraint can alleviate the negative impact of the background interference, through the distribution matching of pixels between prediction and Ground Truth (GT) along each axis. By resorting to the proposed BS-loss and location constraint, the hard regions in both foreground and background are considered. Experimental results on three public datasets demonstrate the superiority of our method. Specifically, compared to the second-best method tested in this study, our method improves performance on hard regions in terms of Dice similarity coefficient (DSC) and 95% Hausdorff distance (95%HD) of up to 4.17% and 73% respectively. In addition, it also achieves the best overall segmentation performance. Hence, we can conclude that our method can accurately segment these hard regions and improve the overall segmentation performance in medical images.",
        "publication_year": "2022",
        "authors": [
            "Jie Du",
            "K. Guan",
            "Peng Liu",
            "Yuanman Li",
            "Tianfu Wang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "52",
        "references": [
            "/paper/BATFormer%3A-Towards-Boundary-Aware-Lightweight-for-Lin-Yu/6e97f1ced85428cf7207fbcc9205afc0daa68017",
            "/paper/Distance-Map-Loss-Penalty-Term-for-Semantic-Caliv%C3%A1-Iriondo/8d1ae1fb2fdaddd58e57f089a1df8c78786510cf",
            "/paper/Progressive-Abdominal-Segmentation-with-Adaptively-Wang-Zhao/ec59fe08fab6bfb9c91606f66b7c4543c4953453",
            "/paper/CT-male-pelvic-organ-segmentation-using-fully-with-Wang-He/715a5f8c6d63e3c191b49f969ffe6a859fbcf5e6",
            "/paper/Boundary-loss-for-highly-unbalanced-segmentation-Kervadec-Bouchtiba/a1e392a596bc2f34fe34dddf79ee11c20fe5d00e",
            "/paper/3D-Segmentation-with-Exponential-Logarithmic-Loss-Wong-Moradi/88b3a6c3900b189f02cb8a3bfae95214f90ca585",
            "/paper/3-D-RoI-Aware-U-Net-for-Accurate-and-Efficient-Huang-Dou/721d3a3c0d8f9d7cabf6a708286306af14bb5ab5",
            "/paper/Automatic-Pancreas-Segmentation-in-CT-Images-With-Hu-Li/97b3aae575c18e395c38b966fc1c5bf039cdf9cd",
            "/paper/Dynamic-weighting-hierarchical-segmentation-network-Guo-Yang/061218e8c8e2bb4e31ea6aaf6ab5e681fd2787aa",
            "/paper/Boundary-Weighted-Domain-Adaptive-Neural-Network-MR-Zhu-Du/a514e1f6d9eda557e06f69844a2c863c78f59ad4",
            "/paper/Knowledge-Aided-Convolutional-Neural-Network-for-Zhao-Li/857ca3a4591332dbb4d2d56a9f386fb203dbce1b"
        ]
    },
    {
        "id": "fbf097f626a02b2c49947e003f80915aab08147a",
        "title": "A Two-stage Refinement Network for Nuclei Segmentation in Histopathology Images",
        "abstract": "A two-stage deep learning network is proposed for nuclei segmentation tasks that is the first stage network responsible for coarse segmentation, and the second stage network for refined segmentation. Histopathology images are used to assess the status of certain biological structures and to diagnose diseases such as cancer. In computer-assisted diagnosis (CAD), nuclear segmentation for histopathology images is an essential prerequisite. In recent years, deep-learning technology has been gaining popularity in the field of nuclei segmentation. However, nuclei segmentation is still faced with challenging a lot of difficulties due to (1) staining intensity inhomogeneity, (2) background noise caused by preprocessing, (3) blurred boundaries due to a large number of overlapping cells. Furthermore, in histopathology imaging, the number of data samples in the dataset is relatively low, preventing deep convolutional neural networks (CNNs) from segmenting nuclei images with high accuracy like in other vision applications. To overcome the above difficulties, we propose a two-stage deep learning network for nuclei segmentation tasks. It is the first stage network responsible for coarse segmentation, and the second stage network for refined segmentation. In comparison with traditional network architectures, our method achieves near SOTA performance in the nuclei segmentation task.",
        "publication_year": "2022",
        "authors": [
            "Peiyi Jian",
            "S. Kamata"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "10",
        "references": [
            "/paper/DCAN%3A-Deep-Contour-Aware-Networks-for-Accurate-Chen-Qi/ba124bbde8d114a9103eb5751036e2e4710e2fff",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/A-Multi-Organ-Nucleus-Segmentation-Challenge-Kumar-Verma/87c0dd990287d92796c7dc83edba6f52a2f52e21",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/FANet%3A-A-Feedback-Attention-Network-for-Improved-Tomar-Jha/81c35b12898c7f46115547b70f628f966ed73c50",
            "/paper/UNet%2B%2B%3A-Redesigning-Skip-Connections-to-Exploit-in-Zhou-Siddiquee/42b0a8f757e45462e627e57f9af7e9849dcdacdf",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/Real-Time-High-Resolution-Background-Matting-Lin-Ryabtsev/1f476738e6d2950ab2ca08ac852764640c8e9d93",
            "/paper/Nucleus-segmentation-across-imaging-experiments%3A-Caicedo-Goodman/0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf"
        ]
    },
    {
        "id": "0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
        "title": "A general deep learning framework for neuron instance segmentation based on Efficient UNet and morphological post-processing",
        "abstract": "Semantic Scholar extracted view of \"A general deep learning framework for neuron instance segmentation based on Efficient UNet and morphological post-processing\" by Huaqian Wu et al.",
        "publication_year": "2022",
        "authors": [
            "Huaqian Wu",
            "N. Souedet",
            "C. Jan",
            "C. Clouchoux",
            "T. Delzescaux"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "55",
        "references": [
            "/paper/Adversarial-Stain-Transfer-to-Study-the-Effect-of-Wu-Souedet/3379d2fb4f23b19cfcf0d6ed4b246b7f724a7122",
            "/paper/STCD-EffV2T-Unet%3A-Semi-Transfer-Learning-T-Unet-for-Gomroki-Hasanlou/2b473717c8923ac78693006ff22e3508a98f639e",
            "/paper/Evaluation-of-Deep-Learning-Topcoders-Method-for-in-Wu-Souedet/056806e5ba9f2b39cbe86b529c325998c3bdd016",
            "/paper/Nucleus-segmentation-across-imaging-experiments%3A-Caicedo-Goodman/0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Automated-Individualization-of-Size-Varying-and-in-You-Balbastre/c9adc95b6d67621c72b5a8b68d144ac7851b0b4d",
            "/paper/EfficientNet%3A-Rethinking-Model-Scaling-for-Neural-Tan-Le/4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9",
            "/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "/paper/IEEE-Transactions-on-Pattern-Analysis-and-Machine-Kim-Scott/9e7e1d962ab25ae00e6fb5713116967e9b64be50",
            "/paper/Deep-High-Resolution-Representation-Learning-for-Wang-Sun/441555b5cd09703e55c03e70bd2c9f82c0ffcf9b",
            "/paper/RIC-Unet%3A-An-Improved-Neural-Network-Based-on-Unet-Zeng-Xie/4a91c15880a788711c0a7e00ba3968580e3052a5"
        ]
    },
    {
        "id": "b6d233e5a2c14e958c19cf1fc5d0a87531889f8f",
        "title": "Neuroplastic graph attention networks for nuclei segmentation in histopathology images",
        "abstract": "This work proposes a novel architecture for semantic segmentation of cell nuclei robust to differences in experimental configuration such as staining and variation of cell types based on a novel neuroplastic graph attention network based on residual graph attention layers and concurrent optimization of the graph structure representing multiple magnification levels of the histopathological image. Modern histopathological image analysis relies on the segmentation of cell structures to derive quantitative metrics required in biomedical research and clinical diagnostics. State-of-the-art deep learning approaches predominantly apply convolutional layers in segmentation and are typically highly customized for a specific experimental configuration; often unable to generalize to unknown data. As the model capacity of classical convolutional layers is limited by a finite set of learned kernels, our approach uses a graph representation of the image and focuses on the node transitions in multiple magnifications. We propose a novel architecture for semantic segmentation of cell nuclei robust to differences in experimental configuration such as staining and variation of cell types. The architecture is comprised of a novel neuroplastic graph attention network based on residual graph attention layers and concurrent optimization of the graph structure representing multiple magnification levels of the histopathological image. The modification of graph structure, which generates the node features by projection, is as important to the architecture as the graph neural network itself. It determines the possible message flow and critical properties to optimize attention, graph structure, and node updates in a balanced magnification loss. In experimental evaluation, our framework outperforms ensembles of state-of-the-art neural networks, with a fraction of the neurons typically required, and sets new standards for the segmentation of new nuclei datasets. \u00a9 2022 Elsevier B. V. All rights reserved.",
        "publication_year": "2022",
        "authors": [
            "Yoav Alon",
            "Huiyu Zhou"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "98",
        "references": [
            "/paper/Multi-Scale-Relational-Graph-Convolutional-Network-Bazargani-Fazli/a3e36619f167b9ae2f1b9162a5a270966b86c5cd",
            "/paper/Deep-Adversarial-Training-for-Multi-Organ-Nuclei-in-Mahmood-Borders/7ae5b1b4b488473314d40711e4d2b0e8d7e210ed",
            "/paper/Deep-Recurrent-Attention-Models-for-Image-Analysis-Momeni-Thibault/5104b466cbccba132fbad0a0f9660b9464d62ea0",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/XY-Network-for-Nuclear-Segmentation-in-Multi-Tissue-Graham-Vu/9e125fff5eb38d3ea120d6cc57aa41bc1ce586e5",
            "/paper/Deep-neural-network-models-for-computational-A-Srinidhi-Ciga/7f91d6acef932c471ca40a81cc8ec22d0482e459",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/A-resolution-adaptive-deep-hierarchical-(RADHicaL)-Janowczyk-Doyle/3ad945c6e59f10da30f7bd506c7c47ab42c869cd",
            "/paper/Unsupervised-Histopathology-Image-Synthesis-Hou-Agarwal/3d5f72d8f649d3014e53a2ca1f4145a15cd5953e",
            "/paper/Synthetic-Augmentation-and-Feature-based-Filtering-Xue-Zhou/a33a87a73287e4e940d1d0733fb98d13fafd68c4",
            "/paper/Region-segmentation-in-histopathological-breast-Su-Liu/31cf1c5198a37a8bee0e9a497744a110dcdb72f1"
        ]
    },
    {
        "id": "9a2ce0b25d3a0f82eae38a0d1e8064d710aa11d0",
        "title": "X-Net: a dual encoding\u2013decoding method in medical image segmentation",
        "abstract": "The characteristics of CNNs and Transformer are integrated to propose a dual encoding\u2013decoding structure of the X-shaped network (X-Net), which can serve as a good alternative to the traditional pure convolutional medical image segmentation network. Medical image segmentation has the priori guiding significance for clinical diagnosis and treatment. In the past ten years, a large number of experimental facts have proved the great success of deep convolutional neural networks in various medical image segmentation tasks. However, the convolutional networks seem to focus too much on the local image details, while ignoring the long-range dependence. The Transformer structure can encode long-range dependencies in image and learn high-dimensional image information through the self-attention mechanism. But this structure currently depends on the database scale to give full play to its excellent performance, which limits its application in medical images with limited database size. In this paper, the characteristics of CNNs and Transformer are integrated to propose a dual encoding\u2013decoding structure of the X-shaped network (X-Net). It can serve as a good alternative to the traditional pure convolutional medical image segmentation network. In the encoding phase, the local and global features are simultaneously extracted by two types of encoders, convolutional downsampling, and Transformer and then merged through jump connection. In the decoding phase, a variational auto-encoder branch is added to reconstruct the input image itself in order to weaken the impact of insufficient data. Comparative experiments on three medical image datasets show that X-Net can realize the organic combination of Transformer and CNNs.",
        "publication_year": "2021",
        "authors": [
            "Yuanyuan Li",
            "Ziyu Wang",
            "Li Yin",
            "Zhiqin Zhu",
            "Guanqiu Qi",
            "Yu Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "31",
        "reference_count": "39",
        "references": [
            "/paper/Medical-Image-Segmentation-Based-on-Transformer-and-Shen-Xu/03d66c8cb662f7b93f50570b2664ed894502cfe4",
            "/paper/iU-Net%3A-a-hybrid-structured-network-with-a-novel-Jiang-Dong/bca61b46a57a93fa9d8bd9a81f2ab31ff139270c",
            "/paper/Medical-image-segmentation-model-based-on-triple-Yan-Wang/9d33b323a549d67b22c88d74411ce9f24be0fad1",
            "/paper/A-medical-image-segmentation-method-based-on-Xu-He/44005894791836969cc5408d5ebb37f31dac3fc7",
            "/paper/Dual-feature-Fusion-Attention-Network-for-Small-Fei-Li/20ae765c8e49d12088a2434e84d8827f7b6e38e4",
            "/paper/Transforming-medical-imaging-with-Transformers-A-of-Li-Chen/1cb5a1fce0b65b616e69cc5ffd4e43e03d259e97",
            "/paper/SF-Net%3A-A-Multi-Task-Model-for-Brain-Tumor-in-MRI-Liu-Mu/865d5745ac3f1c54fdbb38f24f5841cf5a9cedac",
            "/paper/Dual-attention-network-for-unsupervised-medical-on-Li-Tang/68269c90117a261f741f60bacbfc40c2c9b143ad",
            "/paper/FSA-Net%3A-Rethinking-the-attention-mechanisms-in-Zhan-Song/56ac99469b08321d60e3f3d8ed904cf20a27d3bd",
            "/paper/Multi-modal-data-Alzheimer's-disease-detection-on-Kong-Zhang/c38d90a41c70ac73139da412f3e681c9206ad57e",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/CPFNet%3A-Context-Pyramid-Fusion-Network-for-Medical-Feng-Zhao/937253956dc6ab942764c13ab1a132238740d5b3",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Brain-tumor-segmentation-with-Deep-Neural-Networks-Havaei-Davy/441ff323c92331e655ce9ff896773fc00b55089a",
            "/paper/RA-UNet%3A-A-Hybrid-Deep-Attention-Aware-Network-to-Jin-Meng/5090fbfc9cf5db61ed060e5afdf01d2c08a8fcce",
            "/paper/H-DenseUNet%3A-Hybrid-Densely-Connected-UNet-for-and-Li-Chen/a86d7289c76d832e83c99539859b7b186e4ea6c8",
            "/paper/Kvasir-SEG%3A-A-Segmented-Polyp-Dataset-Jha-Smedsrud/349461d60b4d3d34dc97147e4b9ec2b9bd611be8",
            "/paper/Automatic-Multi-Organ-Segmentation-on-Abdominal-CT-Gibson-Giganti/e77d17d21941ed10adf14800d4a28bbd0f7c6eca",
            "/paper/Nuclei-segmentation-in-histopathology-images-using-Naylor-La%C3%A9/78db21fabea962592ac0aef54624251550929109"
        ]
    },
    {
        "id": "81c35b12898c7f46115547b70f628f966ed73c50",
        "title": "FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation",
        "abstract": "This work proposes a novel architecture called feedback attention network (FANet) that unifies the previous epoch mask with the feature map of the current training epoch that provides hard attention to the learned feature maps at different convolutional layers. The increase of available large clinical and experimental datasets has contributed to a substantial amount of important contributions in the area of biomedical image analysis. Image segmentation, which is crucial for any quantitative analysis, has especially attracted attention. Recent hardware advancement has led to the success of deep learning approaches. However, although deep learning models are being trained on large datasets, existing methods do not use the information from different learning epochs effectively. In this work, we leverage the information of each training epoch to prune the prediction maps of the subsequent epochs. We propose a novel architecture called feedback attention network (FANet) that unifies the previous epoch mask with the feature map of the current training epoch. The previous epoch mask is then used to provide hard attention to the learned feature maps at different convolutional layers. The network also allows rectifying the predictions in an iterative fashion during the test time. We show that our proposed feedback attention model provides a substantial improvement on most segmentation metrics tested on seven publicly available biomedical imaging datasets demonstrating the effectiveness of FANet. The source code is available at https://github.com/nikhilroxtomar/FANet.",
        "publication_year": "2021",
        "authors": [
            "Nikhil Kumar Tomar",
            "Debesh Jha",
            "M. Riegler",
            "Haavard D. Johansen",
            "Dag Johansen",
            "J. Rittscher",
            "P. Halvorsen",
            "Sharib Ali"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "44",
        "reference_count": "64",
        "references": [
            "/paper/RCGA-Net%3A-An-Improved-Multi-hybrid-Attention-in-Xiao-Shen/19b0b1c8629904a81121e0311aed2a401ebc3aae",
            "/paper/DCSAU-Net%3A-A-Deeper-and-More-Compact-U-Net-for-Xu-Duan/2b7aecc0c942ffe2abcea5bb8742d01314a69fa1",
            "/paper/CASF-Net%3A-Cross-attention-and-cross-scale-fusion-Zheng-Liu/7c274eb51477d8aedb253a1be88fc10ff8005de4",
            "/paper/iU-Net%3A-a-hybrid-structured-network-with-a-novel-Jiang-Dong/bca61b46a57a93fa9d8bd9a81f2ab31ff139270c",
            "/paper/AlexSegNet%3A-an-accurate-nuclei-segmentation-deep-in-Singha-Bhowmik/b556d04e6f62abb904bb47799f1ceb113fbfd940",
            "/paper/TransAttUnet%3A-Multi-level-Attention-guided-U-Net-Chen-Liu/69b985ae4a8331107cdfa148335bf08d15787bda",
            "/paper/MTPA_Unet%3A-Multi-Scale-Transformer-Position-Retinal-Jiang-Liang/237c7533357933c5d8f1ee087000dc66420a0134",
            "/paper/EG-TransUNet%3A-a-transformer-based-U-Net-with-and-Pan-Liu/4a6bf17538ded4eae48629728ee17adebb688094",
            "/paper/FSA-Net%3A-Rethinking-the-attention-mechanisms-in-Zhan-Song/56ac99469b08321d60e3f3d8ed904cf20a27d3bd",
            "/paper/A-Two-stage-Refinement-Network-for-Nuclei-in-Images-Jian-Kamata/fbf097f626a02b2c49947e003f80915aab08147a",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Attention-Gated-Networks%3A-Learning-to-Leverage-in-Schlemper-Oktay/2a2bdf5cf0d73bc333423a8fd246593f4bf65322",
            "/paper/MultiResUNet-%3A-Rethinking-the-U-Net-Architecture-Ibtehaz-Rahman/5bc8d8e541045d5c5a2b4c329e5fea5b5e3bc10d",
            "/paper/SA-UNet%3A-Spatial-Attention-U-Net-for-Retinal-Vessel-Guo-Szemenyei/557180b3ec281593cf4d7088c735316ab3405a8b",
            "/paper/Attention-U-Net%3A-Learning-Where-to-Look-for-the-Oktay-Schlemper/ae1c89817a3a239e5344293138bdd80293983460",
            "/paper/Recurrent-Residual-Convolutional-Neural-Network-on-Alom-Hasan/27c761258329eddb90b64d52679ff190cb4527b5",
            "/paper/UNet%2B%2B%3A-Redesigning-Skip-Connections-to-Exploit-in-Zhou-Siddiquee/42b0a8f757e45462e627e57f9af7e9849dcdacdf",
            "/paper/An-overview-of-deep-learning-in-medical-imaging-on-Lundervold-Lundervold/0ebc300c16f01a4e94c8551997922fdb67ac1951",
            "/paper/DoubleU-Net%3A-A-Deep-Convolutional-Neural-Network-Jha-Riegler/61af9ff6ec3dbb5299455746a1c63588ccf62cf8",
            "/paper/Boundary-aware-Context-Neural-Network-for-Medical-Wang-Chen/6af3f80dfc19651187ef568880ba61a542f54010"
        ]
    },
    {
        "id": "02a3042552b70feb47f3dca08806f8ce82f35b84",
        "title": "CPP-Net: Context-Aware Polygon Proposal Network for Nucleus Segmentation",
        "abstract": "A Context-aware Polygon Proposal Network (CPP-Net) for nucleus segmentation that substantially enhances contextual information and thereby improves the robustness of the prediction and is found to achieve state-of-the-art performance on three publicly available databases. Nucleus segmentation is a challenging task due to the crowded distribution and blurry boundaries of nuclei. Recent approaches represent nuclei by means of polygons to differentiate between touching and overlapping nuclei and have accordingly achieved promising performance. Each polygon is represented by a set of centroid-to-boundary distances, which are in turn predicted by features of the centroid pixel for a single nucleus. However, using the centroid pixel alone does not provide sufficient contextual information for robust prediction and thus degrades the segmentation accuracy. To handle this problem, we propose a Context-aware Polygon Proposal Network (CPP-Net) for nucleus segmentation. First, we sample a point set rather than one single pixel within each cell for distance prediction. This strategy substantially enhances contextual information and thereby improves the robustness of the prediction. Second, we propose a Confidence-based Weighting Module, which adaptively fuses the predictions from the sampled point set. Third, we introduce a novel Shape-Aware Perceptual (SAP) loss that constrains the shape of the predicted polygons. Here, the SAP loss is based on an additional network that is pre-trained by means of mapping the centroid probability map and the pixel-to-boundary distance maps to a different nucleus representation. Extensive experiments justify the effectiveness of each component in the proposed CPP-Net. Finally, CPP-Net is found to achieve state-of-the-art performance on three publicly available databases, namely DSB2018, BBBC06, and PanNuke. Code of this paper is available at https://github.com/csccsccsccsc/cpp-net.",
        "publication_year": "2021",
        "authors": [
            "Shengcong Chen",
            "Changxing Ding",
            "Minfeng Liu",
            "Jun Cheng",
            "D. Tao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "61",
        "references": [
            "/paper/PointNu-Net%3A-Keypoint-assisted-Convolutional-Neural-Yao-Huang/35996e1b1f34985ab10cdb07163f00c50a23d8d4",
            "/paper/Nuclei-probability-and-centroid-map-network-for-in-Rashid-Fraz/5adf5d8b6d9a6f327257a8b1c5bf47bc47e596e0",
            "/paper/Structure-Embedded-Nucleus-Classification-for-Lou-Wan/5dba785e24772910be9817992033851c89b57603",
            "/paper/ConvNeXt-backbone-HoVerNet-for-nuclei-segmentation-Li-Wang/a75bd45c1b623de4793dc9d82aa7831f17219dbb",
            "/paper/Cell-Detection-in-Whole-Slide-Images-With-Sokolovas/f34611a051a9160b8e38f12a7272249a7072d089",
            "/paper/Nucleus-segmentation-across-imaging-experiments%3A-Caicedo-Goodman/0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf",
            "/paper/PanNuke%3A-An-Open-Pan-Cancer-Histology-Dataset-for-Gamper-Koohbanani/b218b13756f3aacadf5f06d09652058d024dc9d4",
            "/paper/Boundary-assisted-Region-Proposal-Networks-for-Chen-Ding/bbffe75a1b5c5bc02f3a13bbc4f6700b17686102",
            "/paper/PatchPerPix-for-Instance-Segmentation-Hirsch-Mais/220530cc1db8c822d56bddb749bb525143d1e640",
            "/paper/Hover-Net%3A-Simultaneous-segmentation-and-of-nuclei-Graham-Vu/5986547c7380f5a8fb6028093f827b3662f838a2",
            "/paper/Mask-R-CNN-He-Gkioxari/1a0912bb76777469295bb2c059faee907e7f3258",
            "/paper/ImageNet%3A-A-large-scale-hierarchical-image-database-Deng-Dong/d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "/paper/Panoptic-Feature-Fusion-Net%3A-A-Novel-Instance-for-Liu-Zhang/b57c925acd708fd7e27facd3e8d11053ea7cca30",
            "/paper/Multi-scale-Cell-Instance-Segmentation-with-Graph-Yi-Wu/ab0e039f03059e5d143b90b83324712827d16fad",
            "/paper/CIA-Net%3A-Robust-Nuclei-Instance-Segmentation-with-Zhou-Onder/5fd490e5ceed129a83d16dbda29ab61fe4aa1acb"
        ]
    },
    {
        "id": "0a78085721f70d82c1284c124c3137bb7c2b34e7",
        "title": "nucleAIzer: A Parameter-free Deep Learning Framework for Nucleus Segmentation Using Image Style Transfer",
        "abstract": "Semantic Scholar extracted view of \"nucleAIzer: A Parameter-free Deep Learning Framework for Nucleus Segmentation Using Image Style Transfer\" by R. Hollandi et al.",
        "publication_year": "2020",
        "authors": [
            "R. Hollandi",
            "\u00c1bel Szkalisity",
            "Timea Toth",
            "Ervin Tasn\u00e1di",
            "Csaba Molnar",
            "Botond Mathe",
            "Istvan Grexa",
            "J\u00f3zsef Moln\u00e1r",
            "\u00c1. B\u00e1lind",
            "Mate Gorbe",
            "M\u00e1ria Kov\u00e1cs",
            "E. Migh",
            "A. Goodman",
            "Tam\u00e1s Balassa",
            "K. Koos",
            "Wenyu Wang",
            "Juan C. Caicedo",
            "Norbert Bara",
            "F. Kov\u00e1cs",
            "L. Paavolainen",
            "Tivadar Danka",
            "A. Kriston",
            "Anne E Carpenter",
            "Kevin Smith",
            "P. Horv\u00e1th"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "104",
        "reference_count": "24",
        "references": [
            "/paper/ASW-Net%3A-A-Deep-Learning-based-Tool-for-Cell-of-Pan-Liu/c7c1b005a042e52be8523ddf0d26941a242d5402",
            "/paper/Multi-Modality-Microscopy-Image-Style-Transfer-for-Liu-Wagner/3a8150de52d52c3d3ac36a7db695b00949409942",
            "/paper/Learning-with-minimal-effort%3A-leveraging-in-silico-Bonte-Philbert/81f0e648e4776dcbe933bda553f6ac4e5b31876e",
            "/paper/A-Deep-Learning-Model-for-Automated-Segmentation-of-Ayd%C4%B1n-Kiraz/9fc2e80923c10f1619e51be64cf44516f55cd131",
            "/paper/Multi-Modality-Microscopy-Image-Style-Augmentation-Liu-Wagner/191d3915ce8f8edb9d38a5486798f84c9c7488a8",
            "/paper/Segmentor%3A-a-tool-for-manual-refinement-of-3D-Borland-McCormick/86e92a4b836db293a7a63d81e2a400846088648a",
            "/paper/Automatic-improvement-of-deep-learning-based-cell-Zhu-Meijering/2b40eabd11fe435dfa56bb0f8a6434b0dcccb5bf",
            "/paper/AnnotatorJ%3A-an-ImageJ-plugin-to-ease-hand-of-Hollandi-Diosdi/3ad4b29906c8987bac46ea0ea9586b58a38fa8f4",
            "/paper/An-Integrative-Segmentation-Framework-for-Cell-of-Pan-Liu/e33f7928a45e395f1bc2a1aa1dd9349bc725ba24",
            "/paper/CellSeg%3A-a-robust%2C-pre-trained-nucleus-segmentation-Lee-Bedia/bd316183cad100b12d717d25f2e55676eaa8f701",
            "/paper/Evaluation-of-Deep-Learning-Strategies-for-Nucleus-Caicedo-Roth/c89bfd998b0a6c656010b629814ab0cad3cff72e",
            "/paper/Deep-Learning-Automates-the-Quantitative-Analysis-Valen-Kudo/e1b3ad532f9346d51578c32dc6b070c9744a8d88",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/U-Net%3A-deep-learning-for-cell-counting%2C-detection%2C-Falk-Mai/779b489971775507fe6a39d98c52c4df56d9cce1",
            "/paper/Ilastik%3A-Interactive-learning-and-segmentation-Sommer-Straehle/5c5be36e3111e42247d78a6d529e4b1d7d2ced12",
            "/paper/Deep-learning-for-cellular-image-analysis-Moen-Bannon/48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852",
            "/paper/Segmentation-of-touching-cell-nuclei-using-gradient-Li-Liu/268241fd604918a86e1b27e1a880d47e0ecc2d5b",
            "/paper/Accurate-Morphology-Preserving-Segmentation-of-on-Molnar-Jermyn/318f82a3e593e391cfd0da7964b16d83299aa943",
            "/paper/Clinically-applicable-deep-learning-for-diagnosis-Fauw-Ledsam/b2d952fbd6951cbed68ea13003a045300970731a",
            "/paper/Computational-Framework-for-Simulating-Fluorescence-Lehmussola-Ruusuvuori/06791ac9c0d9fe98ddd7da2117ca8ef1809480e3"
        ]
    },
    {
        "id": "4a6bf17538ded4eae48629728ee17adebb688094",
        "title": "EG-TransUNet: a transformer-based U-Net with enhanced and guided models for biomedical image segmentation",
        "abstract": "This paper used the attention-based Transformer during the encoder and decoder stages to improve feature discrimination at the level of spatial detail and semantic location by its multihead-based self-attention to propose an architecture called EG-TransUNet, including three modules improved by a transformer. Although various methods based on convolutional neural networks have improved the performance of biomedical image segmentation to meet the precision requirements of medical imaging segmentation task, medical image segmentation methods based on deep learning still need to solve the following problems: (1) Difficulty in extracting the discriminative feature of the lesion region in medical images during the encoding process due to variable sizes and shapes; (2) difficulty in fusing spatial and semantic information of the lesion region effectively during the decoding process due to redundant information and the semantic gap. In this paper, we used the attention-based Transformer during the encoder and decoder stages to improve feature discrimination at the level of spatial detail and semantic location by its multihead-based self-attention. In conclusion, we propose an architecture called EG-TransUNet, including three modules improved by a transformer: progressive enhancement module, channel spatial attention, and semantic guidance attention. The proposed EG-TransUNet architecture allowed us to capture object variabilities with improved results on different biomedical datasets. EG-TransUNet outperformed other methods on two popular colonoscopy datasets (Kvasir-SEG and CVC-ClinicDB) by achieving 93.44% and 95.26% on mDice. Extensive experiments and visualization results demonstrate that our method advances the performance on five medical segmentation datasets with better generalization ability.",
        "publication_year": "2023",
        "authors": [
            "S. Pan",
            "Xin Liu",
            "Ningdi Xie",
            "Yanwen Chong"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "47",
        "references": [
            "/paper/Accurate-segmentation-algorithm-of-acoustic-neuroma-Zhang-Zhang/2fc4c2b52f2b9becb63915af6b8f1cddda63331e",
            "/paper/TransU-Net%2B%2B%3A-Rethinking-attention-gated-TransU-Net-Jamali-Roy/9a7a17ef18f70d121bdb25d8a8aa90bb2727aa8a",
            "/paper/Recent-advances-of-Transformers-in-medical-image-A-Xia-Wang/2bf7a8f4731bcd1d10bd506234c96aaad0345c2d",
            "/paper/TransAttUnet%3A-Multi-level-Attention-guided-U-Net-Chen-Liu/69b985ae4a8331107cdfa148335bf08d15787bda",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/DS-TransUNet%3A-Dual-Swin-Transformer-U-Net-for-Image-Lin-Chen/6feecbba7eacf002edeee797db2704d15ffbda1b",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/MA-Unet%3A-An-improved-version-of-Unet-based-on-and-Cai-Wang/1f94d3883f0f4ad29546faa5ad185321d7be4d21",
            "/paper/TransFuse%3A-Fusing-Transformers-and-CNNs-for-Medical-Zhang-Liu/20db2a2fadcf563a2d522aabc440b6b4f3ee46f4",
            "/paper/DoubleU-Net%3A-A-Deep-Convolutional-Neural-Network-Jha-Riegler/61af9ff6ec3dbb5299455746a1c63588ccf62cf8",
            "/paper/Channel-Unet%3A-A-Spatial-Channel-Wise-Convolutional-Chen-Wang/0a041d4ca50fb6c5a01b809313488b92031f6730",
            "/paper/MSRF-Net%3A-A-Multi-Scale-Residual-Fusion-Network-for-Srivastava-Jha/75808111f4b554d3d99563c8f2b22359bc011c45",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5"
        ]
    },
    {
        "id": "056806e5ba9f2b39cbe86b529c325998c3bdd016",
        "title": "Evaluation of Deep Learning Topcoders Method for Neuron Individualization in Histological Macaque Brain Section*",
        "abstract": "A pipeline to synthesize pixel-level labels with only point annotations provided is established and an ensemble Deep Learning algorithm is tested to perform cell individualization on neurological data. Cell individualization has a vital role in digital pathology image analysis. Deep Learning is considered as an efficient tool for instance segmentation tasks, including cell individualization. However, the precision of the Deep Learning model relies on massive unbiased dataset and manual pixel-level annotations, which is labor intensive. Moreover, most applications of Deep Learning have been developed for processing oncological data. To overcome these challenges, i) we established a pipeline to synthesize pixel-level labels with only point annotations provided; ii) we tested an ensemble Deep Learning algorithm to perform cell individualization on neurological data. Results suggest that the proposed method successfully segments neuronal cells in both object-level and pixel-level, with an average detection accuracy of 0.93.",
        "publication_year": "2021",
        "authors": [
            "Huaqian Wu",
            "N. Souedet",
            "Z. You",
            "C. Jan",
            "C. Clouchoux",
            "T. Delzescaux"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "15",
        "references": [
            "/paper/A-general-deep-learning-framework-for-neuron-based-Wu-Souedet/0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
            "/paper/End-to-end-Neuron-Instance-Segmentation-based-on-Wu-Souedet/c49a547b3424f42cc290f29c4f648514efc37229",
            "/paper/Quantitative-Evaluation-of-Inflammatory-Markers-in-Henin-Fiorin/fdb10b8cd4125bdd1b4ed889a155c04a7c86e82f",
            "/paper/Nucleus-segmentation-across-imaging-experiments%3A-Caicedo-Goodman/0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf",
            "/paper/Automated-Individualization-of-Size-Varying-and-in-You-Balbastre/c9adc95b6d67621c72b5a8b68d144ac7851b0b4d",
            "/paper/EfficientNet%3A-Rethinking-Model-Scaling-for-Neural-Tan-Le/4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/U-Net%3A-deep-learning-for-cell-counting%2C-detection%2C-Falk-Mai/779b489971775507fe6a39d98c52c4df56d9cce1",
            "/paper/A-deep-learning-algorithm-for-one-step-contour-of-Cui-Zhang/505e72b8d60e987e89b93fdd98859b857ca94207",
            "/paper/Dual-Path-Networks-Chen-Li/d7ddad7bbda29de7676c21bfeac6be2ce0a07d6f",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Densely-Connected-Convolutional-Networks-Huang-Liu/5694e46284460a648fe29117cbc55f6c9be3fa3c",
            "/paper/Inception-v4%2C-Inception-ResNet-and-the-Impact-of-on-Szegedy-Ioffe/b5c26ab8767d046cb6e32d959fdf726aee89bb62"
        ]
    },
    {
        "id": "0e8446c00ed21c19f62d71ab208a7b3601671766",
        "title": "A Unified Model for Multi-class Anomaly Detection",
        "abstract": "UniAD is presented, that accomplishes anomaly detection for multiple classes with a unified framework and makes three improvements, including a layer-wise query decoder to help model the multi-class distribution and a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a unified framework. Under such a challenging setting, popular reconstruction networks may fall into an\"identical shortcut\", where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and confirm the important role of query embedding (i.e., within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10 datasets, where we surpass the state-of-the-art alternatives by a sufficiently large margin. For example, when learning a unified model for 15 categories in MVTec-AD, we surpass the second competitor on the tasks of both anomaly detection (from 88.1% to 96.5%) and anomaly localization (from 89.5% to 96.8%). Code is available at https://github.com/zhiyuanyou/UniAD.",
        "publication_year": "2022",
        "authors": [
            "Zhiyuan You",
            "Lei Cui",
            "Yujun Shen",
            "Kai Yang",
            "Xin Lu",
            "Yu Zheng",
            "Xinyi Le"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "10",
        "reference_count": "55",
        "references": [
            "/paper/AnoRand%3A-A-Semi-Supervised-Deep-Learning-Anomaly-by-Mayaki-Riveill/2c91de722d5cbb7048c2e80a3c7676a3c576f762",
            "/paper/Factorized-Industrial-Anomaly-Detection-and-Zhu-Dai/361493f638981e3aec1f55966a066f0138f01bc8",
            "/paper/AnoOnly%3A-Semi-Supervised-Anomaly-Detection-without-Zhou-Yang/4141b5740f8ff7464f9bbcb152b0ac7cde5d7954",
            "/paper/Deep-Industrial-Image-Anomaly-Detection%3A-A-Survey-Liu-Xie/1312e46326f7e36fc82d16098b824540fe2dca66",
            "/paper/ReContrast%3A-Domain-Specific-Anomaly-Detection-via-Guo-Lu/829417264611445436f635020d942244911d8301",
            "/paper/Deep-Visual-Anomaly-Detection-in-Industrial-A-Liu-Xie/c39aac50bc5dbaf1ea14eef48043156b51884238",
            "/paper/Industrial-Anomaly-Detection-with-Domain-Shift%3A-A-Zhang-Zhao/dbab222bcaa0717048feb2967e184ee267226ef5",
            "/paper/Towards-Total-Online-Unsupervised-Anomaly-Detection-Gao-Luo/861d11c147a8ad472c733ede13e8ef1275994a0d",
            "/paper/MIAD%3A-A-Maintenance-Inspection-Dataset-for-Anomaly-Bao-Chen/21ef67614bb9733adf46f378c4bc7e816a1a829c",
            "/paper/FractalAD%3A-A-simple-industrial-anomaly-segmentation-Xia-Lv/188a76b513b61a496f50f3e7bcd2540dde66d65e",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/PANDA%3A-Adapting-Pretrained-Features-for-Anomaly-and-Reiss-Cohen/78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Glancing-at-the-Patch%3A-Anomaly-Localization-with-Wang-Wu/4758baad6b22c61682e7f7182bb93723046f36f5",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Learning-Semantic-Context-from-Normal-Samples-for-Yan-Zhang/8ee35ed698527d9695c872e3b76715fec4ef69ad",
            "/paper/Divide-and-Assemble%3A-Learning-Block-wise-Memory-for-Hou-Zhang/93040f8a5d10e8fde279e18d353aa3dca2873900"
        ]
    },
    {
        "id": "3b3aefbbdb64e5812f133f220b3f129a36a30065",
        "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
        "abstract": "A novel T-S model consisting of a teacher encoder and a student decoder is proposed and a simple yet effective \u201creverse distillation\u201d paradigm is introduced, demonstrating the proposed approach's effectiveness and generalizability. Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.",
        "publication_year": "2022",
        "authors": [
            "Hanqiu Deng",
            "Xingyu Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "62",
        "reference_count": "50",
        "references": [
            "/paper/An-Improved-Reverse-Distillation-Model-for-Anomaly-Nguyen-Bach/205a1c89058ea55fe536c6484a62213d1d0f0160",
            "/paper/Asymmetric-Distillation-Post-Segmentation-Method-Xing-Li/61840de4d9610558d510cfcf32986e93511a4cef",
            "/paper/SLSG%3A-Industrial-Image-Anomaly-Detection-by-Better-Yang-Liu/5c04ce7f8510af40f2931535feeaf220832ab548",
            "/paper/Pull-%26-Push%3A-Leveraging-Differential-Knowledge-for-Zhou-He/2013f18832e0fb11c7aaf1f4f8da453aebda488c",
            "/paper/DeSTSeg%3A-Segmentation-Guided-Denoising-for-Anomaly-Zhang-Li/d17df33c9b6453d61d01353e94592f1757caee8a",
            "/paper/Lightning-Fast-Video-Anomaly-Detection-via-Ristea-Croitoru/a2098146f85a41e38d3d33c86ba9060dd2ce26a1",
            "/paper/Anomaly-Detection-via-Multi-Scale-Contrasted-Memory-Jezequel-Vu/bb0c598b0306bcc862e83a997fd42131d0c292bf",
            "/paper/MixedTeacher%3A-Knowledge-Distillation-for-Fast-Thomine-Snoussi/2c820847a5fa8ca285066bc48920ca95c1e2168e",
            "/paper/Visual-Anomaly-Detection-via-Dual-Attention-and-Yao-Luo/a865519bd5373cc5b73f672c1c787064c380aaaf",
            "/paper/A-Unified-Model-for-Multi-class-Anomaly-Detection-You-Cui/0e8446c00ed21c19f62d71ab208a7b3601671766",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/OCGAN%3A-One-Class-Novelty-Detection-Using-GANs-With-Perera-Nallapati/599fd051c9438011ec5b581983c89e8922b4a5e6",
            "/paper/G2D%3A-Generate-to-Detect-Anomaly-PourReza-Mohammadi/30895c61bb836f2cae7ef5ba6516886f746a7153",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Divide-and-Assemble%3A-Learning-Block-wise-Memory-for-Hou-Zhang/93040f8a5d10e8fde279e18d353aa3dca2873900",
            "/paper/Similarity-Preserving-Knowledge-Distillation-Tung-Mori/9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08",
            "/paper/PANDA%3A-Adapting-Pretrained-Features-for-Anomaly-and-Reiss-Cohen/78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ]
    },
    {
        "id": "2013f18832e0fb11c7aaf1f4f8da453aebda488c",
        "title": "Pull & Push: Leveraging Differential Knowledge Distillation for Efficient Unsupervised Anomaly Detection and Localization",
        "abstract": "This work designs an efficient teacher-student model for anomaly detection and localization, which maximizes pixel-wise discrepancies for anomalous regions approximated by data augmentation and simultaneously minimizes discrepancies for pixel- wise normal regions between these two networks. Recently, much attention has been paid to segmenting subtle unknown defect regions by knowledge distillation in an unsupervised setting. Most previous studies concentrated on guiding the student network to learn the same representations on the normality, neglecting the different behaviors of the abnormality. This leads to a high probability of false detection of subtle defects. To address such an issue, we propose to push representations on abnormal areas of the teacher and student network as far as possible while pulling representations on normal areas as close as possible. Based on this idea, we design an efficient teacher-student model for anomaly detection and localization, which maximizes pixel-wise discrepancies for anomalous regions approximated by data augmentation and simultaneously minimizes discrepancies for pixel-wise normal regions between these two networks. The explicit differential knowledge distillation enlarges the margin between normal representations and abnormal ones in favour of discriminating them. Then, the appropriate small student network is not only efficient, but more importantly, helps inhibit the generalization ability of anomalous patterns when learning normal patterns, facilitating the precise decision boundary. The experimental results on the MVTec AD, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our proposed method achieves better performance than current state-of-the-art (SOTA) approaches. Especially, For the MVTec AD dataset with high resolution images, we achieve 98.1 AUROC% and 93.6 AUPRO% in anomaly localization, outperforming knowledge distillation based SOTA methods by 1.1 AUROC% and 1.5 AUPRO% with a lightweight model.",
        "publication_year": "2023",
        "authors": [
            "Qihang Zhou",
            "Shibo He",
            "Haoyu Liu",
            "Tao Chen",
            "Jiming Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "64",
        "references": [
            "/paper/Teacher-Student-Network-for-3D-Point-Cloud-Anomaly-Qin-Gu/35dfd96486c38d9a21b1d29e2381d72cd7928b2f",
            "/paper/Learning-Global-Local-Correspondence-with-Semantic-Yao-Yu/58d59beb750e8c0e1d52b04dbc6c1c8b5ea3178a",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/PANDA%3A-Adapting-Pretrained-Features-for-Anomaly-and-Reiss-Cohen/78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "/paper/DFR%3A-Deep-Feature-Reconstruction-for-Unsupervised-Yang-Shi/cc63b87a654e28aefe60250e950572bfb3d7e2ea",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/Mean-Shifted-Contrastive-Loss-for-Anomaly-Detection-Reiss-Hoshen/7d90243c5a46430a36c5ba88627b5d254450a1e1",
            "/paper/Memorizing-Normality-to-Detect-Anomaly%3A-Deep-for-Gong-Liu/d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Towards-Total-Recall-in-Industrial-Anomaly-Roth-Pemula/23ad8fc48530ce366f8192dfb48d0f7df1dba277"
        ]
    },
    {
        "id": "61840de4d9610558d510cfcf32986e93511a4cef",
        "title": "Asymmetric Distillation Post-Segmentation Method for Image Anomaly Detection",
        "abstract": "A novel Asymmetric Distillation Post-Segmentation (ADPS) method is proposed to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network and achieves state-of-the-art anomaly segmentation results. Knowledge distillation-based anomaly detection methods generate same outputs for unknown classes due to the symmetric form of the input and ignore the powerful semantic information of the output of the teacher network since it is only used as a\"reference standard\". Towards this end, this work proposes a novel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network. Specifically, a simple yet effective asymmetric input approach is proposed to make different data flows through the teacher and student networks. The student network enables to have different inductive and expressive abilities, which can generate different outputs in anomalous regions. Besides, to further explore the semantic information of the teacher network and obtain effective discriminative boundaries, the Weight Mask Block (WMB) and the post-segmentation module are proposede. WMB leverages a weighted strategy by exploring teacher-student feature maps to highlight anomalous features. The post-segmentation module further learns the anomalous features and obtains valid discriminative boundaries. Experimental results on three benchmark datasets demonstrate that the proposed ADPS achieves state-of-the-art anomaly segmentation results.",
        "publication_year": "2022",
        "authors": [
            "Peng-Fei Xing",
            "Zechao Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "52",
        "references": [
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/Self-Supervised-Guided-Segmentation-Framework-for-Xing-Sun/2b32b46f346d9b13268f0e74e5242a10a712a352",
            "/paper/Learning-Unsupervised-Metaformer-for-Anomaly-Wu-Chen/8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "/paper/AnoSeg%3A-Anomaly-Segmentation-Network-Using-Learning-Song-Kong/d08775cf2bebcffa05c6fa506f687ef56953f128",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Reconstruction-Student-with-Attention-for-Pyramid-Yamada-Hotta/6517f92d519fc126cc18924231bafd8945a554d1",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f"
        ]
    },
    {
        "id": "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
        "title": "Explainable Deep Few-shot Anomaly Detection with Deviation Networks",
        "abstract": "This work introduces a novel weakly-supervised anomaly detection framework to train detection models without assuming the examples illustrating all possible classes of anomaly, and learns discriminative normality by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. Existing anomaly detection paradigms overwhelmingly focus on training detection models using exclusively normal data or unlabeled data (mostly normal samples). One notorious issue with these approaches is that they are weak in discriminating anomalies from normal samples due to the lack of the knowledge about the anomalies. Here, we study the problem of few-shot anomaly detection, in which we aim at using a few labeled anomaly examples to train sample-efficient discriminative detection models. To address this problem, we introduce a novel weakly-supervised anomaly detection framework to train detection models without assuming the examples illustrating all possible classes of anomaly. Specifically, the proposed approach learns discriminative normality (regularity) by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. This is achieved by an end-to-end optimization of anomaly scores with a neural deviation learning, in which the anomaly scores of normal samples are imposed to approximate scalar scores drawn from the prior while that of anomaly examples is enforced to have statistically significant deviations from these sampled scores in the upper tail. Furthermore, our model is optimized to learn fine-grained normality and abnormality by top-K multiple-instance-learning-based feature subspace deviation learning, allowing more generalized representations. Comprehensive experiments on nine real-world image anomaly detection benchmarks show that our model is substantially more sample-efficient and robust, and performs significantly better than state-of-the-art competing methods in both closed-set and open-set settings. Our model can also offer explanation capability as a result of its prior-driven anomaly score learning. Code and datasets are available at: https://git.io/DevNet.",
        "publication_year": "2021",
        "authors": [
            "Guansong Pang",
            "Choubo Ding",
            "Chunhua Shen",
            "A. Hengel"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "29",
        "reference_count": "72",
        "references": [
            "/paper/Deep-Weakly-supervised-Anomaly-Detection-Pang-Shen/30aa23a6a32312666f2609339582744203024993",
            "/paper/Few-shot-Anomaly-Detection-and-Classification-Data-Han-Xu/9f667d6cec1d607d729ac3a4b6ff9b673d634887",
            "/paper/Catching-Both-Gray-and-Black-Swans%3A-Open-set-Ding-Pang/6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "/paper/Explicit-Boundary-Guided-Semi-Push-Pull-Contrastive-Yao-Li/62d49fa60b54fed1e2a2cde3cb49d3639db76768",
            "/paper/Prototypical-Residual-Networks-for-Anomaly-and-Zhang-Wu/ac62ed8a9b77d613189b63004f4a5d4c5cc082fe",
            "/paper/Hierarchical-Semi-Supervised-Contrastive-Learning-Wang-Zhan/5e5ae3d3439151cd7a026aadb8da9eab16a7b7a7",
            "/paper/Explicit-Boundary-Guided-Semi-Push-Pull-Contrastive-Yao-Zhang/0795b7462b6d186d4ccd63d185a25f54d56aaf5f",
            "/paper/SaliencyCut%3A-Augmenting-Plausible-Anomalies-for-Ye-Hu/2e925205de0150d759518c767811dcbb89fca058",
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/Explanation-Method-for-Anomaly-Detection-on-Mixed-Botana-Eiras-Franco/c635a32124b0ae9f71e04af94df589c5d82dc41e",
            "/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "/paper/Toward-Deep-Supervised-Anomaly-Detection%3A-Learning-Pang-Hengel/8ed98bd58c799718d6fd389e2218bb89b1ecb9d7",
            "/paper/Deep-Anomaly-Detection-with-Deviation-Networks-Pang-Shen/f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Margin-Learning-Embedded-Prediction-for-Video-with-Liu-Luo/c48def9076e58095c4aea49a8daa931af1990701",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Toward-Supervised-Anomaly-Detection-G%C3%B6rnitz-Kloft/f5a951b9596be0df5ad7ede180b405c9e97a65c9",
            "/paper/A-Hierarchical-Transformation-Discriminating-Model-Sheynin-Benaim/182d11020bf2842f135f1ec1dcac20237e0dc8b7",
            "/paper/Adversarially-Learned-Anomaly-Detection-Zenati-Romain/5f61089d3d548a515f01b473f0119137d1f340d4",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d"
        ]
    },
    {
        "id": "ac62ed8a9b77d613189b63004f4a5d4c5cc082fe",
        "title": "Prototypical Residual Networks for Anomaly Detection and Localization",
        "abstract": "A framework called Prototypical Residual Network (PRN), which learns feature residuals of varying scales and sizes between anomalous and normal patterns to accurately reconstruct the segmentation maps of anomalous regions, is proposed. Anomaly detection and localization are widely used in industrial manufacturing for its efficiency and effectiveness. Anomalies are rare and hard to collect and supervised models easily over-fit to these seen anomalies with a handful of abnormal samples, producing unsatisfactory performance. On the other hand, anomalies are typically subtle, hard to discern, and of various appearance, making it difficult to detect anomalies and let alone locate anomalous regions. To address these issues, we propose a framework called Prototypical Residual Network (PRN), which learns feature residuals of varying scales and sizes between anomalous and normal patterns to accurately reconstruct the segmentation maps of anomalous regions. PRN mainly consists of two parts: multi-scale prototypes that explicitly represent the residual features of anomalies to normal patterns; a multisize self-attention mechanism that enables variable-sized anomalous feature learning. Besides, we present a variety of anomaly generation strategies that consider both seen and unseen appearance variance to enlarge and diversify anomalies. Extensive experiments on the challenging and widely used MVTec AD benchmark show that PRN outperforms current state-of-the-art unsupervised and supervised methods. We further report SOTA results on three additional datasets to demonstrate the effectiveness and generalizability of PRN.",
        "publication_year": "2022",
        "authors": [
            "H. Zhang",
            "Zuxuan Wu",
            "Z. Wang",
            "Zhineng Chen",
            "Yuwei Jiang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "69",
        "references": [
            "/paper/DiffusionAD%3A-Denoising-Diffusion-for-Anomaly-Zhang-Wang/55d49aa6bd3e6605c6510a147c1fb5bdd7af0b12",
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Focus-Your-Distribution%3A-Coarse-to-Fine-Learning-Zheng-Wang/e5349e937545d3f3d18d254bd21d695e7350ea8e",
            "/paper/Catching-Both-Gray-and-Black-Swans%3A-Open-set-Ding-Pang/6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Margin-Learning-Embedded-Prediction-for-Video-with-Liu-Luo/c48def9076e58095c4aea49a8daa931af1990701",
            "/paper/FastFlow%3A-Unsupervised-Anomaly-Detection-and-via-2D-Yu1-Zheng/11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "/paper/Natural-Synthetic-Anomalies-for-Self-supervised-and-Schl%C3%BCter-Tan/912a659ba09887c3abc99dc3ec5818bd1a36e1ec",
            "/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "/paper/Toward-Supervised-Anomaly-Detection-G%C3%B6rnitz-Kloft/f5a951b9596be0df5ad7ede180b405c9e97a65c9"
        ]
    },
    {
        "id": "f48d6b404932c23b701d01d7f7382384103b0bd6",
        "title": "Multiresolution Feature Guidance Based Transformer for Anomaly Detection",
        "abstract": "A multiresolution feature guidance method based on Transformer named GTrans for unsupervised anomaly detection and localization based on an Anomaly Guided Network pre-trained on ImageNet to provide surrogate labels for features and tokens. Anomaly detection is represented as an unsupervised learning to identify deviated images from normal images. In general, there are two main challenges of anomaly detection tasks, i.e., the class imbalance and the unexpectedness of anomalies. In this paper, we propose a multiresolution feature guidance method based on Transformer named GTrans for unsupervised anomaly detection and localization. In GTrans, an Anomaly Guided Network (AGN) pre-trained on ImageNet is developed to provide surrogate labels for features and tokens. Under the tacit knowledge guidance of the AGN, the anomaly detection network named Trans utilizes Transformer to effectively establish a relationship between features with multiresolution, enhancing the ability of the Trans in fitting the normal data manifold. Due to the strong generalization ability of AGN, GTrans locates anomalies by comparing the differences in spatial distance and direction of multi-scale features extracted from the AGN and the Trans. Our experiments demonstrate that the proposed GTrans achieves state-of-the-art performance in both detection and localization on the MVTec AD dataset. GTrans achieves image-level and pixel-level anomaly detection AUROC scores of 99.0% and 97.9% on the MVTec AD dataset, respectively.",
        "publication_year": "2023",
        "authors": [
            "Shuting Yan",
            "Pingping Chen",
            "Honghui Chen",
            "Huan-hao Mao",
            "F. Chen",
            "Zhi-Long Lin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "51",
        "references": [
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Inpainting-Transformer-for-Anomaly-Detection-Pirnay-Chai/19862af96b6af51e879e6e3f1d3d421af5427005",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/Sub-Image-Anomaly-Detection-with-Deep-Pyramid-Cohen-Hoshen/9277dc70c74bcadf80dab11c28ead83fd085deec",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70"
        ]
    },
    {
        "id": "4d0506d3e7f5dd23e1620cf8c48650bf1552bd3e",
        "title": "Image-based cell profiling enhancement via data cleaning methods",
        "abstract": "The experiments indicate that by performing these time-efficient preprocessing steps, image-based profiles can preserve more meaningful information compared to raw profiles, and suggest possible avenues for future research. With the advent of high-throughput assays, a large number of biological experiments can be carried out. Image-based assays are among the most accessible and inexpensive technologies for this purpose. Indeed, these assays have proved to be effective in characterizing unknown functions of genes and small molecules. Image analysis pipelines have a pivotal role in translating raw images that are captured in such assays into useful and compact representation, also known as measurements. CellProfiler is a popular and commonly used tool for this purpose through providing readily available modules for the cell/nuclei segmentation, and making various measurements, or features, for each cell/nuclei. Single cell features are then aggregated for each treatment replica to form treatment \u201cprofiles\u201d. However, there may be several sources of error in the CellProfiler quantification pipeline that affects the downstream analysis that is performed on the profiles. In this work, we examined various preprocessing approaches to improve the profiles. We consider the identification of drug mechanisms of action as the downstream task to evaluate such preprocessing approaches. Our enhancement steps mainly consist of data cleaning, cell level outlier detection, toxic drug detection, and regressing out the cell area from all other features, as many of them are widely affected by the cell area. Our experiments indicate that by performing these time-efficient preprocessing steps, image-based profiles can preserve more meaningful information compared to raw profiles. In the end, we also suggest possible avenues for future research.",
        "publication_year": "2022",
        "authors": [
            "Arghavan Rezvani",
            "Mahtab Bigverdi",
            "M. Rohban"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "2",
        "reference_count": "31",
        "references": [
            "/paper/Interpreting-Image%E2%80%90based-Profiles-using-Similarity-Garcia-Fossa-Cruz/46276273cf92c31e103feab0cdc2ad0adda0dcc9",
            "/paper/Analysis-and-modeling-of-cancer-drug-responses-cell-Gross-Mohammadi/881b3732b72fc42968e8ccda0c256f3f5d3a9540",
            "/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5",
            "/paper/Comparison-of-Methods-for-Image-Based-Profiling-of-Ljosa-Caie/929a490198770abcb8c123d68a59384879b69adb",
            "/paper/A-dataset-of-images-and-morphological-profiles-of-Bray-G%C3%BAstafsd%C3%B3ttir/05ba3c532b7b98c9448da0bee52d7cba0ef29621",
            "/paper/Multidimensional-Drug-Profiling-By-Automated-Perlman-Slack/8b73514fd708f6bdd3786d47a8673a97fdce4dfe",
            "/paper/Systematic-morphological-profiling-of-human-gene-Rohban-Singh/c6bf43a2bfffec64989baa2d193a6a845defa59e",
            "/paper/High-Throughput-Imaging-for-the-Discovery-of-of-Pegoraro-Misteli/f638edf9370a9a07681d80f7c6366e9783848a25",
            "/paper/An-approach-for-extensibly-profiling-the-molecular-Loo-Lin/796f794f3aa5366e8f525a0d2c814fa19c917db4",
            "/paper/Statistical-practice-in-high-throughput-screening-Malo-Hanley/8a2b9eac4e36e5f62a59f118c7bfc1ed9763b59c",
            "/paper/A-Beginner's-Guide-to-Analysis-of-RNA-Sequencing-Koch-Chiu/559c6ae809700119458006edb129ba966b147bda",
            "/paper/A-brain-tumor-segmentation-framework-based-on-Prastawa-Bullitt/64bda8b75fcb70e60efc6816888fa7a0368f2c96"
        ]
    },
    {
        "id": "f7ec3c2396844cb7f60649be7c059f206d8c3b46",
        "title": "Variance-stabilization-based compressive inversion under Poisson or Poisson\u2013Gaussian noise with analytical bounds",
        "abstract": "The authors' is the first piece of work to derive bounds on compressive inversion for the Poisson\u2013Gaussian noise model, and uses the properties of the variance stabilizer to develop a principle for selection of the regularization parameter in penalized estimators for Poisson and Poisson-Gaussian inverse problems. Most existing bounds for signal reconstruction from compressive measurements make the assumption of additive signal-independent noise. However in many compressive imaging systems, the noise statistics are more accurately represented by Poisson or Poisson\u2013Gaussian noise models. In this paper, we derive upper bounds for signal reconstruction error from compressive measurements which are corrupted by Poisson or Poisson\u2013Gaussian noise. The features of our bounds are as follows: (1) the bounds are derived for a computationally tractable convex estimator with statistically motivated parameter selection. The estimator penalizes signal sparsity subject to a constraint that imposes a novel statistically motivated upper bound on a term based on variance stabilization transforms to approximate the Poisson or Poisson\u2013Gaussian distributions by distributions with (nearly) constant variance. (2) The bounds are applicable to signals that are sparse as well as compressible in any orthonormal basis, and are derived for compressive systems obeying realistic constraints such as non-negativity and flux-preservation. Our bounds are motivated by several properties of the variance stabilization transforms that we develop and analyze. We present extensive numerical results for signal reconstruction under varying number of measurements and varying signal intensity levels. Ours is the first piece of work to derive bounds on compressive inversion for the Poisson\u2013Gaussian noise model. We also use the properties of the variance stabilizer to develop a principle for selection of the regularization parameter in penalized estimators for Poisson and Poisson\u2013Gaussian inverse problems.",
        "publication_year": "2019",
        "authors": [
            "Pakshal Bohra",
            "Deepak Garg",
            "Karthik S. Gurumoorthy",
            "Ajit V. Rajwade"
        ],
        "related_topics": [
            "Computer Science",
            "Mathematics"
        ],
        "citation_count": "6",
        "reference_count": "62",
        "references": [
            "/paper/Two-penalized-estimators-based-on-variance-for-with-Rajwade-Gurumoorthy/9e35901cbd1c258e99a2d119c666d8f1f0c62c88",
            "/paper/Reconstruction-Of-Sparse-Signals-Using-Likelihood-Banerjee-Srivastava/62085a0d75c7daeb2b8b9ee58428e3339bc4ce48",
            "/paper/Analyzing-cross-validation-in-compressed-sensing-Rajasekaran-Rajwade/e8e1b2d7917c22b01d0528d6d6159564cc284cfd",
            "/paper/Compressive-Phase-Retrieval-under-Poisson-Noise-Talegaonkar-Khirwadkar/da7523cd505a253a6d86131897696354ff65232e",
            "/paper/Performance-Bounds-for-LASSO-under-Multiplicative-Das-Ninan/b5a4218270924748ab6ea2f122ae446faf937b8b",
            "/paper/A-Compressed-Sensing-Approach-to-Group-testing-for-Ghosh-Agarwal/ef9125a2db9ee309baaaa86254528fc93c2f5fd1",
            "/paper/Using-an-Information-Theoretic-Metric-for-Recovery-Patil-Gurumoorthy/90d5988e60124db3e2221b90e2560d99790e7daf",
            "/paper/Performance-bounds-for-Poisson-compressed-sensing-Garg-Rajwade/c0ff008fe0ea97f117d200b702be481a073fbae8",
            "/paper/Minimax-Optimal-Sparse-Signal-Recovery-With-Poisson-Rohban-Saligrama/0e16a10560b4f7d5f891b932c79d1b2005407acf",
            "/paper/Reconstruction-Error-Bounds-for-Compressed-Sensing-Patil-Rajwade/f0737ce218f93f5252fe2c7978e33fead964dbc3",
            "/paper/Compressed-Sensing-Performance-Bounds-Under-Poisson-Raginsky-Willett/51ff6cfb98eec39da52035d87f329cf9e89462e6",
            "/paper/A-Convex-Approach-for-Image-Restoration-with-Exact-Chouzenoux-Jezierska/dca27a6f185258eca876c209ceaab0bf810f16c8",
            "/paper/Sparse-signal-recovery-with-exponential-family-Rish-Grabarnik/1ed22f981940b25d3ceac8846153b3521e8cae7b",
            "/paper/Minimax-Optimal-Rates-for-Poisson-Inverse-Problems-Jiang-Raskutti/b88f2df713c30c358076441e188d4339db993f65",
            "/paper/This-is-SPIRAL-TAP%3A-Sparse-Poisson-Intensity-and-Harmany-Marcia/18b04752a09119494d21c9d57c6097e9595be8c8",
            "/paper/Image-Denoising-in-Mixed-Poisson%E2%80%93Gaussian-Noise-Luisier-Blu/5136c28493c6cc15a61c4a6aa45b834494935b39"
        ]
    },
    {
        "id": "38ca689c2f916c648ea3ecb1043facbc4bea0d4f",
        "title": "Puzzle-AE: Novelty Detection in Images through Solving Puzzles",
        "abstract": "This work proposes adversarial robust training as an effective automatic shortcut removal and achieves competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Autoencoder, as an essential part of many anomaly detection methods, is lacking flexibility on normal data in complex datasets. U-Net is proved to be effective for this purpose but overfits on the training data if trained by just using reconstruction error similar to other AE-based frameworks. Puzzle-solving, as a pretext task of self-supervised learning (SSL) methods, has earlier proved its ability in learning semantically meaningful features. We show that training U-Nets based on this task is an effective remedy that prevents overfitting and facilitates learning beyond pixel-level features. Shortcut solutions, however, are a big challenge in SSL tasks, including jigsaw puzzles. We propose adversarial robust training as an effective automatic shortcut removal. We achieve competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Unlike many competitors, the proposed framework is stable, fast, data-efficient, and does not require unprincipled early stopping.",
        "publication_year": "2020",
        "authors": [
            "Mohammadreza Salehi",
            "Ainaz Eftekhar",
            "Niousha Sadjadi",
            "M. Rohban",
            "H. Rabiee"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "27",
        "reference_count": "61",
        "references": [
            "/paper/Ano-Graph%3A-Learning-Normal-Scene-Contextual-Graphs-PourReza-Salehi/12ebe64bf81b85b2331875895bd3a2b5978dabd8",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Efficient-Anomaly-Detection-Using-Self-Supervised-Jezequel-Vu/338c55f43bc6bce1174a766b9f6bd2fec4cf6c5e",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Adaptive-Adversarial-Latent-Space-for-Novelty-Jiang-Xu/b632ec4447c1d5dfdf41bb0288e9fcaa8d02f713",
            "/paper/Data-Invariants-to-Understand-Unsupervised-Doorenbos-Sznitman/0f23a44418aabe3344c6f3809d6a8ab898292813",
            "/paper/Transformaly-Two-(Feature-Spaces)-Are-Better-Than-Cohen-Avidan/a090711c5e17f0d9907f243c05251350215c088f",
            "/paper/Visual-Anomaly-Detection-for-Images%3A-A-Survey-Yang-Xu/cf122c84af8c85e15c3dffaca4069dd455b56a1e",
            "/paper/A-Unified-Survey-on-Anomaly%2C-Novelty%2C-Open-Set%2C-and-Salehi-Mirzaei/8b153cc2c7f5ea9f307f12ea945a5e9196ee5c52",
            "/paper/Multimodal-Self-Supervised-Learning-for-Medical-Taleb-Lippert/b94a3bfe8ca48855e4b4c6bcab5b051197052d9e",
            "/paper/ARAE%3A-Adversarially-Robust-Training-of-Autoencoders-Salehi-Arya/10b219619e88931fabb674037bbb633682775136",
            "/paper/AVID%3A-Adversarial-Visual-Irregularity-Detection-Sabokrou-PourReza/c2b733a79db700b971327a58ef42699fe8a416aa",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Fast-is-better-than-free%3A-Revisiting-adversarial-Wong-Rice/6d4a87759917132913319960389f17fa1fe8b630",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Generative-Probabilistic-Novelty-Detection-with-Pidhorskyi-Almohsen/70f9968a356d840040a1c9207906f60376dc6bd4",
            "/paper/Memorizing-Normality-to-Detect-Anomaly%3A-Deep-for-Gong-Liu/d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "/paper/OCGAN%3A-One-Class-Novelty-Detection-Using-GANs-With-Perera-Nallapati/599fd051c9438011ec5b581983c89e8922b4a5e6"
        ]
    },
    {
        "id": "6e97f1ced85428cf7207fbcc9205afc0daa68017",
        "title": "BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation.",
        "abstract": "The results demonstrate the necessity of developing customized transformers for efficient and better medical image segmentation and the design of BATFormer requires the least amount of model parameters and the lowest computational complexity compared to the state-of-the-art approaches. OBJECTIVE\nTransformers, born to remedy the inadequate receptive fields of CNNs, have drawn explosive attention recently. However, the daunting computational complexity of global representation learning, together with rigid window partitioning, hinders their deployment in medical image segmentation. This work aims to address the above two issues in transformers for better medical image segmentation.\n\n\nMETHODS\nWe propose a boundary-aware lightweight transformer (BATFormer) that can build cross-scale global interaction with lower computational complexity and generate windows flexibly under the guidance of entropy. Specifically, to fully explore the benefits of transformers in long-range dependency establishment, a cross-scale global transformer (CGT) module is introduced to jointly utilize multiple small-scale feature maps for richer global features with lower computational complexity. Given the importance of shape modeling in medical image segmentation, a boundary-aware local transformer (BLT) module is constructed. Different from rigid window partitioning in vanilla transformers which would produce boundary distortion, BLT adopts an adaptive window partitioning scheme under the guidance of entropy for both computational complexity reduction and shape preservation.\n\n\nRESULTS\nBATFormer achieves the best performance in Dice of 92.84 %, 91.97 %, 90.26 %, and 96.30 % for the average, right ventricle, myocardium, and left ventricle respectively on the ACDC dataset and the best performance in Dice, IoU, and ACC of 90.76 %, 84.64 %, and 96.76 % respectively on the ISIC 2018 dataset. More importantly, BATFormer requires the least amount of model parameters and the lowest computational complexity compared to the state-of-the-art approaches.\n\n\nCONCLUSION AND SIGNIFICANCE\nOur results demonstrate the necessity of developing customized transformers for efficient and better medical image segmentation. We believe the design of BATFormer is inspiring and extendable to other applications/frameworks. The source code is publicly available at https://github.com/xianlin7/BATFormer.",
        "publication_year": "2022",
        "authors": [
            "Xian Lin",
            "Li Yu",
            "Kwang-Ting Cheng",
            "Zengqiang Yan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "53",
        "references": [
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/MISSFormer%3A-An-Effective-Medical-Image-Segmentation-Huang-Deng/f75bf767d060785e553326627adfee77f8e19d86",
            "/paper/UTNet%3A-A-Hybrid-Transformer-Architecture-for-Image-Gao-Zhou/a2a0fc5014423d6283c80511b9272d941109ece2",
            "/paper/DS-TransUNet%3A-Dual-Swin-Transformer-U-Net-for-Image-Lin-Chen/6feecbba7eacf002edeee797db2704d15ffbda1b",
            "/paper/Mixed-Transformer-U-Net-for-Medical-Image-Wang-Xie/435a43bbb6d6fbbf2beb03ef17868df9d5be87e8",
            "/paper/nnFormer%3A-Interleaved-Transformer-for-Volumetric-Zhou-Guo/77d785cedf8be8ca6aeb4cb249af579ecb839956",
            "/paper/CoTr%3A-Efficiently-Bridging-CNN-and-Transformer-for-Xie-Zhang/8356d155d730e374f4db6dfd03d19a7b66c348a8",
            "/paper/Medical-Image-Segmentation-using-Transformers-Li-Sui/ec561a375a100097f00fcf4924a2c14a9a7735e7",
            "/paper/LeViT-UNet%3A-Make-Faster-Encoders-with-Transformer-Xu-Wu/faa30dfcb1531df4e4d5c219bad06d65f6c860fa",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30"
        ]
    },
    {
        "id": "ba124bbde8d114a9103eb5751036e2e4710e2fff",
        "title": "DCAN: Deep Contour-Aware Networks for Accurate Gland Segmentation",
        "abstract": "An efficient deep contour-aware network (DCAN) to solve this challenging problem under a unified multi-task learning framework and can be efficient when applied to large-scale histopathological data without resorting to additional steps to generate contours based on low-level cues for post-separating. The morphology of glands has been used routinely by pathologists to assess the malignancy degree of adenocarcinomas. Accurate segmentation of glands from histology images is a crucial step to obtain reliable morphological statistics for quantitative diagnosis. In this paper, we proposed an efficient deep contour-aware network (DCAN) to solve this challenging problem under a unified multi-task learning framework. In the proposed network, multi-level contextual features from the hierarchical architecture are explored with auxiliary supervision for accurate gland segmentation. When incorporated with multi-task regularization during the training, the discriminative capability of intermediate features can be further improved. Moreover, our network can not only output accurate probability maps of glands, but also depict clear contours simultaneously for separating clustered objects, which further boosts the gland segmentation performance. This unified framework can be efficient when applied to large-scale histopathological data without resorting to additional steps to generate contours based on low-level cues for post-separating. Our method won the 2015 MICCAI Gland Segmentation Challenge out of 13 competitive teams, surpassing all the other methods by a significant margin.",
        "publication_year": "2016",
        "authors": [
            "Hao Chen",
            "Xiaojuan Qi",
            "Lequan Yu",
            "P. Heng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "471",
        "reference_count": "41",
        "references": [
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/BE-Net%3ABoudary-Enhanced-Networks-for-Accurate-Gland-Fan-Dong/ef3bcf7951dc144fe4f6a898b62e6e16afa85da1",
            "/paper/Gland-segmentation-in-colorectal-cancer-images-Rastogi-Khanna/61be61a2da82291f01ee5ea0abd19528adfc6045",
            "/paper/TA-Net%3A-Topology-Aware-Network-for-Gland-Wang-Xian/318e936b588aebb4bbc047e0882d5a645ebcf715",
            "/paper/Boosting-Boundary-Representation-for-Gland-Instance-Kang-Li/2ae725a2819ecd72aa8a35de5a22f13581c7de46",
            "/paper/DPANet%3A-A-Novel-Network-Based-on-Dense-Pyramid-and-Liu-Zhang/6f759136e1a074bd0ca166b5eefc6228ddb53a61",
            "/paper/A-Hybrid-Feature-Enhancement-Method-for-Gl-And-In-Wu-Li/11d051f9c6a959bfd60e1a7beb256d018614e690",
            "/paper/Gland-Instance-Segmentation-Using-Deep-Multichannel-Xu-Li/08c9e730aa7af6d5c9f3a1325a01f71de58863f7",
            "/paper/Dense-Contour-Imbalance-Aware-framework-for-Colon-Mei-Guo/7afad945dd099d19af6ad51e5f0b52fcf5c9b282",
            "/paper/Glandular-Cell-Image-Segmentation-Method-based-on-Lin-Chen/859a5cc656b37cbcfb072b267952c116f5aa37f6",
            "/paper/DeepOrgan%3A-Multi-level-Deep-Convolutional-Networks-Roth-Lu/ca29aaab1ecdd80120b80a405ecec530ec4d63a8",
            "/paper/Structure-and-Context-in-Prostatic-Gland-and-Nguyen-Sarkar/a7da95bdbd0ccab6762d069214f9c7475548ddea",
            "/paper/Automatic-segmentation-of-colon-glands-using-Demir-Kandemir/e3168cffeafc53b8f72076f4699057250a9fe31c",
            "/paper/Gland-segmentation-in-colon-histology-images%3A-The-Sirinukunwattana-Pluim/8ecc6ecd5b77665b261cce1a96d431d9f43bdaea",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Deep-Contextual-Networks-for-Neuronal-Structure-Chen-Qi/49a86f6bf8f684f2d5cbb01dca7da03ee53b69d5",
            "/paper/Semantic-Image-Segmentation-with-Deep-Convolutional-Chen-Papandreou/39ad6c911f3351a3b390130a6e4265355b4d593b",
            "/paper/BoxSup%3A-Exploiting-Bounding-Boxes-to-Supervise-for-Dai-He/f084f0126d48a0793cf7e60830089b93ef09c844",
            "/paper/A-Boosting-Cascade-for-Automated-Detection-of-from-Doyle-Madabhushi/31e53eaf795ff31ea949f23a276d7db2668f6fbc",
            "/paper/Holistically-Nested-Edge-Detection-Xie-Tu/8da55e685a7bef9c897788ab519a8710c695c419"
        ]
    },
    {
        "id": "3379d2fb4f23b19cfcf0d6ed4b246b7f724a7122",
        "title": "Adversarial Stain Transfer to Study the Effect of Color Variation on Cell Instance Segmentation",
        "abstract": "A deep learning image-recoloring method was applied and the impact of color variation on cell segmentation was quantitatively investigated, demonstrating the necessity of color normalization prior to subsequent analysis. . Stain color variation in histological images, caused by a vari-ety of factors, is a challenge not only for the visual diagnosis of patholo-gists but also for cell segmentation algorithms. To eliminate the color variation, many stain normalization approaches have been proposed. However, most were designed for hematoxylin and eosin staining images and performed poorly on immunohistochemical staining images. Cur-rent cell segmentation methods systematically apply stain normalization as a preprocessing step, but the impact brought by color variation has not been quantitatively investigated yet. In this paper, we produced \ufb01ve groups of NeuN staining images with di\ufb00erent colors. We applied a deep learning image-recoloring method to perform color transfer between histological image groups. Finally, we altered the color of a segmentation set and quanti\ufb01ed the impact of color variation on cell segmentation. The results demonstrated the necessity of color normalization prior to subsequent analysis.",
        "publication_year": "2022",
        "authors": [
            "Huaqian Wu",
            "N. Souedet",
            "Camille Mabillon",
            "C. Jan",
            "C. Clouchoux",
            "T. Delzescaux"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "15",
        "references": [
            "/paper/Adversarial-Stain-Transfer-for-Histopathology-Image-Bentaieb-Hamarneh/a9c564185882bc9dd2b7becfc6928407bf1089b2",
            "/paper/Quantifying-the-effects-of-data-augmentation-and-in-Tellez-Litjens/35ee6606ec99b5bf282a0c5f400edbd16a6e22d9",
            "/paper/Staingan%3A-Stain-Style-Transfer-for-Digital-Images-Shaban-Baur/e926486ab0dfd772d7da41489b47da0db935b3d8",
            "/paper/Structure-Preserving-Color-Normalization-and-Sparse-Vahadane-Peng/a243c7bbd2affd548e18a35dadf0313c1b2198c2",
            "/paper/A-deep-learning-algorithm-for-one-step-contour-of-Cui-Zhang/505e72b8d60e987e89b93fdd98859b857ca94207",
            "/paper/A-general-deep-learning-framework-for-neuron-based-Wu-Souedet/0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
            "/paper/Cross-patch-Dense-Contrastive-Learning-for-of-in-Wu-Wang/6ca8dd91ffa9e80975bcd44a3734cb967078cd02",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/HistoGAN%3A-Controlling-Colors-of-GAN-Generated-and-Afifi-Brubaker/0ddfdbf470c961bcf9ecbba42e9afebcbab044ee",
            "/paper/Panoptic-Feature-Fusion-Net%3A-A-Novel-Instance-for-Liu-Zhang/b57c925acd708fd7e27facd3e8d11053ea7cca30"
        ]
    },
    {
        "id": "a3e36619f167b9ae2f1b9162a5a270966b86c5cd",
        "title": "Multi-Scale Relational Graph Convolutional Network for Multiple Instance Learning in Histopathology Images",
        "abstract": "This work introduces the Multi-Scale Relational Graph Convolutional Network (MS-RGCN) as a multiple instance learning method that outperforms the state-of-the-art on both datasets and especially on the classification of grade groups 2 and 3, which are significant for clinical decisions for patient management. Graph convolutional neural networks have shown significant potential in natural and histopathology images. However, their use has only been studied in a single magnification or multi-magnification with late fusion. In order to leverage the multi-magnification information and early fusion with graph convolutional networks, we handle different embedding spaces at each magnification by introducing the Multi-Scale Relational Graph Convolutional Network (MS-RGCN) as a multiple instance learning method. We model histopathology image patches and their relation with neighboring patches and patches at other scales (i.e., magnifications) as a graph. To pass the information between different magnification embedding spaces, we define separate message-passing neural networks based on the node and edge type. We experiment on prostate cancer histopathology images to predict the grade groups based on the extracted features from patches. We also compare our MS-RGCN with multiple state-of-the-art methods with evaluations on both source and held-out datasets. Our method outperforms the state-of-the-art on both datasets and especially on the classification of grade groups 2 and 3, which are significant for clinical decisions for patient management. Through an ablation study, we test and show the value of the pertinent design features of the MS-RGCN.",
        "publication_year": "2022",
        "authors": [
            "Roozbeh Bazargani",
            "L. Fazli",
            "L. Goldenberg",
            "M. Gleave",
            "A. Bashashati",
            "S. Salcudean"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "55",
        "references": [
            "/paper/Representation-Learning-of-Histopathology-Images-Adnan-Kalra/77873e0843113d5465417f5309f5ae258af52a6f",
            "/paper/A-Survey-on-Graph-Based-Deep-Learning-for-Ahmedt-Aristizabal-Armin/70727c82f1ab97b3f64ee3e81e6e209c40fa0a02",
            "/paper/Neuroplastic-graph-attention-networks-for-nuclei-in-Alon-Zhou/b6d233e5a2c14e958c19cf1fc5d0a87531889f8f",
            "/paper/Predicting-Lymph-Node-Metastasis-Using-Images-Based-Zhao-Yang/a91c08128834b7add5c556f67d2939335d137762",
            "/paper/Ms-Gwnn%3A-Multi-Scale-Graph-Wavelet-Neural-Network-Zhang-Li/185f8bb9bfc4252c5aca4bb2d30b47cca2dc91df",
            "/paper/Multi-stain-graph-fusion-for-multimodal-integration-Dwivedi-Nofallah/7d649e7843ce681b399a81d5302617b3768f622f",
            "/paper/Deep-Learning-Based-Gleason-Grading-of-Prostate-of-Karimi-Nir/95db99286b274352e7e1906ebf63e10ae9fce30c",
            "/paper/Whole-slide-images-based-cancer-survival-prediction-Yao-Zhu/f0c24d4ba514081a7bc77905e3e12998937ba68b",
            "/paper/Graph-CNN-for-Survival-Analysis-on-Whole-Slide-Li-Yao/2c0cdbf4f412f320242481bf7fe718a6237e74e2",
            "/paper/Multi-scale-Domain-adversarial-Multiple-instance-Hashimoto-Fukushima/e334e781e58ec06834a93e924c57ed5c8a64c897"
        ]
    },
    {
        "id": "03d66c8cb662f7b93f50570b2664ed894502cfe4",
        "title": "Medical Image Segmentation Based on Transformer and HarDNet Structures",
        "abstract": "A dual-encoder image segmentation network, including HarDNet68 and Transformer branch, is proposed, which can extract the local features and global feature information of the input image, allowing the segmentationnetwork to learn more image information, thus improving the effectiveness and accuracy of medical segmentation. Medical image segmentation is a crucial way to assist doctors in the accurate diagnosis of diseases. However, the accuracy of medical image segmentation needs further improvement due to the problems of many noisy medical images and the high similarity between background and target regions. The current mainstream image segmentation networks, such as TransUnet, have achieved accurate image segmentation. Still, the encoders of such segmentation networks do not consider the local connection between adjacent chunks and lack the interaction of inter-channel information during the upsampling of the decoder. To address the above problems, this paper proposed a dual-encoder image segmentation network, including HarDNet68 and Transformer branch, which can extract the local features and global feature information of the input image, allowing the segmentation network to learn more image information, thus improving the effectiveness and accuracy of medical segmentation. In this paper, to realize the fusion of image feature information of different dimensions in two stages of encoding and decoding, we propose a feature adaptation fusion module to fuse the channel information of multi-level features and realize the information interaction between channels, and then improve the segmentation network accuracy. The experimental results on CVC-ClinicDB, ETIS-Larib, and COVID-19 CT datasets show that the proposed model performs better in four evaluation metrics, Dice, Iou, Prec, and Sens, and achieves better segmentation results in both internal filling and edge prediction of medical images. Accurate medical image segmentation can assist doctors in making a critical diagnosis of cancerous regions in advance, ensure cancer patients receive timely targeted treatment, and improve their survival quality.",
        "publication_year": "2023",
        "authors": [
            "Tongping Shen",
            "Huanqing Xu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "55",
        "references": [
            "/paper/Ensembles-of-Convolutional-Neural-Networks-and-for-Nanni-Fantozzi/5ea7d1e0934876fac06c7ca6f5f56dbc57f133d9",
            "/paper/FSA-Net%3A-Rethinking-the-attention-mechanisms-in-Zhan-Song/56ac99469b08321d60e3f3d8ed904cf20a27d3bd",
            "/paper/X-Net%3A-a-dual-encoding%E2%80%93decoding-method-in-medical-Li-Wang/9a2ce0b25d3a0f82eae38a0d1e8064d710aa11d0",
            "/paper/CE-Net%3A-Context-Encoder-Network-for-2D-Medical-Gu-Cheng/a07aa5b834e5083624189a929be07c7ae2389229",
            "/paper/Hybrid-dilation-and-attention-residual-U-Net-for-Wang-Zou/c6ee91b3faf751fd3273fbbfb4e40f2a98f2bcb9",
            "/paper/Multi-path-connected-network-for-medical-image-Wang-Hu/6dca4cd021e3dceb2e50714f4f3f2bd084756d63",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/CA-Net%3A-Comprehensive-Attention-Convolutional-for-Gu-Wang/6b78b2cde7015539ecb0e4be4ee14ed021210753",
            "/paper/Medical-Image-Segmentation-via-Cascaded-Attention-Rahman-Marculescu/c27dcfd2e6bbe0954eeb06c9b72f4937778ec4bb",
            "/paper/Multiscale-attention-guided-U-Net-architecture-for-Cui-Yuwen/8270afd12aa683d166586983abfdde024cefa5c8",
            "/paper/CMM-Net%3A-Contextual-multi-scale-multi-level-network-Al-masni-Kim/7863d62073960398f4ca258bd08b5f2b7854e574",
            "/paper/Medical-Image-Segmentation-Using-Deep-Learning%3A-A-Lei-Wang/2080d37c0072934b6a0d9c06d307037f03677a5a"
        ]
    },
    {
        "id": "19b0b1c8629904a81121e0311aed2a401ebc3aae",
        "title": "RCGA-Net: An Improved Multi-hybrid Attention Mechanism Network in Biomedical Image Segmentation",
        "abstract": "Inspired by the state-of-the-art deep learning works, an end-to-end multi-layer network named RCGA-Net is proposed that consists of an encoder-decoder backbone that integrates a coordinate attention mechanism based on space and channel and a global context extraction module to highlight more valuable information. Drawing support from an effective Medical Image Segmentation (MIS) is conducive to a substantial diagnostic basis for the physicians to identify the focus lesion in the patient body and give the subsequent clinical assessment of the patient status. Although various works have tried the challenging quantitative analysis problem, it is still difficult to conduct precise automatic segmentation, especially the soft tissue organs. In this decade, with the increased amount of available datasets, deep learning-based networks have achieved remarkable performance in image processing. Inspired by the state-of-the-art deep learning works, in this paper, we propose an end-to-end multi-layer network named RCGA-Net. It consists of an encoder-decoder backbone that integrates a coordinate attention mechanism based on space and channel and a global context extraction module to highlight more valuable information. To evaluate the performance of RCGA-Net, we apply it to different kinds of clinical and experimental MIS tasks to testify its generalization ability. Extensive experiments represent that our schema has taken the outperform or compatible results among the comparison methods group. Specifically, the numeric result of RCGA-Net on the pulmonary dataset has achieved a 99.12% optimum F1-score.",
        "publication_year": "2021",
        "authors": [
            "F. Xiao",
            "Cong Shen",
            "Yu Chen",
            "Tian Yang",
            "Shengyong Chen",
            "Z. Liao",
            "Jijun Tang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "30",
        "references": [
            "/paper/SLRFormer%3A-Continuous-Sign-Language-Recognition-on-Xiao-Liu/a822077fa6047efcff467d396aa9c8562e5fb6a9",
            "/paper/BAT-Net%3A-An-enhanced-RNA-Secondary-Structure-via-Shen-Chen/1e6f7813662022b4b344438b8da8a395d6d7f963",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/TWD-SFNN%3A-Three-way-decisions-with-a-single-hidden-Cheng-Wu/c5846a04695928d1a568ff2c817195ffca19013a",
            "/paper/CRB-Net%3A-A-Sign-Language-Recognition-Deep-Learning-Xiao-Shen/5106e4f5e3e6fbc3a183d4dec21f5d72e64d9264",
            "/paper/A-Multichannel-Deep-Neural-Network-for-Retina-via-a-Ding-Zhang/ac2ffe760e939c3bf2ece44c472e9c11cf52b38b",
            "/paper/MSRF-Net%3A-A-Multi-Scale-Residual-Fusion-Network-for-Srivastava-Jha/75808111f4b554d3d99563c8f2b22359bc011c45",
            "/paper/FANet%3A-A-Feedback-Attention-Network-for-Improved-Tomar-Jha/81c35b12898c7f46115547b70f628f966ed73c50",
            "/paper/Coordinate-Attention-for-Efficient-Mobile-Network-Hou-Zhou/70cf7c785952375e8061c92235aa20e94b02ecd4",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/DoubleU-Net%3A-A-Deep-Convolutional-Neural-Network-Jha-Riegler/61af9ff6ec3dbb5299455746a1c63588ccf62cf8"
        ]
    },
    {
        "id": "35996e1b1f34985ab10cdb07163f00c50a23d8d4",
        "title": "PointNu-Net: Keypoint-assisted Convolutional Neural Network for Simultaneous Multi-tissue Histology Nuclei Segmentation and Classification",
        "abstract": "A reliable and robust method capable of dealing with data from the 'the clinical wild' by decoupling two simultaneous challenging tasks and taking advantage of JPFM, which can benefit from class-aware detection and class-agnostic segmentation, thus leading to a significant performance boost. Automatic nuclei segmentation and classification play a vital role in digital pathology. However, previous works are mostly built on data with limited diversity and small sizes, making the results questionable or misleading in actual downstream tasks. In this paper, we aim to build a reliable and robust method capable of dealing with data from the 'the clinical wild'. Specifically, we study and design a new method to simultaneously detect, segment, and classify nuclei from Haematoxylin and Eosin (H&E) stained histopathology data, and evaluate our approach using the recent largest dataset: PanNuke. We address the detection and classification of each nuclei as a novel semantic keypoint estimation problem to determine the center point of each nuclei. Next, the corresponding class-agnostic masks for nuclei center points are obtained using dynamic instance segmentation. Meanwhile, we proposed a novel Joint Pyramid Fusion Module (JPFM) to model the cross-scale dependencies, thus enhancing the local feature for better nuclei detection and classification. By decoupling two simultaneous challenging tasks and taking advantage of JPFM, our method can benefit from class-aware detection and class-agnostic segmentation, thus leading to a significant performance boost. We demonstrate the superior performance of our proposed approach for nuclei segmentation and classification across 19 different tissue types, delivering new benchmark results.",
        "publication_year": "2021",
        "authors": [
            "Kai Yao",
            "Kaizhu Huang",
            "Jie Sun",
            "Amir Hussain"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "45",
        "references": [
            "/paper/PanNuke-Dataset-Extension%2C-Insights-and-Baselines-Gamper-Koohbanani/f80a77c7800b10a3ef83ab7cac51e42b14ff5a15",
            "/paper/Hover-Net%3A-Simultaneous-segmentation-and-of-nuclei-Graham-Vu/5986547c7380f5a8fb6028093f827b3662f838a2",
            "/paper/PanNuke%3A-An-Open-Pan-Cancer-Histology-Dataset-for-Gamper-Koohbanani/b218b13756f3aacadf5f06d09652058d024dc9d4",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/Contour-Seed-Pairs-Learning-Based-Framework-for-and-Song-Xiao/f0d7076beb1938487942570043a3e3f746da53a7",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/CIA-Net%3A-Robust-Nuclei-Instance-Segmentation-with-Zhou-Onder/5fd490e5ceed129a83d16dbda29ab61fe4aa1acb",
            "/paper/Multi-Crop-Convolutional-Neural-Networks-for-Fast-Chen-Xie/3fbe96fafecd31e3f3ee4c02baef2c61137de2b5",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Triple-U-net%3A-Hematoxylin-aware-nuclei-segmentation-Zhao-Chen/38d037e22c056827fa3d0295d9615cc08788309d"
        ]
    },
    {
        "id": "c7c1b005a042e52be8523ddf0d26941a242d5402",
        "title": "ASW-Net: A Deep Learning-based Tool for Cell Nucleus Segmentation of Fluorescence Microscopy",
        "abstract": "This paper proposed a novel framework called Attention-enhanced Simplified W-Net (ASW-Net), in which a cascade-like structure with between-net connections was used, and showed that this lightweight model could reach remarkable segmentation performance in the testing set. Nucleus segmentation of fluorescence microscopy is a critical step in quantifying measurements in cell biology. Automatic and accurate nucleus segmentation has powerful applications in analyzing intrinsic characterization in nucleus morphology. However, existing methods have limited capacity to perform accurate segmentation in challenging samples, such as noisy images and clumped nuclei. In this paper, inspired by the idea of cascaded U-Net (or W-Net) and its remarkable performance improvement in medical image segmentation, we proposed a novel framework called Attention-enhanced Simplified W-Net (ASW-Net), in which a cascade-like structure with between-net connections was used. Results showed that this lightweight model could reach remarkable segmentation performance in the testing set (aggregated Jaccard index, 0.7981). In addition, our proposed framework performed better than the state-of-the-art methods in terms of segmentation performance. Moreover, we further explored the effectiveness of our designed network by visualizing the deep features from the network. Notably, our proposed framework is open-source.",
        "publication_year": "2021",
        "authors": [
            "Weihao Pan",
            "Zhe Liu",
            "G. Lin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "35",
        "references": [
            "/paper/Evaluation-of-Deep-Learning-Strategies-for-Nucleus-Caicedo-Roth/c89bfd998b0a6c656010b629814ab0cad3cff72e",
            "/paper/nucleAIzer%3A-A-Parameter-free-Deep-Learning-for-Hollandi-Szkalisity/0a78085721f70d82c1284c124c3137bb7c2b34e7",
            "/paper/Integrating-deep-convolutional-neural-networks-with-Xie-Qi/0ea3e5215ac2676a15bef2354b2938704a0789a3",
            "/paper/RIC-Unet%3A-An-Improved-Neural-Network-Based-on-Unet-Zeng-Xie/4a91c15880a788711c0a7e00ba3968580e3052a5",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Hover-Net%3A-Simultaneous-segmentation-and-of-nuclei-Graham-Vu/5986547c7380f5a8fb6028093f827b3662f838a2",
            "/paper/W-net%3A-Bridged-U-net-for-2D-Medical-Image-Chen-Zhang/29fbe4a6c55f8eae8ff40841440e4cb198cd9aec",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Methods-for-Segmentation-and-Classification-of-Vu-Graham/26d5ad3849f97cfa9fa61f68330e3fa31f261668",
            "/paper/3D-cell-nuclei-segmentation-based-on-gradient-flow-Li-Liu/a62e525615747b4b6dd58709c3f1f914f6512b9d"
        ]
    },
    {
        "id": "2fc4c2b52f2b9becb63915af6b8f1cddda63331e",
        "title": "Accurate segmentation algorithm of acoustic neuroma in the cerebellopontine angle based on ACP-TransUNet",
        "abstract": "An automatic segmentation method based on Transformer is proposed, using TransUNet as the core model, and shows better performance than the newly-proposed SOTA (state-of-the-art) models such as CCNet, MANet, BiseNetv2, Swin-Unet, MedT, Trans UNet, and UCTransNet. Acoustic neuroma is one of the most common tumors in the cerebellopontine angle area. Patients with acoustic neuroma have clinical manifestations of the cerebellopontine angle occupying syndrome, such as tinnitus, hearing impairment and even hearing loss. Acoustic neuromas often grow in the internal auditory canal. Neurosurgeons need to observe the lesion contour with the help of MRI images, which not only takes a lot of time, but also is easily affected by subjective factors. Therefore, the automatic and accurate segmentation of acoustic neuroma in cerebellopontine angle on MRI is of great significance for surgical treatment and expected rehabilitation. In this paper, an automatic segmentation method based on Transformer is proposed, using TransUNet as the core model. As some acoustic neuromas are irregular in shape and grow into the internal auditory canal, larger receptive fields are thus needed to synthesize the features. Therefore, we added Atrous Spatial Pyramid Pooling to CNN, which can obtain a larger receptive field without losing too much resolution. Since acoustic neuromas often occur in the cerebellopontine angle area with relatively fixed position, we combined channel attention with pixel attention in the up-sampling stage so as to make our model automatically learn different weights by adding the attention mechanism. In addition, we collected 300 MRI sequence nuclear resonance images of patients with acoustic neuromas in Tianjin Huanhu hospital for training and verification. The ablation experimental results show that the proposed method is reasonable and effective. The comparative experimental results show that the Dice and Hausdorff 95 metrics of the proposed method reach 95.74% and 1.9476\u2009mm respectively, indicating that it is not only superior to the classical models such as UNet, PANet, PSPNet, UNet++, and DeepLabv3, but also show better performance than the newly-proposed SOTA (state-of-the-art) models such as CCNet, MANet, BiseNetv2, Swin-Unet, MedT, TransUNet, and UCTransNet.",
        "publication_year": "2023",
        "authors": [
            "Zhu Zhang",
            "Xiaochen Zhang",
            "Yong-Xiang Yang",
            "Jieyu Liu",
            "Chenzi Zheng",
            "Hua Bai",
            "Quan-feng Ma"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "66",
        "references": [
            "/paper/MRI-findings-of-lesions-in-the-cerebellopontine-Xiao-xi/139f1748e12275bc52b34579b77f2e75e9d043d3",
            "/paper/Assessing-Surgical-Approaches-for-Acoustic-Neuroma-North-Weishaar/71f3b720e7bd9d26488a5fa323b7b3d1c6890353",
            "/paper/An-Enhancement-of-Deep-Learning-Algorithm-for-Brain-Thillaikkarasi-Saravanan/e32a6d4bd0f266615e2e359cc3899de4b427d5ee",
            "/paper/EG-TransUNet%3A-a-transformer-based-U-Net-with-and-Pan-Liu/4a6bf17538ded4eae48629728ee17adebb688094",
            "/paper/Early-gastric-cancer-segmentation-in-gastroscopic-a-Du-Rao/ed3e670cef62677636fae24d9ad66bcfb76d47bb",
            "/paper/Morbidity-and-mortality-following-acoustic-neuroma-McClelland-Guo/0e3431af8a9b17a6c3d3da28e951f87cf71c9629",
            "/paper/Spherical-coordinates-transformation-pre-processing-Russo-Liu/02fac38c2b79a58840783697833bba6340781cac",
            "/paper/Channel-attention-generative-adversarial-network-of-Song-Qiu/ab1614a6b46f99d892177858d33de0eb960f49f9",
            "/paper/Swin-Unet%3A-Unet-like-Pure-Transformer-for-Medical-Cao-Wang/ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "/paper/Multi-Level-Attention-Network-for-Retinal-Vessel-Yuan-Zhang/f1c7da2117cba702aebea99818fe9a8db1886694"
        ]
    },
    {
        "id": "c49a547b3424f42cc290f29c4f648514efc37229",
        "title": "End-to-end Neuron Instance Segmentation based on Weakly Supervised Efficient UNet and Morphological Post-processing",
        "abstract": "This paper presents an end-to-end weakly-supervised framework to automatically detect and segment NeuN stained neuronal cells on histological images using only point annotations and integrates the state-of-the-art network, EfficientNet, into the U-Net-like architecture. Recent studies have demonstrated the superiority of deep learning in medical image analysis, especially in cell instance segmentation, a fundamental step for many biological studies. However, the good performance of the neural networks requires training on large unbiased dataset and annotations, which is labor-intensive and expertise-demanding. In this paper, we present an end-to-end weakly-supervised framework to automatically detect and segment NeuN stained neuronal cells on histological images using only point annotations. We integrate the state-of-the-art network, EfficientNet, into our U-Net-like architecture. Validation results show the superiority of our model compared to other recent methods. In addition, we investigated multiple post-processing schemes and proposed an original strategy to convert the probability map into segmented instances using ultimate erosion and dynamic reconstruction. This approach is easy to configure and outperforms other classical post-processing techniques.",
        "publication_year": "2022",
        "authors": [
            "Huaqian Wu",
            "N. Souedet",
            "C. Jan",
            "C. Clouchoux",
            "T. Delzescaux"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "48",
        "references": [
            "/paper/A-deep-learning-algorithm-for-one-step-contour-of-Cui-Zhang/505e72b8d60e987e89b93fdd98859b857ca94207",
            "/paper/Weakly-Supervised-Multi-Task-Learning-for-Cell-and-Chamanzar-Nie/a89cf9c6aa4cad62a78421916726b8b16c0cb9f2",
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/Evaluation-of-Deep-Learning-Topcoders-Method-for-in-Wu-Souedet/056806e5ba9f2b39cbe86b529c325998c3bdd016",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/UNet%2B%2B%3A-Redesigning-Skip-Connections-to-Exploit-in-Zhou-Siddiquee/42b0a8f757e45462e627e57f9af7e9849dcdacdf",
            "/paper/Integrating-deep-convolutional-neural-networks-with-Xie-Qi/0ea3e5215ac2676a15bef2354b2938704a0789a3",
            "/paper/A-Multi-Organ-Nucleus-Segmentation-Challenge-Kumar-Verma/87c0dd990287d92796c7dc83edba6f52a2f52e21",
            "/paper/An-Automatic-Learning-Based-Framework-for-Robust-Xing-Xie/d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88"
        ]
    },
    {
        "id": "2c91de722d5cbb7048c2e80a3c7676a3c576f762",
        "title": "AnoRand: A Semi Supervised Deep Learning Anomaly Detection Method by Random Labeling",
        "abstract": "A new semi-supervised anomaly detection method called AnoRand is presented by combining a deep learning architecture with random synthetic label generation and has very good performance compared to most of state-of-the-art supervised algorithms. Anomaly detection or more generally outliers detection is one of the most popular and challenging subject in theoretical and applied machine learning. The main challenge is that in general we have access to very few labeled data or no labels at all. In this paper, we present a new semi-supervised anomaly detection method called \\textbf{AnoRand} by combining a deep learning architecture with random synthetic label generation. The proposed architecture has two building blocks: (1) a noise detection (ND) block composed of feed forward ferceptron and (2) an autoencoder (AE) block. The main idea of this new architecture is to learn one class (e.g. the majority class in case of anomaly detection) as well as possible by taking advantage of the ability of auto encoders to represent data in a latent space and the ability of Feed Forward Perceptron (FFP) to learn one class when the data is highly imbalanced. First, we create synthetic anomalies by randomly disturbing (add noise) few samples (e.g. 2\\%) from the training set. Second, we use the normal and the synthetic samples as input to our model. We compared the performance of the proposed method to 17 state-of-the-art unsupervised anomaly detection method on synthetic datasets and 57 real-world datasets. Our results show that this new method generally outperforms most of the state-of-the-art methods and has the best performance (AUC ROC and AUC PR) on the vast majority of reference datasets. We also tested our method in a supervised way by using the actual labels to train the model. The results show that it has very good performance compared to most of state-of-the-art supervised algorithms.",
        "publication_year": "2023",
        "authors": [
            "M. Z. A. Mayaki",
            "M. Riveill"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "44",
        "references": [
            "/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "/paper/Feature-Encoding-With-Autoencoders-for-Weakly-Zhou-Song/cf2e99c821af11966bf415e8c277ae3eb9f8677c",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/A-Unified-Model-for-Multi-class-Anomaly-Detection-You-Cui/0e8446c00ed21c19f62d71ab208a7b3601671766",
            "/paper/Deep-Anomaly-Detection-with-Deviation-Networks-Pang-Shen/f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "/paper/Loda%3A-Lightweight-on-line-detector-of-anomalies-Pevn%C3%BD/ca56df64a351f873c8c138874326a6f64eec011d",
            "/paper/ADBench%3A-Anomaly-Detection-Benchmark-Han-Hu/0bff4af924788d9779041513b6894385eac51ffd",
            "/paper/Unsupervised-anomaly-segmentation-via-deep-feature-Shi-Yang/4dd78b8d466b4cfe55a1bbdc694291197ce62541"
        ]
    },
    {
        "id": "205a1c89058ea55fe536c6484a62213d1d0f0160",
        "title": "An Improved Reverse Distillation Model for Unsupervised Anomaly Detection",
        "abstract": "Testing results obtained on benchmarks for AD and one-class novelty detection showed that the proposed model outperforms the SOTA ones, proving the utility and applicability of the suggested strategy. Using knowledge distillation for unsupervised anomaly detection problems is more efficient. Recently, a reverse distillation (RD) model has been presented a novel teacher-student (T-S) model for the problem [7]. In the model, the student network uses the one-class embedding from the teacher model as input with the goal of restoring the teacher's rep-resentations. The knowledge distillation starts with high-level abstract presentations and moves down to low-level aspects using a model called one-class bottleneck embedding (OCBE). Although its performance is expressive, it still leverages the power of transforming input images before applying this architecture. Instead of only using raw images, in this paper, we transform them using augmentation techniques. The teacher will encode raw and transformed inputs to get raw representation (encoded from raw inputs) and transformed representation (encoded from transformed inputs). The student must restore the transformed representation from the bottleneck to the raw representation. Testing results obtained on benchmarks for AD and one-class novelty detection showed that our proposed model outperforms the SOTA ones, proving the utility and applicability of the suggested strategy.",
        "publication_year": "2023",
        "authors": [
            "Van-Duc Nguyen",
            "Hoang Huu Bach",
            "L. Trang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "24",
        "references": [
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Memorizing-Normality-to-Detect-Anomaly%3A-Deep-for-Gong-Liu/d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Divide-and-Assemble%3A-Learning-Block-wise-Memory-for-Hou-Zhang/93040f8a5d10e8fde279e18d353aa3dca2873900",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Learning-Unsupervised-Metaformer-for-Anomaly-Wu-Chen/8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e"
        ]
    },
    {
        "id": "35dfd96486c38d9a21b1d29e2381d72cd7928b2f",
        "title": "Teacher-Student Network for 3D Point Cloud Anomaly Detection with Few Normal Samples",
        "abstract": "A teacher-student structured model for 3D anomaly detection that uses feature space alignment, dimension zoom, and max pooling to extract the features of the point cloud and then minimize a multi-scale loss between the feature vectors produced by the teacher and the student networks. Anomaly detection, which is a critical and popular topic in computer vision, aims to detect anomalous samples that are different from the normal (i.e., non-anomalous) ones. The current mainstream methods focus on anomaly detection for images, whereas little attention has been paid to 3D point cloud. In this paper, drawing inspiration from the knowledge transfer ability of teacher-student architecture and the impressive feature extraction capability of recent neural networks, we design a teacher-student structured model for 3D anomaly detection. Specifically, we use feature space alignment, dimension zoom, and max pooling to extract the features of the point cloud and then minimize a multi-scale loss between the feature vectors produced by the teacher and the student networks. Moreover, our method only requires very few normal samples to train the student network due to the teacher-student distillation mechanism. Once trained, the teacher-student network pair can be leveraged jointly to fulfill 3D point cloud anomaly detection based on the calculated anomaly score. For evaluation, we compare our method against the reconstruction-based method on the ShapeNet-Part dataset. The experimental results and ablation studies quantitatively and qualitatively confirm that our model can achieve higher performance compared with the state of the arts in 3D anomaly detection with very few training samples.",
        "publication_year": "2022",
        "authors": [
            "J. Qin",
            "Chunzhi Gu",
            "Junzhou Yu",
            "Chaoxi Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "55",
        "references": [
            "/paper/Composite-Layers-for-Deep-Anomaly-Detection-on-3D-Floris-Frittoli/7d5c0ae2985e0c665cb3713aaa169ee5c7c9794f",
            "/paper/Toward-Unsupervised-3d-Point-Cloud-Anomaly-Using-Masuda-Hachiuma/ca6294ce6f38f3f6ff694ba67d02eaad7fc92f4e",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/PointNet%3A-Deep-Learning-on-Point-Sets-for-3D-and-Qi-Su/d997beefc0922d97202789d2ac307c55c2c52fba",
            "/paper/Anomaly-Detection-in-3D-Point-Clouds-using-Deep-Bergmann-Sattlegger/cd382609f0029aae042e91a5a46b3dc2ba58a321",
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "/paper/Pull-%26-Push%3A-Leveraging-Differential-Knowledge-for-Zhou-He/2013f18832e0fb11c7aaf1f4f8da453aebda488c",
            "/paper/Asymmetric-Student-Teacher-Networks-for-Industrial-Rudolph-Wehrbein/655158947fd2a3b1e77703d9f4e951e7c583f894",
            "/paper/Reconstructed-Student-Teacher-and-Discriminative-Yamada-Kamiya/5fdd9cfb9b22b9e575d36e98e5d6f52a83729e42"
        ]
    },
    {
        "id": "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
        "title": "Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection",
        "abstract": "This paper proposes a simple yet powerful approach to anomaly detection, implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Anomaly detection is a challenging task and usually for-mulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Given a strong model pre-trained on image classi\ufb01cation as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, signi\ufb01cantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256 \u00d7 256), at least dozens of times faster than the latest counterparts.",
        "publication_year": "2021",
        "authors": [
            "Guodong Wang",
            "Shumin Han",
            "Errui Ding",
            "Di Huang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "44",
        "reference_count": "45",
        "references": [
            "/paper/Y-GAN%3A-Learning-Dual-Data-Representations-for-Ivanovska-%C5%A0truc/19fd7a304b1496260adcc4e85de7a26e51646543",
            "/paper/CFLOW-AD%3A-Real-Time-Unsupervised-Anomaly-Detection-Gudovskiy-Ishizaka/fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "/paper/Data-augmentation-and-pre-trained-networks-for-low-Gutierrez-Cordier/f533e50758dfdfe18d52d9cc2287cf9b8d98f233",
            "/paper/A-Multi-Scale-A-Contrario-method-for-Unsupervised-Tailani%C3%A1n-Mus'e/00b46923c31b21f59ab53cf693b6159c3dc4375d",
            "/paper/Surface-Defect-Detection-Methods-for-Industrial-A-Chen-Ding/08b66b00a9ce6ab8090668f9f848c5659617bae9",
            "/paper/ViTALnet%3A-Anomaly-on-Industrial-Textured-Surfaces-Tao-Adak/3c38d1145fc91245de7d9f2bc80a1e331bdb0b4e",
            "/paper/FractalAD%3A-A-simple-industrial-anomaly-segmentation-Xia-Lv/188a76b513b61a496f50f3e7bcd2540dde66d65e",
            "/paper/DeSTSeg%3A-Segmentation-Guided-Denoising-for-Anomaly-Zhang-Li/d17df33c9b6453d61d01353e94592f1757caee8a",
            "/paper/A-Survey-on-Unsupervised-Visual-Industrial-Anomaly-Cui-Liu/19aaeec8a81a711eb9a497c7d158068b27cb7b75",
            "/paper/Image-Based-Detection-of-Modifications-in-Assembled-Oliveira-Nassu/a26218ab1d36d4afdf68707a7e7bf95583dee6b8",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/Metric-Learning-for-Novelty-and-Anomaly-Detection-Masana-Ruiz/317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "/paper/Clustering-and-Unsupervised-Anomaly-Detection-with-Aytekin-Ni/388645c44061f6e88fff0ecdad2f622936207d67",
            "/paper/Anomaly-Detection-using-One-Class-Neural-Networks-Chalapathy-Menon/67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "/paper/High-dimensional-and-large-scale-anomaly-detection-Erfani-Rajasegarar/f076e4355c0facf111716dcab2837803367dd2d8",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Knowledge-Distillation-and-Student-Teacher-Learning-Wang-Yoon/2528a82dd2266600d4ee2b54165556a984de94d4"
        ]
    },
    {
        "id": "30aa23a6a32312666f2609339582744203024993",
        "title": "Deep Weakly-supervised Anomaly Detection",
        "abstract": "This work addresses an important anomaly detection problem termed weakly-supervised anomaly detection, in which, in addition to a large amount of unlabeled data, a limited number of labeled anomalies are available during modeling, by formulating it as a pairwise relation prediction task. Anomaly detection is typically posited as an unsupervised learning task in the literature due to the prohibitive cost and difficulty to obtain large-scale labeled anomaly data, but this ignores the fact that a very small number (e.g.,, a few dozens) of labeled anomalies can often be made available with small/trivial cost in many real-world anomaly detection applications. To leverage such labeled anomaly data, we study an important anomaly detection problem termed weakly-supervised anomaly detection, in which, in addition to a large amount of unlabeled data, a limited number of labeled anomalies are available during modeling. Learning with the small labeled anomaly data enables anomaly-informed modeling, which helps identify anomalies of interest and address the notorious high false positives in unsupervised anomaly detection. However, the problem is especially challenging, since (i) the limited amount of labeled anomaly data often, if not always, cannot cover all types of anomalies and (ii) the unlabeled data is often dominated by normal instances but has anomaly contamination. We address the problem by formulating it as a pairwise relation prediction task. Particularly, our approach defines a two-stream ordinal regression neural network to learn the relation of randomly sampled instance pairs, i.e., whether the instance pair contains two labeled anomalies, one labeled anomaly, or just unlabeled data instances. The resulting model effectively leverages both the labeled and unlabeled data to substantially augment the training data and learn well-generalized representations of normality and abnormality. Comprehensive empirical results on 40 real-world datasets show that our approach (i) significantly outperforms four state-of-the-art methods in detecting both of the known and previously unseen anomalies and (ii) is substantially more data-efficient.",
        "publication_year": "2019",
        "authors": [
            "Guansong Pang",
            "Chunhua Shen",
            "Huidong Jin",
            "A. Hengel"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "26",
        "reference_count": "68",
        "references": [
            "/paper/Deep-Learning-for-Anomaly-Detection-Pang-Shen/775247047d0b56950ba5ea77d4a29772eca95c1b",
            "/paper/Weakly-Supervised-Anomaly-Detection%3A-A-Survey-Jiang-Hou/7ac3e09d74ca15fdafa5f730617cd65059a144f3",
            "/paper/ADMoE%3A-Anomaly-Detection-with-Mixture-of-Experts-Zhao-Zheng/f1305bbd54db0345533906726e3425f742312c55",
            "/paper/Toward-Deep-Supervised-Anomaly-Detection%3A-Learning-Pang-Hengel/8ed98bd58c799718d6fd389e2218bb89b1ecb9d7",
            "/paper/AnoOnly%3A-Semi-Supervised-Anomaly-Detection-without-Zhou-Yang/4141b5740f8ff7464f9bbcb152b0ac7cde5d7954",
            "/paper/SCART%3A-Simulation-of-Cyber-Attacks-for-Real-Time-Girstein-Rahimi/66d9814f0ce0a83145f5904f03289145bd578d4b",
            "/paper/Robust-Semi-Supervised-Anomaly-Detection-via-Noise-Barker-Bhowmik/69244cd6455392f7eb0dec90119d5c689ee6f1ba",
            "/paper/Deep-Anomaly-Detection-for-In-Vehicle-Monitoring%E2%80%94An-Caetano-Carvalho/16117969f1fd354e90ed9906d8b3f7d9c1fd39d7",
            "/paper/Fine-tuning-the-Robust-Temporal-Feature-Magnitude-Charupalli-Seshadri/36307c1180292a2942b66e836b20ac7c3374f567",
            "/paper/Recent-Advances-in-Baggage-Threat-Detection%3A-A-and-Velayudhan-Hassan/401910c5c2abe1a65e1efe9ff2271c7363c1d733",
            "/paper/Few-shot-Network-Anomaly-Detection-via-Ding-Zhou/5365948c073e51a0568b20931c56dc8d6a6f94cb",
            "/paper/Explainable-Deep-One-Class-Classification-Liznerski-Ruff/16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "/paper/Learning-Representations-of-Ultrahigh-dimensional-Pang-Cao/267502d21b44884570fcd95a855821cc3e86e6eb",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/PUMAD%3A-PU-Metric-learning-for-anomaly-detection-Ju-Lee/de638f32e6e5762328357b855a9af3de8c20ea29",
            "/paper/Deep-Anomaly-Detection-with-Deviation-Networks-Pang-Shen/f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "/paper/XGBOD%3A-Improving-Supervised-Outlier-Detection-with-Zhao-Hryniewicki/49785334abf54313682b940c25e7a52cdbe941e9",
            "/paper/Anomaly-Detection-with-Partially-Observed-Anomalies-Zhang-Li/add459d9d37743dc2baad703fe17f794cb6b5d3f",
            "/paper/UNSW-NB15%3A-a-comprehensive-data-set-for-network-Moustafa-Slay/0e7af8e91b8cb2cea1164be5ac5d280b0d12c153"
        ]
    },
    {
        "id": "55d49aa6bd3e6605c6510a147c1fb5bdd7af0b12",
        "title": "DiffusionAD: Denoising Diffusion for Anomaly Detection",
        "abstract": "A new pipeline, DiffusionAD, to anomaly detection is introduced, which frame anomaly detection as a ``noise-to-norm'' paradigm, in which anomalies are identified as inconsistencies between a query image and its flawless approximation, and delivers satisfactory performance with just one diffusion reverse process step. Anomaly detection is widely applied due to its remarkable effectiveness and efficiency in meeting the needs of real-world industrial manufacturing. We introduce a new pipeline, DiffusionAD, to anomaly detection. We frame anomaly detection as a ``noise-to-norm'' paradigm, in which anomalies are identified as inconsistencies between a query image and its flawless approximation. Our pipeline achieves this by restoring the anomalous regions from the noisy corrupted query image while keeping the normal regions unchanged. DiffusionAD includes a denoising sub-network and a segmentation sub-network, which work together to provide intuitive anomaly detection and localization in an end-to-end manner, without the need for complicated post-processing steps. Remarkably, during inference, this framework delivers satisfactory performance with just one diffusion reverse process step, which is tens to hundreds of times faster than general diffusion methods. Extensive evaluations on standard and challenging benchmarks including VisA and DAGM show that DiffusionAD outperforms current state-of-the-art paradigms, demonstrating the effectiveness and generalizability of the proposed pipeline.",
        "publication_year": "2023",
        "authors": [
            "H. Zhang",
            "Z. Wang",
            "Zuxuan Wu",
            "Yuwei Jiang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "62",
        "references": [
            "/paper/On-Diffusion-Modeling-for-Anomaly-Detection-Livernoche-Jain/ea1d04d4d83253d6343993e5a550b22b7833000c",
            "/paper/AnoDDPM%3A-Anomaly-Detection-with-Denoising-Diffusion-Wyatt-Leach/20f6fce7726e7b3ab4ca45ef40d92b79f093f825",
            "/paper/Prototypical-Residual-Networks-for-Anomaly-and-Zhang-Wu/ac62ed8a9b77d613189b63004f4a5d4c5cc082fe",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/CFLOW-AD%3A-Real-Time-Unsupervised-Anomaly-Detection-Gudovskiy-Ishizaka/fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "/paper/FastFlow%3A-Unsupervised-Anomaly-Detection-and-via-2D-Yu1-Zheng/11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Divide-and-Assemble%3A-Learning-Block-wise-Memory-for-Hou-Zhang/93040f8a5d10e8fde279e18d353aa3dca2873900",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/Fast-Unsupervised-Brain-Anomaly-Detection-and-with-Pinaya-Graham/bacfa58d33e53efc40bffd87094f8731371277f2"
        ]
    },
    {
        "id": "19862af96b6af51e879e6e3f1d3d421af5427005",
        "title": "Inpainting Transformer for Anomaly Detection",
        "abstract": "This work poses anomaly detection as a patch-inpainting problem and proposes to solve it with a purely self-attention based approach discarding convolutions, which achieves results on par with the current state of the art on the MVTec AD dataset for detection and surpassing them on segmentation. Anomaly detection in computer vision is the task of identifying images which deviate from a set of normal images. A common approach is to train deep convolutional autoencoders to inpaint covered parts of an image and compare the output with the original image. By training on anomaly-free samples only, the model is assumed to not being able to reconstruct anomalous regions properly. For anomaly detection by inpainting we suggest it to be beneficial to incorporate information from potentially distant regions. In particular we pose anomaly detection as a patch-inpainting problem and propose to solve it with a purely self-attention based approach discarding convolutions. The proposed Inpainting Transformer (InTra) is trained to inpaint covered patches in a large sequence of image patches, thereby integrating information across large regions of the input image. When training from scratch, in comparison to other methods not using extra training data, InTra achieves results on par with the current state-of-the-art on the MVTec AD dataset for detection and surpassing them on segmentation.",
        "publication_year": "2021",
        "authors": [
            "Jonathan Pirnay",
            "K. Chai"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "50",
        "reference_count": "44",
        "references": [
            "/paper/Spatial-Contrastive-Learning-for-Anomaly-Detection-Kim-Jeong/6eedf365c6b580a6fc201eab867f1608f09adbae",
            "/paper/ADTR%3A-Anomaly-Detection-Transformer-with-Feature-You-Yang/5533bf9f2385ebece563fea35b19e998db64e597",
            "/paper/Masked-Swin-Transformer-Unet-for-Industrial-Anomaly-Jiang-Zhu/8ae2303e51f78954199e2a400c827aae4bb8e76a",
            "/paper/Multiresolution-Feature-Guidance-Based-Transformer-Yan-Chen/f48d6b404932c23b701d01d7f7382384103b0bd6",
            "/paper/Generalizable-Industrial-Visual-Anomaly-Detection-Yao-Yu/7db5da4321d526539ac567fb56cd8900def4b1e5",
            "/paper/Self-Supervised-Training-with-Autoencoders-for-Bauer/b93e7503fc1092cf6b012e1053df4a3a9d3561c7",
            "/paper/DeSTSeg%3A-Segmentation-Guided-Denoising-for-Anomaly-Zhang-Li/d17df33c9b6453d61d01353e94592f1757caee8a",
            "/paper/HaloAE%3A-An-HaloNet-based-Local-Transformer-for-and-Mathian-Liu/886fa942f73fa0c047c5a5ab87d9770dda3c8119",
            "/paper/Multi-Scale-Patch-Based-Representation-Learning-for-Tsai-Wu/45535b86c60661dd4c4e4f375abae80937563499",
            "/paper/A-Survey-on-Unsupervised-Visual-Industrial-Anomaly-Cui-Liu/19aaeec8a81a711eb9a497c7d158068b27cb7b75",
            "/paper/Reconstruction-by-inpainting-for-visual-anomaly-Zavrtanik-Kristan/2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Anomaly-detection-of-defects-on-concrete-structures-Chow-Su/24046c62be024695e9c73768ef6bcf870ca383c0",
            "/paper/Anomaly-Detection-Using-Deep-Learning-Based-Image-Haselmann-Gruber/a70bc416b1124525499b0ac3d5b009637dc6c187",
            "/paper/Skip-GANomaly%3A-Skip-Connected-and-Adversarially-Ak%C3%A7ay-Atapour-Abarghouei/5435a9ab36a308cef10bc725104e8f778ed3a328",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Unsupervised-Region-Based-Anomaly-Detection-In-MRI-Nguyen-Feldman/cb3d43139c682518b1e05e64df6239b7c26527ff",
            "/paper/Generative-Image-Inpainting-with-Contextual-Yu-Lin/6b0bbf3e7df725cc3b781d2648e41782cb3d8539"
        ]
    },
    {
        "id": "46276273cf92c31e103feab0cdc2ad0adda0dcc9",
        "title": "Interpreting Image\u2010based Profiles using Similarity Clustering and Single\u2010Cell Visualization",
        "abstract": "Two complementary protocols to help explore and interpret data from image\u2010based profiling experiments and provide scripts to create visualizations of representative single cells and image sites to understand how changes in features are reflected in the images are reflected. Image\u2010based profiling quantitatively assesses the effects of perturbations on cells by capturing a breadth of changes via microscopy. Here, we provide two complementary protocols to help explore and interpret data from image\u2010based profiling experiments. In the first protocol, we examine the similarity among perturbed cell samples using data from compounds that cluster by their mechanisms of action. The protocol includes steps to examine feature\u2010driving differences between samples and to visualize correlations between features and treatments to create interpretable heatmaps using the open\u2010source web tool Morpheus. In the second protocol, we show how to interactively explore images together with the numerical data, and we provide scripts to create visualizations of representative single cells and image sites to understand how changes in features are reflected in the images. Together, these two tutorials help researchers interpret image\u2010based data to speed up research. \u00a9 2023 The Authors. Current Protocols published by Wiley Periodicals LLC.",
        "publication_year": "2023",
        "authors": [
            "Fernanda Garcia-Fossa",
            "Mario Costa Cruz",
            "Marzieh Haghighi",
            "M. D. de Jesus",
            "Shantanu Singh",
            "Anne E Carpenter",
            "B. Cimini"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "26",
        "references": [
            "/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5",
            "/paper/Image-based-cell-profiling-enhancement-via-data-Rezvani-Bigverdi/4d0506d3e7f5dd23e1620cf8c48650bf1552bd3e",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0",
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/Morphology-and-gene-expression-profiling-provide-Way-Natoli/1f7bb6a080c1db96c778793514bf2b1638b623ab",
            "/paper/CellProfiler-4%3A-improvements-in-speed%2C-utility-and-Stirling-Swain-Bowden/0e9789615e4f3a55d300b8ca46070efab8a93513",
            "/paper/Blue-intensity-matters-for-cell-cycle-profiling-in-Ferro-Mestre/0a82315290e1a527895075a5471d0a3c96c6027b",
            "/paper/Predicting-cell-health-phenotypes-using-image-based-Way-Kost-Alimova/faf891f3f9bd76dcdd348c0ce8c389782cd49c90",
            "/paper/Virtual-screening-for-small-molecule-pathway-by-Rohban-Fuller/650531d909502e0ac2a54feb5539ba1877bef141",
            "/paper/Comparative-gene-marker-selection-suite-Gould-Getz/849a24bf0a00783e7d564c26c99ed8e2bf50b9f6"
        ]
    },
    {
        "id": "9e35901cbd1c258e99a2d119c666d8f1f0c62c88",
        "title": "Two penalized estimators based on variance stabilization transforms for sparse compressive recovery with Poisson measurement noise",
        "abstract": "Semantic Scholar extracted view of \"Two penalized estimators based on variance stabilization transforms for sparse compressive recovery with Poisson measurement noise\" by Ajit V. Rajwade et al.",
        "publication_year": "2021",
        "authors": [
            "Ajit V. Rajwade",
            "Karthik S. Gurumoorthy"
        ],
        "related_topics": [
            "Computer Science",
            "Mathematics"
        ],
        "citation_count": "2",
        "reference_count": "47",
        "references": [
            "/paper/Performance-Bounds-for-LASSO-under-Multiplicative-Das-Ninan/b5a4218270924748ab6ea2f122ae446faf937b8b",
            "/paper/A-neighborhood-based-multiple-orthogonal-least-for-Song-Wu/745990a3a401900874855d6041b03015e114eb09",
            "/paper/Variance-stabilization-based-compressive-inversion-Bohra-Garg/f7ec3c2396844cb7f60649be7c059f206d8c3b46",
            "/paper/Performance-bounds-for-Poisson-compressed-sensing-Garg-Rajwade/c0ff008fe0ea97f117d200b702be481a073fbae8",
            "/paper/Analyzing-cross-validation-in-compressed-sensing-Rajasekaran-Rajwade/e8e1b2d7917c22b01d0528d6d6159564cc284cfd",
            "/paper/Compressed-Sensing-Performance-Bounds-Under-Poisson-Raginsky-Willett/51ff6cfb98eec39da52035d87f329cf9e89462e6",
            "/paper/Minimax-Optimal-Sparse-Signal-Recovery-With-Poisson-Rohban-Saligrama/0e16a10560b4f7d5f891b932c79d1b2005407acf",
            "/paper/Using-an-Information-Theoretic-Metric-for-Recovery-Patil-Gurumoorthy/90d5988e60124db3e2221b90e2560d99790e7daf",
            "/paper/Nonlinear-Blind-Compressed-Sensing-Under-Noise-Das-Rajwade/ab2452f31db5505c2a03553acc573167a4f8840c",
            "/paper/Compressed-sensing-with-linear-correlation-between-Arildsen-Larsen/20723ba867599bdd492b1b0fd6f05072626ea84a",
            "/paper/A-Proximal-Iteration-for-Deconvolving-Poisson-Noisy-Dup%C3%A9-Fadili/96c3209106cc0fd1310be658eac19124ec01bf85",
            "/paper/This-is-SPIRAL-TAP%3A-Sparse-Poisson-Intensity-and-Harmany-Marcia/18b04752a09119494d21c9d57c6097e9595be8c8"
        ]
    },
    {
        "id": "12ebe64bf81b85b2331875895bd3a2b5978dabd8",
        "title": "Ano-Graph: Learning Normal Scene Contextual Graphs to Detect Video Anomalies",
        "abstract": "This work proposes a novel yet efficient method named Ano-Graph for learning and modeling the interaction of normal objects, which is data-efficient, significantly more robust against common real-world variations such as illumination, and passes SOTA by a large margin on the challenging datasets ADOC and Street Scene. Video anomaly detection has proved to be a challenging task owing to its unsupervised training procedure and high spatio-temporal complexity existing in real-world scenarios. In the absence of anomalous training samples, state-of-the-art methods try to extract features that fully grasp normal behaviors in both space and time domains using different approaches such as autoencoders, or generative adversarial networks. However, these approaches completely ignore or, by using the ability of deep networks in the hierarchical modeling, poorly model the spatio-temporal interactions that exist between objects. To address this issue, we propose a novel yet efficient method named Ano-Graph for learning and modeling the interaction of normal objects. Towards this end, a Spatio-Temporal Graph (STG) is made by considering each node as an object's feature extracted from a real-time off-the-shelf object detector, and edges are made based on their interactions. After that, a self-supervised learning method is employed on the STG in such a way that encapsulates interactions in a semantic space. Our method is data-efficient, significantly more robust against common real-world variations such as illumination, and passes SOTA by a large margin on the challenging datasets ADOC and Street Scene while stays competitive on Avenue, ShanghaiTech, and UCSD.",
        "publication_year": "2021",
        "authors": [
            "M. PourReza",
            "Mohammadreza Salehi",
            "M. Sabokrou"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "9",
        "reference_count": "92",
        "references": [
            "/paper/A-Hierarchical-Spatio-Temporal-Graph-Convolutional-Zeng-Jiang/8f66cd3c89239ae596656eb13d8290035c7e550a",
            "/paper/A-graph-based-approach-to-video-anomaly-detection-Siemon-Nasrollahi/8afe9473732dfa46e7ce0f4ea3197328021aeeb9",
            "/paper/Region-Anomaly-Detection-via-Spatial-and-Semantic-Zhang-Fadjrimiratno/09b8bef3ba56535c989c641d504386656d6f907d",
            "/paper/Approaches-Toward-Physical-and-General-Video-Kart-Cohen/8d6d799d6723a751b8808ab783d223671f89e552",
            "/paper/Extrinsic-Behavior-Prediction-of-Pedestrians-via-Ghadi-Akhter/2ddda82f40b6b1509402385e379e1b422aa55fd8",
            "/paper/Multimedia-Datasets-for-Anomaly-Detection%3A-A-Review-Kumari-Bedi/681ea93c2c87766551fadd807f9b882f1b7e6fa8",
            "/paper/Multimodal-Video-Understanding-using-Graph-Neural-Singh-Gupta/0b27accabd084450c88b356202ef409b5afe414d",
            "/paper/Multimedia-Datasets-for-Anomaly-Detection%3A-A-Survey-Kumari-Bedi/0c24e6fcd3d1cc4242e94eb702aeca2a6b0f4df4",
            "/paper/Human-Body-3D-Reconstruction-and-Gait-Analysis-via-Akhter-Hafeez/c688a1fdf4646f306dec15c3c3650f09f55e83df",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/Stan%3A-Spatio-Temporal-Adversarial-Networks-for-Lee-Kim/1df6db34c477aa43218f2efc4ec5458eaf734849",
            "/paper/Graph-Convolutional-Label-Noise-Cleaner%3A-Train-a-Zhong-Li/a03bda078490e8ee991a1f86b53f27df7cf93a14",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Self-Trained-Deep-Ordinal-Regression-for-End-to-End-Pang-Yan/a4c94b221062d0737ee967affa80ce2110cc50c0",
            "/paper/Cloze-Test-Helps%3A-Effective-Video-Anomaly-Detection-Yu-Wang/96d7a07237e146c28173767dfc6290a337696c04",
            "/paper/Scene-Aware-Context-Reasoning-for-Unsupervised-in-Sun-Jia/e4667dab1f686537b66806b9061275f8ee1eba85",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/A-Deep-One-Class-Neural-Network-for-Anomalous-Event-Wu-Liu/355b4e74774798c177c82943eef925d66a2bb2ce"
        ]
    },
    {
        "id": "1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
        "title": "Medical Transformer: Gated Axial-Attention for Medical Image Segmentation",
        "abstract": "A Gated Axial-Attention model is proposed which extends the existing architectures by introducing an additional control mechanism in the self-attention module and achieves better performance than the convolutional and other related transformer-based architectures. Over the past decade, Deep Convolutional Neural Networks have been widely adopted for medical image segmentation and shown to achieve adequate performance. However, due to the inherent inductive biases present in the convolutional architectures, they lack understanding of long-range dependencies in the image. Recently proposed Transformer-based architectures that leverage self-attention mechanism encode long-range dependencies and learn representations that are highly expressive. This motivates us to explore Transformer-based solutions and study the feasibility of using Transformer-based network architectures for medical image segmentation tasks. Majority of existing Transformer-based network architectures proposed for vision applications require large-scale datasets to train properly. However, compared to the datasets for vision applications, for medical imaging the number of data samples is relatively low, making it difficult to efficiently train transformers for medical applications. To this end, we propose a Gated Axial-Attention model which extends the existing architectures by introducing an additional control mechanism in the self-attention module. Furthermore, to train the model effectively on medical images, we propose a Local-Global training strategy (LoGo) which further improves the performance. Specifically, we operate on the whole image and patches to learn global and local features, respectively. The proposed Medical Transformer (MedT) is evaluated on three different medical image segmentation datasets and it is shown that it achieves better performance than the convolutional and other related transformer-based architectures. Code: https://github.com/jeya-maria-jose/Medical-Transformer",
        "publication_year": "2021",
        "authors": [
            "Jeya Maria Jose Valanarasu",
            "Poojan Oza",
            "I. Hacihaliloglu",
            "Vishal M. Patel"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "386",
        "reference_count": "46",
        "references": [
            "/paper/Pyramid-Medical-Transformer-for-Medical-Image-Zhang-Sun/c3dff4eb8c0ec1cbe6fc0db17522cc26bb693dac",
            "/paper/DS-TransUNet%3A-Dual-Swin-Transformer-U-Net-for-Image-Lin-Chen/6feecbba7eacf002edeee797db2704d15ffbda1b",
            "/paper/Swin-Unet%3A-Unet-like-Pure-Transformer-for-Medical-Cao-Wang/ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "/paper/UNETR%3A-Transformers-for-3D-Medical-Image-Hatamizadeh-Yang/7519a1e9e7371df79bd8a21cee871feb0ec597a5",
            "/paper/TransCrowd%3A-Weakly-Supervised-Crowd-Counting-with-Liang-Chen/ba66adf1b73793c46dbcd39cfbe0f244a881e0ad",
            "/paper/SpecTr%3A-Spectral-Transformer-for-Hyperspectral-Yun-Wang/eaeb6e0fb32626677018fa94d452e06bcb8e24f6",
            "/paper/Simultaneous-Face-Hallucination-and-Translation-for-Immidisetti-Hu/d27eac86c86a953a5b1ad13f7c7bc9d5fb127837",
            "/paper/Multiscale-Vision-Transformers-Fan-Xiong/18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6",
            "/paper/Analogous-to-Evolutionary-Algorithm%3A-Designing-a-Zhang-Xu/2ac218e12afb4959c00839c5723b175fbcc9e87c",
            "/paper/Water%E2%80%93Land-Segmentation-via-Structure-Aware-Network-Zhou-Yang/aeed5c63744cc11ebaa4c52517e7d76a543d316d",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/Multi-Scale-Self-Guided-Attention-for-Medical-Image-Sinha-Dolz/00a43fd83bef341da691695dc9acd3c9f6c4338f",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/KiU-Net%3A-Overcomplete-Convolutional-Architectures-Valanarasu-Sindagi/380f9376e00ae9e56c79c1bef7e4e3a10ae75365",
            "/paper/Attention-U-Net%3A-Learning-Where-to-Look-for-the-Oktay-Schlemper/ae1c89817a3a239e5344293138bdd80293983460",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/UNet-3%2B%3A-A-Full-Scale-Connected-UNet-for-Medical-Huang-Lin/0b444f74dd9cc06c2833dd15f9258ef5e169e6ea",
            "/paper/Axial-Attention-in-Multidimensional-Transformers-Ho-Kalchbrenner/366244acdd930e488ae224ab6e2a92dc24aa7e06",
            "/paper/Volumetric-Attention-for-3D-Medical-Image-and-Wang-Han/c42eceea279e7a95dce87b56d8f8792f98325f45"
        ]
    },
    {
        "id": "929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
        "title": "DCAN: Deep contour\u2010aware networks for object instance segmentation from histology images",
        "abstract": "Semantic Scholar extracted view of \"DCAN: Deep contour\u2010aware networks for object instance segmentation from histology images\" by Hao Chen et al.",
        "publication_year": "2017",
        "authors": [
            "Hao Chen",
            "Xiaojuan Qi",
            "Lequan Yu",
            "Q. Dou",
            "J. Qin",
            "P. Heng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "361",
        "reference_count": "88",
        "references": [
            "/paper/A-general-deep-learning-framework-for-neuron-based-Wu-Souedet/0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
            "/paper/MIU-Net%3A-MIX-Attention-and-Inception-U-Net-for-Li-Li/50f94d7225158d6ec467aca927b2d533a478512c",
            "/paper/Micro%E2%80%90Net%3A-A-unified-model-for-segmentation-of-in-Raza-Cheung/5e1335f1cf45fb4c29a0697f65c1e5c8e26d7dd4",
            "/paper/SAMS-NET%3A-Stain-aware-multi-scale-network-for-in-Graham-Rajpoot/7058f9b5e86fe98d5014ff74400cb4e7cc1e5af8",
            "/paper/InsMix%3A-Towards-Realistic-Generative-Data-for-Lin-Wang/15f43d9d78d4ea9ea4c3ee3c929640c258653d07",
            "/paper/Robust-nuclei-segmentation-in-histopathology-using-Wan-Zhao/9a5356d74076b7e1b8a7bcb0e459fc923abafb27",
            "/paper/Strategies-to-Reduce-the-Expert-Supervision-for-of-Eycke-Foucart/e8ba771b0a7028dcbe30ff31f640a68961019c55",
            "/paper/Review-of-Histopathological-Image-Segmentation-via-Dabass-Vig/7256aed0fbfb4df74f3831a9bbad3a5b89a1cc2f",
            "/paper/Nuclear-Instance-Segmentation-Using-a-Proposal-Free-Koohbanani-Jahanifar/78079ff363b4b7ecc1d03b88be69e526668432ec",
            "/paper/Deeply-Self-Supervising-Edge-to-Contour-Neural-to-Chung-Lee/25dcad21b45a7a5a5fd24ab195140e96241d6f4d",
            "/paper/DCAN%3A-Deep-Contour-Aware-Networks-for-Accurate-Chen-Qi/ba124bbde8d114a9103eb5751036e2e4710e2fff",
            "/paper/Iterative-Multi-domain-Regularized-Deep-Learning-Chen-Zheng/ccb0d384ed0a8d4223a771421a394bf87ba39ccb",
            "/paper/Locality-Sensitive-Deep-Learning-for-Detection-and-Sirinukunwattana-Raza/6605814a6a0abac781bd8c15549f19a1aa958a52",
            "/paper/Semantic-Segmentation-of-Colon-Glands-with-Deep-and-Kainz-Pfeiffer/807ae6760d799acae11c0b8cab5326ef0597c5a2",
            "/paper/Gland-Instance-Segmentation-by-Deep-Multichannel-Xu-Li/4092d01c4d069bd9102d0bd5b5bf1f9bb3092a65",
            "/paper/Mitosis-Detection-in-Breast-Cancer-Histology-Images-Chen-Dou/bed1bcdf96bdd3bc56e80fe769e87f12ad6b2e6b",
            "/paper/Stacked-Sparse-Autoencoder-(SSAE)-for-Nuclei-on-Xu-Xiang/8ad3263bf71ffae41fbb777d600ef1e3e8689bb6",
            "/paper/Automatic-Lymph-Node-Cluster-Segmentation-Using-and-Nogues-Lu/77d2b5423e591585f07bc5c0b27c59024fc91962",
            "/paper/3D-Deeply-Supervised-Network-for-Automatic-Liver-CT-Dou-Chen/9e2d1a10e5732c1d9efca5ec72193a3252869b02",
            "/paper/DeepOrgan%3A-Multi-level-Deep-Convolutional-Networks-Roth-Lu/ca29aaab1ecdd80120b80a405ecec530ec4d63a8"
        ]
    },
    {
        "id": "a9c564185882bc9dd2b7becfc6928407bf1089b2",
        "title": "Adversarial Stain Transfer for Histopathology Image Analysis",
        "abstract": "A discriminative image analysis model equipped with a stain normalization component that transfers stains across datasets is designed, which achieves superior results in terms of accuracy and quality of normalized images compared to various baselines. It is generally recognized that color information is central to the automatic and visual analysis of histopathology tissue slides. In practice, pathologists rely on color, which reflects the presence of specific tissue components, to establish a diagnosis. Similarly, automatic histopathology image analysis algorithms rely on color or intensity measures to extract tissue features. With the increasing access to digitized histopathology images, color variation and its implications have become a critical issue. These variations are the result of not only a variety of factors involved in the preparation of tissue slides but also in the digitization process itself. Consequently, different strategies have been proposed to alleviate stain-related tissue inconsistencies in automatic image analysis systems. Such techniques generally rely on collecting color statistics to perform color matching across images. In this work, we propose a different approach for stain normalization that we refer to as stain transfer. We design a discriminative image analysis model equipped with a stain normalization component that transfers stains across datasets. Our model comprises a generative network that learns data set-specific staining properties and image-specific color transformations as well as a task-specific network (e.g., classifier or segmentation network). The model is trained end-to-end using a multi-objective cost function. We evaluate the proposed approach in the context of automatic histopathology image analysis on three data sets and two different analysis tasks: tissue segmentation and classification. The proposed method achieves superior results in terms of accuracy and quality of normalized images compared to various baselines.",
        "publication_year": "2018",
        "authors": [
            "A. Bentaieb",
            "G. Hamarneh"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "150",
        "reference_count": "36",
        "references": [
            "/paper/Stain-Adaptive-Self-Supervised-Learning-for-Image-Ye-Wang/78e82653b2da81541350dc0616372ac5a45b683a",
            "/paper/Pix2Pix-based-Stain-to-Stain-Translation%3A-A-for-in-Salehi-Chalechale/da663cac292b8c6e714ee8ee9300cb3bc35e16d5",
            "/paper/Adversarial-Stain-Transfer-to-Study-the-Effect-of-Wu-Souedet/3379d2fb4f23b19cfcf0d6ed4b246b7f724a7122",
            "/paper/Histopathology-stain-color-normalization-using-deep-Zanjani-Zinger/e4729ac7bfdb707e3207b0a91b57a2f907f5351b",
            "/paper/Unsupervised-Domain-Adaptation-for-Classification-Ren-Hacihaliloglu/299fd96bd856c0ae4391a8c0348dd0b885e767ec",
            "/paper/The-role-of-unpaired-image-to-image-translation-for-Altini-Marvulli/e7155f21263042383036a283b46128ba4a49a581",
            "/paper/A-Fast-Texture-to-Stain-Adversarial-Stain-Network-Jia-Guo/fbf7dce2ee7b06e6b56e35e3ee0b0d1be8468ba8",
            "/paper/Stain-Style-Transfer-Using-Transitive-Adversarial-Cai-Xue/76e18a25cc01010cc6de76ca2e83967a422542da",
            "/paper/Multi-domain-stain-normalization-for-digital-A-for-Hetz-Bucher/7ff1912b10d5886545d74f54b6cbe4ae8df9d382",
            "/paper/Generative-Adversarial-Networks-in-Digital-and-A-Jose-Liu/5d90bf78c959be9821ad4e0fcb83d575e98d495c",
            "/paper/A-Nonlinear-Mapping-Approach-to-Stain-Normalization-Khan-Rajpoot/0eac0ed2c87910dbb7d9f622854efb7c7b7b6f0b",
            "/paper/EM-based-segmentation-driven-color-standardization-Basavanhally-Madabhushi/1ebe0ec51f314a345b02edf839b2bad69c4219eb",
            "/paper/Structure-Preserving-Color-Normalization-and-Sparse-Vahadane-Peng/a243c7bbd2affd548e18a35dadf0313c1b2198c2",
            "/paper/Stain-Specific-Standardization-of-Whole-Slide-Bejnordi-Litjens/2729d2918978d5ed602aa843fbdd027d83e0036f",
            "/paper/Quantitative-analysis-of-stain-variability-in-and-Bejnordi-Timofeeva/e39a5aa36977c617a9caecb6da5c87e27886ad6f",
            "/paper/A-Review-on-Color-Normalization-and-Color-Methods-Onder-Zengin/c176210be9ae5506e139605dc0b5145ffb5c7136",
            "/paper/Histopathological-Image-Analysis%3A-A-Review-Gurcan-Boucheron/bd898f483476e3dcacf83cd85efc64e6319da0e1",
            "/paper/Image-analysis-and-machine-learning-in-digital-and-Madabhushi-Lee/c767fbf94ae063f91fbf14b511bbb21664a394bf",
            "/paper/Colour-Normalisation-in-Digital-Histopathology-Magee-Treanor/8efdf7bc5e765673feae964735a9ebd1312e8b99",
            "/paper/Colour-in-digital-pathology%3A-a-review-Clarke-Treanor/2e457079a643f399fe9a82160c3e34eca5bb9258"
        ]
    },
    {
        "id": "77873e0843113d5465417f5309f5ae258af52a6f",
        "title": "Representation Learning of Histopathology Images using Graph Neural Networks",
        "abstract": "A two-stage framework for WSI representation learning using graph neural networks to learn relations among sampled patches to aggregate the image information into a single vector representation and introduces attention via graph pooling to automatically infer patches with higher relevance. Representation learning for Whole Slide Images (WSIs) is pivotal in developing image-based systems to achieve higher precision in diagnostic pathology. We propose a two-stage framework for WSI representation learning. We sample relevant patches using a color-based method and use graph neural networks to learn relations among sampled patches to aggregate the image information into a single vector representation. We introduce attention via graph pooling to automatically infer patches with higher relevance. We demonstrate the performance of our approach for discriminating two sub-types of lung cancers, Lung Adenocarcinoma (LUAD) & Lung Squamous Cell Carcinoma (LUSC). We collected 1,026 lung cancer WSIs with the 40\u00d7 magnification from The Cancer Genome Atlas (TCGA) dataset, the largest public repository of histopathology images and achieved state-of-the-art accuracy of 88.8% and AUC of 0.89 on lung cancer sub-type classification by extracting features from a pre-trained DenseNet model.",
        "publication_year": "2020",
        "authors": [
            "Mohammed Adnan",
            "S. Kalra",
            "H. Tizhoosh"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "48",
        "reference_count": "34",
        "references": [
            "/paper/A-deep-learning-based-graph-transformer-for-whole-Zheng-Gindra/c626c7c6fdf0f7b0e23dd42e9ff1fc6d1d8c5326",
            "/paper/A-Survey-on-Graph-Based-Deep-Learning-for-Ahmedt-Aristizabal-Armin/70727c82f1ab97b3f64ee3e81e6e209c40fa0a02",
            "/paper/A-Graph-Transformer-for-Whole-Slide-Image-Zheng-Gindra/e2c16ffbb1a590d8cc04f7bfbe080b611484a75e",
            "/paper/Multi-Scale-Relational-Graph-Convolutional-Network-Bazargani-Fazli/a3e36619f167b9ae2f1b9162a5a270966b86c5cd",
            "/paper/Topological-Feature-Extraction-and-Visualization-of-Levy-Haudenschild/322a90333cd2ca86d559641c37c8cd0eb1428560",
            "/paper/A-Convolutional-Neural-Network-and-Graph-Network-of-Gao-Lu/8bc9516bbd2bdec86d882c533a0c6853e2011c2c",
            "/paper/Context-Aware-Self-Supervised-Learning-of-Whole-Aryal-Yahyasoltani/cad483ac27725e769bba0cf576c1eb6d828fa68d",
            "/paper/A-self-supervised-contrastive-learning-approach-for-Fashi-Hemati/13e05e18964c7cc7221149125364a075e57cf1fe",
            "/paper/Learning-Permutation-Invariant-Representations-Kalra-Adnan/37078710fc9148fe539b53c6a54a4e86e4407d29",
            "/paper/Generating-Hypergraph-Based-High-Order-of-Images-Di-Zou/56c63032a3ad764dbd24c3777005d3c0fd2b00a1",
            "/paper/Histographs%3A-Graphs-in-Histopathology-Gadiya-Anand/d9ba3644714b249be7d89e848d7ec5b0eb5d4aa5",
            "/paper/Classification-and-mutation-prediction-from-cell-Coudray-Ocampo/769149c0dc0ed308eca8bc916f4326b2e2f57a1f",
            "/paper/Deep-Convolutional-Neural-Networks-Enable-of-Images-Khosravi-Kazemi/bd6f783022ebd6704ff34f6bf824ef1cb1ad0cee",
            "/paper/Multiple-instance-learning-for-histopathological-Sudharshan-Petitjean/7bfc41af5653255df067395928f164210f71d7f9",
            "/paper/Pan-cancer-diagnostic-consensus-through-searching-Kalra-Tizhoosh/70c403c8ef04d1b63358df4532f0587c1637a620",
            "/paper/Predicting-non-small-cell-lung-cancer-prognosis-by-Yu-Zhang/94087ad5ed11555c260a42f2f9ca9da183c6f87e",
            "/paper/Classification-of-lung-cancer-histology-images-Graham-Shaban/77e07e0576d27cb60e0b0eafbf4a2e3997eab250",
            "/paper/Deep-Learning-with-Permutation-invariant-Operator-Tomczak-Ilse/82deacec91ccd7b94e416a047e133c8ee34fbfe6",
            "/paper/Automated-classification-of-brain-tumor-type-in-Barker-Hoogi/8d82925550395b5b545eae4475222b215ad149fb",
            "/paper/Deep-multiple-instance-learning-for-digital-Ilse-Tomczak/2d5cc6d5c8a30ba13c8645fc3f38ea5ad1882b3e"
        ]
    },
    {
        "id": "5ea7d1e0934876fac06c7ca6f5f56dbc57f133d9",
        "title": "Ensembles of Convolutional Neural Networks and Transformers for Polyp Segmentation",
        "abstract": "This work provides a review of the literature on deep ensemble learning models for polyp segmentation and develops new ensembles based on convolutional neural networks and transformers and introduces a new method to obtain the segmentation mask by averaging intermediate masks after the sigmoid layer. In the realm of computer vision, semantic segmentation is the task of recognizing objects in images at the pixel level. This is done by performing a classification of each pixel. The task is complex and requires sophisticated skills and knowledge about the context to identify objects\u2019 boundaries. The importance of semantic segmentation in many domains is undisputed. In medical diagnostics, it simplifies the early detection of pathologies, thus mitigating the possible consequences. In this work, we provide a review of the literature on deep ensemble learning models for polyp segmentation and develop new ensembles based on convolutional neural networks and transformers. The development of an effective ensemble entails ensuring diversity between its components. To this end, we combined different models (HarDNet-MSEG, Polyp-PVT, and HSNet) trained with different data augmentation techniques, optimization methods, and learning rates, which we experimentally demonstrate to be useful to form a better ensemble. Most importantly, we introduce a new method to obtain the segmentation mask by averaging intermediate masks after the sigmoid layer. In our extensive experimental evaluation, the average performance of the proposed ensembles over five prominent datasets beat any other solution that we know of. Furthermore, the ensembles also performed better than the state-of-the-art on two of the five datasets, when individually considered, without having been specifically trained for them.",
        "publication_year": "2023",
        "authors": [
            "L. Nanni",
            "C. Fantozzi",
            "Andrea Loreggia",
            "A. Lumini"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "77",
        "references": [
            "/paper/An-Empirical-Study-on-Ensemble-of-Segmentation-Nanni-Lumini/315635d267ba033b0ba66de398d925edb38549a8",
            "/paper/Deep-ensembles-based-on-Stochastic-Activation-for-Lumini-Nanni/1f249c7824dcd68013851fb6ec1a9a825b80e9b8",
            "/paper/Robust-Boundary-Segmentation-in-Medical-Images-a-Nguyen-Lee/0b25744e1a88e5746d8b442b2072c62073e1925a",
            "/paper/Deep-ensembles-in-bioimage-segmentation-Nanni-Cuza/227a9738447669f973ffa61d6bf8ba513c92e467",
            "/paper/Improving-Generalizability-in-Polyp-Segmentation-Tomar-Ibtehaz/351acb62d197a17a713720a7a0ba8e12c05e31d7",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/TransFuse%3A-Fusing-Transformers-and-CNNs-for-Medical-Zhang-Liu/20db2a2fadcf563a2d522aabc440b6b4f3ee46f4",
            "/paper/Deep-ensembles-based-on-Stochastic-Activations-for-Lumini-Nanni/1dc7195e6460d5949f1f80128ba6369030da3df4",
            "/paper/Image-Segmentation-Using-Deep-Learning%3A-A-Survey-Minaee-Boykov/712e32e2da67428ba6c6add1605410e1c3792883"
        ]
    },
    {
        "id": "a822077fa6047efcff467d396aa9c8562e5fb6a9",
        "title": "SLRFormer: Continuous Sign Language Recognition Based on Vision Transformer",
        "abstract": "A novel vision transformer-based sign language recognition network combined with the off-frame extraction (KFE) module for accurate end-to-end recognition of input video sequences and a substantial degree of redundancy in the sign language data is discovered. Human-Robot interaction (HRI) usually focuses on the interaction between normal people and robots, ignoring the needs of deaf-mute people. Deaf-mute individuals utilize sign language to communicate their thoughts and emotions. Therefore, continuous sign language recognition (CSLR) can be introduced to the robot for communicating with deaf-mute people. However, the mainstream CSLR, which consists of two main modules, i.e., visual feature extraction and contextual modeling, has several problems. Visual features are usually extracted frame-by-frame and lack global contextual information, which results in a crucial impact on subsequent context modeling. In addition, we discovered a substantial degree of redundancy in the sign language data, which can significantly slow down model training and exacerbate the problem of model overfitting. To solve these problems, in this paper, we propose a novel vision transformer-based sign language recognition network combined with the off-frame extraction (KFE) module for accurate end-to-end recognition of input video sequences. Two CSLR benchmarks, TJUT-SLRT and USTC-CSL, have been the subject of our experiments. The outcomes of our experiments illustrate the efficacy of our method.",
        "publication_year": "2022",
        "authors": [
            "Feng Xiao",
            "Ruyu Liu",
            "Tiantian Yuan",
            "Zhimin Fan",
            "Jiajia Wang",
            "Jianhua Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "29",
        "references": [
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e",
            "/paper/Self-Mutual-Distillation-Learning-for-Continuous-Hao-Min/609d68085efa9b1da1068639e4850252cc0cf6ae",
            "/paper/CRB-Net%3A-A-Sign-Language-Recognition-Deep-Learning-Xiao-Shen/5106e4f5e3e6fbc3a183d4dec21f5d72e64d9264",
            "/paper/Context-Matters%3A-Self-Attention-for-Sign-Language-Slimane-Bouguessa/33850edc37e06732f843aa0aaaadb572023f4634",
            "/paper/Visual-Alignment-Constraint-for-Continuous-Sign-Min-Hao/2d2d5bb1d025c5e17abe13716599c93e1f131927",
            "/paper/Boosting-Continuous-Sign-Language-Recognition-via-Pu-Zhou/ce50fa888551b640fe3dddc57289c27f325c029b",
            "/paper/Online-Early-Late-Fusion-Based-on-Adaptive-HMM-for-Guo-Zhou/2871cb56a9a8b0dfe882d16996defec0a0e0732b",
            "/paper/A-Deep-Neural-Framework-for-Continuous-Sign-by-Cui-Liu/f96ffd8c71b97e46eb3ba48263c9012d197494d4",
            "/paper/Hierarchical-Recurrent-Deep-Fusion-Using-Adaptive-Guo-Zhou/a97b13151ee3b3ddfc6f17c3cc04eaf827f00341",
            "/paper/Iterative-Alignment-Network-for-Continuous-Sign-Pu-Zhou/714df3e97817ec56b8dbc7217155adadf2a0487f"
        ]
    },
    {
        "id": "f80a77c7800b10a3ef83ab7cac51e42b14ff5a15",
        "title": "PanNuke Dataset Extension, Insights and Baselines",
        "abstract": "This work study the performance of segmentation and classification models when applied to the proposed dataset and demonstrate the application of models trained on PanNuke to whole-slide images. The emerging area of computational pathology (CPath) is ripe ground for the application of deep learning (DL) methods to healthcare due to the sheer volume of raw pixel data in whole-slide images (WSIs) of cancerous tissue slides. However, it is imperative for the DL algorithms relying on nuclei-level details to be able to cope with data from `the clinical wild', which tends to be quite challenging. \nWe study, and extend recently released PanNuke dataset consisting of ~200,000 nuclei categorized into 5 clinically important classes for the challenging tasks of segmenting and classifying nuclei in WSIs. Previous pan-cancer datasets consisted of only up to 9 different tissues and up to 21,000 unlabeled nuclei and just over 24,000 labeled nuclei with segmentation masks. PanNuke consists of 19 different tissue types that have been semi-automatically annotated and quality controlled by clinical pathologists, leading to a dataset with statistics similar to the clinical wild and with minimal selection bias. We study the performance of segmentation and classification models when applied to the proposed dataset and demonstrate the application of models trained on PanNuke to whole-slide images. We provide comprehensive statistics about the dataset and outline recommendations and research directions to address the limitations of existing DL tools when applied to real-world CPath applications.",
        "publication_year": "2020",
        "authors": [
            "Jevgenij Gamper",
            "Navid Alemi Koohbanani",
            "S. Graham",
            "M. Jahanifar",
            "S. A. Khurram",
            "A. Azam",
            "K. Hewitt",
            "N. Rajpoot"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "74",
        "reference_count": "51",
        "references": [
            "/paper/Lizard%3A-A-Large-Scale-Dataset-for-Colonic-Nuclear-Graham-Jahanifar/2e71e26bb816c6729e955e3c9e2b1c14906e73b4",
            "/paper/PointNu-Net%3A-Keypoint-assisted-Convolutional-Neural-Yao-Huang/35996e1b1f34985ab10cdb07163f00c50a23d8d4",
            "/paper/A-Large-scale-Synthetic-Pathological-Dataset-for-of-Ding-Zhou/3499afedecabd747d913bb184721b6a4e82dca59",
            "/paper/PointNu-Net%3A-Simultaneous-Multi-tissue-Histology-in-Yao-Huang/c7461acf6deb778cbc21cde4ca341bef51c9adba",
            "/paper/MoNuSAC2020%3A-A-Multi-Organ-Nuclei-Segmentation-and-Verma-Kumar/9e166d301097ab2755918a82379527161c522d4d",
            "/paper/NuCLS%3A-A-scalable-crowdsourcing-approach-and-for-in-Amgad-Atteya/bf993ea34b71addffad744fc57d28da70f4157cb",
            "/paper/NuClick%3A-A-Deep-Learning-Framework-for-Interactive-Koohbanani-Jahanifar/48d0975ff581640b970d29b84af95cdd04e63f11",
            "/paper/TSHVNet%3A-Simultaneous-Nuclear-Instance-Segmentation-Chen-Jia/bbd8077eb30e29af29b06fbbdfce4b8c75d03f24",
            "/paper/CA-Net%3A-Context-Aggregation-Network-for-Nuclei-in-Xiao-Qu/718f074cf42574450afcaf85935cc4bc35deeeb8",
            "/paper/A-Pragmatic-Machine-Learning-Approach-to-Quantify-Shvetsov-Gr%C3%B8nnesby/7892a557922ec919fafe67ca3240ae2dbfe900a6",
            "/paper/Terabyte-scale-Deep-Multiple-Instance-Learning-for-Campanella-Silva/52df0f3f7d765380370c87faf4e45596bf6c09d7",
            "/paper/PanNuke%3A-An-Open-Pan-Cancer-Histology-Dataset-for-Gamper-Koohbanani/b218b13756f3aacadf5f06d09652058d024dc9d4",
            "/paper/A-Multi-Organ-Nucleus-Segmentation-Challenge-Kumar-Verma/87c0dd990287d92796c7dc83edba6f52a2f52e21",
            "/paper/HistoSegNet%3A-Semantic-Segmentation-of-Histological-Chan-Hosseini/f77ae2f69b7432d9505d737c6209661f7be1eeb4",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Atlas-of-Digital-Pathology%3A-A-Generalized-Tissue-Hosseini-Chan/883a659062b3412747ea9b2f72539cc63dfca709",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/Locality-Sensitive-Deep-Learning-for-Detection-and-Sirinukunwattana-Raza/6605814a6a0abac781bd8c15549f19a1aa958a52",
            "/paper/Invariant-Delineation-of-Nuclear-Architecture-in-Chang-Han/930b28f5255a6633ec89bdafb9f72af8e9148fac"
        ]
    },
    {
        "id": "c89bfd998b0a6c656010b629814ab0cad3cff72e",
        "title": "Evaluation of Deep Learning Strategies for Nucleus Segmentation in Fluorescence Images",
        "abstract": "This work presents an evaluation framework to measure accuracy, types of errors, and computational efficiency; and uses it to compare two deep learning strategies (U-Net and DeepCell) alongside a classical approach implemented in CellProfiler. Identifying nuclei is often a critical first step in analyzing microscopy images of cells, and classical image processing algorithms are most commonly used for this task. Recent developments in deep learning can yield superior accuracy, but typical evaluation metrics for nucleus segmentation do not satisfactorily capture error modes that are relevant in cellular images. Besides, large image data sets with ground truth for evaluation have been limiting. We present an evaluation framework to measure accuracy, types of errors, and computational efficiency; and use it to compare two deep learning strategies (U-Net and DeepCell) alongside a classical approach implemented in CellProfiler. We publicly release a set of 23,165 manually annotated nuclei and source code to reproduce experiments. Our results show that U-Net outperforms both pixel-wise classification networks and classical algorithms. Also, our evaluation framework shows that deep learning improves accuracy and reduces the number of biologically relevant errors by half.",
        "publication_year": "2018",
        "authors": [
            "Juan C. Caicedo",
            "J. Roth",
            "A. Goodman",
            "T. Becker",
            "Kyle W. Karhohs",
            "C. McQuin",
            "Shantanu Singh",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "207",
        "reference_count": "54",
        "references": [
            "/paper/Evaluating-Very-Deep-Convolutional-Neural-Networks-Ali-Misko/69bce314f35a83b83665b0bb03b3a165c58e0edc",
            "/paper/An-Auxiliary-Task-for-Learning-Nuclei-Segmentation-Hirsch-Kainmueller/40071396490823a1f110911ee314c8bdb6aea813",
            "/paper/Practical-segmentation-of-nuclei-in-brightfield-on-Fishman-Salumaa/9ff52e99a1246b5b65bed186bce559e2152ca3f3",
            "/paper/EVICAN%E2%80%94a-balanced-dataset-for-algorithm-development-Schwendy-Unger/3af9f90488ef3333d55f8785fd95f63b3c3bf9e7",
            "/paper/Deep-Learning-architectures-for-generalized-based-Kromp-Fischer/c1f68f43973e9312bd35420d3c25e79375f3b520",
            "/paper/Benchmarking-of-deep-learning-algorithms-for-3D-of-Kar-Petit/3d157f03484d913cbdb2463b8bc33fc4266c42d6",
            "/paper/Application-of-convolutional-neural-networks-nuclei-Mela-Liu/65389e7ab951a21fd0610236ae84f0cd48941860",
            "/paper/Combining-Deep-Learning-with-Handcrafted-Features-*-Narotamo-Sanches/6b5b67dc4c2d4925ba7f182c8adc5606abbb454e",
            "/paper/Microscopy-cell-nuclei-segmentation-with-enhanced-Long/75bdaacf355d0a6d52d9a4a8790e1fdc936eb867",
            "/paper/ASW-Net%3A-A-Deep-Learning-based-Tool-for-Cell-of-Pan-Liu/c7c1b005a042e52be8523ddf0d26941a242d5402",
            "/paper/Deep-Learning-Automates-the-Quantitative-Analysis-Valen-Kudo/e1b3ad532f9346d51578c32dc6b070c9744a8d88",
            "/paper/An-Automatic-Learning-Based-Framework-for-Robust-Xing-Xie/d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88",
            "/paper/Detection-and-Segmentation-of-Cell-Nuclei-in-A-Wienert-Heim/68f30bd22817a17adc837eb285e51c9628f00e8d",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Comparison-of-segmentation-algorithms-for-images-of-Dima-Elliott/cdecac6e2f578cfc56140e00aaa74a78f864fea2",
            "/paper/Accurate-Morphology-Preserving-Segmentation-of-on-Molnar-Jermyn/318f82a3e593e391cfd0da7964b16d83299aa943",
            "/paper/U-Net%3A-deep-learning-for-cell-counting%2C-detection%2C-Falk-Mai/779b489971775507fe6a39d98c52c4df56d9cce1",
            "/paper/A-high%E2%80%90throughput-system-for-segmenting-nuclei-Gudla-Nandy/1268de7bda769e651dc6c089d006c7edbe37f563",
            "/paper/CellProfiler-3.0%3A-Next-generation-image-processing-McQuin-Goodman/713e881b5c3134debf934026edf6f0ba3cb42c3c",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0"
        ]
    },
    {
        "id": "139f1748e12275bc52b34579b77f2e75e9d043d3",
        "title": "MRI findings of lesions in the cerebellopontine angle",
        "abstract": "MRI can be used as the first choice for detecting the CPA tumors, and it has a high value in the diagonosis and differential diagnosis of C PA tumors. Objective To investigate the MRI features of lesions in the cerebellopontine angle.Methods 83patients with lesions in the CPA were confirmed by pathology,the MR imaging features of them were analysed.Results In 83cases,50cases were acoustic neuroma,13cases were meningioma,13cases were epidermoid cyst,4cases were trigeminal neuroma,1case was arachnoid cyst,1case was strocytoma,and 1case was ependymoma.38lesions were located in the left CPA,45lesions were located in the right CPA.Compared with pathological results,the accuracy rates of location and qualitative diagnosis were 98.8% and 95.2%.Conclusion MRI can be used as the first choice for detecting the CPA tumors,and it has a high value in the diagonosis and differential diagnosis of CPA tumors.",
        "publication_year": "2014",
        "authors": [
            "Ping Xiao-xi"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": 0,
        "references": [
            "/paper/Accurate-segmentation-algorithm-of-acoustic-neuroma-Zhang-Zhang/2fc4c2b52f2b9becb63915af6b8f1cddda63331e"
        ]
    },
    {
        "id": "71f3b720e7bd9d26488a5fa323b7b3d1c6890353",
        "title": "Assessing Surgical Approaches for Acoustic Neuroma Resection: Do Patients Perceive a Difference in Quality-of-Life Outcomes?",
        "abstract": "A lack of association between patient response on hearing PANQOL and surgical approach illustrates the impact of preoperative patient counseling in appropriately setting patient expectations after surgical acoustic neuroma resection. Objective The objective of this study is to further patient-physician discussion regarding postoperative quality of life expectations after surgical acoustic neuroma resection. Study Design This study is retrospective prospective. Qualifying patients were identified and administered Penn Acoustic Neuroma Quality-of-Life (PANQOL) Scale. Setting The setting was Loyola University Chicago Health System. Patients Three hundred twenty-six patients at our center with surgically resected acoustic neuroma between January 1990 and July 2021 completed the PANQOL. Intervention(s) During postresection follow-up visits, patients were administered the PANQOL survey. Main Outcome Measure(s) The total PANQOL is comprised of questions addressing quality of life in seven domains of hearing, balance, face, energy, pain, health, and anxiety. Univariate and multivariable analyses were performed to test for associations between surgical approach and/or patient characteristics. Results Patients who were treated with retrosigmoid approach reported slightly higher PANQOL pain scores when compared with translabyrinthine approach. No association was found between responses on hearing PANQOL and surgical approach. No association was found between approach and total PANQOL score. However, on average female patients reported lower total PANQOL compared with male patients. Conclusion The lack of association between patient response on hearing PANQOL and surgical approach illustrates the impact of preoperative patient counseling in appropriately setting patient expectations. The difference in pain PANQOL response may be due to a higher rate of occipital neuralgia due to incision placement and soft tissue retraction in the retrosigmoid patient group. Surgeons may consider alternative surgical incisions and soft tissue dissection to improve patient's quality of life with respect to postoperative pain.",
        "publication_year": "2022",
        "authors": [
            "Monique North",
            "Jeffrey R. Weishaar",
            "Mohammed Nuru",
            "D. Anderson",
            "J. Leonetti"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "22",
        "references": [
            "/paper/Accurate-segmentation-algorithm-of-acoustic-neuroma-Zhang-Zhang/2fc4c2b52f2b9becb63915af6b8f1cddda63331e",
            "/paper/Patient-assessed-outcomes-after-excision-of-and-of-Martin-Sethi/7d457bbc2bde775d6b4bf81723da814b045aa8ff",
            "/paper/Acoustic-Neuroma-Surgery%3A-The-Results-of-Long-term-Chee-Nedzelski/adc56d5e838ab24975933a62a1f112add80887cb",
            "/paper/Hearing-preservation-in-the-resection-of-vestibular-Wind-Leonetti/a135408c51e0bf7ea619ae88f37287eea96aa8ee",
            "/paper/Systematic-review-of-quality-of-life-in-the-of-Gauden-Weir/ea2e2bd633917f823eba2f100acfe1df9b41edcd",
            "/paper/Cerebrospinal-fluid-leak-after-acoustic-neuroma-of-Brennan-Rowed/b04cc7e7c62a64f28b25a3742b63f6e7d99ae0df",
            "/paper/Validation-and-multidimensional-analysis-of-the-Nishiyama-Oishi/e34ad487fc5cce498ff2e1a78301e22598e4b794",
            "/paper/Morbidity-and-mortality-following-acoustic-neuroma-McClelland-Guo/0e3431af8a9b17a6c3d3da28e951f87cf71c9629",
            "/paper/Long-Term-Hearing-Preservation-After-Microsurgical-Woodson-Dempewolf/957de8517d96d464e73bb77ce2d95202ac3a9dcc",
            "/paper/Early-and-late-postoperative-hearing-preservation-Umezu-Aiba/63d913b8c6acea2232db76dac1d552244868acfd",
            "/paper/Factors-associated-with-preservation-of-facial-of-Bloch-Sughrue/5abb245c2741706c55b9578c684a1a5c7b255029"
        ]
    },
    {
        "id": "a89cf9c6aa4cad62a78421916726b8b16c0cb9f2",
        "title": "Weakly Supervised Multi-Task Learning for Cell Detection and Segmentation",
        "abstract": "An end-to-end deep learning algorithm to perform both single cell detection and segmentation using only point labels is developed through the combination of different task orientated point label encoding methods and a multi-task scheduler for training. Cell detection and segmentation is fundamental for all downstream analysis of digital pathology images. However, obtaining the pixel-level ground truth for single cell segmentation is extremely labor intensive. To overcome this challenge, we developed an end-to-end deep learning algorithm to perform both single cell detection and segmentation using only point labels. This is achieved through the combination of different task orientated point label encoding methods and a multi-task scheduler for training. We apply and validate our algorithm on PMS2 stained colon rectal cancer and tonsil tissue images. Compared to the state-of-the-art, our algorithm shows significant improvement in cell detection and segmentation without increasing the annotation efforts.",
        "publication_year": "2019",
        "authors": [
            "Alireza Chamanzar",
            "Yao Nie"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "31",
        "reference_count": "16",
        "references": [
            "/paper/D2E2-Net%3A-Double-Deep-Edge-Enhancement-for-Cell/ea1016999109a842b3c6cb33a26bd30e6396f281",
            "/paper/End-to-end-Neuron-Instance-Segmentation-based-on-Wu-Souedet/c49a547b3424f42cc290f29c4f648514efc37229",
            "/paper/A-general-deep-learning-framework-for-neuron-based-Wu-Souedet/0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
            "/paper/A-Weakly-Supervised-Method-With-Colorization-for-Xia-Qu/a5ee62db221460479384528652b18c312166e3aa",
            "/paper/Category-Separation-For-Weakly-Supervised-Cell-Cai-Zhu/baac3cd5cb1850cb714232c50aa5bd7d3a4e9591",
            "/paper/Meta-multi-task-nuclei-segmentation-with-fewer-Han-Yao/a2aa5a08ad6d5e6432f0468e077e523430cf46a1",
            "/paper/NuClick%3A-A-Deep-Learning-Framework-for-Interactive-Koohbanani-Jahanifar/48d0975ff581640b970d29b84af95cdd04e63f11",
            "/paper/Unsupervised-Dense-Nuclei-Detection-and-with-Prior-Chen-Zhu/a6d82676c10d1440ef4c19f8621fa3313a9096b5",
            "/paper/Weakly-Supervised-Nucleus-Segmentation-Based-on-A-Tian-Zhang/2af96daa1456fdb2a004f62a3fa28986e76e7fa4",
            "/paper/Multi-Class-Cell-Detection-Using-Spatial-Context-Abousamra-Belinsky/5d3fa9334df96ff26916aa3cdb750c9deb179c16",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-using-in-Qu-Wu/2b60f01e916725a8f0b5dddc44b4cb9bd3e5e8c3",
            "/paper/Joint-Segmentation-and-Fine-Grained-Classification-Qu-Riedlinger/a4387fb99253e13ef998446e33b0737f0903b269",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/An-Automatic-Learning-Based-Framework-for-Robust-Xing-Xie/d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Automatic-Nuclei-Segmentation-in-H%26E-Stained-Breast-Veta-Diest/e312652daf82ed144d1696aae7ab412030d4f7eb",
            "/paper/Enhanced-Center-Coding-for-Cell-Detection-with-Liang-Naik/70a5603dec6b400eb364f9483808df2aae45c2bd",
            "/paper/Multi-task-Learning-Using-Uncertainty-to-Weigh-for-Kendall-Gal/f98788f32b0d33d200c9bc7d900d0ef39519c927",
            "/paper/ImageNet-Large-Scale-Visual-Recognition-Challenge-Russakovsky-Deng/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd"
        ]
    },
    {
        "id": "cf2e99c821af11966bf415e8c277ae3eb9f8677c",
        "title": "Feature Encoding With Autoencoders for Weakly Supervised Anomaly Detection",
        "abstract": "This article proposes a novel strategy to transform the input data into a more meaningful representation that could be used for anomaly detection and leverages an autoencoder to encode the data and utilizes three factors, hidden representation, reconstruction residual vector, and reconstruction error, as the new representation for the inputData. Weakly supervised anomaly detection aims at learning an anomaly detector from a limited amount of labeled data and abundant unlabeled data. Recent works build deep neural networks for anomaly detection by discriminatively mapping the normal samples and abnormal samples to different regions in the feature space or fitting different distributions. However, due to the limited number of annotated anomaly samples, directly training networks with the discriminative loss may not be sufficient. To overcome this issue, this article proposes a novel strategy to transform the input data into a more meaningful representation that could be used for anomaly detection. Specifically, we leverage an autoencoder to encode the input data and utilize three factors, hidden representation, reconstruction residual vector, and reconstruction error, as the new representation for the input data. This representation amounts to encode a test sample with its projection on the training data manifold, its direction to its projection, and its distance to its projection. In addition to this encoding, we also propose a novel network architecture to seamlessly incorporate those three factors. From our extensive experiments, the benefits of the proposed strategy are clearly demonstrated by its superior performance over the competitive methods. Code is available at: https://github.com/yj-zhou/Feature_Encoding_with_AutoEncoders_for_Weakly-supervised_Anomaly_Detection.",
        "publication_year": "2021",
        "authors": [
            "Yingjie Zhou",
            "Xuchen Song",
            "Yanru Zhang",
            "Fanxing Liu",
            "Ce Zhu",
            "Lingqiao Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "35",
        "reference_count": "39",
        "references": [
            "/paper/AnoOnly%3A-Semi-Supervised-Anomaly-Detection-without-Zhou-Yang/4141b5740f8ff7464f9bbcb152b0ac7cde5d7954",
            "/paper/Cost-effective-Elderly-Fall-Detection-with-Symmetry-Li-Cui/a0589621579ef10004024a4544f28d9582d0b185",
            "/paper/Privacy-Preserving-Anomaly-Detection-in-Cloud-Via-Ma-Nie/4ca6c59584e3379908a1a87ba447811b1f1ccc02",
            "/paper/NFAD%3A-fixing-anomaly-detection-using-normalizing-Ryzhikov-Borisyak/3bf2ce96a12639491409072a2d9089a95a34b816",
            "/paper/A-Triplet-Deviation-Network-Framework%3A-Boosting-By-Ling-Pan/b2c8a5666080cc840c0bf53a0538c25c0c8c1e5a",
            "/paper/AnoRand%3A-A-Semi-Supervised-Deep-Learning-Anomaly-by-Mayaki-Riveill/2c91de722d5cbb7048c2e80a3c7676a3c576f762",
            "/paper/Autoencoders-with-Exponential-Deviation-Loss-for-Kwon-Moon/f4b296d2ded4f6ac789f98034512825874ead447",
            "/paper/Weakly-supervised-machine-learning-Ren-Wang/e432f46393b45bb146000a92d7993b6f5ebc2493",
            "/paper/Zero-shot-domain-adaptation-of-anomalous-samples-Nishida-Endo/85da2a80112d789e04ecdb69f847d30de953843a",
            "/paper/Anomaly-detection-for-blueberry-data-using-sparse-Wei-Zheng/5dc752aa4a5e1fed1ad85791fc017cb1d60c2e27",
            "/paper/Deep-Anomaly-Detection-with-Deviation-Networks-Pang-Shen/f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/Learning-Features-of-Brain-Network-for-Anomaly-Liu-Zhao/bd307d3f9c9be3785faffbf5d92af4d2494d314c",
            "/paper/Citywide-Traffic-Flow-Prediction-Based-on-Multiple-Chen-Li/8af41682af9a33f833543dc8ba70b88084c94ba4",
            "/paper/Deep-Learning-Based-Multi-Channel-Intelligent-for-Jiang-Fu/a79a3c277ef865b35ac3a674289c1b9570ec5a33",
            "/paper/Self-Trained-Deep-Ordinal-Regression-for-End-to-End-Pang-Yan/a4c94b221062d0737ee967affa80ce2110cc50c0",
            "/paper/Deep-Anomaly-Detection-in-Packet-Payload-Liu-Song/854e5eadfb692631de3fba86bf0208a2f09a28d5",
            "/paper/Deep-Weakly-supervised-Anomaly-Detection-Pang-Shen/30aa23a6a32312666f2609339582744203024993"
        ]
    },
    {
        "id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "publication_year": "2021",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "234",
        "reference_count": "65",
        "references": [
            "/paper/Just-Noticeable-Learning-for-Unsupervised-Anomaly-Zhao/57e0b6a1a47afe3d0cee58d387a7cfcd3bdd5e73",
            "/paper/CRADL%3A-Contrastive-Representations-for-Unsupervised-Luth-Zimmerer/6d27d4104738b3ee75be4ecf3ad7f527f1be2849",
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "/paper/Semi-Supervised-Anomaly-Detection-with-Contrastive-Jezequel-Vu/f088df615c52381c1e84527543b403edea4f6fe8",
            "/paper/Image-Anomaly-Detection-With-Semantic-Enhanced-and-Wang-Zhu/61eb26d960eb7b9ea45c26694eec09356773f43a",
            "/paper/Self-Trained-One-class-Classification-for-Anomaly-Yoon-Sohn/a7d75aa3a0a9faa310fb524c350fba2093b0ec97",
            "/paper/Transfer-Learning-Gaussian-Anomaly-Detection-by-Rippel-Chavan/d78f2e0d5e3040ad62d5bcd0abca8a8507bff209",
            "/paper/No-Shifted-Augmentations-(NSA)%3A-compact-for-robust-Yousef-Ackermann/1b57766d294f54fdeb453695f886686c123b23ee",
            "/paper/Self-supervise%2C-Refine%2C-Repeat%3A-Improving-Anomaly-Yoon-Sohn/b9ca44d3501a101200ecedb8812d5a2c7eebc24b",
            "/paper/Self-Supervised-Anomaly-Detection-via-Neural-Flows-Zhang-Saleeby/d0697fb970ba92e970bf39ebf25561a8fee61cd6",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/6cf1d69e447e9687dbd2d92572f44bddbabd8192",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/Modeling-the-Distribution-of-Normal-Data-in-Deep-Rippel-Mertens/37595f7a51982d776e57c7280b9445474d90f0be",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Explainable-Deep-One-Class-Classification-Liznerski-Ruff/16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Improved-anomaly-detection-by-training-an-with-skip-Collin-Vleeschouwer/206c2e79b5f1b4541b85f47517666961ed49500e",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/A-Unifying-Review-of-Deep-and-Shallow-Anomaly-Ruff-Kauffmann/30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ]
    },
    {
        "id": "ca6294ce6f38f3f6ff694ba67d02eaad7fc92f4e",
        "title": "Toward Unsupervised 3d Point Cloud Anomaly Detection Using Variational Autoencoder",
        "abstract": "This work proposes a deep variational autoencoder based unsupervised anomaly detection network adapted to the 3D point cloud and an anomaly score specifically for3D point clouds that outperforms the baseline method. In this paper, we present an end-to-end unsupervised anomaly detection framework for 3D point clouds. To the best of our knowledge, this is the first work to tackle the anomaly detection task on a general object represented by a 3D point cloud. We propose a deep variational autoencoder based unsupervised anomaly detection network adapted to the 3D point cloud and an anomaly score specifically for 3D point clouds. To verify the effectiveness of the model, we conducted extensive experiments on ShapeNet dataset. Through quantitative and qualitative evaluation, we demonstrate that the proposed method outperforms the baseline method.",
        "publication_year": "2021",
        "authors": [
            "Mana Masuda",
            "Ryo Hachiuma",
            "Ryoske Fujii",
            "H. Saito",
            "Yusuke Sekikawa"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "23",
        "references": [
            "/paper/Teacher-Student-Network-for-3D-Point-Cloud-Anomaly-Qin-Gu/35dfd96486c38d9a21b1d29e2381d72cd7928b2f",
            "/paper/Composite-Layers-for-Deep-Anomaly-Detection-on-3D-Floris-Frittoli/7d5c0ae2985e0c665cb3713aaa169ee5c7c9794f",
            "/paper/Point-Cloud-Video-Anomaly-Detection-Based-on-Point-He-Wang/31b8ea745f2f6b2c8b2fe3d6e6377aa1318e48ff",
            "/paper/Anomaly-detection-in-3D-space-for-autonomous-Master-Schilling/1e8b8a1438ca258bffd93625efba7b82845ea582",
            "/paper/Towards-Open-Set-3D-Learning%3A-A-Benchmark-on-Object-Alliegro-Borlino/bd7897e3cf57755541def9d58f7bad0601a9cb1c",
            "/paper/3DOS%3A-Towards-3D-Open-Set-Learning-Benchmarking-and-Alliegro-Borlino/5a94570cb1617133b06457f8a9099fe551e5700c",
            "/paper/Anomaly-Detection-in-Autonomous-Driving%3A-A-Survey-Bogdoll-Nitsche/e6c013c835be471502023b3f31d52d59ada76770",
            "/paper/DDR-Defense%3A-3D-Defense-Network-with-a-Detector%2C-a-Zhao-Zhang/8c6ed1fac4b9f9a2db417252dc2b2ad86224ccb7",
            "/paper/Point-GNN%3A-Graph-Neural-Network-for-3D-Object-in-a-Shi-Rajkumar/22cc76c6d9b25facb2874bbcbbbfe781a4d85bcd",
            "/paper/PointASNL%3A-Robust-Point-Clouds-Processing-Using-Yan-Zheng/40b36071bd553b9fda2ea26c6d4e057f37c0e7e7",
            "/paper/PointNet%3A-Deep-Learning-on-Point-Sets-for-3D-and-Qi-Su/d997beefc0922d97202789d2ac307c55c2c52fba",
            "/paper/FoldingNet%3A-Point-Cloud-Auto-Encoder-via-Deep-Grid-Yang-Feng/572a5aa00f0569887469ffb7554699c21156ba0b",
            "/paper/Mining-Point-Cloud-Local-Structures-by-Kernel-and-Shen-Feng/5eb4a5ac7faa2fc75e1739b45c511ba3fab5bb56",
            "/paper/Learning-Representations-and-Generative-Models-for-Achlioptas-Diamanti/b3159fd22e19e24d7cde9d37b3e482b832d4fa58",
            "/paper/Probabilistic-Point-Cloud-Reconstructions-for-Shape-Sekuboyina-Rempfler/77a5a4dd1dd2d5532f0d0619909eae131d4d9cb5",
            "/paper/Deep-Learning-for-Anomaly-Detection%3A-A-Survey-Sydney-Centre/a2e667e4382aaa8e02a17d0522c1a910790ab65b",
            "/paper/PPF-FoldNet%3A-Unsupervised-Learning-of-Rotation-3D-Deng-Birdal/9ccef6c69e5c16ac2ce9da4f1411415e402dd59c",
            "/paper/Adversarial-Discriminative-Attention-for-Robust-Kimura-Chaudhury/1a00dc525da31292e3734cbae2de681f114e30b1"
        ]
    },
    {
        "id": "fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
        "title": "CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows",
        "abstract": "A real-time model based on a conditional normalizing flow frame- work adopted for anomaly detection with localization that is faster and smaller by a factor of 10\u00d7 than prior state-of-the-art with the same input setting and outperforms previous methods. Unsupervised anomaly detection with localization has many practical applications when labeling is infeasible and, moreover, when anomaly examples are completely missing in the train data. While recently proposed models for such data setup achieve high accuracy metrics, their complexity is a limiting factor for real-time processing. In this paper, we propose a real-time model and analytically derive its relationship to prior methods. Our CFLOW-AD model is based on a conditional normalizing flow frame- work adopted for anomaly detection with localization. In particular, CFLOW-AD consists of a discriminatively pretrained encoder followed by a multi-scale generative de- coders where the latter explicitly estimate likelihood of the encoded features. Our approach results in a computationally and memory-efficient model: CFLOW-AD is faster and smaller by a factor of 10\u00d7 than prior state-of-the-art with the same input setting. Our experiments on the MVTec dataset show that CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by 1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source our code with fully reproducible experiments1.",
        "publication_year": "2021",
        "authors": [
            "Denis A. Gudovskiy",
            "Shun Ishizaka",
            "K. Kozuka"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "106",
        "reference_count": "44",
        "references": [
            "/paper/FastFlow%3A-Unsupervised-Anomaly-Detection-and-via-2D-Yu1-Zheng/11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "/paper/Self-Supervised-Anomaly-Detection-via-Neural-Flows-Zhang-Saleeby/d0697fb970ba92e970bf39ebf25561a8fee61cd6",
            "/paper/AltUB%3A-Alternating-Training-Method-to-Update-Base-Kim-Jang/b6c1dff75a15e5dbf52dd120371fce2cb4d52fe2",
            "/paper/Benchmarking-Unsupervised-Anomaly-Detection-and-Zheng-Wang/76077e1e12908b525907e7c3419368291f5965ab",
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/Anomaly-Detection-using-Contrastive-Normalizing-Schmier-K%C3%B6the/d4cf347ba89b0663c0464bbb9d5160010ebaaa70",
            "/paper/MAEDAY%3A-MAE-for-few-and-zero-shot-AnomalY-Detection-Schwartz-Arbelle/3f1ab9aec5920752eb5dc478b30485df1e437066",
            "/paper/Registration-based-Few-Shot-Anomaly-Detection-Huang-Guan/4b182347b943548fe6479393bb24adac21740675",
            "/paper/Visual-Anomaly-Detection-via-Dual-Attention-and-Yao-Luo/a865519bd5373cc5b73f672c1c787064c380aaaf",
            "/paper/Data-Invariants-to-Understand-Unsupervised-Doorenbos-Sznitman/0f23a44418aabe3344c6f3809d6a8ab898292813",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Understanding-Anomaly-Detection-with-Deep-Networks-Schirrmeister-Zhou/06671547fd94c44688b10c8cd550242557e55154",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Modeling-the-Distribution-of-Normal-Data-in-Deep-Rippel-Mertens/37595f7a51982d776e57c7280b9445474d90f0be",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/A-Revisit-of-Sparse-Coding-Based-Anomaly-Detection-Luo-Liu/99dff291f260b3cc3ff190106b0c2e3e685223a4",
            "/paper/Unsupervised-anomaly-segmentation-via-deep-feature-Shi-Yang/4dd78b8d466b4cfe55a1bbdc694291197ce62541",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/A-Unifying-Review-of-Deep-and-Shallow-Anomaly-Ruff-Kauffmann/30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ]
    },
    {
        "id": "7ac3e09d74ca15fdafa5f730617cd65059a144f3",
        "title": "Weakly Supervised Anomaly Detection: A Survey",
        "abstract": "This study presents the first comprehensive survey of WSAD methods by categorizing them into the above three weak supervision settings across four data modalities (i.e., tabular, graph, time-series, and image/video data). Anomaly detection (AD) is a crucial task in machine learning with various applications, such as detecting emerging diseases, identifying financial frauds, and detecting fake news. However, obtaining complete, accurate, and precise labels for AD tasks can be expensive and challenging due to the cost and difficulties in data annotation. To address this issue, researchers have developed AD methods that can work with incomplete, inexact, and inaccurate supervision, collectively summarized as weakly supervised anomaly detection (WSAD) methods. In this study, we present the first comprehensive survey of WSAD methods by categorizing them into the above three weak supervision settings across four data modalities (i.e., tabular, graph, time-series, and image/video data). For each setting, we provide formal definitions, key algorithms, and potential future directions. To support future research, we conduct experiments on a selected setting and release the source code, along with a collection of WSAD methods and data.",
        "publication_year": "2023",
        "authors": [
            "Minqi Jiang",
            "Chaochuan Hou",
            "Ao Zheng",
            "Xiyang Hu",
            "Songqiao Han",
            "Hailiang Huang",
            "Xiangnan He",
            "Philip S. Yu",
            "Yue Zhao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "59",
        "references": [
            "/paper/AnoOnly%3A-Semi-Supervised-Anomaly-Detection-without-Zhou-Yang/4141b5740f8ff7464f9bbcb152b0ac7cde5d7954",
            "/paper/Data-centric-Artificial-Intelligence%3A-A-Survey-Zha-Bhat/a1302409469284cdd9dbf535548e6b3a401caae2",
            "/paper/GADBench%3A-Revisiting-and-Benchmarking-Supervised-Tang-Hua/2bba87662399bd5d856afdcb848124d3e1e67df4",
            "/paper/ADBench%3A-Anomaly-Detection-Benchmark-Han-Hu/0bff4af924788d9779041513b6894385eac51ffd",
            "/paper/Cross-Epoch-Learning-for-Weakly-Supervised-Anomaly-Yu-Wang/88504c972e84aefd8d11ece83961765b80fde6c2",
            "/paper/Dual-MGAN%3A-An-Efficient-Approach-for-Outlier-with-Li-Sun/8d53096bdf5c0b387fbad537a755151e015518ec",
            "/paper/Deep-Weakly-supervised-Anomaly-Detection-Pang-Shen/30aa23a6a32312666f2609339582744203024993",
            "/paper/ADMoE%3A-Anomaly-Detection-with-Mixture-of-Experts-Zhao-Zheng/f1305bbd54db0345533906726e3425f742312c55",
            "/paper/Fraud-Detection-under-Multi-Sourced-Extremely-Noisy-Zhang-Wang/ec59f3b23c74aa0d1b12a8c2f3e83dce144e274d",
            "/paper/Semi-supervised-anomaly-detection-in-dynamic-Meng-Wang/e9b3da7ef244d233acf307dbf0ec01237e05cd0f",
            "/paper/Weakly-Supervised-Video-Anomaly-Detection-via-Wan-Fang/49133ffa30e0acaf4ea5bd8bbf68c841b02e3f2a",
            "/paper/MIST%3A-Multiple-Instance-Self-Training-Framework-for-Feng-Hong/297e83bc6d4498ad2e2906092e2b3df1b7621c26",
            "/paper/Graph-Convolutional-Label-Noise-Cleaner%3A-Train-a-Zhong-Li/a03bda078490e8ee991a1f86b53f27df7cf93a14"
        ]
    },
    {
        "id": "20f6fce7726e7b3ab4ca45ef40d92b79f093f825",
        "title": "AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise",
        "abstract": "A novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM, and a multi-scale simplex noise diffusion process that gives control over the target anomaly size is developed. Generative models have been shown to provide a powerful mechanism for anomaly detection by learning to model healthy or normal reference data which can subsequently be used as a baseline for scoring anomalies. In this work we consider denoising diffusion probabilistic models (DDPMs) for unsupervised anomaly detection. DDPMs have superior mode coverage over generative adversarial networks (GANs) and higher sample quality than variational autoencoders (VAEs). However, this comes at the expense of poor scalability and increased sampling times due to the long Markov chain sequences required. We observe that within reconstruction-based anomaly detection a full-length Markov chain diffusion is not required. This leads us to develop a novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM. A secondary problem is that Gaussian diffusion fails to capture larger anomalies; therefore we develop a multi-scale simplex noise diffusion process that gives control over the target anomaly size. AnoDDPM with simplex noise is shown to significantly outperform both f-AnoGAN and Gaussian diffusion for the tumorous dataset of 22 T1-weighted MRI scans (CCBS Edinburgh) qualitatively and quantitatively (improvement of +25.5% S\u00f8rensen\u2013Dice coefficient, +17.6% IoU and +7.4% AUC).",
        "publication_year": "2022",
        "authors": [
            "Julian Wyatt",
            "Adam Leach",
            "Sebastian M. Schmon",
            "Chris G. Willcocks"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "37",
        "reference_count": "29",
        "references": [
            "/paper/Anomaly-Detection-with-Conditioned-Denoising-Models-Mousakhan-Brox/28367cd3b68489ebd819ddfc3fb042b301abd3c7",
            "/paper/On-Diffusion-Modeling-for-Anomaly-Detection-Livernoche-Jain/ea1d04d4d83253d6343993e5a550b22b7833000c",
            "/paper/DiffusionAD%3A-Denoising-Diffusion-for-Anomaly-Zhang-Wang/55d49aa6bd3e6605c6510a147c1fb5bdd7af0b12",
            "/paper/Reversing-the-Abnormal%3A-Pseudo-Healthy-Generative-Bercea-Wiestler/daf9247aae99a36058a6f37912eeaf70b85cf8af",
            "/paper/The-role-of-noise-in-denoising-models-for-anomaly-Kascenas-Sanchez/646ec133173ac3aa1a602935d2ea7eb2ec87f19d",
            "/paper/MAEDAY%3A-MAE-for-few-and-zero-shot-AnomalY-Detection-Schwartz-Arbelle/3f1ab9aec5920752eb5dc478b30485df1e437066",
            "/paper/Denoising-Diffusion-Models-for-Out-of-Distribution-Graham-Pinaya/4ccc473ab4322da33f84cb194158305e2b9e5238",
            "/paper/Unsupervised-Visual-Defect-Detection-with-Model-Teng-Li/5ed3143fda212a40c4267666fbb7382fbae27cd2",
            "/paper/Mask%2C-Stitch%2C-and-Re-Sample%3A-Enhancing-Robustness-Bercea-Neumayr/71ff5bb5b6206cfda2790627cc446fe1fcc03bab",
            "/paper/Anomaly-Detection-via-Multi-Scale-Contrasted-Memory-Jezequel-Vu/bb0c598b0306bcc862e83a997fd42131d0c292bf",
            "/paper/Improved-Denoising-Diffusion-Probabilistic-Models-Nichol-Dhariwal/de18baa4964804cf471d85a5a090498242d2e79f",
            "/paper/f%E2%80%90AnoGAN%3A-Fast-unsupervised-anomaly-detection-with-Schlegl-Seeb%C3%B6ck/f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "/paper/Tackling-the-Generative-Learning-Trilemma-with-GANs-Xiao-Kreis/0d4154cbd76c4753ba3cb7a5b89ab29bab53384f",
            "/paper/Context-encoding-Variational-Autoencoder-for-Zimmerer-Kohl/ae97c81b45780dc91e18eb84236d8a40a290b329",
            "/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214",
            "/paper/Unsupervised-Brain-Anomaly-Detection-and-with-Pinaya-Tudosiu/87e9842de97fc610ba69f0e8bc3e13b9619787b9",
            "/paper/Unsupervised-Region-Based-Anomaly-Detection-In-MRI-Nguyen-Feldman/cb3d43139c682518b1e05e64df6239b7c26527ff",
            "/paper/Context-Encoders%3A-Feature-Learning-by-Inpainting-Pathak-Kr%C3%A4henb%C3%BChl/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87"
        ]
    },
    {
        "id": "5533bf9f2385ebece563fea35b19e998db64e597",
        "title": "ADTR: Anomaly Detection Transformer with Feature Reconstruction",
        "abstract": "This paper proposes Anomaly Detection TRansformer (ADTR) to apply a transformer to reconstruct pre-trained features to reconstruct anomalies well such that anomalies could be detected easily once the reconstruction fails. Anomaly detection with only prior knowledge from normal samples attracts more attention because of the lack of anomaly samples. Existing CNN-based pixel reconstruction approaches suffer from two concerns. First, the reconstruction source and target are raw pixel values that contain indistinguishable semantic information. Second, CNN tends to reconstruct both normal samples and anomalies well, making them still hard to distinguish. In this paper, we propose Anomaly Detection TRansformer (ADTR) to apply a transformer to reconstruct pre-trained features. The pre-trained features contain distinguishable semantic information. Also, the adoption of transformer limits to reconstruct anomalies well such that anomalies could be detected easily once the reconstruction fails. Moreover, we propose novel loss functions to make our approach compatible with the normal-sample-only case and the anomaly-available case with both image-level and pixel-level labeled anomalies. The performance could be further improved by adding simple synthetic or external irrelevant anomalies. Extensive experiments are conducted on anomaly detection datasets including MVTec-AD and CIFAR-10. Our method achieves superior performance compared with all baselines.",
        "publication_year": "2022",
        "authors": [
            "Zhiyuan You",
            "Kai Yang",
            "Wenhan Luo",
            "Lei Cui",
            "Xinyi Le",
            "Yu Zheng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "39",
        "references": [
            "/paper/A-Unified-Model-for-Multi-class-Anomaly-Detection-You-Cui/0e8446c00ed21c19f62d71ab208a7b3601671766",
            "/paper/Deep-Industrial-Image-Anomaly-Detection%3A-A-Survey-Liu-Xie/1312e46326f7e36fc82d16098b824540fe2dca66",
            "/paper/Deep-Visual-Anomaly-Detection-in-Industrial-A-Liu-Xie/c39aac50bc5dbaf1ea14eef48043156b51884238",
            "/paper/BMAD%3A-Benchmarks-for-Medical-Anomaly-Detection-Bao-Sun/32b64b7c68f29f2f92f571eb1e2a2b60fdcc9303",
            "/paper/ReContrast%3A-Domain-Specific-Anomaly-Detection-via-Guo-Lu/829417264611445436f635020d942244911d8301",
            "/paper/Inpainting-Transformer-for-Anomaly-Detection-Pirnay-Chai/19862af96b6af51e879e6e3f1d3d421af5427005",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/AnoViT%3A-Unsupervised-Anomaly-Detection-and-with-Lee-Kang/9cbbce7fc7fd38abf568e005606ea35e02da6cfa",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Learning-Semantic-Context-from-Normal-Samples-for-Yan-Zhang/8ee35ed698527d9695c872e3b76715fec4ef69ad",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/Glancing-at-the-Patch%3A-Anomaly-Localization-with-Wang-Wu/4758baad6b22c61682e7f7182bb93723046f36f5",
            "/paper/VT-ADL%3A-A-Vision-Transformer-Network-for-Image-and-Mishra-Verk/913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e"
        ]
    },
    {
        "id": "36748de338909976f72ffbadaf097470ec040da0",
        "title": "Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes",
        "abstract": "This protocol describes the design and execution of experiments using Cell Painting, which is a morphological profiling assay that multiplexes six fluorescent dyes, imaged in five channels, to reveal eight broadly relevant cellular components or organelles. In morphological profiling, quantitative data are extracted from microscopy images of cells to identify biologically relevant similarities and differences among samples based on these profiles. This protocol describes the design and execution of experiments using Cell Painting, which is a morphological profiling assay that multiplexes six fluorescent dyes, imaged in five channels, to reveal eight broadly relevant cellular components or organelles. Cells are plated in multiwell plates, perturbed with the treatments to be tested, stained, fixed, and imaged on a high-throughput microscope. Next, an automated image analysis software identifies individual cells and measures \u223c1,500 morphological features (various measures of size, shape, texture, intensity, and so on) to produce a rich profile that is suitable for the detection of subtle phenotypes. Profiles of cell populations treated with different experimental perturbations can be compared to suit many goals, such as identifying the phenotypic impact of chemical or genetic perturbations, grouping compounds and/or genes into functional pathways, and identifying signatures of disease. Cell culture and image acquisition takes 2 weeks; feature extraction and data analysis take an additional 1\u20132 weeks.",
        "publication_year": "2016",
        "authors": [
            "M. Bray",
            "Shantanu Singh",
            "Han Han",
            "C. Davis",
            "Blake Borgeson",
            "C. Hartland",
            "M. Kost-Alimova",
            "S. G\u00fastafsd\u00f3ttir",
            "C. Gibson",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "429",
        "reference_count": "54",
        "references": [
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/Assessing-the-performance-of-the-Cell-Painting-Jamali-Tromans-Coia/dbe577b3cdc30f0f1b264a86affc9db96c6065a7",
            "/paper/A-dataset-of-images-and-morphological-profiles-of-Bray-G%C3%BAstafsd%C3%B3ttir/05ba3c532b7b98c9448da0bee52d7cba0ef29621",
            "/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5",
            "/paper/Phenotypic-Profiling-of-Reference-Chemicals-across-Willis-Nyffeler/10d692fe72765a890974ceb1f0ac4b160b8a8c87",
            "/paper/High%E2%80%90throughput%2C-microscope%E2%80%90based-sorting-to-Hasle-Cooke/0c827ba45612a206f4a31a45606f0c924f306518",
            "/paper/Visual-Cell-Sorting%3A-A-High-throughput%2C-Method-to-Hasle-Cooke/04bb5d374c1fb4215fd4de02fc865a5994627046",
            "/paper/High-Content-Imaging-to-Phenotype-Antimicrobial-on-Sridhar-Forrest/2c3ad6d1afad0be4eee76bb08aa38e3192769c7b",
            "/paper/Novel-image-analysis-tool-for-rapid-screening-of-in-Guignet-Schmuck/98ac4c2e541ac29d2f23f2d015a1ac4e0991c934",
            "/paper/Linking-chemicals%2C-genes-and-morphological-to-Cerisier-Dafniet/93c2b03652546fbefa4760714501371610d96f9f",
            "/paper/Comparison-of-Methods-for-Image-Based-Profiling-of-Ljosa-Caie/929a490198770abcb8c123d68a59384879b69adb",
            "/paper/Multiplex-Cytological-Profiling-Assay-to-Measure-G%C3%BAstafsd%C3%B3ttir-Ljosa/df775e0093d4e96e2690fa9f48f60d76e4fede19",
            "/paper/Image-based-multivariate-profiling-of-drug-from-Loo-Wu/bfc8a8724b36cd2b1d068d1f997400e74791a68d",
            "/paper/Morphological-Profiles-of-RNAi-Induced-Gene-Are-but-Singh-Wu/4cebfa50e9e48afc6260df161582f0271c84d86a",
            "/paper/Linking-phenotypes-and-modes-of-action-through-Reisen-Chalon/9e93ab699a70701f8100a7730b9f6ee250bbaa18",
            "/paper/Linking-phenotypes-and-modes-of-action-through-ReisenFelix-ChalonAmelie/a1e06f125aeb3899c0eda9e9286820ccff76a494",
            "/paper/Annotated-high-throughput-microscopy-image-sets-for-Ljosa-Sokolnicki/ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869",
            "/paper/Compound-classification-using-image-based-cellular-Adams-Kutsyy/fdb0014af8197c8f303dca3fccad5d27bd264dcd",
            "/paper/CellProfiler%3A-image-analysis-software-for-and-cell-Carpenter-Jones/a2e75b7d9727b7ea7cefb4060d93ac75813e3c48",
            "/paper/Clustering-phenotype-populations-by-genome-wide-and-Fuchs-Pau/cd989ec0c4b17b06921668b2030020ce51736f7c"
        ]
    },
    {
        "id": "745990a3a401900874855d6041b03015e114eb09",
        "title": "A neighborhood-based multiple orthogonal least square method for sparse signal recovery",
        "abstract": "Semantic Scholar extracted view of \"A neighborhood-based multiple orthogonal least square method for sparse signal recovery\" by Yan-Chong Song et al.",
        "publication_year": "2023",
        "authors": [
            "Yan-Chong Song",
            "Feiyun Wu",
            "Ru Peng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "27",
        "references": [
            "/paper/A-Scaled-LMS-Algorithm-for-Sparse-System-with-Wu-Song/620c8bd40fb70209659c31a8055fc6cc79b07d78",
            "/paper/Optimal-design-of-NLMS-algorithm-with-a-variable-Wu-Song/df96cfba7b910fa24e92f8d0ab01f1a731e9104d",
            "/paper/Sparse-signal-recovery-from-noisy-measurements-via-Sun-Wu/b3ec8f5cca12b8684d063ee4c5630f2e801a963f",
            "/paper/Two-penalized-estimators-based-on-variance-for-with-Rajwade-Gurumoorthy/9e35901cbd1c258e99a2d119c666d8f1f0c62c88",
            "/paper/An-effective-framework-for-underwater-acoustic-data-Wu-Song/38c991d92a4d5531ef0b0e6b8eb5ec46c0e18369",
            "/paper/A-mixed-norm-constraint-IPNLMS-algorithm-for-sparse-Wu-Song/60f55c80d06c39006acf21cacc2e2f3c2aa751b9",
            "/paper/Channel-Estimation-for-MmWave-Massive-MIMO-With-on-Zhang-Cao/d9732e8cc593070b3ff4724da8cec7f7bf37d301",
            "/paper/An-improved-differential-evolution-algorithm-and-in-Deng-Shang/923bceafbf4e1c5a80e763d9c0a8b4a96eb87917",
            "/paper/Feature-Selection-Using-Fuzzy-Neighborhood-Measures-Sun-Wang/1739c6d0cb3bf9c52631520c9fde423179e95eab",
            "/paper/Efficient-Implementations-for-Orthogonal-Matching-Zhu-Chen/094b8bb98b45a622404e30271dca5f96103ae9ca"
        ]
    },
    {
        "id": "8afe9473732dfa46e7ce0f4ea3197328021aeeb9",
        "title": "A graph-based approach to video anomaly detection from the perspective of superpixels",
        "abstract": "This work proposes to shape the given problem by means of graphical models to shift the way the authors currently look at and process videos when trying to detect anomalous events. Video Anomaly Detection refers to the concept of discovering activities in a video feed that deviate from the usual visible pattern. It is a very well-studied and explored field in the domain of Computer Vision and Deep Learning, in which automated learning-based systems are capable of detecting certain kinds of anomalies at an accuracy greater than 90%. Deep Learning based Artificial Neural Network models, however, suffer from very low interpretability. In order to address and design a possible solution for this issue, this work proposes to shape the given problem by means of graphical models. Given the high flexibility of compositing easily interpretable graphs, a great variety of techniques exist to build a model representing spatial as well as temporal relationships occurring in the given video sequence. The experiments conducted on common anomaly detection benchmark datasets show that significant performance gains can be achieved through simple re-modelling of individual graph components. In contrast to other video anomaly detection approaches, the one presented in this work focuses primarily on the exploration of the possibility to shift the way we currently look at and process videos when trying to detect anomalous events.",
        "publication_year": "2023",
        "authors": [
            "M. Siemon",
            "Kamal Nasrollahi",
            "T. Moeslund"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "29",
        "references": [
            "/paper/Ano-Graph%3A-Learning-Normal-Scene-Contextual-Graphs-PourReza-Salehi/12ebe64bf81b85b2331875895bd3a2b5978dabd8",
            "/paper/Knowledge-Graphs-for-Semantic-Aware-Anomaly-in-Nesen-Bhargava/1a50298e16ebefb61151bcdfa0e2a4bd5afb92cf",
            "/paper/Anomaly-Detection-in-Video-via-Self-Supervised-and-Georgescu-B%C4%83rb%C4%83l%C4%83u/57b2198f9a8df773425aa6cc88c9870cb07779e2",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Graph-Embedded-Pose-Clustering-for-Anomaly-Markovitz-Sharir/8109587a56d53c6ba30fe19ba9aa4d9213ec91a0",
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Semi-supervised-Anomaly-Detection-using-Minhas-Zelek/98df4dd94f6d5fb5527984c8067d869744ff9ad7",
            "/paper/A-Background-Agnostic-Framework-With-Adversarial-in-Georgescu-Ionescu/51548f7f7493b8ae758925a924df0394051b8ba8",
            "/paper/Survey-of-Video-Based-Small-Target-Detection-Liu-Geng/be65c197d5a72b7a3154e97ecb73c8f7abab0479"
        ]
    },
    {
        "id": "6feecbba7eacf002edeee797db2704d15ffbda1b",
        "title": "DS-TransUNet: Dual Swin Transformer U-Net for Medical Image Segmentation",
        "abstract": "A novel deep medical image segmentation framework called dual swin transformer U-Net (DS-TransUNet), which aims to incorporate the hierarchical swin transformers into both the encoder and the decoder of the standard U-shaped architecture and adopts a well-established dual-scale encoding mechanism. Automatic medical image segmentation has made great progress owing to powerful deep representation learning. Inspired by the success of self-attention mechanism in transformer, considerable efforts are devoted to designing the robust variants of the encoder\u2013decoder architecture with transformer. However, the patch division used in the existing transformer-based models usually ignores the pixel-level intrinsic structural features inside each patch. In this article, we propose a novel deep medical image segmentation framework called dual swin transformer U-Net (DS-TransUNet), which aims to incorporate the hierarchical swin transformer into both the encoder and the decoder of the standard U-shaped architecture. Our DS-TransUNet benefits from the self-attention computation in swin transformer and the designed dual-scale encoding, which can effectively model the non-local dependencies and multiscale contexts for enhancing the semantic segmentation quality of varying medical images. Unlike many prior transformer-based solutions, the proposed DS-TransUNet adopts a well-established dual-scale encoding mechanism that uses dual-scale encoders based on swin transformer to extract the coarse and fine-grained feature representations of different semantic scales. Meanwhile, a well-designed transformer interactive fusion (TIF) module is proposed to effectively perform multiscale information fusion through the self-attention mechanism. Furthermore, we introduce the swin transformer block into the decoder to further explore the long-range contextual information during the up-sampling process. Extensive experiments across four typical tasks for medical image segmentation demonstrate the effectiveness of DS-TransUNet, and our approach significantly outperforms the state-of-the-art methods.",
        "publication_year": "2021",
        "authors": [
            "Ai-Jun Lin",
            "Bingzhi Chen",
            "Jiayu Xu",
            "Zheng Zhang",
            "Guangming Lu",
            "David Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "122",
        "reference_count": "51",
        "references": [
            "/paper/EG-TransUNet%3A-a-transformer-based-U-Net-with-and-Pan-Liu/4a6bf17538ded4eae48629728ee17adebb688094",
            "/paper/C2FTrans%3A-Coarse-to-Fine-Transformers-for-Medical-Lin-Yan/7070ae889786abe2b363bb7a0e3b1a7b81077742",
            "/paper/nnFormer%3A-Volumetric-Medical-Image-Segmentation-via-Zhou-Guo/bd9ab344da99022cbbbfd3f5c9c82a0b21c60ad9",
            "/paper/Dilated-UNet%3A-A-Fast-and-Accurate-Medical-Image-a-Saadati-Manzari/d16e5ab3919188d89bef1ce9cc7d813b90e94df5",
            "/paper/HST-MRF%3A-Heterogeneous-Swin-Transformer-with-Field-Huang-Gong/f20982cea07674eb779de507f09c26f65d445719",
            "/paper/Enhancing-Medical-Image-Segmentation-with-A-Feature-Azad-Jia/34b702d794e9601f0aab42b115fa3f546696ae49",
            "/paper/DIAMANT%3A-Dual-Image-Attention-Map-Encoders-For-Yeganeh-Farshad/56ae4887db15b38c7773123efd9ef69e7bd3ef54",
            "/paper/VA-TransUNet%3A-A-U-shaped-Medical-Image-Segmentation-Jiang-Xu/44173878ed1c8acc4fa5fef0e8c4a5e4fd1a8f97",
            "/paper/UNesT%3A-Local-Spatial-Representation-Learning-with-Yu-Yang/e4234671cd432fc5003e66ea0d74493386b509cd",
            "/paper/A-Multi-scale-Transformer-for-Medical-Image-Model-Gao-Zhou/7bbd8d675df1b08cb73a0f260c7c3606f707323c",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/TransFuse%3A-Fusing-Transformers-and-CNNs-for-Medical-Zhang-Liu/20db2a2fadcf563a2d522aabc440b6b4f3ee46f4",
            "/paper/DoubleU-Net%3A-A-Deep-Convolutional-Neural-Network-Jha-Riegler/61af9ff6ec3dbb5299455746a1c63588ccf62cf8",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/UNet-3%2B%3A-A-Full-Scale-Connected-UNet-for-Medical-Huang-Lin/0b444f74dd9cc06c2833dd15f9258ef5e169e6ea",
            "/paper/Bi-Directional-ConvLSTM-U-Net-with-Densley-Azad-Asadi-Aghbolaghi/f737fccce1c34492ee736f2c455ad6929232c17c",
            "/paper/Recurrent-Residual-Convolutional-Neural-Network-on-Alom-Hasan/27c761258329eddb90b64d52679ff190cb4527b5",
            "/paper/H-DenseUNet%3A-Hybrid-Densely-Connected-UNet-for-and-Li-Chen/a86d7289c76d832e83c99539859b7b186e4ea6c8",
            "/paper/FANet%3A-A-Feedback-Attention-Network-for-Improved-Tomar-Jha/81c35b12898c7f46115547b70f628f966ed73c50"
        ]
    },
    {
        "id": "50f94d7225158d6ec467aca927b2d533a478512c",
        "title": "MIU-Net: MIX-Attention and Inception U-Net for Histopathology Image Nuclei Segmentation",
        "abstract": "MIU-net, an efficient deep learning network structure for the nuclei segmentation of histopathology images, and the experimental results show that the proposed method achieves better performance than other state-of-the-art methods. In the medical field, hematoxylin and eosin (H&E)-stained histopathology images of cell nuclei analysis represent an important measure for cancer diagnosis. The most valuable aspect of the nuclei analysis is the segmentation of the different nuclei morphologies of different organs and subsequent diagnosis of the type and severity of the disease based on pathology. In recent years, deep learning techniques have been widely used in digital histopathology analysis. Automated nuclear segmentation technology enables the rapid and efficient segmentation of tens of thousands of complex and variable nuclei in histopathology images. However, a challenging problem during nuclei segmentation is the blocking of cell nuclei, overlapping, and background complexity of the tissue fraction. To address this challenge, we present MIU-net, an efficient deep learning network structure for the nuclei segmentation of histopathology images. Our proposed structure includes two blocks with modified inception module and attention module. The advantage of the modified inception module is to balance the computation and network performance of the deeper layers of the network, combined with the convolutional layer using different sizes of kernels to learn effective features in a fast and efficient manner to complete kernel segmentation. The attention module allows us to extract small and fine irregular boundary features from the images, which can better segment cancer cells that appear disorganized and fragmented. We test our methodology on public kumar datasets and achieve the highest AUC score of 0.92. The experimental results show that the proposed method achieves better performance than other state-of-the-art methods.",
        "publication_year": "2023",
        "authors": [
            "Jiangqi Li",
            "X. Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "19",
        "references": [
            "/paper/Robust-nuclei-segmentation-in-histopathology-using-Wan-Zhao/9a5356d74076b7e1b8a7bcb0e459fc923abafb27",
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/Hover-Net%3A-Simultaneous-segmentation-and-of-nuclei-Graham-Vu/5986547c7380f5a8fb6028093f827b3662f838a2",
            "/paper/Robust-nuclei-segmentation-in-images-using-level-Taheri-Fevens/b3b0ef5dbd138e6ac5c94f92c93808dcb671d688",
            "/paper/Automatic-Nuclei-Segmentation-in-H%26E-Stained-Breast-Veta-Diest/e312652daf82ed144d1696aae7ab412030d4f7eb",
            "/paper/Multi-tissue-and-multi-scale-approach-for-nuclei-in-Salvi-Molinari/ac158a0fa7ae122cc5e3785382aa364762c26839",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Spatial-Statistics-for-Segmenting-Histological-in-Nguyen-Tosun/2bb4dd5d7d33dcd5a6ebfae71a02f85fbc3ab982",
            "/paper/Fast-unsupervised-nuclear-segmentation-and-scheme-Mouelhi-Rmili/450bd98214fdbe72b38ddb7ac4539df0c6d1d577",
            "/paper/CE-Net%3A-Context-Encoder-Network-for-2D-Medical-Gu-Cheng/a07aa5b834e5083624189a929be07c7ae2389229"
        ]
    },
    {
        "id": "da663cac292b8c6e714ee8ee9300cb3bc35e16d5",
        "title": "Pix2Pix-based Stain-to-Stain Translation: A Solution for Robust Stain Normalization in Histopathology Images Analysis",
        "abstract": "A Stain-to-Stain Translation (STST) approach is used to stain normalization for Hematoxylin and Eosin stained histopathology images, which learns not only the specific color distribution but also the preserves corresponding histopathological pattern. The diagnosis of cancer is mainly performed by visual analysis of the pathologists, through examining the morphology of the tissue slices and the spatial arrangement of the cells. If the microscopic image of a specimen is not stained, it will look colorless and textured. Therefore, chemical staining is required to create contrast and help identify specific tissue components. During tissue preparation due to differences in chemicals, scanners, cutting thicknesses, and laboratory protocols, similar tissues are usually varied significantly in appearance. This diversity in staining, in addition to Interpretive disparity among pathologists more is one of the main challenges in designing robust and flexible systems for automated analysis. To address the staining color variations, several methods for normalizing stain have been proposed. In our proposed method, a Stain-to-Stain Translation (STST) approach is used to stain normalization for Hematoxylin and Eosin (H&E) stained histopathology images, which learns not only the specific color distribution but also the preserves corresponding histopathological pattern. We perform the process of translation based on the \"pix2pix\" framework, which uses the conditional generator adversarial networks (cGANs). Our approach showed excellent results, both mathematically and experimentally against the state of the art methods. We have made the source code publicly available 1.",
        "publication_year": "2020",
        "authors": [
            "Pegah Salehi",
            "A. Chalechale"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "42",
        "reference_count": "26",
        "references": [
            "/paper/StainNet%3A-A-Fast-and-Robust-Stain-Normalization-Kang-Luo/4613161c6d14962c5119c299194227e9484a3e68",
            "/paper/Deep-learning-enabled-virtual-histological-staining-Bai-Yang/ce201c4c74744821435a27bdf2e9513219c6645d",
            "/paper/Impact-of-Stain-Normalisation-Technique-on-Deep-in-Vaishnani-Gohel/bfd02f617bbbc76db0eb831d97de8897275938a4",
            "/paper/Stain-normalization-in-digital-pathology%3A-Clinical-Michielli-Caputo/8bc4473651760a4156ffd747fab09c03c68d87f4",
            "/paper/RestainNet%3A-a-self-supervised-digital-re-stainer-Zhao-Lin/2c3b756bed31b3ce8106201973016045a4fdced9",
            "/paper/HistoStarGAN%3A-A-Unified-Approach-to-Stain-Stain-and-Vasiljevi'c-Feuerhake/e3d1a9e6c7292e7ac25490487dc7524a9dfc3f2c",
            "/paper/Stain-normalization-using-score-based-diffusion-and-Jeong-Kim/37c884bacb33fe029dd8aeddd4cfec45370f32ea",
            "/paper/The-devil-is-in-the-details%3A-Whole-Slide-Image-and-Kanwal-P%C3%A9rez-Bueno/0fb4a5ce936abdf3d7b83ed463e91d08f5ab0657",
            "/paper/A-Fast-Texture-to-Stain-Adversarial-Stain-Network-Jia-Guo/fbf7dce2ee7b06e6b56e35e3ee0b0d1be8468ba8",
            "/paper/ParamNet%3A-A-Parameter-variable-Network-for-Fast-Kang-Luo/70a0d404cd603168ce1f4e5cded4d3e44eebd5bd",
            "/paper/A-Nonlinear-Mapping-Approach-to-Stain-Normalization-Khan-Rajpoot/0eac0ed2c87910dbb7d9f622854efb7c7b7b6f0b",
            "/paper/Structure-Preserving-Color-Normalization-and-Sparse-Vahadane-Peng/a243c7bbd2affd548e18a35dadf0313c1b2198c2",
            "/paper/Adversarial-Stain-Transfer-for-Histopathology-Image-Bentaieb-Hamarneh/a9c564185882bc9dd2b7becfc6928407bf1089b2",
            "/paper/GAN-based-Virtual-Re-Staining%3A-A-Promising-Solution-Xu-Moro/24875f5dfc6e3005e3673defce975fbe7ff7dd18",
            "/paper/Stain-Specific-Standardization-of-Whole-Slide-Bejnordi-Litjens/2729d2918978d5ed602aa843fbdd027d83e0036f",
            "/paper/Quantitative-analysis-of-stain-variability-in-and-Bejnordi-Timofeeva/e39a5aa36977c617a9caecb6da5c87e27886ad6f",
            "/paper/Quantification-of-histochemical-staining-by-color-Ruifrok-Johnston/71786049c8c73a007807463c4281431f2b66cc25",
            "/paper/Staingan%3A-Stain-Style-Transfer-for-Digital-Images-Shaban-Baur/e926486ab0dfd772d7da41489b47da0db935b3d8",
            "/paper/Histopathology-stain-color-normalization-using-deep-Zanjani-Zinger/e4729ac7bfdb707e3207b0a91b57a2f907f5351b",
            "/paper/The-importance-of-stain-normalization-in-colorectal-Ciompi-Geessink/87b612323f759cea5cb224331bfacf59a0f335b6"
        ]
    },
    {
        "id": "70727c82f1ab97b3f64ee3e81e6e209c40fa0a02",
        "title": "A Survey on Graph-Based Deep Learning for Computational Histopathology",
        "abstract": "Semantic Scholar extracted view of \"A Survey on Graph-Based Deep Learning for Computational Histopathology\" by David Ahmedt-Aristizabal et al.",
        "publication_year": "2021",
        "authors": [
            "David Ahmedt-Aristizabal",
            "M. Armin",
            "S. Denman",
            "C. Fookes",
            "L. Petersson"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "36",
        "reference_count": "160",
        "references": [
            "/paper/Multi-Scale-Relational-Graph-Convolutional-Network-Bazargani-Fazli/a3e36619f167b9ae2f1b9162a5a270966b86c5cd",
            "/paper/Neural-Graph-Modelling-of-Whole-Slide-Images-for-MacKenzie/3afe6c838fd4303d3b67c505c69723701b462649",
            "/paper/A-Convolutional-Neural-Network-and-Graph-Network-of-Gao-Lu/8bc9516bbd2bdec86d882c533a0c6853e2011c2c",
            "/paper/Graph-Based-Deep-Learning-for-Medical-Diagnosis-and-Ahmedt-Aristizabal-Armin/9811afe1246d52f422545457b06c30bc4b63ae8d",
            "/paper/GraphLSurv%3A-A-scalable-survival-prediction-network-Liu-Ji/d0283780f2020cd51c2b44948b4b2c5d7bdc5a21",
            "/paper/A-comprehensive-review-of-the-deep-learning-based-Abdelnabi-Ali/545d08577056ba64c9ca6434182fa203bfaaf96a",
            "/paper/Graph-Neural-Networks-Ameliorate-Potential-Impacts-Reddy-Reddy/085b85233eed7edeced0c0f199d1dd96316c6f52",
            "/paper/Explainable-and-Position-Aware-Learning-in-Digital-Aryal-Yahyasoltani/e6b9410207916df5f1505c6d1e970902dfaac314",
            "/paper/A-graph-neural-network-framework-for-mapping-in-Nair-Arvidsson/2c66eb266e48d8d257a874f65e478560c0037e51",
            "/paper/HistoCartography%3A-A-Toolkit-for-Graph-Analytics-in-Jaume-Pati/88ece19685da12245045d2047d1c826242d2ff8a",
            "/paper/Visualization-for-Histopathology-Images-using-Graph-Sureka-Patil/3bad80e7e1c38945900c8089a443f91a92c7a93c",
            "/paper/Representation-Learning-of-Histopathology-Images-Adnan-Kalra/77873e0843113d5465417f5309f5ae258af52a6f",
            "/paper/Self-Supervised-Learning-with-Graph-Neural-Networks-Ozen-Aksoy/73f266f2f495f86331609d9d3e24cbc8a762510c",
            "/paper/Deep-neural-network-models-for-computational-A-Srinidhi-Ciga/7f91d6acef932c471ca40a81cc8ec22d0482e459",
            "/paper/Topological-Feature-Extraction-and-Visualization-of-Levy-Haudenschild/322a90333cd2ca86d559641c37c8cd0eb1428560",
            "/paper/Graph-convolutional-networks-for-region-of-interest-Ayg%C3%BCnes-Aksoy/8fc05034aea7c1856cd464eb4e0b0a57037ba085",
            "/paper/Weakly-Supervised-Prostate-Tma-Classification-Via-Wang-Chen/b63248405e0778332209ef2ed88e7d2f2c00da6b",
            "/paper/Feature-Enhanced-Graph-Networks-for-Genetic-Using-Ding-Liu/101e7f9f3bc331fec84c9dc857a67b2482e811bf",
            "/paper/Graph-Based-Deep-Learning-for-Medical-Diagnosis-and-Ahmedt-Aristizabal-Armin/9811afe1246d52f422545457b06c30bc4b63ae8d",
            "/paper/Graph-CNN-for-Survival-Analysis-on-Whole-Slide-Li-Yao/2c0cdbf4f412f320242481bf7fe718a6237e74e2"
        ]
    },
    {
        "id": "1f249c7824dcd68013851fb6ec1a9a825b80e9b8",
        "title": "Deep ensembles based on Stochastic Activation Selection for Polyp Segmentation",
        "abstract": "This work compares some variant of the DeepLab architecture obtained by varying the decoder backbone and compares several decoder architectures, including ResNet, Xception, EfficentNet, MobileNet and perturb their layers by substituting ReLU activation layers with other functions to create deep ensembles shown to be very effective. Semantic segmentation has a wide array of applications ranging from medical-image analysis, scene understanding, autonomous driving and robotic navigation. This work deals with medical image segmentation and in particular with accurate polyp detection and segmentation during colonoscopy examinations. Several convolutional neural network architectures have been proposed to effectively deal with this task and with the problem of segmenting objects at different scale input. The basic architecture in image segmentation consists of an encoder and a decoder: the first uses convolutional filters to extract features from the image, the second is responsible for generating the final output. In this work, we compare some variant of the DeepLab architecture obtained by varying the decoder backbone. We compare several decoder architectures, including ResNet, Xception, EfficentNet, MobileNet and we perturb their layers by substituting ReLU activation layers with other functions. The resulting methods are used to create deep ensembles which are shown to be very effective. Our experimental evaluations show that our best ensemble produces good segmentation results by achieving high evaluation scores with a dice coefficient of 0.884, and a mean Intersection over Union (mIoU) of 0.818 for the Kvasir-SEG dataset. To improve reproducibility and research efficiency the MATLAB source code used for this research is available at GitHub: https://github.com/LorisNanni.",
        "publication_year": "2021",
        "authors": [
            "A. Lumini",
            "L. Nanni",
            "Gianluca Maguolo"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "38",
        "references": [
            "/paper/Ensembles-of-Convolutional-Neural-Networks-and-for-Nanni-Fantozzi/5ea7d1e0934876fac06c7ca6f5f56dbc57f133d9",
            "/paper/Polyp-PVT%3A-Polyp-Segmentation-with-Pyramid-Vision-Dong-Wang/66b92a2250d9b899c03c3f2699a40e18e56bcd51",
            "/paper/Multi-Level-and-Multi-Scale-Feature-Aggregation-for-Liao-Liu/98c14a19544da78d7c9b348ffe7b36f19727793c",
            "/paper/Image-Segmentation-Using-Deep-Learning%3A-A-Survey-Minaee-Boykov/712e32e2da67428ba6c6add1605410e1c3792883",
            "/paper/DDANet%3A-Dual-Decoder-Attention-Network-for-Polyp-Tomar-Jha/41d96e594de2ab2d3c041227db255794debe2f11",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/SegNet%3A-A-Deep-Convolutional-Encoder-Decoder-for-Badrinarayanan-Kendall/b0c065cd43aa7280e766b5dcbcc7e26abce59330",
            "/paper/DeepLab%3A-Semantic-Image-Segmentation-with-Deep-and-Chen-Papandreou/cab372bc3824780cce20d9dd1c22d4df39ed081a",
            "/paper/Encoder-Decoder-with-Atrous-Separable-Convolution-Chen-Zhu/9217e28b2273eb3b26e4e9b7b498b4661e6e09f5",
            "/paper/Learning-Deconvolution-Network-for-Semantic-Noh-Hong/cf986bfe13a24d4739f95df3a856a3c6e4ed4c1c",
            "/paper/Real-Time-Polyp-Detection%2C-Localization-and-in-Deep-Jha-Ali/9c0032a7e3a3a7dcd6f5caa9780ffbb7ffe5a237",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/Comparisons-among-different-stochastic-selection-of-Nanni-Lumini/695173e66bf118966e41de1c80b7c3d5e36add55"
        ]
    },
    {
        "id": "609d68085efa9b1da1068639e4850252cc0cf6ae",
        "title": "Self-Mutual Distillation Learning for Continuous Sign Language Recognition",
        "abstract": "A Self-Mutual Knowledge Distillation (SMKD) method is proposed, which enforces the visual and contextual modules to focus on short-term and long-term information and enhances the discriminative power of both modules simultaneously. In recent years, deep learning moves video-based Continuous Sign Language Recognition (CSLR) significantly forward. Currently, a typical network combination for CSLR includes a visual module, which focuses on spatial and short-temporal information, followed by a contextual module, which focuses on long-temporal information, and the Connectionist Temporal Classification (CTC) loss is adopted to train the network. However, due to the limitation of chain rules in back-propagation, the visual module is hard to adjust for seeking optimized visual features. As a result, it enforces that the contextual module focuses on contextual information optimization only rather than balancing efficient visual and contextual information. In this paper, we propose a Self-Mutual Knowledge Distillation (SMKD) method, which enforces the visual and contextual modules to focus on short-term and long-term information and enhances the discriminative power of both modules simultaneously. Specifically, the visual and contextual modules share the weights of their corresponding classifiers, and train with CTC loss simultaneously. Moreover, the spike phenomenon widely exists with CTC loss. Although it can help us choose a few of the key frames of a gloss, it does drop other frames in a gloss and makes the visual feature saturation in the early stage. A gloss segmentation is developed to relieve the spike phenomenon and decrease saturation in the visual module. We conduct experiments on two CSLR bench-marks: PHOENIX14 and PHOENIX14-T. Experimental results demonstrate the effectiveness of the SMKD.",
        "publication_year": "2021",
        "authors": [
            "Aiming Hao",
            "Yuecong Min",
            "Xilin Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "21",
        "reference_count": "35",
        "references": [
            "/paper/C2SLR%3A-Consistency-enhanced-Continuous-Sign-Zuo-Mak/63399cd601e8f58a833c31d98d87a9c3c144041f",
            "/paper/Improving-Continuous-Sign-Language-Recognition-with-Zuo-Mak/8cac1a726a7fa1160ce86733e66ebba6c78b71eb",
            "/paper/CSLR%3A-Consistency-enhanced-Continuous-Sign-Language-Zuo-Mak/a5b8e64c15c29bc372d040d26e9f5c7cb5ddde99",
            "/paper/Visual-Lexical-Alignment-Constraint-for-Continuous-Guo-Jin/9302c6454350f85c8157aeabe3e60604b9402259",
            "/paper/Conditional-Diffusion-Feature-Refinement-for-Sign-Guo-Xue/314e3cc058b0633a1ca228efa8c455534ed689ca",
            "/paper/Purification-and-Multi-Temporal-Semantic-Network-Chen-Jin/a252999601363856a35a003d3b4f80d740411b9a",
            "/paper/Self-Emphasizing-Network-for-Continuous-Sign-Hu-Gao/1f55d35e1d1a148898a756cb0380b22fa8878dcb",
            "/paper/CVT-SLR%3A-Contrastive-Visual-Textual-Transformation-Zheng-Wang/ff03fe2efa8e0283f06098e9f1ae41b76e66efec",
            "/paper/SLRFormer%3A-Continuous-Sign-Language-Recognition-on-Xiao-Liu/a822077fa6047efcff467d396aa9c8562e5fb6a9",
            "/paper/Self-Sufficient-Framework-for-Continuous-Sign-Jang-Oh/d461accbe1c24e8db79ac8305a869bd30cbd7285",
            "/paper/Spatial-Temporal-Multi-Cue-Network-for-Continuous-Zhou-Zhou/a1e2665ac39dcb389e12f3f993004b4b4651826d",
            "/paper/Visual-Alignment-Constraint-for-Continuous-Sign-Min-Hao/2d2d5bb1d025c5e17abe13716599c93e1f131927",
            "/paper/Boosting-Continuous-Sign-Language-Recognition-via-Pu-Zhou/ce50fa888551b640fe3dddc57289c27f325c029b",
            "/paper/Fully-Convolutional-Networks-for-Continuous-Sign-Cheng-Yang/6af09da568edee80075ec610f431ffa91bfce061",
            "/paper/Recurrent-Convolutional-Neural-Networks-for-Sign-by-Cui-Liu/a3c850001340266d4b2e7479f78387b5fda0815c",
            "/paper/A-Deep-Neural-Framework-for-Continuous-Sign-by-Cui-Liu/f96ffd8c71b97e46eb3ba48263c9012d197494d4",
            "/paper/Iterative-Alignment-Network-for-Continuous-Sign-Pu-Zhou/714df3e97817ec56b8dbc7217155adadf2a0487f",
            "/paper/Stochastic-Fine-Grained-Labeling-of-Multi-state-for-Niu-Mak/d370d25ba348f33bb5a5ff10d78b5dc9630694ec",
            "/paper/Weakly-Supervised-Learning-with-Multi-Stream-to-in-Koller-Camgoz/964502ea316fe9049c464a0925e3dc4246023a0d",
            "/paper/Dynamic-Pseudo-Label-Decoding-for-Continuous-Sign-Zhou-Zhou/f4a391a41b386612a86f6296a7a86b0e71f1381e"
        ]
    },
    {
        "id": "3499afedecabd747d913bb184721b6a4e82dca59",
        "title": "A Large-scale Synthetic Pathological Dataset for Deep Learning-enabled Segmentation of Breast Cancer",
        "abstract": "A large-scale synthetic pathological image dataset paired with the annotation for nuclei semantic segmentation, termed as Synthetic Nuclei and annOtation Wizard (SNOW), and it is shown that SNOW can be used in both supervised and semi-supervised training scenarios. The success of training computer-vision models heavily relies on the support of large-scale, real-world images with annotations. Yet such an annotation-ready dataset is difficult to curate in pathology due to the privacy protection and excessive annotation burden. To aid in computational pathology, synthetic data generation, curation, and annotation present a cost-effective means to quickly enable data diversity that is required to boost model performance at different stages. In this study, we introduce a large-scale synthetic pathological image dataset paired with the annotation for nuclei semantic segmentation, termed as Synthetic Nuclei and annOtation Wizard (SNOW). The proposed SNOW is developed via a standardized workflow by applying the off-the-shelf image generator and nuclei annotator. The dataset contains overall 20k image tiles and 1,448,522 annotated nuclei with the CC-BY license. We show that SNOW can be used in both supervised and semi-supervised training scenarios. Extensive results suggest that synthetic-data-trained models are competitive under a variety of model training settings, expanding the scope of better using synthetic images for enhancing downstream data-driven clinical tasks.",
        "publication_year": "2023",
        "authors": [
            "Kexin Ding",
            "Mu Zhou",
            "He Wang",
            "O. Gevaert",
            "Dimitris N. Metaxas",
            "Shaoting Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "52",
        "references": [
            "/paper/On-the-Challenges-and-Perspectives-of-Foundation-Zhang-Metaxas/fed150a219f9c31bdb4920e615c7c9264c634736",
            "/paper/Evaluating-Scoliosis-Severity-Based-on-X-ray-Images-Fabijan-Fabijan/65b42215894e5252f34f06ac56594c5ba5091465",
            "/paper/SAFRON%3A-Stitching-Across-the-Frontier-Network-for-Deshpande-Minhas/992ea6ad094af25a36a3bedb2da81ab41a0f92e5",
            "/paper/Deep-Adversarial-Training-for-Multi-Organ-Nuclei-in-Mahmood-Borders/7ae5b1b4b488473314d40711e4d2b0e8d7e210ed",
            "/paper/PanNuke-Dataset-Extension%2C-Insights-and-Baselines-Gamper-Koohbanani/f80a77c7800b10a3ef83ab7cac51e42b14ff5a15",
            "/paper/PanNuke%3A-An-Open-Pan-Cancer-Histology-Dataset-for-Gamper-Koohbanani/b218b13756f3aacadf5f06d09652058d024dc9d4",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-Using-in-Qu-Wu/c616b0fe93dc0b52b04ce6bf68ae3a67701200e8",
            "/paper/Selective-synthetic-augmentation-with-HistoGAN-for-Xue-Ye/962676b688b6e35ec2a3c8e6b3bdce638d6ca8db",
            "/paper/Robust-Histopathology-Image-Analysis%3A-To-Label-or-Hou-Agarwal/abee18114d9ff757dc82e44bead6bad39cfb758c",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Style-Consistent-Image-Generation-for-Nuclei-Gong-Chen/9b23dcc2709724d84c61b96e00be2f9b2b4a29fb",
            "/paper/Dataset-of-segmented-nuclei-in-hematoxylin-and-of-Hou-Gupta/1bfc7eb3be7d905dc2cb7ac8f5470c38a62ad7d3"
        ]
    },
    {
        "id": "40071396490823a1f110911ee314c8bdb6aea813",
        "title": "An Auxiliary Task for Learning Nuclei Segmentation in 3D Microscopy Images",
        "abstract": "This work proposes a novel learning strategy that boosts segmentation accuracy by means of a simple auxiliary task, thereby robustly outperforming each of the authors' baselines and shows that one of its baselines, the popular three-label model, when trained with their proposed Auxiliary task, outperforms the recent StarDist-3D. Segmentation of cell nuclei in microscopy images is a prevalent necessity in cell biology. Especially for three-dimensional datasets, manual segmentation is prohibitively time-consuming, motivating the need for automated methods. Learning-based methods trained on pixel-wise ground-truth segmentations have been shown to yield state-of-the-art results on 2d benchmark image data of nuclei, yet a respective benchmark is missing for 3d image data. In this work, we perform a comparative evaluation of nuclei segmentation algorithms on a database of manually segmented 3d light microscopy volumes. We propose a novel learning strategy that boosts segmentation accuracy by means of a simple auxiliary task, thereby robustly outperforming each of our baselines. Furthermore, we show that one of our baselines, the popular three-label model, when trained with our proposed auxiliary task, outperforms the recent StarDist-3D. As an additional, practical contribution, we benchmark nuclei segmentation against nuclei detection, i.e. the task of merely pinpointing individual nuclei without generating respective pixel-accurate segmentations. For learning nuclei detection, large 3d training datasets of manually annotated nuclei center points are available. However, the impact on detection accuracy caused by training on such sparse ground truth as opposed to dense pixel-wise ground truth has not yet been quantified. To this end, we compare nuclei detection accuracy yielded by training on dense vs. sparse ground truth. Our results suggest that training on sparse ground truth yields competitive nuclei detection rates.",
        "publication_year": "2020",
        "authors": [
            "Peter Hirsch",
            "Dagmar Kainmueller"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "21",
        "references": [
            "/paper/Learning-to-Segment-Microscopy-Images-with-Lazy-Ke-Bugeau/25bafc9f20ee8b4390f939766a26fc895dfc7c3b",
            "/paper/Nuclei-Detection-for-3D-Microscopy-With-a-Fully-Lapierre-Landry-Liu/67711d66ff40194c4578b9135ff05d7e60033f35",
            "/paper/Marker-controlled-watershed-with-deep-edge-emphasis-Kaseva-Omidali/f311c0c066f21838afbadf07d9c834bdd65e496c",
            "/paper/PatchPerPix-for-Instance-Segmentation-Hirsch-Mais/220530cc1db8c822d56bddb749bb525143d1e640",
            "/paper/How-Shift-Equivariance-Impacts-Metric-Learning-for-Rumberger-Yu/751c2884390f49a44c7e47500f45ff2bcd3b624a",
            "/paper/Panoptic-segmentation-with-highly-imbalanced-labels-Rumberger-Baumann/09ad8aab80361feea5c0bed6dd10cdb1b3f135fd",
            "/paper/Open-Source-Biomedical-Image-Analysis-Models%3A-A-and-Li-Sharma/48a1067461d22e4edae25cfc857dff5a3d09341c",
            "/paper/Evaluation-of-Deep-Learning-Strategies-for-Nucleus-Caicedo-Roth/c89bfd998b0a6c656010b629814ab0cad3cff72e",
            "/paper/Deep-Voting%3A-A-Robust-Approach-Toward-Nucleus-in-Xie-Kong/9226ff1a514271fb096d9f0897212baa26f84385",
            "/paper/Large-Scale-Image-Segmentation-with-Structured-Loss-Funke-Tschopp/37680090f534ae1dfdc4e7312cf6de8d7b22177a",
            "/paper/3D-U-Net%3A-Learning-Dense-Volumetric-Segmentation-%C3%87i%C3%A7ek-Abdulkadir/7fc464470b441c691d10e7331b14a525bc79b8bb",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Annotated-high-throughput-microscopy-image-sets-for-Ljosa-Sokolnicki/ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869",
            "/paper/DCAN%3A-Deep-Contour-Aware-Networks-for-Accurate-Chen-Qi/ba124bbde8d114a9103eb5751036e2e4710e2fff",
            "/paper/Star-convex-Polyhedra-for-3D-Object-Detection-and-Weigert-Schmidt/c97042386e3571fa39e6e97aeb7dd966636eef05",
            "/paper/Multiclass-Weighted-Loss-for-Instance-Segmentation-Guerrero-Pe%C3%B1a-Marrero-Fern%C3%A1ndez/5896bd31724bd2f57630473e1e466ea08c3b0c34",
            "/paper/Deep-learning-nuclei-detection%3A-A-simple-approach-H%C3%B6fener-Homeyer/6972cf59c18bce34175d131c690aa22f72e002e9"
        ]
    },
    {
        "id": "7d457bbc2bde775d6b4bf81723da814b045aa8ff",
        "title": "Patient-assessed outcomes after excision of acoustic neuroma: postoperative symptoms and quality of life.",
        "abstract": "The present study supports the use of generic QOL measures to assess outcome and to draw comparisons between different populations. OBJECT\nThe aim of this study was to assess whether outcomes from excision of acoustic neuroma vary among patients and have a material impact on their quality of life (QOL).\n\n\nMETHODS\nA questionnaire concerning postoperative symptoms and the Short Form 36 (SF-36) QOL instrument were mailed to 97 consecutive patients who had undergone acoustic neuroma surgery via the translabyrinthine approach. The survey response rate was 78% and the symptomatology was consistent with other reports, supporting the representativeness of the sample. The respondents' QOL was rated significantly below published norms and their work capacity was reportedly reduced. Specifically, the following SF-36 dimensions were reduced: physical functioning and role-physical, together with vitality, general health, and social functioning. Greater numbers of postoperative symptoms and larger tumors were associated with a worse rating of physical functioning. More severe balance problems were associated with lower ratings of social functioning. The disparity between the patient's self-estimate and self-measurement and the clinician's assessment of the patient's facial functioning raises doubts about the validity of subjective reports and assessment.\n\n\nCONCLUSIONS\nThe present study supports the use of generic QOL measures to assess outcome and to draw comparisons between different populations.",
        "publication_year": "2001",
        "authors": [
            "H. Martin",
            "J. Sethi",
            "D. Lang",
            "G. Neil-Dwyer",
            "M. Lutman",
            "L. Yardley"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "142",
        "reference_count": "25",
        "references": [
            "/paper/Self-assessed-quality-of-life-after-acoustic-Betchen-Walsh/48e25055325747db9edffcce0177b653e1538624",
            "/paper/Assessing-Surgical-Approaches-for-Acoustic-Neuroma-North-Weishaar/71f3b720e7bd9d26488a5fa323b7b3d1c6890353",
            "/paper/Surgery-for-large-vestibular-schwannomas%3A-how-and-Nicoucar-Momjian/338f4b9f57034ef52e39aa3af43089f60b4e970a",
            "/paper/Patients'-quality-of-life%2C-reported-difficulties%2C-Browne-Distel/13b23089f515381cd82a3e71a0a93ca2630c45d4",
            "/paper/Quality-of-Life-After-Acoustic-Neuroma-Surgery-Tufarelli-Meli/6aef9ec3ee997bffb42550b74ffaf7b30d522734",
            "/paper/Quality-of-life-after-unilateral-acoustic-neuroma-Baumann-Polligkeit/8bb5549b7b86f65f0157f2374a4f047e2d999008",
            "/paper/Long-term-Quality-of-Life-Following-Vestibular-Via-Broomfield-Mandavia/57acd9b63daee439b292ad3ab3657554a3cc2d67",
            "/paper/Quality-of-Life-Among-Acoustic-Neuroma-Patients-by-Brooker-Fletcher/e5dddd3b88688d2a53397edb7e798af3389d053b",
            "/paper/The-Impact-of-Primary-Treatment-Strategy-on-the-of-Foley-Maweni/7c5abd0cf656ed48db39c27f4f4cefc6d8801ef0",
            "/paper/Quality-of-life-in-vestibular-schwannoma%3A-a-of-Lucidi-Fabbris/609acd3a806945f6095b9da3be6141cbd67718e2",
            "/paper/Evaluation-of-quality-of-life-and-symptoms-after-Andersson-Ekvall/8a7053554d0dd74e61eaf648c0fc47b4d15b580c",
            "/paper/Acoustic-neuroma-surgery%3A-outcome-analysis-of-Rigby-Shah/9c5e01f8d012a45b4cdae955a7a049272f7f9c28",
            "/paper/The-patient's-perspective-after-vestibular-removal%3A-Irving-Beynon/786baba477038f4d232df47ca4643adac167912c",
            "/paper/Functional-outcome-in-patients-after-excision-of-Kane-Kazanas/e8ec19938c8c885e770429735157d338c42c7c43",
            "/paper/Quality-of-life-after-acoustic-neuroma-surgery-Nikolopoulos-Johnson/c5ef43064be085f2cf4003d7cd14ef47d59badd6",
            "/paper/Some-aspects-of-life-quality-after-surgery-for-Parving-Tos/95dfd55d5816a3e40ec0706fcd13dd3322f37d6b",
            "/paper/Long-term-effects-of-M%C3%A9ni%C3%A8re's-disease-on-hearing-Kinney-Sandridge/daed83085dc0534bdc430db43a6d36b2de80282e",
            "/paper/Acoustic-neuroma%E2%80%94the-patient's-perspective%3A-of-and-Wiegand-Fickel/05e71335d1a56212176ff1a9d17838a40d0167a7",
            "/paper/Acoustic-neuroma.-Follow-up-of-78-patients.-J%C3%B8rgensen-Pedersen/b17acbe5657fa9bad031ce5ad6365ab8b282c0f8",
            "/paper/Predicting-Long-Term-Facial-Nerve-Outcome-after-Arriaga-Luxford/39962b5f0c6fe869dca15fcaf755ac7cb31916b9"
        ]
    },
    {
        "id": "ea1016999109a842b3c6cb33a26bd30e6396f281",
        "title": "D2E2-Net: Double Deep Edge Enhancement for Weakly-Supervised Cell Nuclei Segmentation with Incomplete Point Annotations",
        "abstract": "This study proposes a semi- and weakly-supervised cell segmentation network named Deep Double Edge Enhancement Network (D2E2-Net) using only a small amount of points annotated to further enhance the cell boundary delineation. Cell nuclei segmentation is important for histopathology image analysis. While deep learning has demonstrated promising results for automated cell nuclei segmentation, it is difficult to obtain accurate ground truth annotations due to the visual complexity of histopathology images and high density of cells. Weakly supervised cell segmentation can greatly reduce the effort required for annotation while maintaining high accuracy. However, current weakly supervised segmentation methods typically require the annotation of centroids for all cells, which is still a tedious task. In our study, we propose a semi- and weakly-supervised cell segmentation network named Deep Double Edge Enhancement Network (D2E2-Net) using only a small amount of points annotated. Our method focuses on tackling the issue of denoising the background noise to further enhance the cell boundary delineation. Our experimental results demonstrate state-of-the-art performance on three public histopathology image datasets.",
        "publication_year": "2022",
        "authors": [],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "39",
        "references": [
            "/paper/PseudoEdgeNet%3A-Nuclei-Segmentation-only-with-Point-Yoo-Yoo/8500d2883a31e2aae12bcaa4cdf6b13df84419a0",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-using-in-Qu-Wu/2b60f01e916725a8f0b5dddc44b4cb9bd3e5e8c3",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-Using-in-Qu-Wu/c616b0fe93dc0b52b04ce6bf68ae3a67701200e8",
            "/paper/Weakly-Supervised-Histopathology-Image-Segmentation-Chen-Chen/6a6bc1f358a03b73f902f6e454f19cb06cda61c1",
            "/paper/Weakly-Supervised-Multi-Task-Learning-for-Cell-and-Chamanzar-Nie/a89cf9c6aa4cad62a78421916726b8b16c0cb9f2",
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/Improving-Nuclei-Gland-Instance-Segmentation-in-by-Qu-Yan/30d4a6588647db444228bd799381dcd7cdd90eb3",
            "/paper/Weakly-Supervised-Nucleus-Segmentation-Based-on-A-Tian-Zhang/2af96daa1456fdb2a004f62a3fa28986e76e7fa4",
            "/paper/Boundary-Weighted-Domain-Adaptive-Neural-Network-MR-Zhu-Du/a514e1f6d9eda557e06f69844a2c863c78f59ad4",
            "/paper/Scribble2Label%3A-Scribble-Supervised-Cell-via-with-Lee-Jeong/064bbc7df01855d681c34b4fec4a5bd11052c7bc"
        ]
    },
    {
        "id": "a0589621579ef10004024a4544f28d9582d0b185",
        "title": "Cost-effective Elderly Fall Detection with Symmetry Transformer Networks",
        "abstract": "A WiFi-based elderly fall detection approach in a cost-effective manner - being high in detection accuracy, and low in costs of device access and positively -annotated data, which achieves superior performance compared with state-of-the-art models. Elderly fall detection aims at automatically detecting fall actions, a major public health problem for the elderly. Existing fall detection methods are cost-ineffective - a satisfactory performance is commonly traded by high costs in device access/deployment and positive record acquirement. In this paper, we set out to devise a WiFi-based elderly fall detection approach in a cost-effective manner - being high in detection accuracy, and low in costs of device access and positively -annotated data. Specifically, our system builds on commercial WiFi, a ubiquitously available device, which greatly saves device access and deployment costs. To extract the nuanced and implicit features due to the low signal-to-noise ratio of WiFi signals, we propose symmetry Transformer networks, a variant of Transformer to facilitate better feature representation learning. Meanwhile, to overcome the positive scarcity and low inter-environment transferability brought by Transformer, we propose a novel two-stage training scheme, where the representation learning is performed in an unsupervised manner. This unveils a transferability property that reduces the requirements on positive instances in training the resulting model. Empirical evaluation demonstrates our cost-effective desideratum while achieving superior performance compared with state-of-the-art models.",
        "publication_year": "2022",
        "authors": [
            "Bing Li",
            "Wei Cui",
            "Yanru Chen",
            "Joey Tianyi Zhou",
            "Zhenghua Chen",
            "Yuli Li",
            "Wu Min"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "43",
        "references": [
            "/paper/DeFall%3A-Environment-Independent-Passive-Fall-Using-Hu-Zhang/0decb43be5171fcf69b8983844fd4449743b5ab4",
            "/paper/Two-Stream-Convolution-Augmented-Transformer-for-Li-Cui/a3196e65467b80f4755968923b382e40c02ccb51",
            "/paper/A-survey-on-fall-detection%3A-Principles-and-Mubashir-Shao/48d5c7b3dbf631dec66b51f7b7a9e168a86506bd",
            "/paper/A-WiFi-Based-Smart-Home-Fall-Detection-System-Using-Ding-Wang/9eac5c0978696c5cca84a9d730994bbf7d284460",
            "/paper/RT-Fall%3A-A-Real-Time-and-Contactless-Fall-Detection-Wang-Zhang/ca117d143e0e3f6a073ac6705b472072c8f676e5",
            "/paper/Sensor-Technologies-for-Fall-Detection-Systems%3A-A-Singh-Rehman/15c4b134bd764739cff0b546e82d6f6e9d0d0cb9",
            "/paper/Anti-fall%3A-A-Non-intrusive-and-Real-Time-Fall-CSI-Zhang-Wang/a20c2d1fe8122f8c59f0a35bcfa08f14e082daad",
            "/paper/NotiFi%3A-A-ubiquitous-WiFi-based-abnormal-activity-Zhu-Pang/875393ef46f5d3b6b51dfbad039e6a5cef8223a4",
            "/paper/UniMiB-SHAR%3A-a-new-dataset-for-human-activity-using-Micucci-Mobilio/4c1385a5d8f985dde69546bb2c9c2b2531c8e4c6",
            "/paper/WiFi-Based-Indoor-Robot-Positioning-Using-Deep-Zhang-Chen/20c889b6af0758dcf40aabf49a24c98cd91bc7b8"
        ]
    },
    {
        "id": "57e0b6a1a47afe3d0cee58d387a7cfcd3bdd5e73",
        "title": "Just Noticeable Learning for Unsupervised Anomaly Localization and Detection",
        "abstract": "A Just Noticeable learning for unsupervised anomaly Localization and Detection (JNLD) that embeds just noticeable learning in the sub-networks of reconstruction and segmentation to di-rectly localize the defects without any complex additional post-processing. Anomaly detection targets to detect unseen defective ap-pearances that are different from the seen non-anomalous instances. Recent unsupervised learning methods generate anomalous instances to inspire the anomaly detector to learn discriminative features. However, the generated anomalous instances are more easily noticed than real defects and may cause inconsistency between normal and anomalous. It lim-its the reconstruction of anomaly-free images and the seg-mentation of diversity anomalies. To conquer these prob-lems, we propose a Just Noticeable learning for unsupervised anomaly Localization and Detection(JNLD). The method simulates multi-scale noticeable defects to enrich generaliz-able representation. It embeds just noticeable learning in the sub-networks of reconstruction and segmentation to di-rectly localize the defects without any complex additional post-processing. With further equipment of label inconsis-tency correction, our JNLD achieves 73.8 for unseen anomaly localization average precision that surpasses the current state-of-the-art by a large margin of 5.4 percentage on the challenging dataset MVTecAD.",
        "publication_year": "2022",
        "authors": [
            "Ying Zhao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "18",
        "references": [
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Reconstruction-by-inpainting-for-visual-anomaly-Zavrtanik-Kristan/2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "/paper/DR%C3%86M-%E2%80%93-A-discriminatively-trained-reconstruction-Zavrtanik-Kristan/95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/A-Semantic-Enhanced-Method-Based-On-Deep-SVDD-for-Hu-Chen/cbe677a5e9870cd829bd041a99d61ae00db48c97",
            "/paper/Distance-Based-Anomaly-Detection-for-Industrial-Tayeh-Aburakhia/ea68899e52526ce59c1f0b0cbc7cd992a0700383",
            "/paper/Focal-Loss-for-Dense-Object-Detection-Lin-Goyal/72564a69bf339ff1d16a639c86a764db2321caab"
        ]
    },
    {
        "id": "7d5c0ae2985e0c665cb3713aaa169ee5c7c9794f",
        "title": "Composite Layers for Deep Anomaly Detection on 3D Point Clouds",
        "abstract": "The composite layer is introduced, a new convolutional operator for point clouds that extracts and compresses the spatial information from the position of points before combining it with their feature vectors and defines an aggregate composite layer that combines spatial information and features in a nonlinear manner. Deep neural networks require specific layers to process point clouds, as the scattered and irregular location of points prevents us from using convolutional filters. Here we introduce the composite layer, a new convolutional operator for point clouds. The peculiarity of our composite layer is that it extracts and compresses the spatial information from the position of points before combining it with their feature vectors. Compared to well-known point-convolutional layers such as those of ConvPoint and KPConv, our composite layer provides additional regularization and guarantees greater flexibility in terms of design and number of parameters. To demonstrate the design flexibility, we also define an aggregate composite layer that combines spatial information and features in a nonlinear manner, and we use these layers to implement a convolutional and an aggregate CompositeNet. We train our CompositeNets to perform classification and, most remarkably, unsupervised anomaly detection. Our experiments on synthetic and real-world datasets show that, in both tasks, our CompositeNets outperform ConvPoint and achieve similar results as KPConv despite having a much simpler architecture. Moreover, our CompositeNets substantially outperform existing solutions for anomaly detection on point clouds.",
        "publication_year": "2022",
        "authors": [
            "A. Floris",
            "Luca Frittoli",
            "Diego Carrera",
            "G. Boracchi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "58",
        "references": [
            "/paper/Teacher-Student-Network-for-3D-Point-Cloud-Anomaly-Qin-Gu/35dfd96486c38d9a21b1d29e2381d72cd7928b2f",
            "/paper/A-Survey-on-Deep-Learning-Based-Segmentation%2C-and-Vinodkumar-Karabulut/0eaf7b23698b7d37166e66b8346cf0bb4f89b9fd",
            "/paper/Point-Cloud-Video-Anomaly-Detection-Based-on-Point-He-Wang/31b8ea745f2f6b2c8b2fe3d6e6377aa1318e48ff",
            "/paper/PointConv%3A-Deep-Convolutional-Networks-on-3D-Point-Wu-Qi/5ee147684b06ffc4db0f6326e0cba017d12ceff3",
            "/paper/Interpolated-Convolutional-Networks-for-3D-Point-Mao-Wang/06f3e42c28fe87156c8be5188ff38fe9845df769",
            "/paper/PointNet%3A-Deep-Learning-on-Point-Sets-for-3D-and-Qi-Su/d997beefc0922d97202789d2ac307c55c2c52fba",
            "/paper/PAConv%3A-Position-Adaptive-Convolution-with-Dynamic-Xu-Ding/3cf833c45a6d56896a0487d332099e1646a16472",
            "/paper/ConvPoint%3A-Continuous-convolutions-for-point-cloud-Boulch/ea2ed8207be092a332cf07a30f8003ab02d2dfc8",
            "/paper/Relation-Graph-Network-for-3D-Object-Detection-in-Feng-Gilani/494908832aebc61beb522804f59a9cfc694332e4",
            "/paper/Deep-RBFNet%3A-Point-Cloud-Feature-Learning-using-Chen-Han/458a8e1461667c549f779ae4f1871f8fa0ac9f59",
            "/paper/Monte-Carlo-convolution-for-learning-on-sampled-Hermosilla-Ritschel/2c2d7daabd764f981950b71230e3ac96a0d21984",
            "/paper/Deep-Learning-for-3D-Point-Clouds%3A-A-Survey-Guo-Wang/0311ace1d499cadd1cc0c515a625d1d045f60d25",
            "/paper/Relation-Shape-Convolutional-Neural-Network-for-Liu-Fan/a58715797b61588cbd020b9a98292a98f8483420"
        ]
    },
    {
        "id": "11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
        "title": "FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows",
        "abstract": "This work proposes FastFlow implemented with 2D normalizing flows and uses it as the probability distribution estimator for unsupervised anomaly detection and localization and achieves 99.4% AUC in anomaly detection with high inference efficiency. Unsupervised anomaly detection and localization is crucial to the practical application when collecting and labeling sufficient anomaly data is infeasible. Most existing representation-based approaches extract normal image features with a deep convolutional neural network and characterize the corresponding distribution through non-parametric distribution estimation methods. The anomaly score is calculated by measuring the distance between the feature of the test image and the estimated distribution. However, current methods can not effectively map image features to a tractable base distribution and ignore the relationship between local and global features which are important to identify anomalies. To this end, we propose FastFlow implemented with 2D normalizing flows and use it as the probability distribution estimator. Our FastFlow can be used as a plug-in module with arbitrary deep feature extractors such as ResNet and vision transformer for unsupervised anomaly detection and localization. In training phase, FastFlow learns to transform the input visual feature into a tractable distribution and obtains the likelihood to recognize anomalies in inference phase. Extensive experimental results on the MVTec AD dataset show that FastFlow surpasses previous state-of-the-art methods in terms of accuracy and inference efficiency with various backbone networks. Our approach achieves 99.4% AUC in anomaly detection with high inference efficiency.",
        "publication_year": "2021",
        "authors": [
            "Jiawei Yu1",
            "Ye Zheng",
            "Xiang Wang",
            "Wei Li",
            "Yushuang Wu",
            "Rui Zhao",
            "Liwei Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "82",
        "reference_count": "34",
        "references": [
            "/paper/Patch-Density-Estimation-for-Anomaly-Detection-with-Wang-Li/375197faaeefc9362cb7655b8fa1f088746cf20b",
            "/paper/Image-Anomaly-Detection-and-Localization-with-and-Bae-Lee/2eb411964cc0fe51f7ee76f1904df2a2ea1ac976",
            "/paper/CAINNFlow%3A-Convolutional-block-Attention-modules-Yan-Zhang/66811ed2a06af032413ea029257808c8dc058523",
            "/paper/Anomaly-Detection-using-Contrastive-Normalizing-Schmier-K%C3%B6the/d4cf347ba89b0663c0464bbb9d5160010ebaaa70",
            "/paper/PNI-%3A-Industrial-Anomaly-Detection-using-Position-Bae-Lee/1634ee92621a332cbb250a1bdbb951e4e70e232a",
            "/paper/Towards-Total-Online-Unsupervised-Anomaly-Detection-Gao-Luo/861d11c147a8ad472c733ede13e8ef1275994a0d",
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/Unsupervised-Industrial-Anomaly-Detection-via-and-Huang-Li/43e15ca0c27b7e2e6137393b2e56c8587fc08d6d",
            "/paper/Learning-Global-Local-Correspondence-with-Semantic-Yao-Yu/58d59beb750e8c0e1d52b04dbc6c1c8b5ea3178a",
            "/paper/Benchmarking-Unsupervised-Anomaly-Detection-and-Zheng-Wang/76077e1e12908b525907e7c3419368291f5965ab",
            "/paper/CFLOW-AD%3A-Real-Time-Unsupervised-Anomaly-Detection-Gudovskiy-Ishizaka/fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "/paper/Glancing-at-the-Patch%3A-Anomaly-Localization-with-Wang-Wu/4758baad6b22c61682e7f7182bb93723046f36f5",
            "/paper/Modeling-the-Distribution-of-Normal-Data-in-Deep-Rippel-Mertens/37595f7a51982d776e57c7280b9445474d90f0be",
            "/paper/Learning-Semantic-Context-from-Normal-Samples-for-Yan-Zhang/8ee35ed698527d9695c872e3b76715fec4ef69ad",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/PANDA%3A-Adapting-Pretrained-Features-for-Anomaly-and-Reiss-Cohen/78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/Sub-Image-Anomaly-Detection-with-Deep-Pyramid-Cohen-Hoshen/9277dc70c74bcadf80dab11c28ead83fd085deec"
        ]
    },
    {
        "id": "a1302409469284cdd9dbf535548e6b3a401caae2",
        "title": "Data-centric Artificial Intelligence: A Survey",
        "abstract": "This is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle, and it is hoped it can help the readers efficiently grasp a broad picture of this field. Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI",
        "publication_year": "2023",
        "authors": [
            "D. Zha",
            "Zaid Pervaiz Bhat",
            "Kwei-Herng Lai",
            "Fan Yang",
            "Zhimeng Jiang",
            "Shaochen Zhong",
            "Xia Hu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": 0,
        "references": []
    },
    {
        "id": "2bba87662399bd5d856afdcb848124d3e1e67df4",
        "title": "GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection",
        "abstract": "GADBench provides a thorough comparison across 23 distinct models on ten real-world GAD datasets ranging from thousands to millions of nodes and finds that tree ensembles with simple neighborhood aggregation outperform all other baselines, including the latest GNNs tailored for the GAD task. With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting, (2) whether GNNs outperform traditional algorithms such as tree ensembles, and (3) their efficiency on large-scale graphs. In response, we present GADBench -- a comprehensive benchmark for supervised anomalous node detection on static graphs. GADBench provides a thorough comparison across 23 distinct models on ten real-world GAD datasets ranging from thousands to millions of nodes ($\\sim$6M). Our main finding is that tree ensembles with simple neighborhood aggregation outperform all other baselines, including the latest GNNs tailored for the GAD task. By making GADBench available as an open-source tool, we offer pivotal insights into the current advancements of GAD and establish a solid foundation for future research. Our code is available at https://github.com/squareRoot3/GADBench.",
        "publication_year": "2023",
        "authors": [
            "Jianheng Tang",
            "Fengrui Hua",
            "Ziqi Gao",
            "Peilin Zhao",
            "Jia Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "97",
        "references": [
            "/paper/Addressing-Heterophily-in-Graph-Anomaly-Detection%3A-Gao-Wang/4a76ea74e48ee96a0b846c58a843b2031da7b9de",
            "/paper/Rethinking-Graph-Neural-Networks-for-Anomaly-Tang-Li/53e80869c6582d7f95ef0a351170736afd1742d0",
            "/paper/How-Powerful-are-Graph-Neural-Networks-Xu-Hu/62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9",
            "/paper/Inductive-Representation-Learning-on-Large-Graphs-Hamilton-Ying/6b7d6e6416343b2a122f8416e69059ce919026ef",
            "/paper/The-perceptron%3A-a-probabilistic-model-for-storage-Rosenblatt/5d11aad09f65431b5d3cb1d85328743c9e53ba96",
            "/paper/Can-Abnormality-be-Detected-by-Graph-Neural-Chai-You/b7394e219eb2b3f39db5bfc49187e91bb09a902d",
            "/paper/BOND%3A-Benchmarking-Unsupervised-Outlier-Node-on-Liu-Dou/fea848dfcf44e67fe149bbcebcb52c92fba40f28",
            "/paper/ADBench%3A-Anomaly-Detection-Benchmark-Han-Hu/0bff4af924788d9779041513b6894385eac51ffd",
            "/paper/BernNet%3A-Learning-Arbitrary-Graph-Spectral-Filters-He-Wei/bbed89eee0a43baf17dd5eab8354deecadda8acf",
            "/paper/Pick-and-Choose%3A-A-GNN-based-Imbalanced-Learning-Liu-Ao/7487499f91f0c198347a8ebc747ad8d220bdd155"
        ]
    },
    {
        "id": "28367cd3b68489ebd819ddfc3fb042b301abd3c7",
        "title": "Anomaly Detection with Conditioned Denoising Diffusion Models",
        "abstract": "This paper proposes a novel denoising process for image reconstruction conditioned on a target image, leading to defectless reconstruction while maintaining nominal patterns, and introduces a domain adaptation method that utilises generated examples from the conditioned denoisation process to fine-tune the feature extractor. Reconstruction-based methods have struggled to achieve competitive performance on anomaly detection. In this paper, we introduce Denoising Diffusion Anomaly Detection (DDAD). We propose a novel denoising process for image reconstruction conditioned on a target image. This results in a coherent restoration that closely resembles the target image. Subsequently, our anomaly detection framework leverages this conditioning where the target image is set as the input image to guide the denoising process, leading to defectless reconstruction while maintaining nominal patterns. We localise anomalies via a pixel-wise and feature-wise comparison of the input and reconstructed image. Finally, to enhance the effectiveness of feature comparison, we introduce a domain adaptation method that utilises generated examples from our conditioned denoising process to fine-tune the feature extractor. The veracity of the approach is demonstrated on various datasets including MVTec and VisA benchmarks, achieving state-of-the-art results of 99.5% and 99.3% image-level AUROC respectively.",
        "publication_year": "2023",
        "authors": [
            "Arian Mousakhan",
            "T. Brox",
            "Jawad Tayyub"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "47",
        "references": [
            "/paper/AnoDDPM%3A-Anomaly-Detection-with-Denoising-Diffusion-Wyatt-Leach/20f6fce7726e7b3ab4ca45ef40d92b79f093f825",
            "/paper/Anomaly-localization-by-modeling-perceptual-Dehaene-Eline/9775d372bfaf889a395dc714e283b6a179e62537",
            "/paper/DR%C3%86M-%E2%80%93-A-discriminatively-trained-reconstruction-Zavrtanik-Kristan/95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "/paper/SPot-the-Difference-Self-Supervised-Pre-training-Zou-Jeong/2c1837be2e4e6c4f47d51c42773e398897c372a6",
            "/paper/FastFlow%3A-Unsupervised-Anomaly-Detection-and-via-2D-Yu1-Zheng/11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/Skip-GANomaly%3A-Skip-Connected-and-Adversarially-Ak%C3%A7ay-Atapour-Abarghouei/5435a9ab36a308cef10bc725104e8f778ed3a328"
        ]
    },
    {
        "id": "1312e46326f7e36fc82d16098b824540fe2dca66",
        "title": "Deep Industrial Image Anomaly Detection: A Survey",
        "abstract": "This paper provides a comprehensive review of deep learning-based image anomaly detection techniques, from the perspectives of neural network architectures, levels of supervision, loss functions, metrics and datasets. The recent rapid development of deep learning has laid a milestone in industrial Image Anomaly Detection (IAD). In this paper, we provide a comprehensive review of deep learning-based image anomaly detection techniques, from the perspectives of neural network architectures, levels of supervision, loss functions, metrics and datasets. In addition, we extract the new setting from industrial manufacturing and review the current IAD approaches under our proposed our new setting. Moreover, we highlight several opening challenges for image anomaly detection. The merits and downsides of representative network architectures under varying supervision are discussed. Finally, we summarize the research findings and point out future research directions. More resources are available at https://github.com/M-3LAB/awesome-industrial-anomaly-detection.",
        "publication_year": "2023",
        "authors": [
            "Jiaqi Liu",
            "Guoyang Xie",
            "Jingbao Wang",
            "Shangwen Li",
            "Chengjie Wang",
            "Feng Zheng",
            "Yaochu Jin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "174",
        "references": [
            "/paper/High-Fidelity-Zero-Shot-Texture-Anomaly-Using-Ardelean-Weyrich/26b8d5fb1083506cb7569c534312a24c02cb9119",
            "/paper/Deep-Learning-for-Unsupervised-Anomaly-Localization-Tao-Gong/51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
            "/paper/The-MVTec-Anomaly-Detection-Dataset%3A-A-Real-World-Bergmann-Batzner/48f9a48aa5b1230b05a443d2d531e6441a541686",
            "/paper/A-Survey-on-Unsupervised-Industrial-Anomaly-Cui-Liu/53c480c422d528fc379ba1cb160bd4cdbf38bffc",
            "/paper/ADTR%3A-Anomaly-Detection-Transformer-with-Feature-You-Yang/5533bf9f2385ebece563fea35b19e998db64e597",
            "/paper/Spatial-Contrastive-Learning-for-Anomaly-Detection-Kim-Jeong/6eedf365c6b580a6fc201eab867f1608f09adbae",
            "/paper/A-Multi-Scale-A-Contrario-method-for-Unsupervised-Tailani%C3%A1n-Mus'e/00b46923c31b21f59ab53cf693b6159c3dc4375d",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Masked-Swin-Transformer-Unet-for-Industrial-Anomaly-Jiang-Zhu/8ae2303e51f78954199e2a400c827aae4bb8e76a",
            "/paper/Learning-Unsupervised-Metaformer-for-Anomaly-Wu-Chen/8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "/paper/DFR%3A-Deep-Feature-Reconstruction-for-Unsupervised-Yang-Shi/cc63b87a654e28aefe60250e950572bfb3d7e2ea"
        ]
    },
    {
        "id": "42be3e7f9b95fcfa4455988a27dd17cf01d68507",
        "title": "Optimizing the Cell Painting assay for image-based profiling",
        "abstract": "An updated protocol for the most popular assay for image-based profiling, Cell Painting, aiming to improve upon the assay via quantitative optimization, based on the measured ability of the assay to detect morphological phenotypes and group similar perturbations together is described. In image-based profiling, software extracts thousands of morphological features of cells from multi-channel fluorescence microscopy images, yielding single-cell profiles that can be used for basic research and drug discovery. Powerful applications have been proven, including clustering chemical and genetic perturbations based on their similar morphological impact, identifying disease phenotypes by observing differences in profiles between healthy and diseased cells, and predicting assay outcomes using machine learning, among many others. Here we provide an updated protocol for the most popular assay for image-based profiling, Cell Painting. Introduced in 2013, it uses six stains imaged in five channels and labels eight diverse components of the cell: DNA, cytoplasmic RNA, nucleoli, actin, Golgi apparatus, plasma membrane, endoplasmic reticulum, and mitochondria. The original protocol was updated in 2016 based on several years\u2019 experience running it at two sites, after optimizing it by visual stain quality. Here we describe the work of the Joint Undertaking for Morphological Profiling (JUMP) Cell Painting Consortium, aiming to improve upon the assay via quantitative optimization, based on the measured ability of the assay to detect morphological phenotypes and group similar perturbations together. We find that the assay gives very robust outputs despite a variety of changes to the protocol and that two vendors\u2019 dyes work equivalently well. We present Cell Painting version 3, in which some steps are simplified and several stain concentrations can be reduced, saving costs. Cell culture and image acquisition take 1\u20132 weeks for a typically sized batch of 20 or fewer plates; feature extraction and data analysis take an additional 1\u20132 weeks. Key references using this protocol Virtual screening for small-molecule pathway regulators by image-profile matching (https://doi.org/10.1016/j.cels.2022.08.003) - recent work examining the ability to use collected Cell Painting profiles to screen for regulators of a number of diverse biological pathways. JUMP Cell Painting dataset: images and profiles from two billion cells perturbed by 140,000 chemical and genetic perturbations (DOI) - the description of the main JUMP master public data set, using this protocol in the production of >200 TB of image data and >200 TB of measured profiles. Key data used in this protocol Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes (https://doi.org/10.1038/nprot.2016.105) - this paper provides the first step-by-step Cell Painting protocol ever released.",
        "publication_year": "2022",
        "authors": [
            "B. Cimini",
            "S. Chandrasekaran",
            "M. Kost-Alimova",
            "Lisa Miller",
            "A. Goodale",
            "Briana Fritchman",
            "Patrick Byrne",
            "S. Garg",
            "Nasim Jamali",
            "David J. Logan",
            "J. Concannon",
            "Charles-Hugues Lardeau",
            "E. Mouchet",
            "Shantanu Singh",
            "H. Abbasi",
            "Peter Aspesi",
            "Justin D. Boyd",
            "Tamara Gilbert",
            "D. Gnutt",
            "S. Hariharan",
            "D. Hernandez",
            "Gisela Hormel",
            "Karolina Juhani",
            "Michelle Melanson",
            "Lewis H. Mervin",
            "Tiziana Monteverde",
            "J. Pilling",
            "Adam Skepner",
            "Susanne E. Swalley",
            "Anita Vrcic",
            "Erin Weisbart",
            "Guy B. Williams",
            "Shan Yu",
            "Bolek Zapiec",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "9",
        "reference_count": "45",
        "references": [
            "/paper/Assessing-the-performance-of-the-Cell-Painting-Jamali-Tromans-Coia/dbe577b3cdc30f0f1b264a86affc9db96c6065a7",
            "/paper/JUMP-Cell-Painting-dataset%3A-morphological-impact-of-Chandrasekaran-Ackerman/1f96460299f3c74965b4fe8e64c28957ada06c74",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Three-million-images-and-morphological-profiles-of-Chandrasekaran-Cimini/3e173f19037739ae6e84bc3b9f97957c42412660",
            "/paper/Interpreting-Image%E2%80%90based-Profiles-using-Similarity-Garcia-Fossa-Cruz/46276273cf92c31e103feab0cdc2ad0adda0dcc9",
            "/paper/Class-Guided-Image-to-Image-Diffusion%3A-Cell-from-Cross-Zamirski-Anand/e2f4ffbb02f50b50f81bd3070d266b32dab0800a",
            "/paper/High-dimensional-phenotyping-to-define-the-genetic-Tegtmeyer-Arora/bdaa483118aca85811f4612b78122d33d611129e",
            "/paper/Self-Supervised-Learning-of-Phenotypic-from-Cell-Cross-Zamirski-Williams/98496b462b6a0406e41a956e68319ac17344a739",
            "/paper/Multivariate-chemogenomic-screening-prioritizes-new-Wheeler-Ryan/ececbef8af719d96990ebd5998296ca42fd1a727",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0",
            "/paper/Label-free-prediction-of-cell-painting-from-images-Cross-Zamirski-Mouchet/590fc45e167068cac9a8a98eee95725531a5a352",
            "/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5",
            "/paper/Image-based-cell-phenotyping-with-deep-learning.-Pratapa-Doron/8f8a0de72c285f10bd3af311899026193eda632e",
            "/paper/Morphology-and-gene-expression-profiling-provide-Way-Natoli/1f7bb6a080c1db96c778793514bf2b1638b623ab",
            "/paper/Multiplex-Cytological-Profiling-Assay-to-Measure-G%C3%BAstafsd%C3%B3ttir-Ljosa/df775e0093d4e96e2690fa9f48f60d76e4fede19",
            "/paper/Three-million-images-and-morphological-profiles-of-Chandrasekaran-Cimini/3e173f19037739ae6e84bc3b9f97957c42412660",
            "/paper/Cell-Painting-predicts-impact-of-lung-cancer-Caicedo-Arevalo/c5dd04fdd9e9e55cc172e4e1316b58ff1fb7aa45",
            "/paper/High-Dimensional-Gene-Expression-and-Morphology-of-Haghighi-Singh/bff33206f1782c889c393aecb87bbd7939af61f0",
            "/paper/Systematic-morphological-profiling-of-human-gene-Rohban-Singh/c6bf43a2bfffec64989baa2d193a6a845defa59e"
        ]
    },
    {
        "id": "620c8bd40fb70209659c31a8055fc6cc79b07d78",
        "title": "A Scaled LMS Algorithm for Sparse System Identification with Impulsive Interference",
        "abstract": "A new LMS algorithm is proposed to improve the accuracy of the sparse system identification with impulse interference by combining sparse constraint and impulse interference. A new LMS algorithm is proposed to improve the accuracy of the sparse system identification with impulse interference. The algorithm adopts a scaler to filter impulse interference, the scalar is also used for identifying sparse systems. The adaptive iteration can avoid significant changes since the abrupt impulsive interference in the channel estimation. Furthermore, the proposed method searches the sparse solution by considering the system sparsity and using an approximated \u21130\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\ell _0$$\\end{document} norm constraint. Because the proposed method combines sparse constraint and impulse interference, it gradually adjusts the step size according to the gradient. The effectiveness and superiority of the proposed algorithm are confirmed for sparse system identification with impulse interference in simulations.",
        "publication_year": "2023",
        "authors": [
            "F. Wu",
            "Yan-Chong Song",
            "Ru Peng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "22",
        "references": [
            "/paper/A-neighborhood-based-multiple-orthogonal-least-for-Song-Wu/745990a3a401900874855d6041b03015e114eb09",
            "/paper/A-Normalized-Least-Mean-Squares-Algorithm-With-a-Song-Park/98a56025b90612c8f214f6b5551057e43e9991c5",
            "/paper/Cluster-sparsity-induced-affine-projection-and-its-Zong-Ni/14da37bc7afc9dd125adaca89789f2aef0882dd9",
            "/paper/Robust-and-sparsity-aware-adaptive-filters%3A-A-Kumar-Pandey/bdd4e52c88601085cfffa63493f4f5b95eed6034",
            "/paper/Robust-Variable-Step-Size-Reweighted-Least-Mean-for-Wang-Zhao/6e08add5629c51b78421e20053d348814da17f66",
            "/paper/A-sparse-variable-step-size-LMS-algorithm-for-noise-Salman-El-Sayed/ccc43ab1ed556e13df84a8ffbec3fe6293d9f006",
            "/paper/2019-3rd-International-Conference-on-for-Smart/1eaf167053b01698378b16e340e48f867772aaf3",
            "/paper/Compressive-Sampling-and-Reconstruction-of-Acoustic-Wu-Yang/86f3d5fef1a3d50e37fa75cbf79a89b0cdc6b630",
            "/paper/Adaptive-Sparse-System-Identification-in-Compressed-Hosseini-Shayesteh/e93b1233d6abf6b6b5711fb45822c5ba40bfb93b",
            "/paper/NLMS-Algorithm-Based-on-a-Variable-Parameter-Cost-Huang-Zhang/9fe0346e354f91c6db34fb37e35c194be8be05f7",
            "/paper/A-Normalized-Least-Mean-Square-Algorithm-Based-on-Zeng-Lin/dd5396f6999c51f6541d4a442c2226eb96147d72"
        ]
    },
    {
        "id": "1a50298e16ebefb61151bcdfa0e2a4bd5afb92cf",
        "title": "Knowledge Graphs for Semantic-Aware Anomaly Detection in Video",
        "abstract": "A semantics centered method for video anomaly detection which allows to identify entities that are inconsistent with the scene and thus can be marked as a potential anomaly and provides an enhanced framework that leads to anomaly detection in video with higher accuracy and better interpretability. Video understanding, surveillance and analytics fields have been dynamically expanding over the recent years due to the enormous amount of CCTV, dashcams and phone cameras which generate video data stored on cloud servers, in social networks, in public and private repositories. The video data has a great potential to be used for improving situation awareness, prediction and prevention of unwanted events and disasters in various settings. Still, there is a significant need for methods and ways to understand the large amount of video recordings and to extract hidden patterns and knowledge. Deep learning networks have been successfully applied for video object and anomaly detection tasks. However, while neural networks focus on utilizing features within an object to be detected, the vast amount of background knowledge remains unnoticed. We propose a semantics centered method for video anomaly detection which allows to identify entities that are inconsistent with the scene and thus can be marked as a potential anomaly. Our method is inspired with the way humans comprehend the surroundings with incorporating external knowledge and previous experience. As a source of external knowledge for deep learning networks we maintain a knowledge graph which allows to compute semantic similarity between the detected objects. Similarity of the entities in the frame depends on the distance between the graph vertices which represent the recognized entities. The object which is semantically distinct from other entities in the video is an anomalous one. We conduct experiments on real-life data to empirically prove the efficiency of our approach and provide an enhanced framework that leads to anomaly detection in video with higher accuracy and better interpretability.",
        "publication_year": "2020",
        "authors": [
            "A. Nesen",
            "B. Bhargava"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "4",
        "reference_count": "42",
        "references": [
            "/paper/A-graph-based-approach-to-video-anomaly-detection-Siemon-Nasrollahi/8afe9473732dfa46e7ce0f4ea3197328021aeeb9",
            "/paper/Towards-Explainable-Visual-Anomaly-Detection-Wang-Guo/484bbbfe3a4a8cc5fcf3218cac61a7d0efe77490",
            "/paper/Towards-situational-awareness-with-multimodal-data-Nesen-Bhargava/54de7eb889fc1a4b9dfa2816c4769be3c26f8cdd",
            "/paper/Hybrid-Knowledge-Engineering-to-Build-a-Global-Sticha-Broussard/e3530ad791d345822e9b18fbe942120a5d1a7696",
            "/paper/Detecting-anomalous-events-in-videos-by-learning-of-Xu-Yan/e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "/paper/Object-Detection-Meets-Knowledge-Graphs-Fang-Kuan/74793980135737800c9d579f80605669d97cfcdb",
            "/paper/Abnormal-Event-Detection-in-Videos-using-Chong-Tay/527cc8cd2af06a9ac2e5cded806bab5c3faad9cf",
            "/paper/Video-Analytics-for-Visual-Surveillance-and-An-and-Olatunji-Cheng/b918b9a7573956d3d718e88e988bfa7d16856779",
            "/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429",
            "/paper/Anomaly-Detection-with-Graph-Convolutional-Networks-Jiang-Chen/a4e86e9df17292555c10e1023fd2dd1cf635ab35",
            "/paper/Towards-Network-Anomaly-Detection-Using-Graph-Xiao-Liu/74e0152a128a1acc2429473d50a7f3b7e16887d3",
            "/paper/Anomaly-Detection-using-Graph-Neural-Networks-Chaudhary-Mittal/f33b3acd937f70d3408fcbc3f7c63b1b1903f3fe",
            "/paper/Detecting-semantic-anomalies-Ahmed-Courville/4cfd8f903506865e7ccf28b0a07ee3c551487e92",
            "/paper/You-Only-Look-Once%3A-Unified%2C-Real-Time-Object-Redmon-Divvala/f8e79ac0ea341056ef20f2616628b3e964764cfd"
        ]
    },
    {
        "id": "7070ae889786abe2b363bb7a0e3b1a7b81077742",
        "title": "C2FTrans: Coarse-to-Fine Transformers for Medical Image Segmentation",
        "abstract": "C2FTrans is a novel multi-scale architecture that formulates medical image segmentation as a coarse-to-\ufb01ne procedure and superior performance against state-of-the-art CNN-based and transformer-based methods with fewer parameters and lower FLOPs is demonstrated. \u2014Convolutional neural networks (CNN), the most prevailing architecture for deep-learning based medical image analysis, are still functionally limited by their intrinsic inductive biases and inadequate receptive \ufb01elds. Transformer, born to address this issue, has drawn explosive attention in natural language processing and computer vision due to its remarkable ability in capturing long-range dependency. However, most re- cent transformer-based methods for medical image segmentation directly apply vanilla transformers as an auxiliary module in CNN-based methods, resulting in severe detail loss due to the rigid patch partitioning scheme in transformers. To address this problem, we propose C2FTrans, a novel multi-scale architecture that formulates medical image segmentation as a coarse-to-\ufb01ne procedure. C2FTrans mainly consists of a cross-scale global transformer (CGT) which addresses local contextual similarity in CNN and a boundary-aware local transformer (BLT) which over-comes boundary uncertainty brought by rigid patch partitioning in transformers. Speci\ufb01cally, CGT builds global dependency across three different small-scale feature maps to obtain rich global semantic features with an acceptable computational cost, while BLT captures mid-range dependency by adaptively generat- ing windows around boundaries under the guidance of entropy to reduce computational complexity and minimize detail loss based on large-scale feature maps. Extensive experimental results on three public datasets demonstrate the superior performance of C2FTrans against state-of-the-art CNN-based and transformer-based methods with fewer parameters and lower FLOPs. We believe the design of C2FTrans would further inspire future work on developing ef\ufb01cient and lightweight transformers for medical image segmentation. The source code of this paper is publicly available at https://github.com/xianlin7/C2FTrans.",
        "publication_year": "2022",
        "authors": [
            "Xiangru Lin",
            "Zengqiang Yan",
            "Li Yu",
            "Kwang-Ting Cheng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "48",
        "references": [
            "/paper/Coarse-to-Fine-Tranformer-for-articular-disc-of-the-Wu-Zhou/bcce3ad67cd6bd91f1d82b834a7a110c1ea136b9",
            "/paper/Diagnostic-value-of-mammography-density-of-breast-Chen-Lin/915bd2032f0689d75084ca3842271b24f65d8c07",
            "/paper/Multi-Stage-Aggregation-Transformer-for-Medical-Wang-Shao/10c4e1e65313cba9f08f9736916d92fe58066a7a",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/Pyramid-Medical-Transformer-for-Medical-Image-Zhang-Sun/c3dff4eb8c0ec1cbe6fc0db17522cc26bb693dac",
            "/paper/Swin-Unet%3A-Unet-like-Pure-Transformer-for-Medical-Cao-Wang/ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "/paper/A-Multi-scale-Transformer-for-Medical-Image-Model-Gao-Zhou/7bbd8d675df1b08cb73a0f260c7c3606f707323c",
            "/paper/LeViT-UNet%3A-Make-Faster-Encoders-with-Transformer-Xu-Wu/faa30dfcb1531df4e4d5c219bad06d65f6c860fa",
            "/paper/UTNet%3A-A-Hybrid-Transformer-Architecture-for-Image-Gao-Zhou/a2a0fc5014423d6283c80511b9272d941109ece2",
            "/paper/TransAttUnet%3A-Multi-level-Attention-guided-U-Net-Chen-Liu/69b985ae4a8331107cdfa148335bf08d15787bda",
            "/paper/Contextual-Attention-Network%3A-Transformer-Meets-Azad-Heidari/e85ed2810da4ce240c31f4e7d282fa14dfc10282",
            "/paper/CoTr%3A-Efficiently-Bridging-CNN-and-Transformer-for-Xie-Zhang/8356d155d730e374f4db6dfd03d19a7b66c348a8"
        ]
    },
    {
        "id": "9a5356d74076b7e1b8a7bcb0e459fc923abafb27",
        "title": "Robust nuclei segmentation in histopathology using ASPPU-Net and boundary refinement",
        "abstract": "Semantic Scholar extracted view of \"Robust nuclei segmentation in histopathology using ASPPU-Net and boundary refinement\" by T. Wan et al.",
        "publication_year": "2020",
        "authors": [
            "T. Wan",
            "Lei Zhao",
            "Hongxiang Feng",
            "Deyu Li",
            "Chao Tong",
            "Zengchang Qin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "30",
        "reference_count": "50",
        "references": [
            "/paper/MSAL-Net%3A-improve-accurate-segmentation-of-nuclei-Ali-Haq/0ede258f3007863ade1bb2c7316b4b57925485ac",
            "/paper/High-resolution-deep-transferred-ASPPU-Net-for-of-Chanchal-Lal/07341eaa7ea8d8261a15c946127ce5eebb0d463b",
            "/paper/MIU-Net%3A-MIX-Attention-and-Inception-U-Net-for-Li-Li/50f94d7225158d6ec467aca927b2d533a478512c",
            "/paper/DenseRes-Unet%3A-Segmentation-of-overlapped-clustered-Kiran-Raza/c96757792971d93b7a5a3cff3bcc9fbe6e7fa97b",
            "/paper/Efficient-and-robust-deep-learning-architecture-for-Chanchal-Kumar/e34b82190c9177300ed3e002ca5ce1c770eb24d8",
            "/paper/Distance-ordinal-regression-loss-for-an-improved-Doan-Han/21b003003dda08d6299328cbeee519343976ff9b",
            "/paper/Multi-level-feature-fusion-network-for-nuclei-in-Li-Pi/650a504033b1c138dc440b7bea9a496c812c377c",
            "/paper/Deep-learning-based-tumor-segmentation-on-digital-Weishaupt-Torres/f11e9a50197a62ad32b6c8502e3cb952ff7e0dd5",
            "/paper/Nuclei-segmentation-of-HE-stained-histopathological-Shi-Zhong/ea6700185bf1188ee1747f5805f0907fe07343f6",
            "/paper/Effect-of-Color-Normalization-on-Nuclei-Problem-in-Y%C4%B1ld%C4%B1r%C4%B1m-Han%C3%A7er/67649beadb20095c41fd9f0beb96eea1fdf8b948",
            "/paper/Robust-nuclei-segmentation-in-images-using-level-Taheri-Fevens/b3b0ef5dbd138e6ac5c94f92c93808dcb671d688",
            "/paper/Accurate-segmentation-of-nuclei-in-pathological-via-Pan-Li/c9a372fc3b30bb2da051e941cab44c3e5ba31065",
            "/paper/An-Automatic-Learning-Based-Framework-for-Robust-Xing-Xie/d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88",
            "/paper/Improved-Automatic-Detection-and-Segmentation-of-in-Al-Kofahi-Lassoued/63a373063d51489b31e07ee639ab74b6cf586240",
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/Automatic-Nuclei-Segmentation-in-H%26E-Stained-Breast-Veta-Diest/e312652daf82ed144d1696aae7ab412030d4f7eb",
            "/paper/Nuclei-segmentation-in-histopathology-images-using-Naylor-La%C3%A9/78db21fabea962592ac0aef54624251550929109",
            "/paper/Multi-tissue-and-multi-scale-approach-for-nuclei-in-Salvi-Molinari/ac158a0fa7ae122cc5e3785382aa364762c26839"
        ]
    },
    {
        "id": "4613161c6d14962c5119c299194227e9484a3e68",
        "title": "StainNet: A Fast and Robust Stain Normalization Network",
        "abstract": "Distillation learning is used to reduce the complexity of deep learning methods and a fast and robust network called StainNet to learn the color mapping between the source image and the target image and shows that StainNet can achieve comparable performance to the deep learning-based methods. Stain normalization often refers to transferring the color distribution to the target image and has been widely used in biomedical image analysis. The conventional stain normalization usually achieves through a pixel-by-pixel color mapping model, which depends on one reference image, and it is hard to achieve accurately the style transformation between image datasets. In principle, this difficulty can be well-solved by deep learning-based methods, whereas, its complicated structure results in low computational efficiency and artifacts in the style transformation, which has restricted the practical application. Here, we use distillation learning to reduce the complexity of deep learning methods and a fast and robust network called StainNet to learn the color mapping between the source image and the target image. StainNet can learn the color mapping relationship from a whole dataset and adjust the color value in a pixel-to-pixel manner. The pixel-to-pixel manner restricts the network size and avoids artifacts in the style transformation. The results on the cytopathology and histopathology datasets show that StainNet can achieve comparable performance to the deep learning-based methods. Computation results demonstrate StainNet is more than 40 times faster than StainGAN and can normalize a 100,000 \u00d7 100,000 whole slide image in 40 s.",
        "publication_year": "2020",
        "authors": [
            "Hongtao Kang",
            "Die Luo",
            "Weihua Feng",
            "Li Chen",
            "Junbo Hu",
            "S. Zeng",
            "Tingwei Quan",
            "Xiuli Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "25",
        "reference_count": "37",
        "references": [
            "/paper/ParamNet%3A-A-Parameter-variable-Network-for-Fast-Kang-Luo/70a0d404cd603168ce1f4e5cded4d3e44eebd5bd",
            "/paper/Stain-normalization-using-score-based-diffusion-and-Jeong-Kim/37c884bacb33fe029dd8aeddd4cfec45370f32ea",
            "/paper/MS-SST%3A-Single-Image-Reconstruction-Based-Transfer-Kweon-Kim/39735a28b35b58a05ad80a4ae37adc5d019b0f7d",
            "/paper/Impact-of-Stain-Normalisation-Technique-on-Deep-in-Vaishnani-Gohel/bfd02f617bbbc76db0eb831d97de8897275938a4",
            "/paper/HistoStarGAN%3A-A-Unified-Approach-to-Stain-Stain-and-Vasiljevi'c-Feuerhake/e3d1a9e6c7292e7ac25490487dc7524a9dfc3f2c",
            "/paper/Data-driven-color-augmentation-for-H%26E-stained-in-Marini-Ot%C3%A1lora/4a446868cb8c2edba9d08153a44150e19e50ebea",
            "/paper/Automatic-normalized-digital-color-staining-in-the-Barrera-Rodellar/d4e106c61be5134ed7e7136955e4f8155f89fbce",
            "/paper/A-comparative-evaluation-of-image-to-image-methods-Zingman-Frayle/8a4d9e176918a0566aa826b1a20bcc3cca9ca040",
            "/paper/H%26E-adversarial-network%3A-a-convolutional-neural-to-Marini-Atzori/0ebeadfccb243526c4677e8b29f9c9fa7f3fb98c",
            "/paper/MultiPathGAN%3A-Structure-Preserving-Stain-using-with-Nazki-Arandjelovic/bbd95a5cc0137cadadba79ca3b7e5e62c84cc444",
            "/paper/StainCNNs%3A-An-efficient-stain-feature-learning-Lei-Xia/fadacd4b2bf12bdd4f208b9d8823644927b9f854",
            "/paper/Pix2Pix-based-Stain-to-Stain-Translation%3A-A-for-in-Salehi-Chalechale/da663cac292b8c6e714ee8ee9300cb3bc35e16d5",
            "/paper/Quantifying-the-effects-of-data-augmentation-and-in-Tellez-Litjens/35ee6606ec99b5bf282a0c5f400edbd16a6e22d9",
            "/paper/A-Nonlinear-Mapping-Approach-to-Stain-Normalization-Khan-Rajpoot/0eac0ed2c87910dbb7d9f622854efb7c7b7b6f0b",
            "/paper/Stain-Standardization-Capsule-for-Histopathological-Zheng-Jiang/e328836a747c0e51bac7fbd7201e90143cd3a65a",
            "/paper/Staingan%3A-Stain-Style-Transfer-for-Digital-Images-Shaban-Baur/e926486ab0dfd772d7da41489b47da0db935b3d8",
            "/paper/Stain-Color-Adaptive-Normalization-(SCAN)-and-of-in-Salvi-Michielli/e9a0e056e0bc51a105323a1938f79821fa0400c1",
            "/paper/A-High-Performance-System-for-Robust-Stain-of-in-Anghel-Stanisavljevic/d8ea4f5a2e63bbb3e2447d499e0fc3e23767a800",
            "/paper/Enhanced-Cycle-Consistent-Generative-Adversarial-of-Zhou-Cai/ab613e80271896c2a2721f08be1adc60a02a856e",
            "/paper/GCTI-SN%3A-Geometry-inspired-chemical-and-tissue-of-Gupta-Duggal/81aa6aea42e017bc421ab0d72617fc8aefb2bb47"
        ]
    },
    {
        "id": "3afe6c838fd4303d3b67c505c69723701b462649",
        "title": "Neural Graph Modelling of Whole Slide Images for Survival Analysis",
        "abstract": "Analysis over breast cancer patients from The Cancer Genome Atlas shows that the proposed GNN approach is able to rank patients with respect to their disease-specific survival times with a concordance index of 0 . Evaluation of a cancer patient\u2019s prognostic outlook is an essential step in the clinical decision-making process, involving the assessment of complex tissue structures in multi-gigapixel whole slide images (WSIs). Effective risk stratification of patients from WSIs has proven challenging despite several approaches across the literature due to their large size and inability of existing approaches to effectively model inter-relationships between different tissue components. We propose a graph neural network (GNN) model that performs pairwise ranking of graph representations of WSIs based on survival scores. The proposed approach translates spatially-localised deep features along with their spatial context to a graph neural network to produce survival scores. Analysis over breast cancer patients from The Cancer Genome Atlas (TCGA) shows that the proposed GNN approach is able to rank patients with respect to their disease-specific survival times with a concordance index of 0 . 672 \u00b1 0 . 058 . This is a significant improvement over existing state of the art and paves the way for neural graph modelling of WSI data for survival prediction for other cancer types.",
        "publication_year": "2022",
        "authors": [
            "C. MacKenzie"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "19",
        "references": [
            "/paper/A-Survey-on-Graph-Based-Deep-Learning-for-Ahmedt-Aristizabal-Armin/70727c82f1ab97b3f64ee3e81e6e209c40fa0a02",
            "/paper/Deep-learning-for-survival-analysis-in-breast-with-Liu-Kur%C3%A7/ad43ed303b0366d10605a67e7be6ca79558a0afe",
            "/paper/Capturing-Cellular-Topology-in-Multi-Gigapixel-Lu-Graham/b002572090eacb1353e40d1e84f171d44f7cc5c6",
            "/paper/WSISA%3A-Making-Survival-Prediction-from-Whole-Slide-Zhu-Yao/1d4515b228621962f48e873d50edd7442d6b3fc5",
            "/paper/SlideGraph%2B%3A-Whole-Slide-Image-Level-Graphs-to-in-Lu-Toss/665311d9a1482513145b3befddeaa5a6ed524989",
            "/paper/Whole-slide-images-based-cancer-survival-prediction-Yao-Zhu/f0c24d4ba514081a7bc77905e3e12998937ba68b",
            "/paper/Multimodal-Co-Attention-Transformer-for-Survival-in-Chen-Lu/5d1aadd4053ba4fdcd71fe1c87a53b7540ef4eea",
            "/paper/L1-regularized-neural-ranking-for-risk-and-its-to-Minhas-Toss/806d8867c0ddf393d52302896d75a66676b14b0f",
            "/paper/ALBRT%3A-Cellular-Composition-Prediction-in-Routine-Dawood-Branson/7510553411e05cab7c1ed9e1823d164e65627d38",
            "/paper/An-Integrated-TCGA-Pan-Cancer-Clinical-Data-to-Liu-Lichtenberg/0bb89ae07cc71db0792fd1985d24e4d8ca928466"
        ]
    },
    {
        "id": "66b92a2250d9b899c03c3f2699a40e18e56bcd51",
        "title": "Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers",
        "abstract": "The proposed model, named Polyp-PVT, effectively suppresses noises in the features and significantly improves their expressive capabilities, and is more robust to various challenging situations than existing representative methods. Most polyp segmentation methods use CNNs as their backbone, leading to two key issues when exchanging information between the encoder and decoder: 1) taking into account the differences in contribution between different-level features and 2) designing an effective mechanism for fusing these features. Unlike existing CNN-based methods, we adopt a transformer encoder, which learns more powerful and robust representations. In addition, considering the image acquisition influence and elusive properties of polyps, we introduce three standard modules, including a cascaded fusion module (CFM), a camouflage identification module (CIM), and a similarity aggregation module (SAM). Among these, the CFM is used to collect the semantic and location information of polyps from high-level features; the CIM is applied to capture polyp information disguised in low-level features, and the SAM extends the pixel features of the polyp area with high-level semantic position information to the entire polyp area, thereby effectively fusing cross-level features. The proposed model, named Polyp-PVT, effectively suppresses noises in the features and significantly improves their expressive capabilities. Extensive experiments on five widely adopted datasets show that the proposed model is more robust to various challenging situations (\\emph{e.g.}, appearance changes, small objects, rotation) than existing representative methods. The proposed model is available at https://github.com/DengPingFan/Polyp-PVT.",
        "publication_year": "2021",
        "authors": [
            "B. Dong",
            "Wenhai Wang",
            "Deng-Ping Fan",
            "Jinpeng Li",
            "H. Fu",
            "Ling Shao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "61",
        "reference_count": "100",
        "references": [
            "/paper/Meta-Polyp%3A-a-baseline-for-efficient-Polyp-Trinh/0b2f76cda2b8aded9e67629b52361f55f1e8aba7",
            "/paper/TransMixer%3A-A-Hybrid-Transformer-and-CNN-for-Polyp-Huang-Tan/ad2d04b17caafe4c8b349b275244a1eee71f6d8c",
            "/paper/LAPFormer%3A-A-Light-and-Accurate-Polyp-Segmentation-Nguyen-Bui/532ba9f0fe152469b8690fc96433b85b0410f834",
            "/paper/FuzzyNet%3A-A-Fuzzy-Attention-Module-for-Polyp-Patel-Li/6b8c7bf8fb6104f439c60058ccebdd6bf698260f",
            "/paper/PDNet%3A-an-advanced-architecture-for-polyp-image-Liu-Zhao/aa9d5f650bb31f48be1de98785e7b9fb0128bbb1",
            "/paper/Video-Polyp-Segmentation%3A-A-Deep-Learning-Ji-Xiao/624eb5680f4198f2c1fd7afdf0f981bc810a1ba7",
            "/paper/Medical-Image-Segmentation-via-Cascaded-Attention-Rahman-Marculescu/c27dcfd2e6bbe0954eeb06c9b72f4937778ec4bb",
            "/paper/Polyp-Mixer%3A-An-Efficient-Context-Aware-MLP-Based-Shi-Zhang/b6dbc6e7f676e0e52f0d649ef9ccad9f97a64677",
            "/paper/Cooperation-Learning-Enhanced-Colonic-Polyp-Based-Wang-Deng/ed4448734e4e38b5ea335321dd5bc7436d2fc10e",
            "/paper/ICBNet%3A-Iterative-Context-Boundary-Feedback-Network-Xiao-Chen/cd53b4c3ad92c2bf32bcffed7fe6f05d1035d463",
            "/paper/Enhanced-U-Net%3A-A-Feature-Enhancement-Network-for-Patel-Bur/8775dd7a4f3582de8d1b196865495df73638931c",
            "/paper/Selective-Feature-Aggregation-Network-with-for-Fang-Chen/8cd4364347f647f2d2165953988c8895524dd8cc",
            "/paper/Lesion-Aware-Dynamic-Kernel-for-Polyp-Segmentation-Zhang-Lai/3db5d75f4eac3d79128558993e9a5490c32c1f82",
            "/paper/Adaptive-Context-Selection-for-Polyp-Segmentation-Zhang-Li/c7c4c25a5d6a92d386125fa6ff4d259f461ef775",
            "/paper/Video-Polyp-Segmentation%3A-A-Deep-Learning-Ji-Xiao/624eb5680f4198f2c1fd7afdf0f981bc810a1ba7",
            "/paper/Automatic-Polyp-Segmentation-via-Multi-scale-Zhao-Zhang/f36ff155a741f4c404fcac9de1d47e53aa99e71b",
            "/paper/Polyp-Mixer%3A-An-Efficient-Context-Aware-MLP-Based-Shi-Zhang/b6dbc6e7f676e0e52f0d649ef9ccad9f97a64677",
            "/paper/F3Net%3A-Fusion%2C-Feedback-and-Focus-for-Salient-Wei-Wang/b86cf0116da79318b07062b1d3456711fdf808aa",
            "/paper/Progressively-Normalized-Self-Attention-Network-for-Ji-Chou/492ed313c743b58ba64751ebddaba0638e8939d8",
            "/paper/Shallow-Attention-Network-for-Polyp-Segmentation-Wei-Hu/b3b3cb0dca8200dc64971020b39e036e64d72416"
        ]
    },
    {
        "id": "63399cd601e8f58a833c31d98d87a9c3c144041f",
        "title": "C2SLR: Consistency-enhanced Continuous Sign Language Recognition",
        "abstract": "A keypoint-guided spatial attention module is inserted into the visual module to enforce it to focus on informative regions, i.e., spatial attention consistency, and a sentence embedding consistency constraint is imposed between them to enhance the representation power of both the features. The backbone of most deep-learning-based continuous sign language recognition (CSLR) models consists of a visual module, a sequential module, and an alignment module. However, such CSLR backbones are hard to be trained sufficiently with a single connectionist temporal classification loss. In this work, we propose two auxiliary constraints to enhance the CSLR backbones from the perspective of consistency. The first constraint aims to enhance the visual module, which easily suffers from the insufficient training problem. Specifically, since sign languages convey information mainly with signers' faces and hands, we insert a keypoint-guided spatial attention module into the visual module to enforce it to focus on informative regions, i.e., spatial attention consistency. Nevertheless, only enhancing the visual module may not fully exploit the power of the backbone. Motivated by that both the output features of the visual and sequential modules represent the same sentence, we further impose a sentence embedding consistency constraint between them to enhance the representation power of both the features. Experimental results over three representative backbones validate the effectiveness of the two constraints. More remarkably, with a transformer-based backbone, our model achieves state-of-the-art or competitive performance on three benchmarks, PHOENIX-2014, PHOENIX-2014-T, and CSL.",
        "publication_year": "2022",
        "authors": [
            "Ronglai Zuo",
            "B. Mak"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "55",
        "references": [
            "/paper/Improving-Continuous-Sign-Language-Recognition-with-Zuo-Mak/8cac1a726a7fa1160ce86733e66ebba6c78b71eb",
            "/paper/Self-Emphasizing-Network-for-Continuous-Sign-Hu-Gao/1f55d35e1d1a148898a756cb0380b22fa8878dcb",
            "/paper/Conditional-Diffusion-Feature-Refinement-for-Sign-Guo-Xue/314e3cc058b0633a1ca228efa8c455534ed689ca",
            "/paper/Two-Stream-Network-for-Sign-Language-Recognition-Chen-Zuo/78bc5b0a9fa28ccf2a580f36783e310d436a7874",
            "/paper/CVT-SLR%3A-Contrastive-Visual-Textual-Transformation-Zheng-Wang/ff03fe2efa8e0283f06098e9f1ae41b76e66efec",
            "/paper/Natural-Language-Assisted-Sign-Language-Recognition-Zuo-Wei/6648bbbb7ad41397d315d1c83ac02a39ac875b19",
            "/paper/Continuous-sign-language-recognition-based-on-Zhu-Li/539c2d729819d561e0e9a157bb38c611ec6817fb",
            "/paper/Continuous-Sign-Language-Recognition-with-Network-Hu-Gao/d9c38e7957c10252cc0e66b20c55d5be615db10d",
            "/paper/Self-Mutual-Distillation-Learning-for-Continuous-Hao-Min/609d68085efa9b1da1068639e4850252cc0cf6ae",
            "/paper/Visual-Alignment-Constraint-for-Continuous-Sign-Min-Hao/2d2d5bb1d025c5e17abe13716599c93e1f131927",
            "/paper/Spatial-Temporal-Multi-Cue-Network-for-Continuous-Zhou-Zhou/a1e2665ac39dcb389e12f3f993004b4b4651826d",
            "/paper/Boosting-Continuous-Sign-Language-Recognition-via-Pu-Zhou/ce50fa888551b640fe3dddc57289c27f325c029b",
            "/paper/Fully-Convolutional-Networks-for-Continuous-Sign-Cheng-Yang/6af09da568edee80075ec610f431ffa91bfce061",
            "/paper/Connectionist-Temporal-Fusion-for-Sign-Language-Wang-Guo/33e309f993023a0384221733dd884e2b891c8311",
            "/paper/Spatial-Temporal-Multi-Cue-Network-for-Sign-and-Zhou-Zhou/d76e2a01f914b81afacec214c302e82c000c65ef",
            "/paper/A-Deep-Neural-Framework-for-Continuous-Sign-by-Cui-Liu/f96ffd8c71b97e46eb3ba48263c9012d197494d4",
            "/paper/Dilated-Convolutional-Network-with-Iterative-for-Pu-Zhou/9d8ef2cbaaf8281600135670d44dda3acd82e1aa",
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e"
        ]
    },
    {
        "id": "fed150a219f9c31bdb4920e615c7c9264c634736",
        "title": "On the Challenges and Perspectives of Foundation Models for Medical Image Analysis",
        "abstract": "The opportunities, applications and future directions of large-scale pre-trained models, i.e., foundation models, for analyzing medical images, and how foundation models can be leveraged in downstream medical tasks to enhance the accuracy and efficiency of medical image analysis are discussed. This article discusses the opportunities, applications and future directions of large-scale pre-trained models, i.e., foundation models, for analyzing medical images. Medical foundation models have immense potential in solving a wide range of downstream tasks, as they can help to accelerate the development of accurate and robust models, reduce the large amounts of required labeled data, preserve the privacy and confidentiality of patient data. Specifically, we illustrate the\"spectrum\"of medical foundation models, ranging from general vision models, modality-specific models, to organ/task-specific models, highlighting their challenges, opportunities and applications. We also discuss how foundation models can be leveraged in downstream medical tasks to enhance the accuracy and efficiency of medical image analysis, leading to more precise diagnosis and treatment decisions.",
        "publication_year": "2023",
        "authors": [
            "Shaoting Zhang",
            "Dimitris N. Metaxas"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "44",
        "references": [
            "/paper/Segment-Anything-Model-for-Medical-Image-Analysis%3A-Mazurowski-Dong/c6ac64877b2bcac2389be4d91a62dea8c6f73844",
            "/paper/Accuracy-of-Segment-Anything-Model-(SAM)-in-medical-He-Bao/31d84fb10f8c99a0a6fd68c69495d78e2f5fe02a",
            "/paper/STU-Net%3A-Scalable-and-Transferable-Medical-Image-by-Huang-Wang/ebb1acf1eb3705510de5a19065092404427428a5",
            "/paper/Segment-Anything-Model-for-Medical-Images-Huang-Yang/ce429fbb0533585f662a3fdb8a636f3c2403498f",
            "/paper/Segment-Anything-in-Medical-Images-Ma-Wang/4dd869a2c17cacd03b3e8a9b7efcd48f40651925",
            "/paper/UniverSeg%3A-Universal-Medical-Image-Segmentation-Butoi-Ortiz/1648b4b355e15a814453c3a3c297fad815172f67",
            "/paper/A-Large-scale-Synthetic-Pathological-Dataset-for-of-Ding-Zhou/3499afedecabd747d913bb184721b6a4e82dca59",
            "/paper/Self-Supervised-Pre-Training-of-Swin-Transformers-Tang-Yang/076a8e778f2e9efb3c2fd45fed534ae9e6035f1b",
            "/paper/The-Medical-Segmentation-Decathlon-Antonelli-Reinke/979a9f247700d00ff2c3f0612d5eb001379f93c8",
            "/paper/Foundation-models-for-generalist-medical-artificial-Moor-Banerjee/9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a"
        ]
    },
    {
        "id": "25bafc9f20ee8b4390f939766a26fc895dfc7c3b",
        "title": "Learning to Segment Microscopy Images with Lazy Labels",
        "abstract": "A deep convolutional neural network is introduced for microscopy image segmentation that brings more flexibility and efficiency for training deep neural networks that are data hungry and is applicable to biomedical images with poor contrast at the object boundaries or with diverse textures and repeated patterns. The need for labour intensive pixel-wise annotation is a major limitation of many fully supervised learning methods for segmenting bioimages that can contain numerous object instances with thin separations. In this paper, we introduce a deep convolutional neural network for microscopy image segmentation. Annotation issues are circumvented by letting the network being trainable on coarse labels combined with only a very small number of images with pixel-wise annotations. We call this new labelling strategy `lazy' labels. Image segmentation is stratified into three connected tasks: rough inner region detection, object separation and pixel-wise segmentation. These tasks are learned in an end-to-end multi-task learning framework. The method is demonstrated on two microscopy datasets, where we show that the model gives accurate segmentation results even if exact boundary labels are missing for a majority of annotated data. It brings more flexibility and efficiency for training deep neural networks that are data hungry and is applicable to biomedical images with poor contrast at the object boundaries or with diverse textures and repeated patterns.",
        "publication_year": "2019",
        "authors": [
            "Rihuan Ke",
            "A. Bugeau",
            "N. Papadakis",
            "Peter Sch\u00fctz",
            "C. Sch\u00f6nlieb"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "12",
        "reference_count": "48",
        "references": [
            "/paper/Weak-labels-and-anatomical-knowledge%3A-making-deep-Noto-Marie/3c468c3a4211d4df54b16e6fa1246c6bcad9f182",
            "/paper/A-Three-Stage-Self-Training-Framework-for-Semantic-Ke-Avil%C3%A9s-Rivero/12ed6a69793430ff42e0c5ada0efa32d768caaa2",
            "/paper/Assisting-human-experts-in-the-interpretation-of-A-Hascoet-Deng/94705d9bc8580c3d0c64000689c3389dae6e2755",
            "/paper/Weakly-Supervised-Learning-with-Automated-Labels-Noto-Cuadra/462923d1dec7ab6fae044f4505ea49581f7f5e2e",
            "/paper/Accelerating-the-creation-of-instance-segmentation-Sayez-Vleeschouwer/373d6b3df9642698ead3b555589d4280a6249774",
            "/paper/Annotation-Efficient-3d-U-Nets-For-Brain-Plasticity-Gjesteby-Klinghoffer/b2514a7768f7488042ee1a110799f0d319012003",
            "/paper/Towards-Automated-Brain-Aneurysm-Detection-in-Open-Noto-Marie/e8177965012b16c95bb0db3ea5c085e939c2f02f",
            "/paper/Vessel-CAPTCHA%3A-an-efficient-learning-framework-for-Dang-Giacomo/492904963d34db850cf6053d52bbb298eb0bebe7",
            "/paper/Transfer-learning-with-weak-labels-from-radiology-Noto-Cuadra/98fef026effaf736eb93e7dcb06edf89d953c637",
            "/paper/Title-%3A-Towards-clinically-applicable-automated-in-Noto-Marie/ef9329565b114a36ce6ddab2602e1c0bda89107b",
            "/paper/An-Auxiliary-Task-for-Learning-Nuclei-Segmentation-Hirsch-Kainmueller/40071396490823a1f110911ee314c8bdb6aea813",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/DenoiSeg%3A-Joint-Denoising-and-Segmentation-Buchholz-Prakash/b04d54821b7aab4b371c273d51bbb7cf381048c3",
            "/paper/High-Resolution-Encoder%E2%80%93Decoder-Networks-for-Image-Zhou-Nie/556de729a6a4c7fa90acb2bd9a8c8fe9d62f1c93",
            "/paper/A-Novel-Weakly-Supervised-Multitask-Architecture-on-Playout-Duval/9e339bf47933a1b11379e3e3c4d40170f82549d2",
            "/paper/Coarse-to-Fine-Semantic-Segmentation-From-Labels-Jing-Chen/7d514e2a999b37b665e42078fc29d48743ed173c",
            "/paper/Deep-learning-with-mixed-supervision-for-brain-Mlynarski-Delingette/1c9d2244346972d582560b5dbfd10ad7a0784a38",
            "/paper/Weakly-and-Semi-Supervised-Learning-of-a-Deep-for-Papandreou-Chen/da2f85e313160992b1a0e3db70eb02b58ec740c0",
            "/paper/Multiclass-Weighted-Loss-for-Instance-Segmentation-Guerrero-Pe%C3%B1a-Marrero-Fern%C3%A1ndez/5896bd31724bd2f57630473e1e466ea08c3b0c34",
            "/paper/A-two-stage-3D-Unet-framework-for-multi-class-on-Wang-MacGillivray/e90568386be825ef357fe057bc8b6d8c7a7a8feb"
        ]
    },
    {
        "id": "48e25055325747db9edffcce0177b653e1538624",
        "title": "Self-assessed quality of life after acoustic neuroma surgery.",
        "abstract": "The QOL scores are not consistently lower than population normative values compared with different normative studies, and the strongest correlation was between the presence of persistent headache and QOL. OBJECT\nThe aim of this study was to determine if factors such as postoperative hearing, facial function, headaches, or other factors have an impact on self-assessed quality of life (QOL) after acoustic neuroma surgery.\n\n\nMETHODS\nThe SF-36 and seven additional questions on the impact of surgery on the QOL were sent to 135 consecutive patients who had undergone acoustic neuroma surgery. The Spearman rho correlations were calculated for each of the eight categories of the SF-36 (general health, physical functioning, physical role limitations, emotional role limitations, mental health, energy/vitality, pain, social functioning). The results were correlated with patients' sex, age, persistent headache, years since surgery, postoperative hearing level, and facial function. The response rate was 74.8%. The transformed scores of the eight categories of the SF-36 were lower than age-matched healthy controls in approximately half of the categories. The strongest trend toward lower scores with statistical significance in two categories was persistent headaches. Some categories demonstrated trends toward lower scores with females or age older than 55 years. Postoperative hearing and facial functioning, and time since surgery showed no statistically significant impact on QOL measured by the SF-36. Responses to the additional questions indicate that hearing, facial function, and headache influenced people's feelings about surgery and had an impact on their return to work.\n\n\nCONCLUSIONS\nThe QOL scores are not consistently lower than population normative values compared with different normative studies. The strongest correlation was between the presence of persistent headache and QOL. Other correlations were not consistent in all categories, and few were statistically significant. These trends in some categories do not explain the difference seen between patients after acoustic neuroma surgery in this study and normal populations in other studies.",
        "publication_year": "2003",
        "authors": [
            "Simone A. Betchen",
            "Jane Walsh",
            "K. Post"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "100",
        "reference_count": "27",
        "references": [
            "/paper/Quality-of-Life-After-Acoustic-Neuroma-Surgery-Tufarelli-Meli/6aef9ec3ee997bffb42550b74ffaf7b30d522734",
            "/paper/Surgery-for-large-vestibular-schwannomas%3A-how-and-Nicoucar-Momjian/338f4b9f57034ef52e39aa3af43089f60b4e970a",
            "/paper/Quality-of-life-in-vestibular-schwannoma%3A-a-of-Lucidi-Fabbris/609acd3a806945f6095b9da3be6141cbd67718e2",
            "/paper/Quality-of-life-after-microsurgery-for-vestibular-Scheich-Ginzkey/ac98f481ee44e89f926728f166a9ee037929aa44",
            "/paper/%5BQuality-of-life-following-vestibular-schwannoma-Alfonso-Lassaletta/f1a4c4788027295b3bb6e8fc6bccc93efb175ff0",
            "/paper/Audiovestibular-Factors-Influencing-Quality-of-Life-Lloyd-Kasbekar/f2c310e5e7b813094c5ebd7dc6e269059e366dca",
            "/paper/Quality-of-Life-After-Vestibular-Schwannoma-A-of-Bender-Tatagiba/da4fbd5b776eaa044b1b57f1f9bf87dd7b2d8aaf",
            "/paper/Quality-of-Life-Among-Acoustic-Neuroma-Patients-by-Brooker-Fletcher/e5dddd3b88688d2a53397edb7e798af3389d053b",
            "/paper/Headache-Syndromes-After-Acoustic-Neuroma-Surgery-Schankin-Gall/ab9f07ade8567a44fb6c4947d275d8922fd7e676",
            "/paper/Quality-of-life-after-vestibular-schwannoma-does-a-Iyer-Gunn/2e54aa9d490352320bcb56ea86708442d9e19ccc",
            "/paper/Patient-assessed-outcomes-after-excision-of-and-of-Martin-Sethi/7d457bbc2bde775d6b4bf81723da814b045aa8ff",
            "/paper/Acoustic-neuroma-surgery%3A-outcome-analysis-of-Rigby-Shah/9c5e01f8d012a45b4cdae955a7a049272f7f9c28",
            "/paper/Evaluation-of-quality-of-life-and-symptoms-after-Andersson-Ekvall/8a7053554d0dd74e61eaf648c0fc47b4d15b580c",
            "/paper/Quality-of-life-after-acoustic-neuroma-surgery-Nikolopoulos-Johnson/c5ef43064be085f2cf4003d7cd14ef47d59badd6",
            "/paper/Socioeconomic-impact-of-acoustic-neuroma-surgery.-Chung-Rigby/5c504874b7e081c4aadd1acf64716bcc80871b7a",
            "/paper/Some-aspects-of-life-quality-after-surgery-for-Parving-Tos/95dfd55d5816a3e40ec0706fcd13dd3322f37d6b",
            "/paper/The-patient's-perspective-after-vestibular-removal%3A-Irving-Beynon/786baba477038f4d232df47ca4643adac167912c",
            "/paper/Health-related-quality-of-life-in-patients-with-Kelleher-Fernandes/1ee7affd0a4a918ab153311d6d5c541c94ce43a9",
            "/paper/Validating-the-SF-36-health-survey-questionnaire-in-Husted-Gladman/5d3aa2a5aaaa21d55e6158ab7c6b4a2825ae89c5",
            "/paper/Audit-of-headache-following-resection-of-acoustic-Santarius-D'Sousa/f73864e1891474c45d34869a65374f5f5794be48"
        ]
    },
    {
        "id": "8500d2883a31e2aae12bcaa4cdf6b13df84419a0",
        "title": "PseudoEdgeNet: Nuclei Segmentation only with Point Annotations",
        "abstract": "A novel auxiliary network, called PseudoEdgeNet, is introduced, which guides the segmentation network to recognize nuclei edges even without edge annotations, which demonstrates that the method consistently outperforms other weakly supervised methods. Nuclei segmentation is one of the important tasks for whole slide image analysis in digital pathology. With the drastic advance of deep learning, recent deep networks have demonstrated successful performance of the nuclei segmentation task. However, a major bottleneck to achieving good performance is the cost for annotation. A large network requires a large number of segmentation masks, and this annotation task is given to pathologists, not the public. In this paper, we propose a weakly supervised nuclei segmentation method, which requires only point annotations for training. This method can scale to large training set as marking a point of a nucleus is much cheaper than the fine segmentation mask. To this end, we introduce a novel auxiliary network, called PseudoEdgeNet, which guides the segmentation network to recognize nuclei edges even without edge annotations. We evaluate our method with two public datasets, and the results demonstrate that the method consistently outperforms other weakly supervised methods.",
        "publication_year": "2019",
        "authors": [
            "Inwan Yoo",
            "Donggeun Yoo",
            "K. Paeng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "45",
        "reference_count": "21",
        "references": [
            "/paper/A-Weakly-Supervised-Method-With-Colorization-for-Xia-Qu/a5ee62db221460479384528652b18c312166e3aa",
            "/paper/Label-Propagation-for-Annotation-Efficient-Nuclei-Lin-Qu/278a955814209be919449a616c5b8a25781478b7",
            "/paper/NINEPINS%3A-Nuclei-Instance-Segmentation-with-Point-Yen-Hsu/d1c5c22fac0be0728417c028a4106fa8c215dafb",
            "/paper/D2E2-Net%3A-Double-Deep-Edge-Enhancement-for-Cell/ea1016999109a842b3c6cb33a26bd30e6396f281",
            "/paper/SAC-Net%3A-Learning-with-weak-and-noisy-labels-in-Guo-Xie/49d91f47f80156ba6767f263afe24f3a6d1e5e22",
            "/paper/Weakly-Supervised-Nucleus-Segmentation-Based-on-A-Tian-Zhang/2af96daa1456fdb2a004f62a3fa28986e76e7fa4",
            "/paper/Point-Supervised-Segmentation-Of-Microscopy-Images-Li-Dey/45155461fdf4863d7860540938a9696afcceeb63",
            "/paper/Weakly-Supervised-Nuclei-Segmentation-Via-Instance-Liu-He/41d93b3a5740fc48af22d1d6043b759a1ee9e5be",
            "/paper/Weakly-supervised-segmentation-with-point-for-via-Zhang-Burrows/87f99e385207066c5658a9e28405ca5770e9b090",
            "/paper/ImPartial%3A-Partial-Annotations-for-Cell-Instance-Mart%C3%ADnez-Sapiro/a7acdf0cfa9971e1cad316b560e96b7a5c54ce8f",
            "/paper/Nuclei-segmentation-via-sparsity-constrained-Zhou-Chang/043b28c2586e390d6295578243b71e67ecac9a36",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/Cell-Segmentation-Proposal-Network-for-Microscopy-Akram-Kannala/a2e06c347c192c94bcae153c36199d1272f7408f",
            "/paper/Normalized-Cut-Loss-for-Weakly-Supervised-CNN-Tang-Djelouah/9831dc24bba0aaaf32218989a5259d9110437950",
            "/paper/ScribbleSup%3A-Scribble-Supervised-Convolutional-for-Lin-Dai/3d1e82b69663758a1db87fbebed6525d23090146",
            "/paper/Microscopy-cell-counting-with-fully-convolutional-Xie-Noble/6775ba237f3c3d077ba3639d96cb307ce2bce260",
            "/paper/On-Regularized-Losses-for-Weakly-supervised-CNN-Tang-Perazzi/36ad8eaa6d01ceec2efda3a9563320822920088f",
            "/paper/You-Should-Use-Regression-to-Detect-Cells-Kainz-Urschler/99daf0b8c7a3880d34acff7bc7b370fc7e8a4cf1",
            "/paper/SFCN-OPI%3A-Detection-and-Fine-grained-Classification-Zhou-Dou/7dd50431db3c4983270f9d089b1767c3afe981fd"
        ]
    },
    {
        "id": "0decb43be5171fcf69b8983844fd4449743b5ab4",
        "title": "DeFall: Environment-Independent Passive Fall Detection Using WiFi",
        "abstract": "DeFall is proposed, a WiFi-based passive FD system that is independent of the environment and free of prior training in new environments that achieves a detection rate above 95% with a false alarm rate lower than 1.50% under both line-of-sight (LOS) and non-LOS (NLOS) scenarios. Fall is recognized as one of the most frequent accidents among elderly people. Many solutions, either wearable or noncontact, have been proposed for fall detection (FD) recently. Among them, WiFi-based noncontact approaches are gaining popularity due to the ubiquity and noninvasiveness. The existing works, however, usually rely on labor-intensive and time-consuming training before it can achieve a reasonable performance. In addition, the trained models often contain environment-specific information and, thus, cannot be generalized well for new environments. In this article, we propose DeFall, a WiFi-based passive FD system that is independent of the environment and free of prior training in new environments. Unlike previous works, our key insight is to probe the physiological features inherently associated with human falls, i.e., the distinctive patterns of speed and acceleration during a fall. DeFall consists of an offline template-generating stage and an online decision-making stage, both taking the speed estimates as input. In the offline stage, augmented dynamic time-warping (DTW) algorithms are performed to generate a representative template of the speed and acceleration patterns for a typical human fall. In the online phase, we compare the patterns of the real-time speed/acceleration estimates against the template to detect falls. To evaluate the performance of DeFall, we built a prototype using commercial WiFi devices and conducted experiments under different settings. The results demonstrate that DeFall achieves a detection rate above 95% with a false alarm rate lower than 1.50% under both line-of-sight (LOS) and non-LOS (NLOS) scenarios with one single pair of transceivers. Extensive comparison study verifies that DeFall can be generalized well to new environments without any new training.",
        "publication_year": "2022",
        "authors": [
            "Yuqian Hu",
            "Feng Zhang",
            "Chenshu Wu",
            "Beibei Wang",
            "K. Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "15",
        "reference_count": 0,
        "references": [
            "/paper/SiFall%3A-Practical-Online-Fall-Detection-with-RF-Ji-Xie/51377aee7e62d369aadc785ffc2c55355944280e",
            "/paper/Wifi-based-robust-indoor-localization-for-daily-Regani-Hu/1048b5d749a57074a1e0a0b8ff368a82e0572cd3",
            "/paper/AutoFi%3A-Towards-Automatic-WiFi-Human-Sensing-via-Yang-Chen/2a1ea90a71131275685d815daa9c5c40208f9c9f",
            "/paper/Device-Free-Human-Activity-Recognition-Based-on-Gu-He/c503f54e890f4d92dc4ca098a16910dce0fa46d6",
            "/paper/Cost-effective-Elderly-Fall-Detection-with-Symmetry-Li-Cui/a0589621579ef10004024a4544f28d9582d0b185",
            "/paper/AutoFi%3A-Toward-Automatic-Wi-Fi-Human-Sensing-via-Yang-Chen/0339a004619428c06eb619dcb1a4fc41d8542254",
            "/paper/Ubiquitous-WiFi-and-Acoustic-Sensing%3A-Principles%2C-Huang-Wang/89cd811263e20d97cdd7c975a479614561e1039b",
            "/paper/CSI-Based-Location-Independent-Human-Activity-Using-Zhang-Liu/d88f92840f600f6d35bcf42ad021c1d9be2acc3f",
            "/paper/Robust-Passive-Proximity-Detection-Using-Wi-Fi-Hu-Ozturk/3d039c6902f5ffcdd93a1f0322b9906ee2452a57",
            "/paper/Embracing-LoRa-Sensing-with-Device-Mobility-Xie-Ganesan/bf4cfbc8c937db95ba965c30941c6c784b2e182d"
        ]
    },
    {
        "id": "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
        "title": "MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection",
        "abstract": "This work introduces the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories, and conducts a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolved neural networks. The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the \ufb01eld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the \ufb01rst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",
        "publication_year": "2019",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "C. Steger"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "508",
        "reference_count": "29",
        "references": [
            "/paper/The-MVTec-Anomaly-Detection-Dataset%3A-A-Real-World-Bergmann-Batzner/48f9a48aa5b1230b05a443d2d531e6441a541686",
            "/paper/Modeling-the-Distribution-of-Normal-Data-in-Deep-Rippel-Mertens/37595f7a51982d776e57c7280b9445474d90f0be",
            "/paper/A-Comparison-of-Supervised-and-Unsupervised-Deep-in-Wilmet-Verma/4588b87fcec20e40761feb0c4bfce2cb96667d0a",
            "/paper/DFR%3A-Deep-Feature-Reconstruction-for-Unsupervised-Yang-Shi/cc63b87a654e28aefe60250e950572bfb3d7e2ea",
            "/paper/Detecting-Anomalies-using-Generative-Adversarial-on-Zawar-Bhayani/75ff16feb277f705239daf331b8085b7b1ddf037",
            "/paper/Hierarchical-Image-Transformation-and-Multi-Level-Farady-Kuo/2d86ea32eac8da6fbb3f3d24936515e39e477bdb",
            "/paper/AutoEncoder-regularization-using-Support-Vector-for-Ravi-Karray/63976e0132590dd77be422185846f4269c6ee39f",
            "/paper/Inpainting-Transformer-for-Anomaly-Detection-Pirnay-Chai/19862af96b6af51e879e6e3f1d3d421af5427005",
            "/paper/Self-Supervised-Masked-Convolutional-Transformer-Madan-Ristea/90962dfefabe152e36376ff04d9fd66a54b9ad86",
            "/paper/Unsupervised-anomaly-segmentation-via-deep-feature-Shi-Yang/4dd78b8d466b4cfe55a1bbdc694291197ce62541",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/6cf1d69e447e9687dbd2d92572f44bddbabd8192",
            "/paper/Anomaly-Detection-using-One-Class-Neural-Networks-Chalapathy-Menon/67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "/paper/Learning-Deep-Features-for-One-Class-Classification-Perera-Patel/732c21998e251d64cd58b6a86886ee5907efeaa5",
            "/paper/Improving-Unsupervised-Defect-Segmentation-by-to-Bergmann-L%C3%B6we/9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "/paper/Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky/5d90f06bb70a0a3dced62413346235c02b1aa086"
        ]
    },
    {
        "id": "0eaf7b23698b7d37166e66b8346cf0bb4f89b9fd",
        "title": "A Survey on Deep Learning Based Segmentation, Detection and Classification for 3D Point Clouds",
        "abstract": "An in-depth assessment of the latest developments in deep learning-based 3D object recognition is offered, along with evaluations of their distinctive qualities. The computer vision, graphics, and machine learning research groups have given a significant amount of focus to 3D object recognition (segmentation, detection, and classification). Deep learning approaches have lately emerged as the preferred method for 3D segmentation problems as a result of their outstanding performance in 2D computer vision. As a result, many innovative approaches have been proposed and validated on multiple benchmark datasets. This study offers an in-depth assessment of the latest developments in deep learning-based 3D object recognition. We discuss the most well-known 3D object recognition models, along with evaluations of their distinctive qualities.",
        "publication_year": "2023",
        "authors": [
            "Prasoon Kumar Vinodkumar",
            "Do\u011fu\u015f Karabulut",
            "Egils Avots",
            "C. Ozcinar",
            "G. Anbarjafari"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "90",
        "references": [
            "/paper/Deep-Learning-on-Point-Sets-for-3-D-Classification-Qi/8d62db434a5fec66c85153a8109509ff786dd29a",
            "/paper/Deep-Learning-for-3D-Point-Clouds%3A-A-Survey-Guo-Wang/0311ace1d499cadd1cc0c515a625d1d045f60d25",
            "/paper/Review-of-multi-view-3D-object-recognition-methods-Qi-Ning/18b308b2c82a3207de8f3467249731c494ccf5ad",
            "/paper/PointNet%3A-Deep-Learning-on-Point-Sets-for-3D-and-Qi-Su/d997beefc0922d97202789d2ac307c55c2c52fba",
            "/paper/Deep-Hough-Voting-for-3D-Object-Detection-in-Point-Qi-Litany/e60da8d3a79801a3ccbf1abcdd001bb6e001b267",
            "/paper/Revisiting-Point-Cloud-Classification%3A-A-New-and-on-Uy-Pham/b2b0c31d036941cb557be4afb7101dc1b72f17cb",
            "/paper/Joint-3D-Proposal-Generation-and-Object-Detection-Ku-Mozifian/675784f097dbf87cd75a5640019d4469e7bd7905",
            "/paper/SECOND%3A-Sparsely-Embedded-Convolutional-Detection-Yan-Mao/5125a16039cabc6320c908a4764f32596e018ad3",
            "/paper/ImVoteNet%3A-Boosting-3D-Object-Detection-in-Point-Qi-Chen/ddb42aace56362ea9725a33815a64bb213d0329a",
            "/paper/Point-cloud-based-3D-object-detection-and-methods-A-Fernandes-Silva/fe3eb5bdd6aec1633efaf9f71fba21aeae48234a"
        ]
    },
    {
        "id": "375197faaeefc9362cb7655b8fa1f088746cf20b",
        "title": "Patch Density Estimation for Anomaly Detection with Deep Pyramid Features",
        "abstract": "A novel two-stage framework is proposed in this paper to build anomaly estimators with normal data only and model the distribution of training data on the learned representations as the one-class classifier to detect anomaly. Anomaly detection and localization are critical in modern manufacturing for the quality control of products. A particular challenge is that the collecting and labeling of anomaly examples are usually infeasible before implementation. To tackle the problem, a novel two-stage framework is proposed in this paper to build anomaly estimators with normal data only. Specifically, unsupervised deep representations are learned first by a modified SimSiam where an adaptation for one-class learning is implemented. Then the non-parametric method is adopted to model the distribution of training data on the learned representations as the one-class classifier to detect anomaly. Moreover, we model the distribution with different hierarchy level\u2019s features of the convolutional neural network to achieve both image-level and pixel-level detections. Experiments are conducted on MVTec anomaly detection dataset. Competitive results of 92.6% AUROC score for image-level detection and 95.4% for pixel-level detection are obtained to demonstrate the effectiveness of the proposed method.",
        "publication_year": "2022",
        "authors": [
            "XiaoYan Wang",
            "Daping Li",
            "Wanghui Bu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "24",
        "references": [
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/FastFlow%3A-Unsupervised-Anomaly-Detection-and-via-2D-Yu1-Zheng/11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/Sub-Image-Anomaly-Detection-with-Deep-Pyramid-Cohen-Hoshen/9277dc70c74bcadf80dab11c28ead83fd085deec",
            "/paper/Deep-Structured-Energy-Based-Models-for-Anomaly-Zhai-Cheng/10a498003e9204f5fc1328e706510a37e514d8c7",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Anomaly-Detection-with-Robust-Deep-Autoencoders-Zhou-Paffenroth/2b75ba7f75170b73d913c515cc0deefef6c88f5f",
            "/paper/Classification-Based-Anomaly-Detection-for-General-Bergman-Hoshen/04513c7c0b3a63fde81a996dae064a28d453c17a",
            "/paper/Self-Supervised-Out-of-Distribution-Detection-and-Schl%C3%BCter-Tan/0eb80e81580568ce9d70ad1c2495aef188a9587f",
            "/paper/f%E2%80%90AnoGAN%3A-Fast-unsupervised-anomaly-detection-with-Schlegl-Seeb%C3%B6ck/f88cfc38dec02dcf050eb1f56d2d59d90b24e04c"
        ]
    },
    {
        "id": "4a76ea74e48ee96a0b846c58a843b2031da7b9de",
        "title": "Addressing Heterophily in Graph Anomaly Detection: A Perspective of Graph Spectrum",
        "abstract": "The proposed indicator can effectively reduce the heterophily degree of the graph, thus boosting the overall GAD performance and showing that prediction errors are less likely to affect the identification process. Graph anomaly detection (GAD) suffers from heterophily \u2014 abnormal nodes are sparse so that they are connected to vast normal nodes. The current solutions upon Graph Neural Networks (GNNs) blindly smooth the representation of neiboring nodes, thus undermining the discriminative information of the anomalies. To alleviate the issue, recent studies identify and discard inter-class edges through estimating and comparing the node-level representation similarity. However, the representation of a single node can be misleading when the prediction error is high, thus hindering the performance of the edge indicator. In graph signal processing, the smoothness index is a widely adopted metric which plays the role of frequency in classical spectral analysis. Considering the ground truth Y to be a signal on graph, the smoothness index is equivalent to the value of the heterophily ratio. From this perspective, we aim to address the heterophily problem in the spectral domain. First, we point out that heterophily is positively associated with the frequency of a graph. Towards this end, we could prune inter-class edges by simply emphasizing and delineating the high-frequency components of the graph. Recall that graph Laplacian is a high-pass filter, we adopt it to measure the extent of 1-hop label changing of the center node and indicate high-frequency components. As GAD can be formulated as a semi-supervised binary classification problem, only part of the nodes are labeled. As an alternative, we use the prediction of the nodes to estimate it. Through our analysis, we show that prediction errors are less likely to affect the identification process. Extensive empirical evaluations on four benchmarks demonstrate the effectiveness of the indicator over popular homophilic, heterophilic, and tailored fraud detection methods. Our proposed indicator can effectively reduce the heterophily degree of the graph, thus boosting the overall GAD performance. Codes are open-sourced in https://github.com/blacksingular/GHRN.",
        "publication_year": "2023",
        "authors": [
            "Yuan Gao",
            "Xiang Wang",
            "Xiangnan He",
            "Zhenguang Liu",
            "Huamin Feng",
            "Yongdong Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "49",
        "references": [
            "/paper/GADBench%3A-Revisiting-and-Benchmarking-Supervised-Tang-Hua/2bba87662399bd5d856afdcb848124d3e1e67df4",
            "/paper/Clarify-Confused-Nodes-Through-Separated-Learning-Gong-Zhou/a6812ef3160d0b2751c08a960d691dba4718dfbf",
            "/paper/Revisiting-Heterophily-For-Graph-Neural-Networks-Luan-Hua/4becb19c87f0526d9a3a2c15497e0b1c40b576e2",
            "/paper/Rethinking-Graph-Neural-Networks-for-Anomaly-Tang-Li/53e80869c6582d7f95ef0a351170736afd1742d0",
            "/paper/Enhancing-Graph-Neural-Network-based-Fraud-against-Dou-Liu/14156438bafed28a626738630b5181b83ed5d79c",
            "/paper/Adaptive-Universal-Generalized-PageRank-Graph-Chien-Peng/0ee0801ba010a441403f9ed666ef9bf006b3aa07",
            "/paper/Representation-Learning-on-Graphs-with-Jumping-Xu-Li/5aea95e1ae78a66474051a330ded374e199b658c",
            "/paper/H2-FDetector%3A-A-GNN-based-Fraud-Detector-with-and-Shi-Cao/414668b64b026ff50e4d91d14fbe7b8327cfe026",
            "/paper/When-Does-A-Spectral-Graph-Neural-Network-Fail-in-Chen-Ma/23e176e940cfb2362687a2c3dc1e81f1ec0eb55a",
            "/paper/Intention-aware-Heterogeneous-Graph-Attention-for-Liu-Sun/27313cb7a36d419b49b6c81b39d815c9b660bfef",
            "/paper/Semi-Supervised-Classification-with-Graph-Networks-Kipf-Welling/36eff562f65125511b5dfab68ce7f7a943c27478",
            "/paper/Incorporating-Bias-aware-Margins-into-Contrastive-Zhang-Ma/12b1b40d6fa7dc97b3c9093eb668a2517c54bedc"
        ]
    },
    {
        "id": "9775d372bfaf889a395dc714e283b6a179e62537",
        "title": "Anomaly localization by modeling perceptual features",
        "abstract": "This work proposes a new VAE-based model expressing a more complex anomaly model that is also closer to human perception, and achieves clear improvement over state-of-the-art methods on the MVTec anomaly detection and localization datasets. Although unsupervised generative modeling of an image dataset using a Variational AutoEncoder (VAE) has been used to detect anomalous images, or anomalous regions in images, recent works have shown that this method often identifies images or regions that do not concur with human perception, even questioning the usability of generative models for robust anomaly detection. Here, we argue that those issues can emerge from having a simplistic model of the anomaly distribution and we propose a new VAE-based model expressing a more complex anomaly model that is also closer to human perception. This Feature-Augmented VAE is trained by not only reconstructing the input image in pixel space, but also in several different feature spaces, which are computed by a convolutional neural network trained beforehand on a large image dataset. It achieves clear improvement over state-of-the-art methods on the MVTec anomaly detection and localization datasets.",
        "publication_year": "2020",
        "authors": [
            "David Dehaene",
            "P. Eline"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "18",
        "reference_count": "28",
        "references": [
            "/paper/Anomaly-Detection-with-Conditioned-Denoising-Models-Mousakhan-Brox/28367cd3b68489ebd819ddfc3fb042b301abd3c7",
            "/paper/Multi-Scale-Patch-Based-Representation-Learning-for-Tsai-Wu/45535b86c60661dd4c4e4f375abae80937563499",
            "/paper/Unsupervised-Anomaly-Detection-for-Surface-Defects-Tao-Zhang/dffe0f7cd102210333ef533761753a909aa03294",
            "/paper/Industrial-Anomaly-Detection-with-Skip-Autoencoder-Tang-Hsu/57c0eb0d5e89e82336ac605c24d95c4ae99109dc",
            "/paper/Deep-Industrial-Image-Anomaly-Detection%3A-A-Survey-Liu-Xie/1312e46326f7e36fc82d16098b824540fe2dca66",
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/Divide-and-Assemble%3A-Learning-Block-wise-Memory-for-Hou-Zhang/93040f8a5d10e8fde279e18d353aa3dca2873900",
            "/paper/Deep-Learning-for-Unsupervised-Anomaly-Localization-Tao-Gong/51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
            "/paper/Deep-Visual-Anomaly-Detection-in-Industrial-A-Liu-Xie/c39aac50bc5dbaf1ea14eef48043156b51884238",
            "/paper/What-makes-a-good-data-augmentation-for-few-shot-Zhang-Zhang/0ab8bd8ac5d19981af4a12bd07559e77246644e1",
            "/paper/Iterative-energy-based-projection-on-a-normal-data-Dehaene-Frigo/d9d7ab13ce305ccee309c989a2341d72b1252070",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "/paper/Fully-Convolutional-Neural-Network-for-Fast-Anomaly-Sabokrou-Fayyaz/8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6",
            "/paper/Deep-Feature-Consistent-Variational-Autoencoder-Hou-Shen/7c1cfab6b60466c13f07fe028e5085a949ec8b30",
            "/paper/Are-pre-trained-CNNs-good-feature-extractors-for-in-Nazar%C3%A9-Mello/bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73",
            "/paper/Anomaly-Machine-Component-Detection-by-Deep-Model-Matsubara-Tachibana/e858bcc487cea96695102db9bdafe3c5d4269d04",
            "/paper/f%E2%80%90AnoGAN%3A-Fast-unsupervised-anomaly-detection-with-Schlegl-Seeb%C3%B6ck/f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "/paper/Variational-Autoencoder-based-Anomaly-Detection-An-Cho/061146b1d7938d7a8dae70e3531a00fceb3c78e8"
        ]
    },
    {
        "id": "26b8d5fb1083506cb7569c534312a24c02cb9119",
        "title": "High-Fidelity Zero-Shot Texture Anomaly Localization Using Feature Correspondence Analysis",
        "abstract": "We propose a novel method for Zero-Shot Anomaly Localization that leverages a bidirectional mapping derived from the 1-dimensional Wasserstein Distance. The proposed approach allows pinpointing the anomalous regions in a texture with increased precision by aggregating the contribution of a pixel to the errors of all nearby patches. We validate our solution on several datasets and obtain more than a 40% reduction in error over the previous state of the art on the MVTec AD dataset in a zero-shot setting.",
        "publication_year": "2023",
        "authors": [
            "Andrei-Timotei Ardelean",
            "T. Weyrich"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "46",
        "references": [
            "/paper/Zero-shot-versus-Many-shot%3A-Unsupervised-Texture-Aota-Tong/38c3d447839a7fde117a21fdab7ed28c00a51a41",
            "/paper/Sub-Image-Anomaly-Detection-with-Deep-Pyramid-Cohen-Hoshen/9277dc70c74bcadf80dab11c28ead83fd085deec",
            "/paper/A-Hierarchical-Transformation-Discriminating-Model-Sheynin-Benaim/182d11020bf2842f135f1ec1dcac20237e0dc8b7",
            "/paper/Registration-based-Few-Shot-Anomaly-Detection-Huang-Guan/4b182347b943548fe6479393bb24adac21740675",
            "/paper/DR%C3%86M-%E2%80%93-A-discriminatively-trained-reconstruction-Zavrtanik-Kristan/95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "/paper/The-MVTec-Anomaly-Detection-Dataset%3A-A-Real-World-Bergmann-Batzner/48f9a48aa5b1230b05a443d2d531e6441a541686",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/Deep-Learning-for-Unsupervised-Anomaly-Localization-Tao-Gong/51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
            "/paper/Improving-Unsupervised-Defect-Segmentation-by-to-Bergmann-L%C3%B6we/9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7"
        ]
    },
    {
        "id": "dbe577b3cdc30f0f1b264a86affc9db96c6065a7",
        "title": "Assessing the performance of the Cell Painting assay across different imaging systems",
        "abstract": "This work examines the performance of the Cell Painting assay across multiple high-throughput microscope systems and determines independently for each microscope system the best performing settings, providing those who wish to adopt this assay an ideal starting point for their own assays. Quantitative microscopy is a powerful method for performing phenotypic screens, from which image-based profiling can extract a wealth of information, termed profiles. These profiles can be used to elucidate the changes in cellular phenotypes across cell populations from different patient samples or following genetic or chemical perturbations. One such image-based profiling method is the Cell Painting assay, which provides morphological insight through the imaging of eight cellular compartments. Here, we examine the performance of the Cell Painting assay across multiple high-throughput microscope systems and find that all are compatible with this assay. Furthermore, we determine independently for each microscope system the best performing settings, providing those who wish to adopt this assay an ideal starting point for their own assays. We also explore the impact of microscopy setting changes in the Cell Painting assay and find that few dramatically reduce the quality of a Cell Painting profile, regardless of the microscope used.",
        "publication_year": "2023",
        "authors": [
            "Nasim Jamali",
            "Callum Tromans-Coia",
            "H. Abbasi",
            "K. Giuliano",
            "Mai Hagimoto",
            "Kevin Jan",
            "Erika Kaneko",
            "S. Letzsch",
            "Alexander Schreiner",
            "J. Sexton",
            "Mahomi Suzuki",
            "O. J. Trask",
            "Mitsunari Yamaguchi",
            "Fumiki Yanagawa",
            "Michael Yang",
            "Anne E Carpenter",
            "B. Cimini"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "16",
        "references": [
            "/paper/JUMP-Cell-Painting-dataset%3A-morphological-impact-of-Chandrasekaran-Ackerman/1f96460299f3c74965b4fe8e64c28957ada06c74",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0",
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5",
            "/paper/Predicting-cell-health-phenotypes-using-image-based-Way-Kost-Alimova/faf891f3f9bd76dcdd348c0ce8c389782cd49c90",
            "/paper/Morphology-and-gene-expression-profiling-provide-Way-Natoli/1f7bb6a080c1db96c778793514bf2b1638b623ab",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Three-million-images-and-morphological-profiles-of-Chandrasekaran-Cimini/3e173f19037739ae6e84bc3b9f97957c42412660",
            "/paper/Label-free-prediction-of-cell-painting-from-images-Cross-Zamirski-Mouchet/590fc45e167068cac9a8a98eee95725531a5a352",
            "/paper/Systematic-morphological-profiling-of-human-gene-Rohban-Singh/c6bf43a2bfffec64989baa2d193a6a845defa59e",
            "/paper/Repurposing-High-Throughput-Image-Assays-Enables-Simm-Klambauer/06147c4e743d4cbc7d95541c4aaf08d09139cc79"
        ]
    },
    {
        "id": "98a56025b90612c8f214f6b5551057e43e9991c5",
        "title": "A Normalized Least Mean Squares Algorithm With a Step-Size Scaler Against Impulsive Measurement Noise",
        "abstract": "This brief introduces the concept of a step-size scaler by investigating and modifying the tanh cost function for adaptive filtering with impulsive measurement noise, and shows the improvement of robustness against impulsive noise. This brief introduces the concept of a step-size scaler by investigating and modifying the tanh cost function for adaptive filtering with impulsive measurement noise. The step-size scaler instantly scales down the step size of gradient-based adaptive algorithms whenever impulsive measurement noise appears, which eliminates a possibility of updating weight vector estimates based on wrong information due to impulsive noise. The most attractive feature of the step-size scaler is that this is easily applicable to various gradient-based adaptive algorithms. Several representative gradient-based adaptive algorithms are performed without or with the step-size scaler in impulsive-noise environments, which shows the improvement of robustness against impulsive noise.",
        "publication_year": "2013",
        "authors": [
            "Insun Song",
            "P. Park",
            "R. Newcomb"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "64",
        "reference_count": "16",
        "references": [
            "/paper/A-variable-step-size-affine-projection-algorithm-a-Song-Park/cd14ca2ba7775aa6ba29b0823ee52fd5d660dcdd",
            "/paper/A-Variable-Step-Size-Normalized-Subband-Adaptive-a-Hur-Song/4e81a2fd72000928cb2dc93c1646332b9dd1ee1b",
            "/paper/A-filtered-x-VSS-NSAF-active-noise-control-robust-Park-Kim/5fdbb81992d1db84e0e6e3243be75a126d2a4ad2",
            "/paper/A-filtered-x-VSS-NSAF-active-noise-control-robust-Park-Kim/c5e3b3b5ff261a08f4b52a173b421a6a25ab31da",
            "/paper/Optimal-design-of-NLMS-algorithm-with-a-variable-Wu-Song/df96cfba7b910fa24e92f8d0ab01f1a731e9104d",
            "/paper/A-robust-filtered-x-NLMS-algorithm-with-optimal-for-Song-Kim/fcb04dffc7bcf6ee3978b66a3fe1b56b572c3ebb",
            "/paper/Robust-Shrinkage-Normalized-Sign-Algorithm-in-an-Zhang-Zhang/51b5de4767a68ad8d7a654736bdeb5a80cc9b0ac",
            "/paper/NLMS-Algorithm-Based-on-a-Variable-Parameter-Cost-Huang-Zhang/9fe0346e354f91c6db34fb37e35c194be8be05f7",
            "/paper/Novel-active-noise-control-based-on-a-robust-least-Kim-Lee/95b2cf72f6d1e5a3eff92209d3997c48eb0ab5d6",
            "/paper/Active-noise-control-algorithm-robust-to-noisy-and-Park-Kim/b476af597f1ab4a305f91685b0d33c5859a2354e",
            "/paper/A-robust-mixed-norm-adaptive-filter-algorithm-Chambers-Avlonitis/c080e6bdb23022ebb64b7426ff81d1eeb6dd0e61",
            "/paper/A-robust-quasi-Newton-adaptive-filtering-algorithm-Zou-Chan/22797927db9bdbe7a981aa7bf02408fdffae6471",
            "/paper/A-New-Robust-Variable-Step-Size-NLMS-Algorithm-Vega-Rey/2bde3e5067726b559357487cdacdbf0965fc9a02",
            "/paper/A-recursive-least-M-estimate-(RLM)-adaptive-filter-Zou-Chan/45369c0c67b621d3896cfb1f79400f8982551636",
            "/paper/Robust-Huber-adaptive-filter-Petrus/468fb302ecc4f3b5aff2994feff7894c3e9e8566",
            "/paper/A-new-variable-step-size-fractional-lower-order-for-Shao-Zheng/e73c95e06bead21081813593f1c59d73ca77f499",
            "/paper/A-variable-step-size-LMS-algorithm-Chen-Haddad/b75e166f08bca90315bc76c5d463db2bbc585a3d",
            "/paper/An-Affine-Projection-Sign-Algorithm-Robust-Against-Shao-Zheng/71256819d874f4aaa8cdb65c71c751a4123bb568",
            "/paper/Robust-Quasi-Newton-Adaptive-Filtering-Algorithms-Bhotto-Antoniou/d498e0de0a632245223c8a14ac6fea90960a104d",
            "/paper/A-variable-step-size-lmp-algorithm-for-heavy-tailed-Zheng-Shao/51e381eadec88bc80591fcde98daac8eb98a7c1e"
        ]
    },
    {
        "id": "484bbbfe3a4a8cc5fcf3218cac61a7d0efe77490",
        "title": "Towards Explainable Visual Anomaly Detection",
        "abstract": "A comprehensive and exhaustive literature review of explainable anomaly detection methods for both images and videos is presented and several promising future directions and open problems to explore on the explainability of visual anomaly detection are discussed. Anomaly detection and localization of visual data, including images and videos, are of great significance in both machine learning academia and applied real-world scenarios. Despite the rapid development of visual anomaly detection techniques in recent years, the interpretations of these black-box models and reasonable explanations of why anomalies can be distinguished out are scarce. This paper provides the first survey concentrated on explainable visual anomaly detection methods. We first introduce the basic background of image-level anomaly detection and video-level anomaly detection, followed by the current explainable approaches for visual anomaly detection. Then, as the main content of this survey, a comprehensive and exhaustive literature review of explainable anomaly detection methods for both images and videos is presented. Finally, we discuss several promising future directions and open problems to explore on the explainability of visual anomaly detection.",
        "publication_year": "2023",
        "authors": [
            "Yizhou Wang",
            "Dongliang Guo",
            "Sheng Li",
            "Yun Fu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "67",
        "references": [
            "/paper/Towards-Interpretable-Video-Anomaly-Detection-Doshi-Y%C4%B1lmaz/fcc6ab7340575dfb6db7a13225f9bea19bd02c10",
            "/paper/Anomaly-detection-in-crowded-scenes-Mahadevan-Li/9d3f0d47449c7db37d1bae3b70db2928610a8db7",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/Image-Video-Deep-Anomaly-Detection%3A-A-Survey-Mohammadi-Fathy/49ae00b9a8539ba1a2a7d77408daad850fd33095",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Discrete-neural-representations-for-explainable-Szymanowicz-Charles/d85b756b8e4d584a53483c6562eb968efdb1fc0c",
            "/paper/Backpropagated-Gradient-Representations-for-Anomaly-Kwon-Prabhushankar/790eceaa2cb59fef2634dad40f628346eb07cd3d",
            "/paper/X-MAN%3A-Explaining-multiple-sources-of-anomalies-in-Szymanowicz-Charles/296a22664daf1a4a39a22697a6e379720646c283",
            "/paper/Anomaly-Detection-in-Video-via-Self-Supervised-and-Georgescu-B%C4%83rb%C4%83l%C4%83u/57b2198f9a8df773425aa6cc88c9870cb07779e2",
            "/paper/Attention-Guided-Anomaly-Localization-in-Images-Venkataramanan-Peng/211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d"
        ]
    },
    {
        "id": "bcce3ad67cd6bd91f1d82b834a7a110c1ea136b9",
        "title": "Coarse-to-Fine Tranformer for articular disc of the temporomandibular joint Segmentation",
        "abstract": "Comparing U-Net, Unet ++ and Attention-U net models for data segmentation results show the C2Ftrans model performs best with the highest dice of 73.5% and the lowest computational complexity. The most important subtypes of joint abnormalities in patients with temporomandibular disorders are different forms of disc displacement and deformation. An effective segmentation model for jaw joint detection to support the diagnosis of TMJ disease on magnetic resonance imaging is very crucial. Data for this study were obtained from 204 MRI images of patients with articular discs and the corresponding MRI segmentation labels of the temporomandibular joints. These images were used to evaluate four deep learning-based semantic segmentation methods. Using a multi-scale structured C2Ftrans segmentation model transformed from coarse to fine, it describes medical image segmentation as a coarse to fine process. It is able to perform accurate target boundary segmentation with lower computational complexity. Tested on this dataset, comparing U-Net, Unet ++ and Attention-U net models for data segmentation results show the C2Ftrans model performs best with the highest dice of 73.5% and the lowest computational complexity.",
        "publication_year": "2022",
        "authors": [
            "Chenglin Wu",
            "Xuran Zhou",
            "Guannan Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "14",
        "references": [
            "/paper/Current-trends-in-temporomandibular-joint-imaging.-Larheim/7f3fbfcc36170de79bdecebdd2da3861ccf1023e",
            "/paper/The-International-Workshop-on-Osteoarthritis-Knee-A-Desai-Caliv%C3%A1/73c9d413f275a1520aedf4649be817e1a228cedd",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/CoTr%3A-Efficiently-Bridging-CNN-and-Transformer-for-Xie-Zhang/8356d155d730e374f4db6dfd03d19a7b66c348a8",
            "/paper/Weighted-Res-UNet-for-High-Quality-Retina-Vessel-Xiao-Lian/ff8b823d6f04a78bdb568a09139ef6d02111764e",
            "/paper/Temporomandibular-disorders%3A-Old-ideas-and-new-List-Jensen/d7105ecd0f481f089bd88669e52e36c68611c048",
            "/paper/C2FTrans%3A-Coarse-to-Fine-Transformers-for-Medical-Lin-Yan/7070ae889786abe2b363bb7a0e3b1a7b81077742",
            "/paper/Clinical-protocol-for-managing-acute-disc-without-a-Lei-Yap/f56d33f5fa0a10b8a352734f2343b25c1d025ba5",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/Actual-applications-of-magnetic-resonance-imaging-Johnson-Sreela/8711d7fc8326211f1627ff8f9ea5dc86a268b486"
        ]
    },
    {
        "id": "0ede258f3007863ade1bb2c7316b4b57925485ac",
        "title": "MSAL-Net: improve accurate segmentation of nuclei in histopathology images by multiscale attention learning network",
        "abstract": "A multiscale attention learning network (MSAL-Net), where the dense dilated convolutions block captures more comprehensive nuclei context information, and a newly modified decoder part is introduced, which integrates with efficient channel attention and boundary refinement modules to effectively learn spatial information for better prediction and further refine the nuclei cell of boundaries. Background The digital pathology images obtain the essential information about the patient\u2019s disease, and the automated nuclei segmentation results can help doctors make better decisions about diagnosing the disease. With the speedy advancement of convolutional neural networks in image processing, deep learning has been shown to play a significant role in the various analysis of medical images, such as nuclei segmentation, mitosis detection and segmentation etc. Recently, several U-net based methods have been developed to solve the automated nuclei segmentation problems. However, these methods fail to deal with the weak features representation from the initial layers and introduce the noise into the decoder path. In this paper, we propose a multiscale attention learning network (MSAL-Net), where the dense dilated convolutions block captures more comprehensive nuclei context information, and a newly modified decoder part is introduced, which integrates with efficient channel attention and boundary refinement modules to effectively learn spatial information for better prediction and further refine the nuclei cell of boundaries. Results Both qualitative and quantitative results are obtained on the publicly available MoNuseg dataset. Extensive experiment results verify that our proposed method significantly outperforms state-of-the-art methods as well as the vanilla Unet method in the segmentation task. Furthermore, we visually demonstrate the effect of our modified decoder part. Conclusion The MSAL-Net shows superiority with a novel decoder to segment the touching and blurred background nuclei cells obtained from histopathology images with better performance for accurate decoding.",
        "publication_year": "2022",
        "authors": [
            "Haider Ali",
            "I. Haq",
            "Lei Cui",
            "Jun Feng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "49",
        "references": [
            "/paper/Efficient-Staining-Invariant-Nuclei-Segmentation-Abdel-Nasser-Singh/3651275781811643bcda8a39fe7c2ba7e95a1864",
            "/paper/FRE-Net%3A-Full-region-enhanced-network-for-nuclei-in-Huang-Chen/23cd3ee21cbd6d3259dee9f02f607c0df5518558",
            "/paper/A-feature-aggregation-and-feature-fusion-network-Ni-Sun/301f1c0d3ab3df8a886b2456e34239baf23d0242",
            "/paper/MDC-net%3A-A-new-convolutional-neural-network-for-in-Liu-Guo/e177824a15acd20bd2ceb01fb8ca7e5f5c895198",
            "/paper/Robust-nuclei-segmentation-in-histopathology-using-Wan-Zhao/9a5356d74076b7e1b8a7bcb0e459fc923abafb27",
            "/paper/Accurate-segmentation-of-nuclei-in-pathological-via-Pan-Li/c9a372fc3b30bb2da051e941cab44c3e5ba31065",
            "/paper/NucleiSegNet%3A-Robust-deep-learning-architecture-for-Lal-Das/5938b820125a91e19dd05de6c897a835992f3799",
            "/paper/Integrating-deep-convolutional-neural-networks-with-Xie-Qi/0ea3e5215ac2676a15bef2354b2938704a0789a3",
            "/paper/A-Hybrid-Attention-Nested-UNet-for-Nuclear-in-He-Zhang/92713358f5748548b03c3130336b04b5f9028561",
            "/paper/Nuclear-Segmentation-in-Histopathological-Images-Kong-Genchev/4860e4067b1616cc214c971fb86e381855493ba8",
            "/paper/CE-Net%3A-Context-Encoder-Network-for-2D-Medical-Gu-Cheng/a07aa5b834e5083624189a929be07c7ae2389229",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/Transfer-learning-based-deep-CNN-for-segmentation-Wahab-Khan/160befefc99d88390d40910b8cd77a5b4d4e310a"
        ]
    },
    {
        "id": "70a0d404cd603168ce1f4e5cded4d3e44eebd5bd",
        "title": "ParamNet: A Parameter-variable Network for Fast Stain Normalization",
        "abstract": "The results on cytopathology and histopathology datasets show that the proposed parameter-variable stain normalization network, ParamNet outperforms state-of-the-art methods and can effectively improve the generalization of classifiers on pathology diagnosis tasks. In practice, digital pathology images are often affected by various factors, resulting in very large differences in color and brightness. Stain normalization can effectively reduce the differences in color and brightness of digital pathology images, thus improving the performance of computer-aided diagnostic systems. Conventional stain normalization methods rely on one or several reference images, but one or several images are difficult to represent the entire dataset. Although learning-based stain normalization methods are a general approach, they use complex deep networks, which not only greatly reduce computational efficiency, but also risk introducing artifacts. StainNet is a fast and robust stain normalization network, but it has not a sufficient capability for complex stain normalization due to its too simple network structure. In this study, we proposed a parameter-variable stain normalization network, ParamNet. ParamNet contains a parameter prediction sub-network and a color mapping sub-network, where the parameter prediction sub-network can automatically determine the appropriate parameters for the color mapping sub-network according to each input image. The feature of parameter variable ensures that our network has a sufficient capability for various stain normalization tasks. The color mapping sub-network is a fully 1x1 convolutional network with a total of 59 variable parameters, which allows our network to be extremely computationally efficient and does not introduce artifacts. The results on cytopathology and histopathology datasets show that our ParamNet outperforms state-of-the-art methods and can effectively improve the generalization of classifiers on pathology diagnosis tasks. The code has been available at https://github.com/khtao/ParamNet.",
        "publication_year": "2023",
        "authors": [
            "Hongtao Kang",
            "Die Luo",
            "Li Chen",
            "Junbo Hu",
            "Shenghua Cheng",
            "Tingwei Quan",
            "Shaoqun Zeng",
            "Xiuli Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "37",
        "references": [
            "/paper/StainNet%3A-A-Fast-and-Robust-Stain-Normalization-Kang-Luo/4613161c6d14962c5119c299194227e9484a3e68",
            "/paper/StainCNNs%3A-An-efficient-stain-feature-learning-Lei-Xia/fadacd4b2bf12bdd4f208b9d8823644927b9f854",
            "/paper/Quantifying-the-effects-of-data-augmentation-and-in-Tellez-Litjens/35ee6606ec99b5bf282a0c5f400edbd16a6e22d9",
            "/paper/A-High-Performance-System-for-Robust-Stain-of-in-Anghel-Stanisavljevic/d8ea4f5a2e63bbb3e2447d499e0fc3e23767a800",
            "/paper/Adversarial-Stain-Transfer-for-Histopathology-Image-Bentaieb-Hamarneh/a9c564185882bc9dd2b7becfc6928407bf1089b2",
            "/paper/Enhanced-Cycle-Consistent-Generative-Adversarial-of-Zhou-Cai/ab613e80271896c2a2721f08be1adc60a02a856e",
            "/paper/Stain-normalization-of-histopathology-images-using-Zanjani-Zinger/3a40073f704057920b4306d18d7326a568d6b578",
            "/paper/Self-Attentive-Adversarial-Stain-Normalization-Shrivastava-Adorno/588cbc6327da542686e45b44dea53e10741edab8",
            "/paper/Pix2Pix-based-Stain-to-Stain-Translation%3A-A-for-in-Salehi-Chalechale/da663cac292b8c6e714ee8ee9300cb3bc35e16d5",
            "/paper/Fast-GPU-Enabled-Color-Normalization-for-Digital-Ramakrishnan-Anand/b8eedcdc6e6bfa58deb7f16f79630586e5a00c69"
        ]
    },
    {
        "id": "ad43ed303b0366d10605a67e7be6ca79558a0afe",
        "title": "Deep learning for survival analysis in breast cancer with whole slide image data",
        "abstract": "A multi-resolution deep learning method for breast cancer survival analysis that integrates image data at multiple resolutions and tumor, lymphocyte and nuclear segmentation results from deep learning models is proposed and experimentally evaluated. MOTIVATION\nWhole slide tissue images contain detailed data on the sub-cellular structure of cancer. Quantitative analyses of this data can lead to novel biomarkers for better cancer diagnosis and prognosis and can improve our understanding of cancer mechanisms. Such analyses are challenging to execute because of the sizes and complexity of whole slide image data and relatively limited volume of training data for machine learning methods.\n\n\nRESULTS\nWe propose and experimentally evaluate a multi-resolution deep learning method for breast cancer survival analysis. The proposed method integrates image data at multiple resolutions and tumor, lymphocyte and nuclear segmentation results from deep learning models. Our results show that this approach can significantly improve the deep learning model performance compared to using only the original image data. The proposed approach achieves a c-index value of 0.706 compared to a c-index value of 0.551 from an approach that uses only color image data at the highest image resolution. Furthermore, when clinical features (sex, age and cancer stage) are combined with image data, the proposed approach achieves a c-index of 0.773.\n\n\nAVAILABILITY\nhttps://github.com/SBU-BMI/deep_survival_analysis.",
        "publication_year": "2022",
        "authors": [
            "Huidong Liu",
            "T. Kur\u00e7"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": 0,
        "references": [
            "/paper/Neural-Graph-Modelling-of-Whole-Slide-Images-for-MacKenzie/3afe6c838fd4303d3b67c505c69723701b462649",
            "/paper/Deep-Learning-in-Breast-Cancer-Imaging%3A-A-Decade-of-Luo-Wang/841edcf5ae140f455b180fd58029a071286c0095",
            "/paper/Survival-prediction-in-triple-negative-breast-using-Sandarenu-Millar/b59b468797d05d8c95e0110592f1fef9afdbf03c",
            "/paper/Evaluation-of-machine-learning-algorithms-for-the-Wu-Luo/ed078564801135ffd1cb06470575e2bd63f2539c",
            "/paper/Modeling-Dense-Multimodal-Interactions-Between-and-Jaume-Vaidya/e8acb3e6ae754b18eb5e1d8466b11d6e1d81d1ae",
            "/paper/Topology-Guided-Multi-Class-Cell-Context-Generation-Abousamra-Gupta/2af087d2de6007bd6e75e6f1535cbae463057fce",
            "/paper/Design-and-Research-of-High-Resolution-Satellite-on-Yan-Lu/b7e0a37ddc88d7d72b024486f1757459a3e9c454"
        ]
    },
    {
        "id": "806d8867c0ddf393d52302896d75a66676b14b0f",
        "title": "L1-regularized neural ranking for risk stratification and its application to prediction of time to distant metastasis in luminal node negative chemotherapy na\u00efve breast cancer patients",
        "abstract": "The proposed ranking based censoring-aware machine learning model is able to generate an interpretable formula for risk stratification using a minimal number of clinicopathological covariates through L1-regulrization and can discriminate between cases with high and low risk of distant metastasis. \u201cCan we predict if an early stage cancer patient is at high risk of developing distant metastasis and what clinicopathological factors are associated with such a risk?\u201d In this paper, we propose a ranking based censoring-aware machine learning model for answering such questions. The proposed model is able to generate an interpretable formula for risk stratification using a minimal number of clinicopathological covariates through L1-regulrization. Using this approach, we analyze the association of time to distant metastasis (TTDM) with various clinical parameters for early stage, luminal (ER+/HER2-) breast cancer patients who received endocrine therapy but no chemotherapy (n = 728). The TTDM risk stratification formula obtained using the proposed approach is primarily based on mitotic score, histological tumor type and lymphovascular invasion. These findings corroborate with the known role of these covariates in increased risk for distant metastasis. Our analysis shows that the proposed risk stratification formula can discriminate between cases with high and low risk of distant metastasis (p-value < 0.005) and can also rank cases based on their time to distant metastasis with a concordanceindex of 0.73.",
        "publication_year": "2021",
        "authors": [
            "F. Minhas",
            "M. Toss",
            "N. Wahab",
            "E. Rakha",
            "N. Rajpoot"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "32",
        "references": [
            "/paper/Neural-Graph-Modelling-of-Whole-Slide-Images-for-MacKenzie/3afe6c838fd4303d3b67c505c69723701b462649",
            "/paper/Deep-learning-based-survival-prediction-for-cancer-Wulczyn-Steiner/9858f280a7e2d8fb1bdf08bf3a1ec79e4a9d8f41",
            "/paper/Ranking-Based-Survival-Prediction-on-Whole-Slide-Di-Li/30a8bd0be5d8d92d91ff8b161460028a0c342f1d",
            "/paper/Lymphovascular-invasion%2C-race%2C-and-the-21-gene-in-Makower-Lin/bd75d4d93aa2c530caa3e71504dc40e42d27d0ad",
            "/paper/Support-Vector-Regression-for-Censored-Data-(SVRc)%3A-Khan-Zubek/47574ea4ab88175d7f4d7656198edadb794b34db",
            "/paper/A-scalable-discrete-time-survival-model-for-neural-Gensheimer-Narasimhan/ae1def118c46e656fcf6bad7ff9cf2aff955b38e",
            "/paper/The-impact-of-personalized-medicine-on-survival%3A-of-Rossi-Torri/31587412083d1d1693e62afb257d8e4b75f31dc7",
            "/paper/Deep-Neural-Networks-for-Survival-Analysis-Using-Zhao-Feng/e61e6ee03e05247a05de919f8e13226356eefbf7",
            "/paper/Luminal-breast-cancer%3A-from-biology-to-treatment-Ignatiadis-Sotiriou/fca6b836ace6df914ff6cc911cb1d15efde74234",
            "/paper/Deep-Neural-Networks-for-Survival-Analysis-Based-on-Fotso/55ed6e83cba98f6f9a73ee02365f02bb054fae79",
            "/paper/Fast-Training-of-Support-Vector-Machines-for-P%C3%B6lsterl-Navab/874a3baeaffc8cb5c993d1e3b2c09bc5dde403e9"
        ]
    },
    {
        "id": "b6dbc6e7f676e0e52f0d649ef9ccad9f97a64677",
        "title": "Polyp-Mixer: An Efficient Context-Aware MLP-Based Paradigm for Polyp Segmentation",
        "abstract": "A novel Polyp-Mixer, which utilizes MLP-based structures in both encoder and decoder, and uses CycleMLP as the encoder to overcome the fixed input scale issue, and proposes a Multi-head Mixer, allowing the model to explore rich context information from various subspaces. Precise and efficient polyp segmentation plays a crucial role in colonoscopy, which is important for the prevention of colorectal cancer. Despite CNN-based methods have achieved great progress in the polyp segmentation task, they are incapable of modeling long-range dependencies. Transformer-based models utilize self-attention mechanism to overcome this problem while suffering from heavy computing cost. Benefiting from simple structures, MLP-based models seem to be an alternative. However, they struggle with dealing with flexible input scales and modeling long-term dependencies. Both of these two factors are important for image segmentation, which could explain why the MLP architecture performs poorly compared to the Transformer. To remedy this issue, we propose a novel Polyp-Mixer, which utilizes MLP-based structures in both encoder and decoder. In particular, we use CycleMLP as the encoder to overcome the fixed input scale issue. Besides, we propose a Multi-head Mixer by converting the current CycleMLP into a Multi-head fashion, allowing our model to explore rich context information from various subspaces. In addition, we build a powerful Contextual Bridger Module between the encoder and decoder, which can capture semantics from larger receptive fields and combine them with various decoder layers. Experiments demonstrate the proposed method with fewer parameters ( $\\sim 16\\text{M}$ ) achieves SOTA on 4 public benchmarks. Our code will be released at https://github.com/shijinghuihub/Polyp-Mixer",
        "publication_year": "2023",
        "authors": [
            "Jinghua Shi",
            "Qing Zhang",
            "Yu-Hao Tang",
            "Zhong-Qun Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "60",
        "references": [
            "/paper/Polyp-PVT%3A-Polyp-Segmentation-with-Pyramid-Vision-Dong-Wang/66b92a2250d9b899c03c3f2699a40e18e56bcd51",
            "/paper/PRSeg%3A-A-Lightweight-Patch-Rotate-MLP-Decoder-for-Ma-Lin/ba212ac65a49e92b30e5f46a5d1284faa07b1958",
            "/paper/GraphMLP%3A-A-Graph-MLP-Like-Architecture-for-3D-Pose-Li-Liu/d2c49618d8ce3883ce68f51e893c669e12432da8",
            "/paper/Adaptive-Context-Selection-for-Polyp-Segmentation-Zhang-Li/c7c4c25a5d6a92d386125fa6ff4d259f461ef775",
            "/paper/PolypSeg%3A-An-Efficient-Context-Aware-Network-for-Zhong-Wang/f4caafa1acf1ea6f157622f466ce9671f703233f",
            "/paper/Enhanced-U-Net%3A-A-Feature-Enhancement-Network-for-Patel-Bur/8775dd7a4f3582de8d1b196865495df73638931c",
            "/paper/Polyp-PVT%3A-Polyp-Segmentation-with-Pyramid-Vision-Dong-Wang/66b92a2250d9b899c03c3f2699a40e18e56bcd51",
            "/paper/PraNet%3A-Parallel-Reverse-Attention-Network-for-Fan-Ji/89c6badea0d7bf834d4c069517116dd99c4cc0fd",
            "/paper/Selective-Feature-Aggregation-Network-with-for-Fang-Chen/8cd4364347f647f2d2165953988c8895524dd8cc",
            "/paper/Progressively-Normalized-Self-Attention-Network-for-Ji-Chou/492ed313c743b58ba64751ebddaba0638e8939d8",
            "/paper/MISSFormer%3A-An-Effective-Medical-Image-Segmentation-Huang-Deng/f75bf767d060785e553326627adfee77f8e19d86",
            "/paper/Non-equivalent-images-and-pixels%3A-Confidence-aware-Guo-Chen/b7c060cf11fea4c1e6583ca6a7b10bad63c70aa7",
            "/paper/Precise-Yet-Efficient-Semantic-Calibration-and-in-Wu-Zhong/7ca83bac3e9836d4088101e53bfceddfdeadd7ff"
        ]
    },
    {
        "id": "d9c38e7957c10252cc0e66b20c55d5be615db10d",
        "title": "Continuous Sign Language Recognition with Correlation Network",
        "abstract": "CorrNet is proposed to explicitly capture and leverage body trajectories across frames to identify signs in continuous sign language recognition and achieves new state-of-the-art accuracy on four large-scale datasets, i.e., PHOenIX14, PHOENIX14-T, CSL-Daily, and CSL. Human body trajectories are a salient cue to identify actions in the video. Such body trajectories are mainly conveyed by hands and face across consecutive frames in sign language. However, current methods in continuous sign language recognition (CSLR) usually process frames independently, thus failing to capture cross-frame trajectories to effectively identify a sign. To handle this limitation, we propose correlation network (CorrNet) to explicitly capture and leverage body trajectories across frames to identify signs. In specific, a correlation module is first proposed to dynamically compute correlation maps between the current frame and adjacent frames to identify trajectories of all spatial patches. An identification module is then presented to dynamically emphasize the body trajectories within these correlation maps. As a result, the generated features are able to gain an overview of local temporal movements to identify a sign. Thanks to its special attention on body trajectories, CorrNet achieves new state-of-the-art accuracy on four large-scale datasets, i.e., PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. A comprehensive comparison with previous spatial-temporal reasoning methods verifies the effectiveness of CorrNet. Visualizations demonstrate the effects of CorrNet on emphasizing human body trajectories across adjacent frames.",
        "publication_year": "2023",
        "authors": [
            "Lianyu Hu",
            "Liqing Gao",
            "Zekang Liu",
            "Wei Feng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "53",
        "references": [
            "/paper/Conditional-Diffusion-Feature-Refinement-for-Sign-Guo-Xue/314e3cc058b0633a1ca228efa8c455534ed689ca",
            "/paper/Spatial-Temporal-Multi-Cue-Network-for-Continuous-Zhou-Zhou/a1e2665ac39dcb389e12f3f993004b4b4651826d",
            "/paper/Pose-based-Sign-Language-Recognition-using-GCN-and-Tunga-Nuthalapati/2e0d7289231dc4b1cd822186690b426810da620b",
            "/paper/SignBERT%3A-Pre-Training-of-Hand-Model-Aware-for-Sign-Hu-Zhao/39c6076a1284324282d6234c033ef1539c959039",
            "/paper/C2SLR%3A-Consistency-enhanced-Continuous-Sign-Zuo-Mak/63399cd601e8f58a833c31d98d87a9c3c144041f",
            "/paper/Fully-Convolutional-Networks-for-Continuous-Sign-Cheng-Yang/6af09da568edee80075ec610f431ffa91bfce061",
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e",
            "/paper/SF-Net%3A-Structured-Feature-Network-for-Continuous-Yang-Shi/bd712a873ae4eefb6c623c8e605e42c5a0173e3e",
            "/paper/Self-Mutual-Distillation-Learning-for-Continuous-Hao-Min/609d68085efa9b1da1068639e4850252cc0cf6ae",
            "/paper/Continuous-sign-language-recognition%3A-Towards-large-Koller-Forster/aaa0ac831a2546303611419cca74af367effb92a",
            "/paper/Recognize-Actions-by-Disentangling-Components-of-Zhao-Xiong/d66e13a5e128a4ecad78e0c1c128893684292dec"
        ]
    },
    {
        "id": "076a8e778f2e9efb3c2fd45fed534ae9e6035f1b",
        "title": "Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis",
        "abstract": "A new 3D transformer-based model, dubbed Swin UNEt TRansformers (Swin UNETR), with a hierarchical encoder for self-supervised pretraining for medical image analysis and tailored proxy tasks for learning the underlying pattern of human anatomy is proposed. Vision Transformers (ViT)s have shown great performance in self-supervised learning of global and local representations that can be transferred to downstream applications. Inspired by these results, we introduce a novel self-supervised learning framework with tailored proxy tasks for medical image analysis. Specifically, we propose: (i) a new 3D transformer-based model, dubbed Swin UNEt TRansformers (Swin UNETR), with a hierarchical encoder for self-supervised pretraining; (ii) tailored proxy tasks for learning the underlying pattern of human anatomy. We demonstrate successful pre-training of the proposed model on 5,050 publicly available computed tomography (CT) images from various body organs. The effectiveness of our approach is validated by fine-tuning the pre-trained models on the Beyond the Cranial Vault (BTCV) Segmentation Challenge with 13 abdominal organs and segmentation tasks from the Medical Segmentation Decathlon (MSD) dataset. Our model is currently the state-of-the-art on the public test leaderboards of both MSD11https://decathlon-10.grand-challenge.org/evaluation/challenge/leaderboard/ and BTCV 22https://www.synapse.org/#!Synapse:syn3193805/wiki/217785/ datasets. Code: https://monai.io/research/swin-unetr.",
        "publication_year": "2021",
        "authors": [
            "Yucheng Tang",
            "Dong Yang",
            "Wenqi Li",
            "H. Roth",
            "B. Landman",
            "Daguang Xu",
            "V. Nath",
            "Ali Hatamizadeh"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "101",
        "reference_count": "62",
        "references": [
            "/paper/Attentive-Symmetric-Autoencoder-for-Brain-MRI-Huang-Li/73f9d37cf8bd4f2bbcf35ab542d32b53804c1b5f",
            "/paper/Cross-Shaped-Windows-Transformer-with-Pretraining-Li-Wynne/631e3879b7daa24da4014a797850146bfd9f7926",
            "/paper/UNesT%3A-Local-Spatial-Representation-Learning-with-Yu-Yang/e4234671cd432fc5003e66ea0d74493386b509cd",
            "/paper/VoxSeP%3A-semi-positive-voxels-assist-self-supervised-Yang-Xie/6b88227581a7b06b3ee62e38f80309aef037380c",
            "/paper/Advancing-3D-Medical-Image-Analysis-with-Variable-Zhang-Li/efd02c06d2323d699d6d3bbf198e62077a445dbd",
            "/paper/Knowledge-Guided-Self-Supervised-Vision-for-Medical-Miao-Reed/6e87a157747b7136953fab8be429397a455b0626",
            "/paper/FreMAE%3A-Fourier-Transform-Meets-Masked-Autoencoders-Wang-Wang/08caef75e11e67712e7f71bd14d6baabf057b691",
            "/paper/MESTrans%3A-Multi-scale-embedding-spatial-transformer-Liu-Zhu/f7091ba836cbdd6111b3aa14148041182193e549",
            "/paper/3D-UX-Net%3A-A-Large-Kernel-Volumetric-ConvNet-for-Lee-Bao/831ab0f9e9f94bd41f1966d45fdd87640871ec43",
            "/paper/Class-Aware-Generative-Adversarial-Transformers-for-You-Zhao/c7c1ecc0a6ba1d83be684b4f96cb8d53c92be598",
            "/paper/3D-Self-Supervised-Methods-for-Medical-Imaging-Taleb-Loetzsch/11bdffb5d46e8510626384db9ae7420f4a88d981",
            "/paper/Rubik's-Cube%2B%3A-A-self-supervised-feature-learning-Zhu-Li/9ec095b8a711f76d4404a812558a5cb1f6b1f390",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/Swin-Unet%3A-Unet-like-Pure-Transformer-for-Medical-Cao-Wang/ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/UNETR%3A-Transformers-for-3D-Medical-Image-Hatamizadeh-Yang/7519a1e9e7371df79bd8a21cee871feb0ec597a5",
            "/paper/Med3D%3A-Transfer-Learning-for-3D-Medical-Image-Chen-Ma/5bcda431e0b615e094562bf038f1ef4df1865088",
            "/paper/DS-TransUNet%3A-Dual-Swin-Transformer-U-Net-for-Image-Lin-Chen/6feecbba7eacf002edeee797db2704d15ffbda1b",
            "/paper/LeViT-UNet%3A-Make-Faster-Encoders-with-Transformer-Xu-Wu/faa30dfcb1531df4e4d5c219bad06d65f6c860fa",
            "/paper/CoTr%3A-Efficiently-Bridging-CNN-and-Transformer-for-Xie-Zhang/8356d155d730e374f4db6dfd03d19a7b66c348a8"
        ]
    },
    {
        "id": "492904963d34db850cf6053d52bbb298eb0bebe7",
        "title": "Vessel-CAPTCHA: an efficient learning framework for vessel annotation and segmentation",
        "abstract": "Semantic Scholar extracted view of \"Vessel-CAPTCHA: an efficient learning framework for vessel annotation and segmentation\" by Vien Ngoc Dang et al.",
        "publication_year": "2021",
        "authors": [
            "Vien Ngoc Dang",
            "G. D. Giacomo",
            "Viola Marconeto",
            "Pratek Mathur",
            "R. Cortese",
            "Marco Lorenzi",
            "F. Prados",
            "Maria A. Zuluaga"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "13",
        "reference_count": "118",
        "references": [
            "/paper/JoB-VS%3A-Joint-Brain-Vessel-Segmentation-in-TOF-MRA-Valderrama-Pitsiorlas/74ded012a2e1174c91adfc850096cebe75ca59f6",
            "/paper/LIVE-Net%3A-Comprehensive-3D-vessel-extraction-in-CT-Sun-Yang/ba80a77aab48f49b6b7a53f84bc5e3f029d20a48",
            "/paper/Weakly-supervised-Cerebrovascular-Segmentation-with-Wu-Chen/3bd2a11581376468c63d88ee83a62e56181594d4",
            "/paper/High-throughput-3DRA-segmentation-of-brain-and-deep-Lin-Xia/f6cbf70ea872c74c29ab69d5c952fb0a7b08e10a",
            "/paper/All-answers-are-in-the-images%3A-A-review-of-deep-for-Chen-Zhou/2be74dd2433f98d6a3eb8172d84269c436645991",
            "/paper/Construction-of-a-Medical-Micro-Object-Cascade-for-Wei-Chen/fca0ce67c436d382085e73e4a31b4a60558855e8",
            "/paper/i3Deep%3A-Efficient-3D-interactive-segmentation-with-Gotkowski-Gonz%C3%A1lez/6cf00c0077db26325120961c39d6371432e4cac6",
            "/paper/Slim-Scissors%3A-Segmenting-Thin-Object-from-Han-Liew/f428c2a920daa9bb4768cc12aa148f34fe6e77d8",
            "/paper/One-Weird-Trick-to-Improve-Your-Semi-Weakly-Model-Bae-Noh/a583fba699112c88dae067f549f937c876a6ab6e",
            "/paper/CAPTCHA-for-crowdsourced-image-annotation%3A-and-Moradi-Keyvanpour/b52691c0adeb33c78efc25556bac3b3b3ac24c02",
            "/paper/Learning-to-Segment-Microscopy-Images-with-Lazy-Ke-Bugeau/25bafc9f20ee8b4390f939766a26fc895dfc7c3b",
            "/paper/Interactive-Medical-Image-Segmentation-Using-Deep-Wang-Li/4f17e652b2e090c93175eec37dfcd862c848113c",
            "/paper/VesselNet%3A-A-deep-convolutional-neural-network-with-Kitrungrotsakul-Han/489ece232ec65477db0ed2ca01a43edc1bfc4318",
            "/paper/Tracing-in-2D-to-Reduce-the-Annotation-Effort-for-Kozi%C5%84ski-Mosinska/55c1d3a71da590b3948dee378ec4d125e33fb4e3",
            "/paper/DeepCut%3A-Object-Segmentation-From-Bounding-Box-Rajchl-Lee/6e84d83faca994438e5628525123f3466ee9c55d",
            "/paper/IRIS%3A-interactive-real-time-feedback-image-with-Pepe-Schussnig/3ac69d67b746f0e514d88e34fdc224b1c8597818",
            "/paper/3D-U-Net%3A-Learning-Dense-Volumetric-Segmentation-%C3%87i%C3%A7ek-Abdulkadir/7fc464470b441c691d10e7331b14a525bc79b8bb",
            "/paper/A-U-Net-Deep-Learning-Framework-for-High-Vessel-in-Livne-Rieger/907d6d24ddf4a74491f611be6fb57fd102c6d9b0",
            "/paper/Global-channel-attention-networks-for-intracranial-Ni-Wu/958aebc86388e7625fb8df4b0882bc3b764364a8",
            "/paper/Learning-to-Segment-Medical-Images-with-Alone-Can-Chaitanya/4da9ea1dbfaca1bc13afc8f1e7b854fe3a6b4ea7"
        ]
    },
    {
        "id": "e5dddd3b88688d2a53397edb7e798af3389d053b",
        "title": "Quality of Life Among Acoustic Neuroma Patients Managed by Microsurgery, Radiation, or Observation",
        "abstract": "This is only the second study to use multivariate statistical techniques and a large sample to examine quality of life (QoL) among acoustic neuroma patients across the management options of microsurgery, radiation, and observation. Objective: The main aim of this study was to examine differences in quality of life (QoL) among acoustic neuroma patients across the management options of microsurgery, radiation, and observation. Additional aims were to describe QoL and investigate management, medical, and demographic factors that predicted QoL in this patient group. Study Design: Cross-sectional design, using a postal questionnaire. Setting: Tertiary referral centers. Patients: Participants included 180 adults diagnosed with, or treated for, a unilateral acoustic neuroma within 5 years of questionnaire distribution. The mean age of participants was 56.5 years, and 107 (59.4%) were female. Intervention(s): Patients' acoustic neuromas were managed with microsurgery, radiation, or observation. Main Outcome Measure(s): Current QoL was measured using the Short Form 12 Version 2 (SF-12), and postmanagement changes in QoL were assessed with the Glasgow Benefit Inventory (GBI). Results: No significant differences in SF-12 scores were found across microsurgery, radiation, and observation patients. However, microsurgery patients reported more deterioration on the GBI general well-being subscale than radiation patients and more improvement in the GBI social support scale than observation patients. Number of symptoms was a consistent predictor of SF-12 and GBI scores. Conclusion: This is only the second study to use multivariate statistical techniques and a large sample to examine QoL across the acoustic neuroma management options of microsurgery, radiation, and observation. There were few differences in QoL outcomes across management groups. Number of symptoms was an important factor in current QoL and postmanagement changes in QoL.",
        "publication_year": "2010",
        "authors": [
            "J. Brooker",
            "J. Fletcher",
            "M. Dally",
            "R. Briggs",
            "V. Cousins",
            "R. Smee",
            "G. Malham",
            "R. Kennedy",
            "S. Burney"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "35",
        "reference_count": "50",
        "references": [
            "/paper/Quality-of-Life-in-807-Patients-with-Vestibular-Soulier-Leeuwen/aa88fa15f92cdd413c481162b7cad303acd8dc4c",
            "/paper/The-Impact-of-Primary-Treatment-Strategy-on-the-of-Foley-Maweni/7c5abd0cf656ed48db39c27f4f4cefc6d8801ef0",
            "/paper/Quality-of-Life-in-Acoustic-Neuroma-Patients-McLaughlin-Bigelow/a3711983671315b4345e847351c122ac9d720aa2",
            "/paper/Quality-of-life-outcomes-in-acoustic-neuroma%3A-Barker-Collo-Miles/dcdae538590024e33ab3f364d09cf7ca49b9b7c5",
            "/paper/Long-term-Quality-of-Life-Following-Vestibular-Via-Broomfield-Mandavia/57acd9b63daee439b292ad3ab3657554a3cc2d67",
            "/paper/Long-term-quality-of-life-in-patients-with-managed-Maria-Maria/f1fdc50bbdb70a635ec30b6d6835060cd16dd15c",
            "/paper/Self-reported-symptoms-and-patient-experience%3A-A-Broomfield-O'Donoghue/7b8be1217598c349aef1f576669e26fd97b81a59",
            "/paper/Outcome-Measures-and-Quality-of-Life-in-Vestibular-Chartrand-Al-Tamami/4ff3a409def9dfe9bb88ee9808c1eb8ebfc2126d",
            "/paper/Validating-the-Penn-Acoustic-Neuroma-Quality-of-in-Leeuwen-Herruer/241a41010c51be3e36da663b23c12c0a6beeaa55",
            "/paper/Factors-associated-with-anxiety-and-depression-in-Brooker-Fletcher/52e894911895fa923e4dc04dbe8b8c3403f7c60e",
            "/paper/Quality-of-life-after-acoustic-neuroma-surgery-Nikolopoulos-Johnson/c5ef43064be085f2cf4003d7cd14ef47d59badd6",
            "/paper/Quality-of-life-after-unilateral-acoustic-neuroma-Baumann-Polligkeit/8bb5549b7b86f65f0157f2374a4f047e2d999008",
            "/paper/Patient-assessed-outcomes-after-excision-of-and-of-Martin-Sethi/7d457bbc2bde775d6b4bf81723da814b045aa8ff",
            "/paper/Costs-and-effects-of-microsurgery-versus-in-neuroma-Roijen-Nijs/3daa7579087bec926a569faae7a01bf0fad37a87",
            "/paper/Vestibular-Schwannomas%3A-Clinical-Results-and-of-or-Myrseth-M%C3%B8ller/608156e2bae124b16b12c13e4485e75db8c335dd",
            "/paper/Acoustic-neuroma%3A-postoperative-quality-of-life.-Magliulo-Zardo/faa280f7f947a37897d8bbb6dc843770c93e0c0b",
            "/paper/Prospective-comparison-of-quality-of-life-before-or-Maio-Akagami/81394e40bbb59ebcccae4a010e1332c1e2adc806",
            "/paper/Self-assessed-quality-of-life-after-acoustic-Betchen-Walsh/48e25055325747db9edffcce0177b653e1538624",
            "/paper/Surgery-for-large-vestibular-schwannomas%3A-how-and-Nicoucar-Momjian/338f4b9f57034ef52e39aa3af43089f60b4e970a",
            "/paper/Acoustic-neuroma-surgery-and-tinnitus-Fahy-Nikolopoulos/0c45d90ef8a9cf62364aad391e62b60ece8222b2"
        ]
    },
    {
        "id": "41d93b3a5740fc48af22d1d6043b759a1ee9e5be",
        "title": "Weakly Supervised Nuclei Segmentation Via Instance Learning",
        "abstract": "A modular deep network with two branches: a semantic proposal network and an instance encoding network, which are trained in a two-stage manner with an instance-sensitive loss to enable more effective subtask learning and to promote instance-aware representation learning. Weakly supervised nuclei segmentation is a critical problem for pathological image analysis and greatly benefits the community due to the significant reduction of labeling cost. Adopting point annotations, previous methods mostly rely on less expressive representations for nuclei instances and thus have difficulty in handling crowded nuclei. In this paper, we propose to decouple weakly supervised semantic and instance segmentation in order to enable more effective subtask learning and to promote instance-aware representation learning. To achieve this, we design a modular deep network with two branches: a semantic proposal network and an instance encoding network, which are trained in a two-stage manner with an instance-sensitive loss. Empirical results show that our approach achieves the state-of-the-art performance on two public benchmarks of pathological images from different types of organs. Our code is available at https://github.com/weizhenFrank/WeakNucleiSeg.",
        "publication_year": "2022",
        "authors": [
            "Weizhen Liu",
            "Qian He",
            "Xuming He"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "19",
        "references": [
            "/paper/Cyclic-Learning%3A-Bridging-Image-level-Labels-and-Zhou-Wu/ea1e445e610822786ee7322885edfec66dfe421b",
            "/paper/A-Weakly-Supervised-Method-With-Colorization-for-Xia-Qu/a5ee62db221460479384528652b18c312166e3aa",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-using-in-Qu-Wu/2b60f01e916725a8f0b5dddc44b4cb9bd3e5e8c3",
            "/paper/PseudoEdgeNet%3A-Nuclei-Segmentation-only-with-Point-Yoo-Yoo/8500d2883a31e2aae12bcaa4cdf6b13df84419a0",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-Using-in-Qu-Wu/c616b0fe93dc0b52b04ce6bf68ae3a67701200e8",
            "/paper/Weakly-Supervised-Nucleus-Segmentation-Based-on-A-Tian-Zhang/2af96daa1456fdb2a004f62a3fa28986e76e7fa4",
            "/paper/Unsupervised-Instance-Segmentation-in-Microscopy-Liu-Zhang/974ffaf2775a8c32e405c551436a111714a5dc3c",
            "/paper/Semantic-Instance-Segmentation-with-a-Loss-Function-Brabandere-Neven/1f8f0abfe4689aa93f2f6cc7ec4fd4c6adc2c2d6",
            "/paper/Minimizing-Labeling-Cost-for-Nuclei-Instance-and-Yang-Zhang/f9282d8871dd3d87a002ffd6e38eefff65978128",
            "/paper/Point-Supervised-Segmentation-Of-Microscopy-Images-Li-Dey/45155461fdf4863d7860540938a9696afcceeb63",
            "/paper/DARCNN%3A-Domain-Adaptive-Region-based-Convolutional-Hsu-Chiu/7af7213190d85a5f148383dce1e7b1f26dc41637",
            "/paper/Weakly-Supervised-Cell-Instance-Segmentation-by-Nishimura-Ker/1f3135323b2c134eff09d230e9ec8b3db7bb9665"
        ]
    },
    {
        "id": "d88f92840f600f6d35bcf42ad021c1d9be2acc3f",
        "title": "CSI-Based Location-Independent Human Activity Recognition Using Feature Fusion",
        "abstract": "An Attention-based feature Fusion ACTivity recognition system (AF-ACT) that extracts the semantic activity features and temporal features from different dimensions to better characterize the activity at different locations and can reach the highest accuracy in different experimental conditions when recognizing eight categories of activities. Channel state information (CSI)-based human activity recognition (HAR) has important application prospects, such as smart homes, medical monitoring, and public security. Due to the collected CSI data contains not only activity information but also activity-unrelated environmental information, the characteristics of the same activity conducted at different locations are different. The existing methods of collecting samples at a fixed location to train the HAR model can hardly work well at other locations, which limits the application prospect of CSI-based HAR. To deal with this challenge, we proposed an Attention-based feature Fusion ACTivity recognition system (AF-ACT). The proposed system extracts the semantic activity features and temporal features from different dimensions to better characterize the activity at different locations. The semantic activity features are extracted by the convolutional neural network (CNN) combined with the convolutional attention module (CBAM), and the temporal features are extracted by bidirectional gated recurrent unit (BGRU) combined with the self-attention mechanism. The semantic activity features and temporal features are fused through an attention-based feature fusion (A-Fusion) module to obtain complementary information, which will promote recognition accuracy. The proposed system is evaluated in an open environment with 12 activity training locations and ten arbitrary testing locations. The experimental results show that the system can reach the highest accuracy of 91.23% in different experimental conditions when recognizing eight categories of activities.",
        "publication_year": "2022",
        "authors": [
            "Yong Zhang",
            "Qingqing Liu",
            "Yujie Wang",
            "Guangwei Yu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "42",
        "references": [
            "/paper/Multidimensional-Information-Recognition-Algorithm-Tian-Chen/d875b9eb9fc89a8ceeabdd195820f0f137cb3c5f",
            "/paper/A-Random-Forest-Approach-to-Body-Motion-Detection%3A-Kianoush-Savazzi/9f01323502e19092f2fc976225c4d3fd9ef44e9b",
            "/paper/A-Survey-on-Different-Application-Areas-based-on-of-Sarsodia-Bhatt/48e66c4c08c2a90cb5e29bc2a0e350de18935c7f",
            "/paper/Exploiting-Multiple-Receivers-for-CSI-Based-Using-A-Lee-Ahn/108bbf9ca70a634521961f2b9a25a18914eeb90a",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/Utilizing-deep-learning-models-in-CSI-based-human-Shalaby-Elshennawy/aa5069cd1675d513cf874038dc7457cf309e5583",
            "/paper/Wi-Fi-Based-Location-Independent-Human-Activity-via-Ding-Jiang/375eec55ae39ebb39ee0537db9d924858a4fb94b",
            "/paper/An-End-to-End-Deep-Learning-Framework-for-Using-Alazrai-Hababeh/d9b12b6967f0b3ac3e7981a073de44a8bbad5c6d",
            "/paper/Environment-Robust-Device-Free-Human-Activity-With-Shi-Zhang/9fd905eb9de1be660aca05bfbd989d09c40c278b",
            "/paper/Data-Augmentation-and-Dense-LSTM-for-Human-Activity-Zhang-Wu/91bfa0458e09f094e110ca657a3fa10284761e8d",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/Shallow-Convolutional-Neural-Networks-for-Human-Huang-Zhang/3c71fc1b4ee39e722494c4dfff89eca6b1ef2178",
            "/paper/Exploiting-Local-Temporal-Characteristics-via-for-Abbas-Jeann%C3%A8s/ad536f11c7d1e4d254232d68b4793ee9e79f580d"
        ]
    },
    {
        "id": "90962dfefabe152e36376ff04d9fd66a54b9ad86",
        "title": "Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection",
        "abstract": "A novel self-supervised masked convolutional transformer block (SSMCTB) that comprises the reconstruction-based functionality at a core architectural level and is extremely flexible, enabling information masking at any layer of a neural network and being compatible with a wide range of neural architectures. Anomaly detection has recently gained increasing attention in the field of computer vision, likely due to its broad set of applications ranging from product fault detection on industrial production lines and impending event detection in video surveillance to finding lesions in medical scans. Regardless of the domain, anomaly detection is typically framed as a one-class classification task, where the learning is conducted on normal examples only. An entire family of successful anomaly detection methods is based on learning to reconstruct masked normal inputs (e.g. patches, future frames, etc.) and exerting the magnitude of the reconstruction error as an indicator for the abnormality level. Unlike other reconstruction-based methods, we present a novel self-supervised masked convolutional transformer block (SSMCTB) that comprises the reconstruction-based functionality at a core architectural level. The proposed self-supervised block is extremely flexible, enabling information masking at any layer of a neural network and being compatible with a wide range of neural architectures. In this work, we extend our previous self-supervised predictive convolutional attentive block (SSPCAB) with a 3D masked convolutional layer, as well as a transformer for channel-wise attention. Furthermore, we show that our block is applicable to a wider variety of tasks, adding anomaly detection in medical images and thermal videos to the previously considered tasks based on RGB images and surveillance videos. We exhibit the generality and flexibility of SSMCTB by integrating it into multiple state-of-the-art neural models for anomaly detection, bringing forth empirical results that confirm considerable performance improvements on five benchmarks: MVTec AD, BRATS, Avenue, ShanghaiTech, and Thermal Rare Event. We release our code and data as open source at https://github.com/ristea/ssmctb.",
        "publication_year": "2022",
        "authors": [
            "Neelu Madan",
            "Nicolae-Catalin Ristea",
            "Radu Tudor Ionescu",
            "Kamal Nasrollahi",
            "F. Khan",
            "T. Moeslund",
            "M. Shah"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "99",
        "references": [
            "/paper/Deep-Industrial-Image-Anomaly-Detection%3A-A-Survey-Liu-Xie/1312e46326f7e36fc82d16098b824540fe2dca66",
            "/paper/SLSG%3A-Industrial-Image-Anomaly-Detection-by-Better-Yang-Liu/5c04ce7f8510af40f2931535feeaf220832ab548",
            "/paper/Deep-Visual-Anomaly-Detection-in-Industrial-A-Liu-Xie/c39aac50bc5dbaf1ea14eef48043156b51884238",
            "/paper/Lightning-Fast-Video-Anomaly-Detection-via-Ristea-Croitoru/a2098146f85a41e38d3d33c86ba9060dd2ce26a1",
            "/paper/Aerial-Image-Object-Detection-With-Vision-Detector-Wang-Tien/0d77e8ee951acedfe2e80c4927df43956ee692a2",
            "/paper/Improved-Anomaly-Detection-by-Using-the-Isolation-Utkin-Ageev/5e2bb736775f1ddd01884a6bf289eca0ca41ca94",
            "/paper/Cluster-aware-Contrastive-Learning-for-Unsupervised-Chen-Gui/0c612d739dda43f1e0afa95cc2c5d3a337d03f49",
            "/paper/Self-Distilled-Masked-Auto-Encoders-are-Efficient-Ristea-Croitoru/7ad25dbb5022c119144990cde0d364e2519df728",
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/Anomaly-Detection-Using-Deep-Learning-Based-Image-Haselmann-Gruber/a70bc416b1124525499b0ac3d5b009637dc6c187",
            "/paper/Anomaly-Detection-in-Medical-Imaging-With-Deep-Shvetsova-Bakker/d743c1b674ae539ef387252b8400a8b06c3ecf20",
            "/paper/SSMTL%2B%2B%3A-Revisiting-Self-Supervised-Multi-Task-for-B%C4%83rb%C4%83l%C4%83u-Ionescu/507d3bf6e6ee737e49171ad2fce47d4f0dbba724",
            "/paper/Anomaly-Detection-in-Video-via-Self-Supervised-and-Georgescu-B%C4%83rb%C4%83l%C4%83u/57b2198f9a8df773425aa6cc88c9870cb07779e2",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea"
        ]
    },
    {
        "id": "5125a16039cabc6320c908a4764f32596e018ad3",
        "title": "SECOND: Sparsely Embedded Convolutional Detection",
        "abstract": "An improved sparse convolution method for Voxel-based 3D convolutional networks is investigated, which significantly increases the speed of both training and inference and introduces a new form of angle loss regression to improve the orientation estimation performance. LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data. However, problems remain, including a slow inference speed and low orientation estimation performance. We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.",
        "publication_year": "2018",
        "authors": [
            "Yan Yan",
            "Yuxing Mao",
            "Bo Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "1,267",
        "reference_count": "36",
        "references": [
            "/paper/VS-Net%3A-A-Voxel-Encoding-and-Sparse-Convolution-for-Liu-Niu/f0a32283217a78ada5d5dc42e0317d15eafd96d6",
            "/paper/High-Dimensional-Frustum-PointNet-for-3D-Object-and-Wang-Chen/764089b07dcb6c1b75d0e1691412b2821415935a",
            "/paper/Fast-Polar-Attentive-3D-Object-Detection-on-LiDAR-Bhat-Han/cb15fab48c0e4770a68b09a6e5d7d4e274d4406f",
            "/paper/RTL3D%3A-real-time-LIDAR-based-3D-object-detection-Yan-Liu/396320fcabdba131650d74ffc30a19fb5d3dfce2",
            "/paper/Deep-Learning-Based-Vehicle-Orientation-Estimation-Park-Yoon/b0d1261bf192e26f3665347f36f2461afad80c40",
            "/paper/Vehicle-Detection-based-on-Deep-Learning-Heatmap-Th%C3%A9odosc-Denis/a2c0bfd6e7eac7f1ca9c70f733e25a7d5017f8a6",
            "/paper/Deep-Learning-based-3D-Object-Detection-Using-LiDAR-Bharadhwaj-Nair/257c9cded80b51050a1c876fdcf696389b494bf1",
            "/paper/LaserFlow%3A-Efficient-and-Probabilistic-Object-and-Meyer-Charland/11a49f858af15d148af5011e126f4c06f9cc9e36",
            "/paper/JYOLO%3A-Joint-Point-Cloud-for-Autonomous-Driving-3D-Tian-Guo/c2023c25d6f65fdc19883be7ae40ebb8e06e2c1b",
            "/paper/PointPillars-Backbone-Type-Selection-For-Fast-and-Lis-Kryjak/dca9d1e1ab03c9e98a4689d85fbb49315ffd6e5c",
            "/paper/Vehicle-Detection-from-3D-Lidar-Using-Fully-Network-Li-Zhang/7a6ca00c0e2ec1bf97352e13cd3e5f35d608567d",
            "/paper/3D-Semantic-Segmentation-with-Submanifold-Sparse-Graham-Engelcke/1d6a5d0299ed8458191e4e0407d4d513e6a7dd7e",
            "/paper/Joint-3D-Proposal-Generation-and-Object-Detection-Ku-Mozifian/675784f097dbf87cd75a5640019d4469e7bd7905",
            "/paper/Vote3Deep%3A-Fast-object-detection-in-3D-point-clouds-Engelcke-Rao/da09eaa1412aaf0a62622f01f50e2e801a3b4c52",
            "/paper/Multi-view-3D-Object-Detection-Network-for-Driving-Chen-Ma/dc200ab22bf63e10e8b2af328a9e072d82cf75b7",
            "/paper/3D-Object-Proposals-Using-Stereo-Imagery-for-Object-Chen-Kundu/b6de1d55aee1e4c2949d220c986ac07f127a9f8c",
            "/paper/PIXOR%3A-Real-time-3D-Object-Detection-from-Point-Yang-Luo/2bcfce1e68e9adb5f1547307e66a7b23c16d319a",
            "/paper/Submanifold-Sparse-Convolutional-Networks-Graham-Maaten/11356cd6bb0f2776a88cd584ff108470414c6594",
            "/paper/Monocular-3D-Object-Detection-for-Autonomous-Chen-Kundu/d821767b7c7315c69daa39fbb0f4a44426bfaf41",
            "/paper/Frustum-PointNets-for-3D-Object-Detection-from-Data-Qi-Liu/526cf249c2760b7bdbb28f2a2a7c85851d3c2727"
        ]
    },
    {
        "id": "04513c7c0b3a63fde81a996dae064a28d453c17a",
        "title": "Classification-Based Anomaly Detection for General Data",
        "abstract": "This work presents a unifying view and proposes an open-set method to relax current generalization assumptions, and extends the applicability of transformation-based methods to non-image data using random affine transformations. Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence. Recently, classification-based methods were shown to achieve superior results on this task. In this work, we present a unifying view and propose an open-set method to relax current generalization assumptions. Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations. Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types. The strong performance of our method is extensively validated on multiple datasets from different domains.",
        "publication_year": "2020",
        "authors": [
            "Liron Bergman",
            "Yedid Hoshen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "231",
        "reference_count": "28",
        "references": [
            "/paper/Classification-based-self-supervised-learning-for-Li-Zhu/ab6625763940699a8fdc78b732d762ca4f395d5a",
            "/paper/Benchmarking-Unsupervised-Anomaly-Detection-and-Zheng-Wang/76077e1e12908b525907e7c3419368291f5965ab",
            "/paper/Rethinking-Assumptions-in-Deep-Anomaly-Detection-Ruff-Vandermeulen/2494d35c9c84f9b3cede710c16b7f78e9cee3738",
            "/paper/Perturbation-Learning-Based-Anomaly-Detection-Cai-Fan/6823583720f1ccaf027c1dc8f158d406d7ea4bb1",
            "/paper/Deep-Anomaly-Detection-by-Residual-Adaptation-Deecke-Ruff/5647fab83543536ea8424317630e6056dc94076d",
            "/paper/Generalized-Anomaly-Detection-Singh-Luo/cc09fa97cd8a535339184d4d17ef250bffbab88e",
            "/paper/Multi-Class-Anomaly-Detection-Singh-Luo/a68e8666257c02e6d0f2aebf79aff96bfae6a5c8",
            "/paper/Self-Supervised-Anomaly-Detection%3A-A-Survey-and-Hojjati-Ho/f98dbe64ed6fa8925048291fcceb625d704fb294",
            "/paper/Self-Trained-One-class-Classification-for-Anomaly-Yoon-Sohn/a7d75aa3a0a9faa310fb524c350fba2093b0ec97",
            "/paper/Unsupervised-Abnormality-Detection-with-Normalizing-Fang-Tang/912b647c5bb250958389cf7c21d470e970b4258c",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/6cf1d69e447e9687dbd2d92572f44bddbabd8192",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/Image-Anomaly-Detection-with-Generative-Adversarial-Deecke-Vandermeulen/3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "/paper/A-Geometric-Framework-for-Unsupervised-Anomaly-Eskin-Arnold/4d39ee7cca8fedf792570724255a4357aa41dbf8",
            "/paper/Outlier-Detection-with-Autoencoder-Ensembles-Chen-Sathe/b5781eaafe1aff25a084d83dc38831ea09db42f3",
            "/paper/Anomaly-Detection-Using-Autoencoders-with-Nonlinear-Sakurada-Yairi/ee70341e75c2dffebbabd24b239cc158ad691ed1",
            "/paper/LOF%3A-identifying-density-based-local-outliers-Breunig-Kriegel/a7c828184693a453a6c2867dee233ed054b2012e",
            "/paper/Learning-Discriminative-Reconstructions-for-Outlier-Xia-Cao/1c06870e1ecc63e120e45a2283ca4b72c153e867",
            "/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79"
        ]
    },
    {
        "id": "414668b64b026ff50e4d91d14fbe7b8327cfe026",
        "title": "H2-FDetector: A GNN-based Fraud Detector with Homophilic and Heterophilic Connections",
        "abstract": "A Graph Neural Network-based Fraud Detector with Homophilic and Heterophilic Interactions (H2-FDetector for short), which apparently outperforms state-of-the-art baselines on two real public benchmark fraud detection tasks. In the fraud graph, fraudsters often interact with a large number of benign entities to hide themselves. So, there are not only the homophilic connections formed by the same label nodes (similar nodes), but also the heterophilic connections formed by the different label nodes (dissimilar nodes). However, the existing GNN-based fraud detection methods just enhance the homophily in fraud graph and use the low-pass filter to retain the commonality of node features among the neighbors, which inevitably ignore the difference among neighbor of heterophilic connections. To address this problem, we propose a Graph Neural Network-based Fraud Detector with Homophilic and Heterophilic Interactions (H2-FDetector for short). Firstly, we identify the homophilic and heterophilic connections with the supervision of labeled nodes. Next, we design a new information aggregation strategy to make the homophilic connections propagate similar information and the heterophilic connections propagate difference information. Finally, a prototype prior is introduced to guide the identification of fraudsters. Extensive experiments on two real public benchmark fraud detection tasks demonstrate that our method apparently outperforms state-of-the-art baselines.",
        "publication_year": "2022",
        "authors": [
            "Fengzhao Shi",
            "Yanan Cao",
            "Yanmin Shang",
            "Yuchen Zhou",
            "Chuan Zhou",
            "Jia Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "9",
        "reference_count": "41",
        "references": [
            "/paper/Label-Information-Enhanced-Fraud-Detection-against-Wang-Zhang/a73137f4c21e2fb1845d5f50dc7bf286036a8b67",
            "/paper/Addressing-Heterophily-in-Graph-Anomaly-Detection%3A-Gao-Wang/4a76ea74e48ee96a0b846c58a843b2031da7b9de",
            "/paper/Heterophily-aware-Social-Bot-Detection-with-Wu-Yang/c45ca17fd3f360128c2f1f2ee288efa2a33bd253",
            "/paper/Truncated-Affinity-Maximization%3A-One-class-Modeling-Qiao-Pang/6ebe806cdc93521f5bdeefd5c0facd6d84aa79e1",
            "/paper/Temporal-burstiness-and-collaborative-camouflage-Zhang-Wan/f84494e71541f605fd4b7dd36223651fda08e61b",
            "/paper/From-Classic-GNNs-to-Hyper-GNNs-for-Detecting-Haghighi/e2b4cea3142daf95dddd6987087eb82592c57f66",
            "/paper/A-Comprehensive-Survey-on-Graph-Summarization-with-Shabani-Wu/9fc8fdfdc4bfa3dc5e7052cb5da6c1570bd41fad",
            "/paper/Explainable-Graph-based-Fraud-Detection-via-Neural-Qin-Liu/5b50aa69dc0eddc552aa43f7e96504479651275b",
            "/paper/Graph-Contrastive-Learning-for-Anomaly-Detection-Chen-Zhang/d2383b6a00fb52b936d21622b00e6cbc691383c2",
            "/paper/Beyond-Low-frequency-Information-in-Graph-Networks-Bo-Wang/fbc136c8c81cd89206dc0fcb54e16bd98df83b62",
            "/paper/Enhancing-Graph-Neural-Network-based-Fraud-against-Dou-Liu/14156438bafed28a626738630b5181b83ed5d79c",
            "/paper/Simplifying-Graph-Convolutional-Networks-Wu-Zhang/7e71eedb078181873a56f2adcfef9dddaeb95602",
            "/paper/Pick-and-Choose%3A-A-GNN-based-Imbalanced-Learning-Liu-Ao/7487499f91f0c198347a8ebc747ad8d220bdd155",
            "/paper/Live-Streaming-Fraud-Detection%3A-A-Heterogeneous-Wang-Li/3a014744804a12c8565775d2c93c59084ccf3ad6",
            "/paper/Intention-aware-Heterogeneous-Graph-Attention-for-Liu-Sun/27313cb7a36d419b49b6c81b39d815c9b660bfef",
            "/paper/Online-Credit-Payment-Fraud-Detection-via-Recurrent-Lin-Sun/febf81c438668b15b561eb879a78562042fcd2e5",
            "/paper/Breaking-the-Limit-of-Graph-Neural-Networks-by-the-Suresh-Budde/4bc7d63595d194a6e0930019764216e6b42da0d4",
            "/paper/Why-Do-Attributes-Propagate-in-Graph-Convolutional-Yang-Wang/a39193f071efed10af6704133061c15818a27edc"
        ]
    },
    {
        "id": "51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
        "title": "Deep Learning for Unsupervised Anomaly Localization in Industrial Images: A Survey",
        "abstract": "This article comprehensively surveying recent achievements in unsupervised AL in industrial images using deep learning provides detailed technical information for researchers interested in industrial AL and who wish to apply it to the localization of anomalies in other fields. Currently, deep learning-based visual inspection has been highly successful with the help of supervised learning methods. However, in real industrial scenarios, the scarcity of defect samples, the cost of annotation, and the lack of $a$ priori knowledge of defects may render supervised-based methods ineffective. In recent years, unsupervised anomaly localization (AL) algorithms have become more widely used in industrial inspection tasks. This article aims to help researchers in this field by comprehensively surveying recent achievements in unsupervised AL in industrial images using deep learning. The survey reviews more than 120 significant publications covering different aspects of AL, mainly covering various concepts, challenges, taxonomies, benchmark datasets, and quantitative performance comparisons of the methods reviewed. In reviewing the achievements to date, this article provides detailed predictions and analysis of several future research directions. This review provides detailed technical information for researchers interested in industrial AL and who wish to apply it to the localization of anomalies in other fields.",
        "publication_year": "2022",
        "authors": [
            "Xian Tao",
            "Xinyi Gong",
            "X. Zhang",
            "Shaohua Yan",
            "Chandranath Adak"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "21",
        "reference_count": "125",
        "references": [
            "/paper/Deep-Industrial-Image-Anomaly-Detection%3A-A-Survey-Liu-Xie/1312e46326f7e36fc82d16098b824540fe2dca66",
            "/paper/Deep-Learning-for-Automatic-Vision-Based-of-Surface-Prunella-Scardigno/bab40171eafbcf1bc372627c94b500e0f4ec6691",
            "/paper/ViTALnet%3A-Anomaly-on-Industrial-Textured-Surfaces-Tao-Adak/3c38d1145fc91245de7d9f2bc80a1e331bdb0b4e",
            "/paper/Deep-Visual-Anomaly-Detection-in-Industrial-A-Liu-Xie/c39aac50bc5dbaf1ea14eef48043156b51884238",
            "/paper/Deep-learning-based-out-of-distribution-data-in-Lindgren-Zach/247f7c2b667d1d315f002f258a0c60e55ac15cfe",
            "/paper/Reconstruction-from-edge-image-combined-with-color-Liu-Li/015e11f1862ccb808e701123dbe1a84f0bead671",
            "/paper/Unsupervised-Image-Anomaly-Detection-and-in-Based-Liu-Gao/72c92bb989a031318156f876238a8c81f2d1e998",
            "/paper/Prototypical-Residual-Networks-for-Anomaly-and-Zhang-Wu/ac62ed8a9b77d613189b63004f4a5d4c5cc082fe",
            "/paper/Neural-Architecture-Search-for-Visual-Anomaly-Kerssies/3081d3499fdf9b1e50122e7ae9419d032d4966f2",
            "/paper/Industrial-Anomaly-Detection-with-Domain-Shift%3A-A-Zhang-Zhao/dbab222bcaa0717048feb2967e184ee267226ef5",
            "/paper/Attention-Guided-Anomaly-Localization-in-Images-Venkataramanan-Peng/211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "/paper/Anomaly-detection-of-defects-on-concrete-structures-Chow-Su/24046c62be024695e9c73768ef6bcf870ca383c0",
            "/paper/The-MVTec-Anomaly-Detection-Dataset%3A-A-Real-World-Bergmann-Batzner/48f9a48aa5b1230b05a443d2d531e6441a541686",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Unsupervised-anomaly-segmentation-via-deep-feature-Shi-Yang/4dd78b8d466b4cfe55a1bbdc694291197ce62541",
            "/paper/Semi-supervised-anomaly-detection-with-dual-for-Liu-Song/2895770450e9cdfa4bfa42ea035b0a2397205e95",
            "/paper/Reconstruction-by-inpainting-for-visual-anomaly-Zavrtanik-Kristan/2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "/paper/Attribute-Restoration-Framework-for-Anomaly-Ye-Huang/363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "/paper/Image-Video-Deep-Anomaly-Detection%3A-A-Survey-Mohammadi-Fathy/49ae00b9a8539ba1a2a7d77408daad850fd33095",
            "/paper/Mixed-supervision-for-surface-defect-detection%3A-to-Bozic-Tabernik/7eb24c2109f75c614cc7aa4c1cac8b643c05e70c"
        ]
    },
    {
        "id": "9c24454b071bc8e96ea46c5064a7bddf07cca464",
        "title": "Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders",
        "abstract": "This work proposes to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an $\\ell^p$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.",
        "publication_year": "2018",
        "authors": [
            "Paul Bergmann",
            "Sindy L\u00f6we",
            "Michael Fauser",
            "David Sattlegger",
            "C. Steger"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "334",
        "reference_count": "27",
        "references": [
            "/paper/Self-Supervised-Surface-Defect-Localization-via-and-Yang-Zhu/e50f35840c6f9bbfeb468bede9201df2619769e3",
            "/paper/Reference-Based-Autoencoder-for-Surface-Defect-Luo-Yao/a6a93419c94dfe141dbf5b70ba70f0e1edd430d5",
            "/paper/Same-Same-But-DifferNet%3A-Semi-Supervised-Defect-Rudolph-Wandt/b1464ca857593c049873421db2f37bf2d0ff676d",
            "/paper/Fully-Convolutional-Cross-Scale-Flows-for-Defect-Rudolph-Wehrbein/5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9",
            "/paper/Improved-anomaly-detection-by-training-an-with-skip-Collin-Vleeschouwer/206c2e79b5f1b4541b85f47517666961ed49500e",
            "/paper/Semi-Supervised-Learning-for-Defect-Segmentation-Sae-ang-Kumwilaisak/518cadf4765b5e3a84784fade5d205d6b328101f",
            "/paper/Unsupervised-Anomaly-Detection-for-Surface-Defects-Tao-Zhang/dffe0f7cd102210333ef533761753a909aa03294",
            "/paper/PyramidFlow%3A-High-Resolution-Defect-Contrastive-Lei-Hu/cb958dcdf5b50dd8642492193ba8e700e7b96388",
            "/paper/PAEDID%3A-Patch-Autoencoder-Based-Deep-Image-For-Mou-Cao/41486714f22dfa7837366d253479104b8b053ca4",
            "/paper/Automatic-Unsupervised-Fabric-Defect-Detection-on-Peng-Gong/2fe348f8be60fd9bb6e4c8cf9945b8ebc159f8fb",
            "/paper/Learning-to-generate-images-with-perceptual-metrics-Snell-Ridgeway/90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74",
            "/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "/paper/Reliably-Decoding-Autoencoders-%E2%80%99-Latent-Spaces-for-Soukup-Pinetz/8d7aa1e9c135c6998e9abe098c9478874a73f357",
            "/paper/Generating-Images-with-Perceptual-Similarity-based-Dosovitskiy-Brox/9179e740dad4ca4c183f7677b854e5b15f9a122f",
            "/paper/Image-quality-assessment%3A-from-error-visibility-to-Wang-Bovik/eae2e0fa72e898c289365c0af16daf57a7a6cf40",
            "/paper/Novelty-detection-in-images-by-sparse-Boracchi-Carrera/63eb7986f726c7a8cf14b720fa6eba3ab168c4a4",
            "/paper/Anomaly-Detection-in-Nanofibrous-Materials-by-Napoletano-Piccoli/6180c1217c2c37d0b2f3e41930032d5f64b28af2",
            "/paper/Detecting-anomalous-structures-by-convolutional-Carrera-Boracchi/75a838cbc1541858b9c484001cade327640dc280",
            "/paper/Scale-invariant-anomaly-detection-with-multiscale-Carrera-Boracchi/85384a8871030bbd1681adee9e9956dce4d751ba",
            "/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79"
        ]
    },
    {
        "id": "3e173f19037739ae6e84bc3b9f97957c42412660",
        "title": "Three million images and morphological profiles of cells treated with matched chemical and genetic perturbations",
        "abstract": "This work creates a Resource dataset, CPJUMP1, where each perturbed gene is a known target of at least two chemical compounds in the dataset and systematically explores the directionality of correlations among perturbations that target the same gene. Identifying genetic and chemical perturbations with similar impacts on cell morphology can reveal compounds\u2019 mechanisms of action or novel regulators of genetic pathways. Research on methods for identifying such similarities has lagged due to a lack of carefully designed and well-annotated image sets of cells treated with chemical and genetic perturbations. Here, we create such a Resource dataset, CPJUMP1, where each perturbed gene is a known target of at least two chemical compounds in the dataset. We systematically explore the directionality of correlations among perturbations that target the same gene, and we find that identifying matches between chemical perturbations and genetic perturbations is a challenging task. Our dataset and baseline analyses provide a benchmark for evaluating methods that measure perturbation similarities and impact, and more generally, learn effective representations of cellular state from microscopy images. Such advancements would accelerate the applications of image-based profiling, such as functional genomics and drug discovery.",
        "publication_year": "2022",
        "authors": [
            "S. Chandrasekaran",
            "B. Cimini",
            "A. Goodale",
            "Lisa Miller",
            "M. Kost-Alimova",
            "Nasim Jamali",
            "J. Doench",
            "Briana Fritchman",
            "Adam Skepner",
            "Michelle Melanson",
            "John Arevalo",
            "Juan C. Caicedo",
            "Daniel Kuhn",
            "D. Hernandez",
            "Jim Berstler",
            "Hamdah Shafqat-Abbasi",
            "D. Root",
            "Sussane Swalley",
            "Shantanu Singh",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "17",
        "reference_count": "53",
        "references": [
            "/paper/JUMP-Cell-Painting-dataset%3A-morphological-impact-of-Chandrasekaran-Ackerman/1f96460299f3c74965b4fe8e64c28957ada06c74",
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/Virtual-screening-for-small-molecule-pathway-by-Rohban-Fuller/650531d909502e0ac2a54feb5539ba1877bef141",
            "/paper/RxRx3%3A-Phenomics-Map-of-Biology-Fay-Kraus/a4040560bed2818f9e64293c462627858d99cf3e",
            "/paper/High-content-cellular-screen-image-analysis-study-Bray-Weck/668754bae874a8197a31da172c754ce81df43543",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Assessing-the-performance-of-the-Cell-Painting-Jamali-Tromans-Coia/dbe577b3cdc30f0f1b264a86affc9db96c6065a7",
            "/paper/Deep-Representation-Learning-Determines-Drug-of-Wong-Logan/fdad88ff3273f539824d1052e74013df304b717e",
            "/paper/Deep-learning-in-image-based-phenotypic-drug-Krentzel-Shorte/930a3aabbaf3476807dd0fa0cd2830e371cb5b1c",
            "/paper/Self-supervision-advances-morphological-profiling-Kim-Adaloglou/7bfc47f93c5b48222cc553883d24a4f0be291328",
            "/paper/JUMP-Cell-Painting-dataset%3A-morphological-impact-of-Chandrasekaran-Ackerman/1f96460299f3c74965b4fe8e64c28957ada06c74",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0",
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/A-dataset-of-images-and-morphological-profiles-of-Bray-G%C3%BAstafsd%C3%B3ttir/05ba3c532b7b98c9448da0bee52d7cba0ef29621",
            "/paper/Improving-Phenotypic-Measurements-in-High-Content-Ando-McLean/463b1c43dfd689841d2fd43d24058e68b7224dcf",
            "/paper/Virtual-screening-for-small-molecule-pathway-by-Rohban-Fuller/650531d909502e0ac2a54feb5539ba1877bef141",
            "/paper/Systematic-morphological-profiling-of-human-gene-Rohban-Singh/c6bf43a2bfffec64989baa2d193a6a845defa59e",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Image-based-cell-phenotyping-with-deep-learning.-Pratapa-Doron/8f8a0de72c285f10bd3af311899026193eda632e",
            "/paper/Contrastive-Learning-of-Single-Cell-Phenotypic-for-Perakis-Gorji/cf533695bb16e80a922b3a6b3c5b420c2307afc5"
        ]
    },
    {
        "id": "9fe0346e354f91c6db34fb37e35c194be8be05f7",
        "title": "NLMS Algorithm Based on a Variable Parameter Cost Function Robust Against Impulsive Interferences",
        "abstract": "The proposed adaptive approach for the parameter in the cost function is tested in system identification and acoustic echo-cancelation scenarios, which have demonstrated that the proposed approach is effective and robust against non-Gaussian impulsive interferences. The conventional step-size scaler (SSS) normalized least-mean-square algorithm is robust against impulsive noise. However, the constant parameter in the SSS needs to be controlled to satisfy the conflicting requirements of fast convergence rate and low steady-state misadjustment. Therefore, to address this problem, an adaptive approach for the parameter in the cost function is proposed in this brief. The proposed approach is then tested in system identification and acoustic echo-cancelation scenarios, which have demonstrated that the proposed approach is effective and robust against non-Gaussian impulsive interferences.",
        "publication_year": "2017",
        "authors": [
            "Fuyi Huang",
            "Jiashu Zhang",
            "Sheng Zhang"
        ],
        "related_topics": [
            "Engineering"
        ],
        "citation_count": "26",
        "reference_count": "19",
        "references": [
            "/paper/Improved-NSAF-Algorithms-with-Variable-Control-Shen-Huang/a721d255ce68659b8aeb6119f26db1cdd7df2e8f",
            "/paper/Improved-NSAF-Algorithms-with-Variable-Control-Shen-Huang/cd20010c23c2a776633f8ddd78bc1058031ff631",
            "/paper/Optimal-design-of-NLMS-algorithm-with-a-variable-Wu-Song/df96cfba7b910fa24e92f8d0ab01f1a731e9104d",
            "/paper/Variable-Parameter-Arctangent-Cost-Function-Based-Choi-Kim/cc03b15e4c4aae4b5f18e6883be60ed5903c5dab",
            "/paper/Adaptive-Blind-Equalization-in-Impulsive-Noise-Abrar-Zerguine/88488bc60165980ad1b7bec6eba7290d0e54ab77",
            "/paper/Joint-adaptive-step-size-and-zero-attractor-for-Zhang-Zheng/afd2fccb32d622eb06375e6452c8547984708469",
            "/paper/Adaptive-beamforming-based-on-linearly-constrained-Hajiabadi-Khoshbin/2d61fd4defb4d7d18fdf3882559dc0212d2bfb18",
            "/paper/Combined-Step-Size-Normalized-Subband-Adaptive-With-Huang-Zhang/ed7ebe0059ea966e8e9589be1b26edb016433078",
            "/paper/Low-Complexity-Implementation-Method-for-the-based-Yokoyama-Nishikawa/4664038fc96e038d1531b1d186c88ed3a5b831ba",
            "/paper/Lorentzian-Based-Adaptive-Filters-for-Impulsive-Das-Narwaria/c2b51b8f5c9984307e3ac8982d3525b3a7d22c09",
            "/paper/A-New-Robust-Variable-Step-Size-NLMS-Algorithm-Vega-Rey/2bde3e5067726b559357487cdacdbf0965fc9a02",
            "/paper/Combined-Step-Size-Affine-Projection-Sign-Algorithm-Huang-Zhang/6d7ffcc466374eed3deafdd6a69a0e86c5438034",
            "/paper/A-Normalized-Least-Mean-Squares-Algorithm-With-a-Song-Park/98a56025b90612c8f214f6b5551057e43e9991c5",
            "/paper/A-recursive-least-M-estimate-(RLM)-adaptive-filter-Zou-Chan/45369c0c67b621d3896cfb1f79400f8982551636",
            "/paper/A-variable-step-size-lmp-algorithm-for-heavy-tailed-Zheng-Shao/51e381eadec88bc80591fcde98daac8eb98a7c1e",
            "/paper/A-robust-mixed-norm-adaptive-filter-algorithm-Chambers-Avlonitis/c080e6bdb23022ebb64b7426ff81d1eeb6dd0e61",
            "/paper/A-robust-quasi-Newton-adaptive-filtering-algorithm-Zou-Chan/22797927db9bdbe7a981aa7bf02408fdffae6471",
            "/paper/Variable-Step-Size-Affine-Projection-Sign-Algorithm-Yoo-Shin/6064764eba1475f8e10be7b341c2ace0bef595cb",
            "/paper/A-Normalized-Least-Mean-Square-Algorithm-Based-on-Zeng-Lin/dd5396f6999c51f6541d4a442c2226eb96147d72",
            "/paper/Adaptive-step-size-constant-modulus-algorithm-for-Yuvapoositanon-Chambers/ce5cb407a67f31d8fc2bf449d05df6f29d06cc94"
        ]
    },
    {
        "id": "296a22664daf1a4a39a22697a6e379720646c283",
        "title": "X-MAN: Explaining multiple sources of anomalies in video",
        "abstract": "This work proposes an interpretable probabilistic anomaly detector which can describe the reason behind it\u2019s response using high level concepts, is the first to directly consider object interactions for anomaly detection and proposes a new task of explaining anomalies. Our objective is to detect anomalies in video while also automatically explaining the reason behind the detector\u2019s response. In a practical sense, explainability is crucial for this task as the required response to an anomaly depends on its nature and severity. However, most leading methods (based on deep neural networks) are not interpretable and hide the decision making process in uninterpretable feature representations. In an effort to tackle this problem we make the following contributions: (1) we show how to build interpretable feature representations suitable for detecting anomalies with state of the art performance, (2) we propose an interpretable probabilistic anomaly detector which can describe the reason behind it\u2019s response using high level concepts, (3) we are the first to directly consider object interactions for anomaly detection and (4) we propose a new task of explaining anomalies and release a large dataset for evaluating methods on this task. Our method competes well with the state of the art on public datasets while also providing anomaly explanation based on objects and their interactions.",
        "publication_year": "2021",
        "authors": [
            "Stanislaw Szymanowicz",
            "James Charles",
            "R. Cipolla"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "26",
        "references": [
            "/paper/Discrete-neural-representations-for-explainable-Szymanowicz-Charles/d85b756b8e4d584a53483c6562eb968efdb1fc0c",
            "/paper/Multi-Contextual-Predictions-with-Vision-for-Video-Lee-Nam/1c1c590ffd5d5f4e9ce455bbdbc15d0e781ac540",
            "/paper/Anomaly-detection-in-surveillance-videos%3A-a-of-deep-Chandrakala-Deepak/6192fff1c7e296ae0a98985c55246e150d02214b",
            "/paper/Towards-Explainable-Visual-Anomaly-Detection-Wang-Guo/484bbbfe3a4a8cc5fcf3218cac61a7d0efe77490",
            "/paper/Evidential-Reasoning-for-Video-Anomaly-Detection-Sun-Jia/7eac922309a7f562a3012595e86b28529859ca33",
            "/paper/UBnormal%3A-New-Benchmark-for-Supervised-Open-Set-Acsintoae-Florescu/495035ca18ceb82d13e5b42beece8eb633f6095c",
            "/paper/An-Adaptive-Framework-for-Anomaly-Detection-in-Data-Kumari-Saini/781cf89d2aaf41a4089ad82cadf37530415327f7",
            "/paper/A-Survey-on-Explainable-Anomaly-Detection-Li-Zhu/40fc6787c87d60f3f070281c53c8289230009558",
            "/paper/Joint-Detection-and-Recounting-of-Abnormal-Events-Hinami-Mei/094ac7510d1723cb9c2da01db47291322aa29025",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/6cf1d69e447e9687dbd2d92572f44bddbabd8192",
            "/paper/Likelihood-Ratios-for-Out-of-Distribution-Detection-Ren-Liu/925182b91f51f8f2b747f7829e9d25ffc2729e5d",
            "/paper/Training-Adversarial-Discriminators-for-Abnormal-in-Ravanbakhsh-Sangineto/e399a626ba21fafb19b3661603ec9724058e951b",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Generalized-ODIN%3A-Detecting-Out-of-Distribution-Hsu-Shen/ae9bf201f128cabaa4350b54ff6607525c736cd5",
            "/paper/Faster-R-CNN%3A-Towards-Real-Time-Object-Detection-Ren-He/424561d8585ff8ebce7d5d07de8dbf7aae5e7270"
        ]
    },
    {
        "id": "f56d33f5fa0a10b8a352734f2343b25c1d025ba5",
        "title": "Clinical protocol for managing acute disc displacement without reduction: a magnetic resonance imaging evaluation.",
        "abstract": "Semantic Scholar extracted view of \"Clinical protocol for managing acute disc displacement without reduction: a magnetic resonance imaging evaluation.\" by J. Lei et al.",
        "publication_year": "2020",
        "authors": [
            "J. Lei",
            "A. Yap",
            "Y. Li",
            "Mq Liu",
            "K. Fu"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "11",
        "reference_count": "29",
        "references": [
            "/paper/Disc%E2%80%93condyle-relationship-alterations-following-or-Li-Zhou/3d057498bb3dde5f3117b63d9271180b21542683",
            "/paper/A-magnetic-resonance-imaging-study-on-the-joint-in-Luo-Yang/25c7b6038b930cf0d1de9312363aeb9a9e4b66ae",
            "/paper/Magnetic-resonance-imaging-guided-disc%E2%80%93condyle-via-Xiong-Yin/84652767d9104496c583d7f09f8d30717bcdf2c1",
            "/paper/An-Overview-of-Anterior-Repositioning-Splint-for-Guo-Cui/21f1151da578924276a04054ebc25b6125d14bb8",
            "/paper/Indica%C3%A7%C3%B5es-cir%C3%BArgicas-de-deslocamento-do-disco-da-Vilar-Pereira/aaf20fb403df8cfcf4a05c1c25f05284c6be1049",
            "/paper/Nonlinear-Relationship-between-Temporomandibular-A-Zhang-Ye/e48bdaae13c7de29c4d49b28f695c4325719b9fe",
            "/paper/Automated-segmentation-of-articular-disc-of-the-on-Ito-Mine/7d81774fdfa51cec836fde558ebe1f3e064ed9d1",
            "/paper/Automated-Segmentation-of-Articular-Disc-of-the-in-Ito-Mine/c847d909e23f2fa7af5d760d4505dfdfeda17d09",
            "/paper/Mathematical-analysis-of-the-condylar-trajectories-Shu-Ma/17311bbaf0b62c4ea9e17426cb0fb8528023a58b",
            "/paper/Coarse-to-Fine-Tranformer-for-articular-disc-of-the-Wu-Zhou/bcce3ad67cd6bd91f1d82b834a7a110c1ea136b9",
            "/paper/Correlation-between-clinical-and-magnetic-resonance-Muhtaro%C4%9Fullari-Ertan/3c69ad722c2daaf53b1374b351a30077dd53e867",
            "/paper/Is-there-a-role-for-arthrocentesis-in-recapturing-Sembronio-Albiero/eb03c608d8f09fd84e2248b7e71a3d869df06857",
            "/paper/Evaluation-of-the-position%2C-mobility%2C-and-of-the-by-Ohnuki-Fukuda/7496fcafc07de084ebeb854d4aa5487bfdfab33c",
            "/paper/The-use-of-arthrocentesis-in-patients-with-joint-Grossmann-Poluha/714584876668701d5c89a13e07f19225012f31fa",
            "/paper/Arthrographic-evaluation-of-disk-position-following-Segami-Murakami/1edf94bbfbb5c78c005782171381bd9dca3d2a23",
            "/paper/Efficacy-of-a-mandibular-manipulation-technique-in-Kurita-Kurashina/ff943fad2fe1f9d061c44b0296a621e2c030dd05",
            "/paper/Degenerative-temporomandibular-joint-changes-with-Lei-Han/4a58a76c5af8f757fced46b65c39bb6c9e9daa1c",
            "/paper/MRI-study-of-a-physiotherapeutic-protocol-in-disk-Martini-Martini/7dd8873f6faa241eea4fda5703726e3f4f457a9b",
            "/paper/Condylar-remodeling-accompanying-splint-therapy%3A-a-Liu-Chen/84dbc5daa22db4ec6213a13e84aeff386050156a",
            "/paper/Physiological-effects-of-anterior-repositioning-on-Chen-Liu/725ea55f830fd95b330135b26ce285395e48b0c1"
        ]
    },
    {
        "id": "0ea3e5215ac2676a15bef2354b2938704a0789a3",
        "title": "Integrating deep convolutional neural networks with marker-controlled watershed for overlapping nuclei segmentation in histopathology images",
        "abstract": "Semantic Scholar extracted view of \"Integrating deep convolutional neural networks with marker-controlled watershed for overlapping nuclei segmentation in histopathology images\" by Lipeng Xie et al.",
        "publication_year": "2020",
        "authors": [
            "Lipeng Xie",
            "Jin Qi",
            "L. Pan",
            "Samad Wali"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "40",
        "reference_count": "44",
        "references": [
            "/paper/Marker-controlled-watershed-with-deep-edge-emphasis-Kaseva-Omidali/f311c0c066f21838afbadf07d9c834bdd65e496c",
            "/paper/MDC-net%3A-A-new-convolutional-neural-network-for-in-Liu-Guo/e177824a15acd20bd2ceb01fb8ca7e5f5c895198",
            "/paper/MSAL-Net%3A-improve-accurate-segmentation-of-nuclei-Ali-Haq/0ede258f3007863ade1bb2c7316b4b57925485ac",
            "/paper/Nuclei-Segmentation-in-Histopathology-Images-Using-Chen-Li/9f3dc34d787404ade95a80c0367d4ddd3b190ccd",
            "/paper/A-general-deep-learning-framework-for-neuron-based-Wu-Souedet/0f1425c2fc9c3b817b4285813b5fc0a2cb777bf9",
            "/paper/Efficient-Stain-Aware-Nuclei-Segmentation-Deep-for-Hassan-Abdel-Nasser/87c85b7525de3f4127c006174e60d95b6f8b9a7c",
            "/paper/An-Integrative-Segmentation-Framework-for-Cell-of-Pan-Liu/e33f7928a45e395f1bc2a1aa1dd9349bc725ba24",
            "/paper/ASW-Net%3A-A-Deep-Learning-based-Tool-for-Cell-of-Pan-Liu/c7c1b005a042e52be8523ddf0d26941a242d5402",
            "/paper/Multi-layer-segmentation-framework-for-cell-nuclei-Jia-Zhang/d35248733e8b0cd8b5e13e7a63af318772f3081a",
            "/paper/Efficient-Staining-Invariant-Nuclei-Segmentation-Abdel-Nasser-Singh/3651275781811643bcda8a39fe7c2ba7e95a1864",
            "/paper/An-Automatic-Learning-Based-Framework-for-Robust-Xing-Xie/d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88",
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/Nuclei-segmentation-in-histopathology-images-using-Naylor-La%C3%A9/78db21fabea962592ac0aef54624251550929109",
            "/paper/Improved-Automatic-Detection-and-Segmentation-of-in-Al-Kofahi-Lassoued/63a373063d51489b31e07ee639ab74b6cf586240",
            "/paper/Robust-Segmentation-of-Overlapping-Cells-in-Using-Qi-Xing/3ba787154b2411fe89d88b6ab50ea84aa62dea04",
            "/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823",
            "/paper/Segmentation-of-Nuclei-in-Histopathology-Images-by-Naylor-La%C3%A9/5d1d45c89ec13f3b0a83078759bb1dfbac695102",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Robust-Nucleus-Cell-Detection-and-Segmentation-in-A-Xing-Yang/ee07d8530c080caa5056a60bcc176569544a8927",
            "/paper/Overlapping-Cell-Nuclei-Segmentation-Using-a-Active-Plissiti-Nikou/0aa9c29e32cb13b2d011e5730bd4955c7962083b"
        ]
    },
    {
        "id": "588cbc6327da542686e45b44dea53e10741edab8",
        "title": "Self-Attentive Adversarial Stain Normalization",
        "abstract": "A Self-Attentive Adversarial Stain Normalization (SAASN) approach for the normalization of multiple stain appearances to a common domain that includes self-attention mechanism for synthesizing images with finer detail while preserving the structural consistency of the biopsy features during translation. Hematoxylin and Eosin (H&E) stained Whole Slide Images (WSIs) are utilized for biopsy visualization-based diagnostic and prognostic assessment of diseases. Variation in the H&E staining process across different lab sites can lead to significant variations in biopsy image appearance. These variations introduce an undesirable bias when the slides are examined by pathologists or used for training deep learning models. Traditionally proposed stain normalization and color augmentation strategies can handle the human level bias. But deep learning models can easily disentangle the linear transformation used in these approaches, resulting in undesirable bias and lack of generalization. To handle these limitations, we propose a Self-Attentive Adversarial Stain Normalization (SAASN) approach for the normalization of multiple stain appearances to a common domain. This unsupervised generative adversarial approach includes self-attention mechanism for synthesizing images with finer detail while preserving the structural consistency of the biopsy features during translation. SAASN demonstrates consistent and superior performance compared to other popular stain normalization techniques on H&E stained duodenal biopsy image data.",
        "publication_year": "2019",
        "authors": [
            "A. Shrivastava",
            "W. Adorno",
            "L. Ehsan",
            "S. A. Ali",
            "S. Moore",
            "B. Amadi",
            "P. Kelly",
            "Donald E. Brown",
            "Sana Syed"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "17",
        "reference_count": "38",
        "references": [
            "/paper/Deep-computational-pathology-in-breast-cancer.-Duggento-Conti/cd12413a9a90ab802497eb2cd0ba162c38c98182",
            "/paper/Diagnosis-and-Analysis-of-Celiac-Disease-and-on-Kowsari/4fbbf2a1c21c702cd551bcf570bd976b391724ae",
            "/paper/A-Laplacian-Pyramid-Based-Generative-H%26E-Stain-Li-Hu/e5880a6e539f68619cff909491a27d52e2bb84c8",
            "/paper/ParamNet%3A-A-Parameter-variable-Network-for-Fast-Kang-Luo/70a0d404cd603168ce1f4e5cded4d3e44eebd5bd",
            "/paper/Deep-Learning-in-Breast-Cancer-Imaging%3A-A-Decade-of-Luo-Wang/841edcf5ae140f455b180fd58029a071286c0095",
            "/paper/NASDM%3A-Nuclei-Aware-Semantic-Histopathology-Image-Shrivastava-Fletcher/9ec7bc53535a8e0773a9373e80d31f0d75b3e416",
            "/paper/A-Fast-Texture-to-Stain-Adversarial-Stain-Network-Jia-Guo/fbf7dce2ee7b06e6b56e35e3ee0b0d1be8468ba8",
            "/paper/Deep-learning-enabled-virtual-histological-staining-Bai-Yang/ce201c4c74744821435a27bdf2e9513219c6645d",
            "/paper/HistoStarGAN%3A-A-Unified-Approach-to-Stain-Stain-and-Vasiljevi'c-Feuerhake/e3d1a9e6c7292e7ac25490487dc7524a9dfc3f2c",
            "/paper/A-survey-on-artificial-intelligence-in-image-Abdelsamea-Zidan/34f7e0f14329ca96b36b2163ba74db0f09848039",
            "/paper/Staingan%3A-Stain-Style-Transfer-for-Digital-Images-Shaban-Baur/e926486ab0dfd772d7da41489b47da0db935b3d8",
            "/paper/Stain-Normalization-using-Sparse-AutoEncoders-to-Janowczyk-Basavanhally/190cd1600840d5197ae9eefdaf4e6db1edf522df",
            "/paper/Self-Attention-Generative-Adversarial-Networks-Zhang-Goodfellow/a8f3dc53e321fbb2565f5925def4365b9f68d1af",
            "/paper/A-Nonlinear-Mapping-Approach-to-Stain-Normalization-Khan-Rajpoot/0eac0ed2c87910dbb7d9f622854efb7c7b7b6f0b",
            "/paper/Learning-from-Simulated-and-Unsupervised-Images-Shrivastava-Pfister/68cb9fce1e6af2740377494350b650533c9a29e1",
            "/paper/Spectral-Normalization-for-Generative-Adversarial-Miyato-Kataoka/84de7d27e2f6160f634a483e8548c499a2cda7fa",
            "/paper/A-study-about-color-normalization-methods-for-Roy-Jain/80018ab17ba5b77e44a4b811cb22fdabea5d4d56",
            "/paper/Least-Squares-Generative-Adversarial-Networks-Mao-Li/74ff6d48f9c62e937023106629d27ef2d2ddf8bc",
            "/paper/Detecting-Cancer-Metastases-on-Gigapixel-Pathology-Liu-Gadepalli/915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7",
            "/paper/A-method-for-normalizing-histology-slides-for-Macenko-Niethammer/ed81378eb0937a6425f6221800049c03dd8dd114"
        ]
    },
    {
        "id": "9858f280a7e2d8fb1bdf08bf3a1ec79e4a9d8f41",
        "title": "Deep learning-based survival prediction for multiple cancer types using histopathology images",
        "abstract": "This work developed a deep learning system (DLS) to predict disease specific survival across 10 cancer types from The Cancer Genome Atlas, using a weakly-supervised approach without pixel-level annotations, and tested three different survival loss functions. Providing prognostic information at the time of cancer diagnosis has important implications for treatment and monitoring. Although cancer staging, histopathological assessment, molecular features, and clinical variables can provide useful prognostic insights, improving risk stratification remains an active research area. We developed a deep learning system (DLS) to predict disease specific survival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a weakly-supervised approach without pixel-level annotations, and tested three different survival loss functions. The DLS was developed using 9,086 slides from 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In multivariable Cox regression analysis of the combined cohort including all 10 cancers, the DLS was significantly associated with disease specific survival (hazard ratio of 1.58, 95% CI 1.28\u20131.70, p<0.0001) after adjusting for cancer type, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS remained a significant predictor of survival in 5 of 10 cancer types. Compared to a baseline model including stage, age, and sex, the c-index of the model demonstrated an absolute 3.7% improvement (95% CI 1.0\u20136.5) in the combined cohort. Additionally, our models stratified patients within individual cancer stages, particularly stage II (p = 0.025) and stage III (p<0.001). By developing and evaluating prognostic models across multiple cancer types, this work represents one of the most comprehensive studies exploring the direct prediction of clinical outcomes using deep learning and histopathology images. Our analysis demonstrates the potential for this approach to provide significant prognostic information in multiple cancer types, and even within specific pathologic stages. However, given the relatively small number of cases and observed clinical events for a deep learning task of this type, we observed wide confidence intervals for model performance, thus highlighting that future work will benefit from larger datasets assembled for the purposes for survival modeling.",
        "publication_year": "2019",
        "authors": [
            "Ellery Wulczyn",
            "David F. Steiner",
            "Zhaoyang Xu",
            "Apaar Sadhwani",
            "Hongwu Wang",
            "I. Flament",
            "C. Mermel",
            "Po-Hsuan Cameron Chen",
            "Yun Liu",
            "Martin C. Stumpe"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "129",
        "reference_count": "33",
        "references": [
            "/paper/Interpretable-survival-prediction-for-colorectal-Wulczyn-Steiner/5b307b0c9177ac507cbead55d28e5434748e59ca",
            "/paper/Deep-learning-predicts-postsurgical-recurrence-of-Yamashita-Long/2166b7a622e8e336056bd1dd8a3fd7e35287a446",
            "/paper/Predicting-prognosis-and-IDH-mutation-status-for-Jiang-Zanazzi/bb31bde7cb2c04fec3c59608506373e95ade33be",
            "/paper/Deep-learning-in-cancer-pathology%3A-a-new-generation-Echle-Rindtorff/d9a34cd562e936a9722c75c34cb2f13078c91cd4",
            "/paper/Deep-learning-predicts-post-surgical-recurrence-of-Yamashita-Long/dbbab1d26e32b903261bb4d729b4598e3298ba56",
            "/paper/DeepPrognosis%3A-Preoperative-Prediction-of-Cancer-CT-Yao-Shi/103257816e2a8be988ad46136ff9609d20ae22c3",
            "/paper/The-Impact-of-Digital-Histopathology-Batch-Effect-Howard-Dolezal/4f3280b5e4b49e3c4f351c83f010ca6ad8d66bc2",
            "/paper/Development-and-Validation-of-a-Deep-Learning-for-Nagpal-Foote/17b6e6d7ce3ec7afcea1ce46c5a1d28d83b8e3cf",
            "/paper/Whole-slide-images-based-cancer-survival-prediction-Yao-Zhu/f0c24d4ba514081a7bc77905e3e12998937ba68b",
            "/paper/An-Integrated-TCGA-Pan-Cancer-Clinical-Data-to-Liu-Lichtenberg/0bb89ae07cc71db0792fd1985d24e4d8ca928466",
            "/paper/Predicting-cancer-outcomes-from-histology-and-using-Mobadersany-Yousefi/7b05161938f4e5f89ddd7ab7f432de8ecab1566e",
            "/paper/Deep-learning-based-tissue-analysis-predicts-in-Bychkov-Linder/39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "/paper/Predicting-survival-from-colorectal-cancer-slides-A-Kather-Krisam/a4eb7cc590b65e6be34fb74a4568d661385f28a2",
            "/paper/Development-and-validation-of-a-deep-learning-for-Nagpal-Foote/77ac601c30d06782f870f4f9a53b55be2c413347",
            "/paper/Identifying-survival-associated-morphological-of-Wang-P%C3%A9cot/1807d003294f83dcdf16ee4b970c2dc2ef12ec6d",
            "/paper/Predicting-non-small-cell-lung-cancer-prognosis-by-Yu-Zhang/94087ad5ed11555c260a42f2f9ca9da183c6f87e",
            "/paper/Artificial-Intelligence-Based-Breast-Cancer-Nodal-Liu-Kohlberger/cfa3d45a6fcf704fe7ab6953424481d1698055a4",
            "/paper/Diagnostic-Assessment-of-Deep-Learning-Algorithms-Bejnordi-Veta/ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
            "/paper/Predicting-survival-after-curative-colectomy-for-Weiser-G%C3%B6nen/00938d5b99d9d1029931eaca2a7b1b1f342e4c47",
            "/paper/An-Integrated-TCGA-Pan-Cancer-Clinical-Data-to-Liu-Lichtenberg/0bb89ae07cc71db0792fd1985d24e4d8ca928466"
        ]
    },
    {
        "id": "ba212ac65a49e92b30e5f46a5d1284faa07b1958",
        "title": "PRSeg: A Lightweight Patch Rotate MLP Decoder for Semantic Segmentation",
        "abstract": "A parametric-free patch rotate operation to reorganize the pixels spatially, which first divides the feature map into multiple groups and then rotates the patches within each group, and a novel segmentation network, named PRSeg, which is designed to promote the development of MLP-based decoder in semantic segmentation. The lightweight MLP-based decoder has become increasingly promising for semantic segmentation. However, the channel-wise MLP cannot expand the receptive fields, lacking the context modeling capacity, which is critical to semantic segmentation. In this paper, we propose a parametric-free patch rotate operation to reorganize the pixels spatially. It first divides the feature map into multiple groups and then rotates the patches within each group. Based on the proposed patch rotate operation, we design a novel segmentation network, named PRSeg, which includes an off-the-shelf backbone and a lightweight Patch Rotate MLP decoder containing multiple Dynamic Patch Rotate Blocks (DPR-Blocks). In each DPR-Block, the fully connected layer is performed following a Patch Rotate Module (PRM) to exchange spatial information between pixels. Specifically, in PRM, the feature map is first split into the reserved part and rotated part along the channel dimension according to the predicted probability of the Dynamic Channel Selection Module (DCSM), and our proposed patch rotate operation is only performed on the rotated part. Extensive experiments on ADE20K, Cityscapes and COCO-Stuff 10K datasets prove the effectiveness of our approach. We expect that our PRSeg can promote the development of MLP-based decoder in semantic segmentation.",
        "publication_year": "2023",
        "authors": [
            "Yizhe Ma",
            "Fangjian Lin",
            "Sitong Wu",
            "Sheng Tian",
            "Long Yu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "66",
        "references": [
            "/paper/Rethinking-Semantic-Segmentation-from-a-Perspective-Zheng-Lu/d29430adccb805ab57b349afa8553954347b3197",
            "/paper/Stage-Aware-Feature-Alignment-Network-for-Real-Time-Xi-Yan/0f6d6301370df7d40a3336b459224fa3e89e7a49",
            "/paper/Segmenter%3A-Transformer-for-Semantic-Segmentation-Strudel-Pinel/68f080e0ac836ea230cb5316fbed273c70422d75",
            "/paper/Encoder-Decoder-with-Atrous-Separable-Convolution-Chen-Zhu/9217e28b2273eb3b26e4e9b7b498b4661e6e09f5",
            "/paper/CGNet%3A-A-Light-Weight-Context-Guided-Network-for-Wu-Tang/bbd8411033f125b06ad0b59912cfb49395b3cc82",
            "/paper/Squeeze-and-Attention-Networks-for-Semantic-Zhong-Lin/94c7be3d026586be7531ad50a4404d2dabafd986",
            "/paper/Segmenting-Transparent-Objects-in-the-Wild-with-Xie-Wang/f8f40e3bf5c7d578462980ccc46b2447a76a4429",
            "/paper/Context-Encoding-for-Semantic-Segmentation-Zhang-Dana/e746c8eec81384bd37dede9700be9c8a3700f936",
            "/paper/Dynamic-Multi-Scale-Filters-for-Semantic-He-Deng/d18a3fbbdc9b0877eede2740aefe23932c2071c3",
            "/paper/Dual-Attention-Network-for-Scene-Segmentation-Fu-Liu/ad655c25e052fa4eeed53421344aca6f239c4c9d"
        ]
    },
    {
        "id": "314e3cc058b0633a1ca228efa8c455534ed689ca",
        "title": "Conditional Diffusion Feature Refinement for Continuous Sign Language Recognition",
        "abstract": "A novel autoencoder-formed conditional diffusion feature refinement~(ACDR) to refine the sequence representations to equip desired properties by learning the encoding-decoding optimization process in an end-to-end way. In this work, we are dedicated to leveraging the denoising diffusion models' success and formulating feature refinement as the autoencoder-formed diffusion process, which is a mask-and-predict scheme. The state-of-the-art CSLR framework consists of a spatial module, a visual module, a sequence module, and a sequence learning function. However, this framework has faced sequence module overfitting caused by the objective function and small-scale available benchmarks, resulting in insufficient model training. To overcome the overfitting problem, some CSLR studies enforce the sequence module to learn more visual temporal information or be guided by more informative supervision to refine its representations. In this work, we propose a novel autoencoder-formed conditional diffusion feature refinement~(ACDR) to refine the sequence representations to equip desired properties by learning the encoding-decoding optimization process in an end-to-end way. Specifically, for the ACDR, a noising Encoder is proposed to progressively add noise equipped with semantic conditions to the sequence representations. And a denoising Decoder is proposed to progressively denoise the noisy sequence representations with semantic conditions. Therefore, the sequence representations can be imbued with the semantics of provided semantic conditions. Further, a semantic constraint is employed to prevent the denoised sequence representations from semantic corruption. Extensive experiments are conducted to validate the effectiveness of our ACDR, benefiting state-of-the-art methods and achieving a notable gain on three benchmarks.",
        "publication_year": "2023",
        "authors": [
            "Leming Guo",
            "Wanli Xue",
            "Qing Guo",
            "Yuxi Zhou",
            "Tiantian Yuan",
            "Shengyong Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "39",
        "references": [
            "/paper/Continuous-Sign-Language-Recognition-with-Network-Hu-Gao/d9c38e7957c10252cc0e66b20c55d5be615db10d",
            "/paper/Self-Emphasizing-Network-for-Continuous-Sign-Hu-Gao/1f55d35e1d1a148898a756cb0380b22fa8878dcb",
            "/paper/Temporal-Lift-Pooling-for-Continuous-Sign-Language-Hu-Gao/630348d3e789ac1775223fac9d0b64f99e4b469c",
            "/paper/CARD%3A-Classification-and-Regression-Diffusion-Han-Zheng/37232ccce1cfafbe9b9918557f0b6cdf80e5b83a",
            "/paper/Self-Mutual-Distillation-Learning-for-Continuous-Hao-Min/609d68085efa9b1da1068639e4850252cc0cf6ae",
            "/paper/Connectionist-temporal-classification%3A-labelling-Graves-Fern%C3%A1ndez/96494e722f58705fa20302fe6179d483f52705b4",
            "/paper/CVT-SLR%3A-Contrastive-Visual-Textual-Transformation-Zheng-Wang/ff03fe2efa8e0283f06098e9f1ae41b76e66efec",
            "/paper/C2SLR%3A-Consistency-enhanced-Continuous-Sign-Zuo-Mak/63399cd601e8f58a833c31d98d87a9c3c144041f",
            "/paper/A-Simple-Multi-Modality-Transfer-Learning-Baseline-Chen-Wei/33703b1bfecb918aea4dcc2644a759f1de37c940",
            "/paper/Visual-Alignment-Constraint-for-Continuous-Sign-Min-Hao/2d2d5bb1d025c5e17abe13716599c93e1f131927"
        ]
    },
    {
        "id": "73f9d37cf8bd4f2bbcf35ab542d32b53804c1b5f",
        "title": "Attentive Symmetric Autoencoder for Brain MRI Segmentation",
        "abstract": "A novel Attentive Symmetric Auto-encoder (ASA) based on Vision Transformer (ViT) for 3D brain MRI segmentation tasks is proposed and experimental results show that the proposed attentive symmetric auto-encoding outperforms the state-of-the-art self-supervised learning methods and medical image segmentation models on three brainMRI segmentation benchmarks. . Self-supervised learning methods based on image patch reconstruction have witnessed great success in training auto-encoders, whose pre-trained weights can be transferred to \ufb01ne-tune other downstream tasks of image understanding. However, existing methods seldom study the various importance of reconstructed patches and the symmetry of anatomical structures, when they are applied to 3D medical images. In this paper we propose a novel Attentive Symmetric Auto-encoder (ASA) based on Vision Transformer (ViT) for 3D brain MRI segmentation tasks. We conjecture that forcing the auto-encoder to recover informative image regions can harvest more discriminative representations, than to recover smooth image patches. Then we adopt a gradient based metric to estimate the importance of each image patch. In the pre-training stage, the proposed auto-encoder pays more attention to reconstruct the informative patches according to the gradient metrics. Moreover, we resort to the prior of brain structures and develop a Symmetric Position Encoding (SPE) method to better exploit the correlations between long-range but spatially symmetric regions to obtain e\ufb00ective features. Experimental results show that our proposed attentive symmetric auto-encoder outperforms the state-of-the-art self-supervised learning methods and medical image segmentation models on three brain MRI segmentation benchmarks.",
        "publication_year": "2022",
        "authors": [
            "Junjia Huang",
            "Haofeng Li",
            "Guanbin Li",
            "Xiang Wan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "30",
        "references": [
            "/paper/FreMAE%3A-Fourier-Transform-Meets-Masked-Autoencoders-Wang-Wang/08caef75e11e67712e7f71bd14d6baabf057b691",
            "/paper/TransBTS%3A-Multimodal-Brain-Tumor-Segmentation-Using-Wang-Chen/147164a3905f41a7a5a10f732d086a621c9c5862",
            "/paper/Self-Supervised-Pre-Training-of-Swin-Transformers-Tang-Yang/076a8e778f2e9efb3c2fd45fed534ae9e6035f1b",
            "/paper/nnFormer%3A-Interleaved-Transformer-for-Volumetric-Zhou-Guo/77d785cedf8be8ca6aeb4cb249af579ecb839956",
            "/paper/Revisiting-Rubik's-Cube%3A-Self-supervised-Learning-Tao-Li/dd556921696c1bd67445349351c663c404dac8a6",
            "/paper/UNETR%3A-Transformers-for-3D-Medical-Image-Hatamizadeh-Yang/7519a1e9e7371df79bd8a21cee871feb0ec597a5",
            "/paper/3D-Self-Supervised-Methods-for-Medical-Imaging-Taleb-Loetzsch/11bdffb5d46e8510626384db9ae7420f4a88d981",
            "/paper/View-Disentangled-Transformer-for-Brain-Lesion-Li-Huang/509d2110dafee224097f200ad5cc1f51c8dadd0c",
            "/paper/Multimodal-Self-Supervised-Learning-for-Medical-Taleb-Lippert/b94a3bfe8ca48855e4b4c6bcab5b051197052d9e",
            "/paper/Masked-Autoencoders-Are-Scalable-Vision-Learners-He-Chen/6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a"
        ]
    },
    {
        "id": "74ded012a2e1174c91adfc850096cebe75ca59f6",
        "title": "JoB-VS: Joint Brain-Vessel Segmentation in TOF-MRA Images",
        "abstract": "The first joint-task learning framework for brain and vessel segmentation (JoB-VS) from Time-of-Flight Magnetic Resonance images avoids the pre-processing step of implementing a model to extract the brain from the volumetric input data, and is capable of generalizing the segmentation in the IXI dataset. We propose the first joint-task learning framework for brain and vessel segmentation (JoB-VS) from Time-of-Flight Magnetic Resonance images. Unlike state-of-the-art vessel segmentation methods, our approach avoids the pre-processing step of implementing a model to extract the brain from the volumetric input data. Skipping this additional step makes our method an end-to-end vessel segmentation framework. JoB-VS uses a lattice architecture that favors the segmentation of structures of different scales (e.g., the brain and vessels). Its segmentation head allows the simultaneous prediction of the brain and vessel mask. Moreover, we generate data augmentation with adversarial examples, which our results demonstrate to enhance the performance. JoB-VS achieves 70.03% mean AP and 69.09% F1-score in the OASIS-3 dataset and is capable of generalizing the segmentation in the IXI dataset. These results show the adequacy of JoB-VS for the challenging task of vessel segmentation in complete TOF-MRA images.",
        "publication_year": "2023",
        "authors": [
            "Natalia Valderrama",
            "Ioannis Pitsiorlas",
            "Luisa Vargas",
            "Pablo Arbel'aez",
            "Maria A. Zuluaga"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "14",
        "references": [
            "/paper/Vessel-CAPTCHA%3A-an-efficient-learning-framework-for-Dang-Giacomo/492904963d34db850cf6053d52bbb298eb0bebe7",
            "/paper/A-U-Net-Deep-Learning-Framework-for-High-Vessel-in-Livne-Rieger/907d6d24ddf4a74491f611be6fb57fd102c6d9b0",
            "/paper/DS6%2C-Deformation-Aware-Semi-Supervised-Learning%3A-to-Chatterjee-Mattern/b9c4a09f00c17c65605387e3d2a9f1dbaddc6c4c",
            "/paper/SynthStrip%3A-skull-stripping-for-any-brain-image-Hoopes-Mora/220fa61fc328646c3401b8b0baad635c07ebb418",
            "/paper/Towards-Robust-General-Medical-Image-Segmentation-Daza-P'erez/d43a3713cdbf9f39755e4337ece7e04917087da1",
            "/paper/Residual-U-Net-for-Retinal-Vessel-Segmentation-Li-Dharmawan/3c67fb8cecd880f333ef79f3494af5de8315b06e",
            "/paper/Blood-vessel-segmentation-algorithms-Review-of-and-Moccia-Momi/7b7991db1e251ded0a7f0091a4fd958ca5715ef4",
            "/paper/Robust-Brain-Extraction-Across-Datasets-and-With-Iglesias-Liu/4714f863564b32be86dab6f2cd7ef8fbecc9bafb",
            "/paper/Automated-brain-extraction-of-multisequence-MRI-Isensee-Schell/2825be06b3f199977d1a51bac3db745e3f7842fc",
            "/paper/clDice-a-Novel-Topology-Preserving-Loss-Function-Shit-Paetzold/2a4b0f6f50ab629a183a77ac8b69851208e5f3bc"
        ]
    },
    {
        "id": "aa88fa15f92cdd413c481162b7cad303acd8dc4c",
        "title": "Quality of Life in 807 Patients with Vestibular Schwannoma: Comparing Treatment Modalities",
        "abstract": "It is suggested that patients with small vestibular schwannomas experience better quality of life when managed with observation than do patients who have undergone active treatment. Objective In vestibular schwannoma treatment, the choice among treatment modalities is controversial. The first aim of this study was to examine the quality of life of patients with vestibular schwannoma having undergone observation, radiation therapy, or microsurgical resection. The second aim was to examine the relationship between perceived symptoms and quality of life. Last, the association between quality of life and time since treatment was studied. Study Design Cross-sectional study. Setting Tertiary referral center. Subjects and Methods A total of 1208 patients treated for sporadic vestibular schwannoma between 2004 and 2014 were mailed the disease-specific Penn Acoustic Neuroma Quality of Life (PANQOL) questionnaire and additional questions on symptoms associated with vestibular schwannoma. Total and domain scores were calculated and compared among treatment groups. Propensity scores were used, and results were stratified according to tumor size to control for potential confounders. Correlations were calculated to examine the relationship between self-reported symptoms and quality of life, as well as between quality of life and time since treatment. Results Patients with small tumors (\u226410 mm) under observation showed a higher PANQOL score when compared with the radiation therapy and microsurgical resection groups. A strong negative correlation was found between self-reported symptoms and quality of life, with balance problems and vertigo having the largest impact. No correlation was found between PANQOL score and time since treatment. Conclusion This study suggests that patients with small vestibular schwannomas experience better quality of life when managed with observation than do patients who have undergone active treatment.",
        "publication_year": "2017",
        "authors": [
            "G. Soulier",
            "Bibian M. van Leeuwen",
            "H. Putter",
            "J. Jansen",
            "M. Malessy",
            "P. V. van Benthem",
            "A. V. D. van der Mey",
            "A. Stiggelbout"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "48",
        "reference_count": "38",
        "references": [
            "/paper/Long-Term-Quality-of-Life-of-Vestibular-Schwannoma-Neve-Jansen/f887e72876126a010587098dca682084c08e968e",
            "/paper/Quality-of-life-in-vestibular-schwannoma%3A-a-of-Lucidi-Fabbris/609acd3a806945f6095b9da3be6141cbd67718e2",
            "/paper/Disease-Specific-Quality-of-Life-in-Vestibular-A-Chweya-Tombers/de3cb4048338111ad010fc03dd35a1d94eb28e1e",
            "/paper/Quality-of-Life-in-Vestibular-Schwannoma-Patients%3A-Miller-Brant/b2e58514f52bf0e5705c362c24a02e131ef2a7f4",
            "/paper/Vestibular-Complaints-Impact-on-the-Long-Term-of-of-Fuentealba-Bassaletti-Neve/16713ba75cf3e5f4e21aef525f5ff6f77093c52c",
            "/paper/Outcome-Measures-and-Quality-of-Life-in-Vestibular-Chartrand-Al-Tamami/4ff3a409def9dfe9bb88ee9808c1eb8ebfc2126d",
            "/paper/Prospective-Study-of-Disease-Specific-in-Sporadic-Carlson-Barnes/e9f42702f018cc45ae185e61cc47a6950f55ab0a",
            "/paper/Longitudinal-Changes-of-Quality-of-Life-and-Hearing-Windisch-Tonn/6c1bd115932d1737e42b6bb490211ec7d2891f52",
            "/paper/Severity-of-Tinnitus-Distress-Negatively-Impacts-of-Kojima-Oishi/efbef93d335a163cc4eae358caf34918e335155b",
            "/paper/Outcome-and-Toxicity-of-Proton-Therapy-for-A-Cohort-Koetsier-Hensen/a657b6d3bc46b482b7c0ea2dec886d954a6de1ee",
            "/paper/Comparison-of-Long-term-Quality-of-Life-Outcomes-in-Robinett-Walz/40698b032912d301afa310e05e5b7409a6dd3660",
            "/paper/Conservative-management-of-vestibular-schwannoma--a-Breivik-Varughese/d308fc6b5537c5e5db6238e049e2ae43cebe2e66",
            "/paper/Conservative-Treatment-of-Vestibular-Schwannoma%3A-A-Godefroy-Kaptein/94275749bd2c05f2080ba455f9ae728fc30453e1",
            "/paper/Untreated-vestibular-schwannomas%3A-vertigo-is-a-for-Myrseth-M%C3%B8ller/c2800488f3956c0640a1b05fe3bdb68189a7e26f",
            "/paper/The-Effect-of-Observation-versus-Microsurgical-on-A-Sandooram-Hornigold/f92e32c7df9eca8b10bbd1df7b3ab660b241cfb6",
            "/paper/Long-term-quality-of-life-in-patients-with-an-study-Carlson-Tveiten/d571627b938399be35a8268c6f743d03a9fe95ed",
            "/paper/Quality-of-Life-Among-Acoustic-Neuroma-Patients-by-Brooker-Fletcher/e5dddd3b88688d2a53397edb7e798af3389d053b",
            "/paper/Prospective-comparison-of-quality-of-life-before-or-Maio-Akagami/81394e40bbb59ebcccae4a010e1332c1e2adc806",
            "/paper/Audiovestibular-Factors-Influencing-Quality-of-Life-Lloyd-Kasbekar/f2c310e5e7b813094c5ebd7dc6e269059e366dca",
            "/paper/Quality-of-Life-in-Acoustic-Neuroma-Patients-McLaughlin-Bigelow/a3711983671315b4345e847351c122ac9d720aa2"
        ]
    },
    {
        "id": "ea1e445e610822786ee7322885edfec66dfe421b",
        "title": "Cyclic Learning: Bridging Image-level Labels and Nuclei Instance Segmentation",
        "abstract": "Cyclic learning is designed to circularly share knowledge between the front-end classifier and the back-end semi-supervised part, which allows the whole system to fully extract the underlying information from image-level labels and converge to a better optimum. Nuclei instance segmentation on histopathology images is of great clinical value for disease analysis. Generally, fully-supervised algorithms for this task require pixel-wise manual annotations, which is especially time-consuming and laborious for the high nuclei density. To alleviate the annotation burden, we seek to solve the problem through image-level weakly supervised learning, which is underexplored for nuclei instance segmentation. Compared with most existing methods using other weak annotations (scribble, point, etc.) for nuclei instance segmentation, our method is more labor-saving. The obstacle to using image-level annotations in nuclei instance segmentation is the lack of adequate location information, leading to severe nuclei omission or overlaps. In this paper, we propose a novel image-level weakly supervised method, called cyclic learning, to solve this problem. Cyclic learning comprises a front-end classification task and a back-end semi-supervised instance segmentation task to benefit from multi-task learning (MTL). We utilize a deep learning classifier with interpretability as the front-end to convert image-level labels to sets of high-confidence pseudo masks and establish a semi-supervised architecture as the back-end to conduct nuclei instance segmentation under the supervision of these pseudo masks. Most importantly, cyclic learning is designed to circularly share knowledge between the front-end classifier and the back-end semi-supervised part, which allows the whole system to fully extract the underlying information from image-level labels and converge to a better optimum. Experiments on three datasets demonstrate the good generality of our method, which outperforms other image-level weakly supervised methods for nuclei instance segmentation, and achieves comparable performance to fully-supervised methods.",
        "publication_year": "2023",
        "authors": [
            "Yang Zhou",
            "Yongjian Wu",
            "Z. Wang",
            "Bingzheng Wei",
            "Maode Lai",
            "Jianzhong Shou",
            "Yubo Fan",
            "Yan Xu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "82",
        "references": [
            "/paper/Minimizing-Labeling-Cost-for-Nuclei-Instance-and-Yang-Zhang/f9282d8871dd3d87a002ffd6e38eefff65978128",
            "/paper/CAMEL%3A-A-Weakly-Supervised-Learning-Framework-for-Xu-Song/5c5a02edeb5623cbe82968d711f505ac76df62f5",
            "/paper/Transformer-based-multiple-instance-learning-for-Qian-Li/d2dd993ebd5fe26aeeb9c87b1fb4530031a62e64",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-Using-in-Qu-Wu/c616b0fe93dc0b52b04ce6bf68ae3a67701200e8",
            "/paper/Weakly-Supervised-Nuclei-Segmentation-Via-Instance-Liu-He/41d93b3a5740fc48af22d1d6043b759a1ee9e5be",
            "/paper/A-Weakly-Supervised-Method-for-Instance-of-Cells-Guerrero-Pe%C3%B1a-Marrero-Fern%C3%A1ndez/66c211884f5c8580200c3a99ece3da825c73772d",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-using-in-Qu-Wu/2b60f01e916725a8f0b5dddc44b4cb9bd3e5e8c3",
            "/paper/DCAN%3A-Deep-contour%E2%80%90aware-networks-for-object-from-Chen-Qi/929c9a90e2ceac3f6684f2b29e6579c40b4ce3c1",
            "/paper/HistoSegResT%3A-A-Weakly-Supervised-Learning-Method-Gu-Wang/f30e6ce1323d306c20e4331ab7c8d03c2879b085",
            "/paper/BoxNet%3A-Deep-Learning-Based-Biomedical-Image-Using-Yang-Zhang/09e0363a81c010157ebb2454497a3a06c249c458"
        ]
    },
    {
        "id": "d875b9eb9fc89a8ceeabdd195820f0f137cb3c5f",
        "title": "Multidimensional Information Recognition Algorithm Based on CSI Decomposition",
        "abstract": "A long short-term memory (LSTM) multidimensional information recognition network that successively recognizes the location and activity information of humans. Wireless sensing technology based on channel state information (CSI) has broad application prospects in human\u2013computer interaction, smart homes, and other fields due to its advantages, which include no special equipment deployment, no privacy leakage, and no light intensity and line of sight influence. The existing studies have achieved satisfactory recognition accuracy for human localization or activity information. However, many applications need to recognize not only the activity of humans but also the location of humans. Therefore, multidimensional information recognition for human targets has become an urgent problem to be solved. For this problem, a multidimensional information recognition algorithm for human targets based on CSI decomposition (called the CD-MDIR algorithm) is proposed. Specifically, we first decompose the CSI time series into dynamic location CSI (DLC) components affected by human location and dynamic activity CSI (DAC) components affected by human activity, according to the independent characteristics of the influence of human location and activity on CSI. Then, the linear discriminant analysis (LDA) algorithm is used to transform the DLC component to enhance the location information, and the features of the DAC component are extracted to enhance the activity information. Finally, we designed a long short-term memory (LSTM) multidimensional information recognition network that successively recognizes the location and activity information of humans. Experimental results show that the proposed CD-MDIR algorithm achieves both higher localization and activity recognition accuracy.",
        "publication_year": "2023",
        "authors": [
            "Yong Tian",
            "Chen Chen",
            "Qiyue Zhang",
            "Ying Li",
            "Sirou Li",
            "Xuejun Ding"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "31",
        "references": [
            "/paper/CSI-Based-Wireless-Localization-and-Activity-Using-Wu-Yang/5f1e6b38d476773bebd09e15a7c8f7bffde66674",
            "/paper/CSI-Based-Device-Free-Wireless-Localization-and-Gao-Wang/6c1bd2f72daaee0136f605a43ae21a08de48421b",
            "/paper/CSI-Based-Location-Independent-Human-Activity-Using-Zhang-Liu/d88f92840f600f6d35bcf42ad021c1d9be2acc3f",
            "/paper/Device-Free-Simultaneous-Wireless-Localization-and-Wang-Zhang/cb713443e49f09cc5ef760e145a89c7b115590bd",
            "/paper/CSI-Fingerprinting-Localization-With-Low-Human-Tong-Wan/fff3236a634df15a5f6dba0ceb198d71c6a7d67a",
            "/paper/Multimodal-CSI-Based-Human-Activity-Recognition-Wang-Yang/db5796032ac7fec7abd457dfa6531131b3ebe70f",
            "/paper/Device-Free-Wireless-Localization-and-Activity-A-Wang-Zhang/29f4a957802fa54c5e23a170121e46f5f1e7a49b",
            "/paper/Environment-Robust-Device-Free-Human-Activity-With-Shi-Zhang/9fd905eb9de1be660aca05bfbd989d09c40c278b",
            "/paper/Joint-Activity-Localization-and-Recognition-with-on-Cheng-Wang/5b0beb1372ae2e1992ed0ecc3a3524997fe715f1",
            "/paper/Indoor-Multifloor-Localization-Method-Based-on-WiFi-Luo-Zhang/cd6ddc39829928d76f96c95032783d64156db59e"
        ]
    },
    {
        "id": "5c04ce7f8510af40f2931535feeaf220832ab548",
        "title": "SLSG: Industrial Image Anomaly Detection by Learning Better Feature Embeddings and One-Class Classification",
        "abstract": "A network based on self-supervised learning and self-attentive graph convolution (SLSG) for anomaly detection, which comprehensively models the dense and sparse relationships among elements in the image, which further strengthens the detection of logical anomalies. Industrial image anomaly detection under the setting of one-class classification has significant practical value. However, most existing models struggle to extract separable feature representations when performing feature embedding and struggle to build compact descriptions of normal features when performing one-class classification. One direct consequence of this is that most models perform poorly in detecting logical anomalies which violate contextual relationships. Focusing on more effective and comprehensive anomaly detection, we propose a network based on self-supervised learning and self-attentive graph convolution (SLSG) for anomaly detection. SLSG uses a generative pre-training network to assist the encoder in learning the embedding of normal patterns and the reasoning of position relationships. Subsequently, SLSG introduces the pseudo-prior knowledge of anomaly through simulated abnormal samples. By comparing the simulated anomalies, SLSG can better summarize the normal features and narrow down the hypersphere used for one-class classification. In addition, with the construction of a more general graph structure, SLSG comprehensively models the dense and sparse relationships among elements in the image, which further strengthens the detection of logical anomalies. Extensive experiments on benchmark datasets show that SLSG achieves superior anomaly detection performance, demonstrating the effectiveness of our method.",
        "publication_year": "2023",
        "authors": [
            "Minghui Yang",
            "Jing Liu",
            "Zhiwei Yang",
            "Zhaoyang Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "57",
        "references": [
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/A-Deep-One-Class-Neural-Network-for-Anomalous-Event-Wu-Liu/355b4e74774798c177c82943eef925d66a2bb2ce",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Focus-Your-Distribution%3A-Coarse-to-Fine-Learning-Zheng-Wang/e5349e937545d3f3d18d254bd21d695e7350ea8e",
            "/paper/SimpleNet%3A-A-Simple-Network-for-Image-Anomaly-and-Liu-Zhou/a23c0a89bd21bd2481fedcdd6d1ac891c6c06bdc",
            "/paper/AnoSeg%3A-Anomaly-Segmentation-Network-Using-Learning-Song-Kong/d08775cf2bebcffa05c6fa506f687ef56953f128"
        ]
    },
    {
        "id": "f0a32283217a78ada5d5dc42e0317d15eafd96d6",
        "title": "VS-Net: A Voxel Encoding and Sparse Convolution Embedded Network for LiDAR 3D Object Detection",
        "abstract": "A solution for LiDAR-only detection which employs voxel features and a sparse convolution network and leveraged residual learning to design the backbone network is provided. Accurate and efficient 3D object detection in LiDAR point cloud is critical for autonomous driving. In this paper, we provide a solution for LiDAR-only detection which employs voxel features and a sparse convolution network. Specifically, we utilized voxel centers to encode point clouds' voxel features. Then, combining the sparse convolution method, we leveraged residual learning to design the backbone network. The detector output predicted results for multi-category and multi-object detection. Our method was evaluated on three popular and challenging datasets (KITTI, nuScence and Waymo). Experimental results demonstrated that the accuracy and speed (27.8 FPS) of our model could effectively support object detection for autonomous driving in various scenarios.",
        "publication_year": "2022",
        "authors": [
            "Meng Liu",
            "Jianwei Niu",
            "Yu Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "29",
        "references": [
            "/paper/HVNet%3A-Hybrid-Voxel-Network-for-LiDAR-Based-3D-Ye-Xu/09c958fa8e755ccb5a5f2ca22f9834e7e0a045ff",
            "/paper/SECOND%3A-Sparsely-Embedded-Convolutional-Detection-Yan-Mao/5125a16039cabc6320c908a4764f32596e018ad3",
            "/paper/VoxelNet%3A-End-to-End-Learning-for-Point-Cloud-Based-Zhou-Tuzel/80f5ee8578ee76e2c17824f211762ffec7e029d4",
            "/paper/Multi-view-3D-Object-Detection-Network-for-Driving-Chen-Ma/dc200ab22bf63e10e8b2af328a9e072d82cf75b7",
            "/paper/Joint-3D-Proposal-Generation-and-Object-Detection-Ku-Mozifian/675784f097dbf87cd75a5640019d4469e7bd7905",
            "/paper/Deep-Continuous-Fusion-for-Multi-sensor-3D-Object-Liang-Yang/85d9aff092d860aebf8ea5aa255b06de25a1930e",
            "/paper/PIXOR%3A-Real-time-3D-Object-Detection-from-Point-Yang-Luo/2bcfce1e68e9adb5f1547307e66a7b23c16d319a",
            "/paper/Deep-Learning-for-LiDAR-Point-Clouds-in-Autonomous-Li-Ma/1dc1281096cbbd8a36de307bca1b6573b1c62ee0",
            "/paper/HDNET%3A-Exploiting-HD-Maps-for-3D-Object-Detection-Yang-Liang/bcfe57e2d05648c7ace15f3e96bb899b3fa262f2",
            "/paper/3D-Semantic-Segmentation-with-Submanifold-Sparse-Graham-Engelcke/1d6a5d0299ed8458191e4e0407d4d513e6a7dd7e"
        ]
    },
    {
        "id": "ab6625763940699a8fdc78b732d762ca4f395d5a",
        "title": "Classification-based self-supervised learning for anomaly detection",
        "abstract": "An Absolute Measurement Anomaly Detection (AMAD) is proposed, to constrain the distribution of activations of each input in the classification network, which achieves better performance in terms of AUROC and F1 score when compared with previous similar methods. Anomaly detection aims to find different patterns from those seen previously. It is usually regarded as a oneclassification problem where abnormal classes are often scarce or not well defined, while the target class (training objects) are sufficient. Recently, several methods have achieved excellent performance through an auxiliary multi-class task(such as rotation predict) used in self-supervised learning. However, these classification-based approaches which adopt the crossentropy loss have inherent defects in anomaly detection. Specifically, the relative measure of cross-entropy may result that a normal sample suffered from a low score would be misclassified as an abnormality. In order to solve this problem, we propose an Absolute Measurement Anomaly Detection (AMAD), to constrain the distribution of activations of each input in the classification network. In details, this technique encourages the output of the ground truth class to be higher, vice versa for unrelated classes. Furtherly, different from the previous evaluation methods that counting the log-softmax activation of the model as normality score, we ignore the log-softmax since the score would be affected heavily provided that more misclassification occurs. We present experiments both in image datasets(CIFAR-10, Fashion-MNIST) and tabular datasets(KDDCUP et al.), which show that our technique achieves better performance in terms of AUROC and F1 score when compared with previous similar methods.",
        "publication_year": "2021",
        "authors": [
            "Honghu Li",
            "Yuesheng Zhu",
            "Ying He"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "23",
        "references": [
            "/paper/Classification-Based-Anomaly-Detection-for-General-Bergman-Hoshen/04513c7c0b3a63fde81a996dae064a28d453c17a",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/Rethinking-Assumptions-in-Deep-Anomaly-Detection-Ruff-Vandermeulen/2494d35c9c84f9b3cede710c16b7f78e9cee3738",
            "/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7",
            "/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "/paper/LOF%3A-identifying-density-based-local-outliers-Breunig-Kriegel/a7c828184693a453a6c2867dee233ed054b2012e",
            "/paper/Outlier-Detection-with-Autoencoder-Ensembles-Chen-Sathe/b5781eaafe1aff25a084d83dc38831ea09db42f3",
            "/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "/paper/Using-Self-Supervised-Learning-Can-Improve-Model-Hendrycks-Mazeika/db787640c9b42416ff8d7015546e667e58267177"
        ]
    },
    {
        "id": "a73137f4c21e2fb1845d5f50dc7bf286036a8b67",
        "title": "Label Information Enhanced Fraud Detection against Low Homophily in Graphs",
        "abstract": "This work proposes GAGA, a novel Group AGgregation enhanced TrAnsformer, which outperforms other competitive graph-based fraud detectors by up to 24.39% on two trending public datasets and a real-world industrial dataset from Baidu. Node classification is a substantial problem in graph-based fraud detection. Many existing works adopt Graph Neural Networks (GNNs) to enhance fraud detectors. While promising, currently most GNN-based fraud detectors fail to generalize to the low homophily setting. Besides, label utilization has been proved to be significant factor for node classification problem. But we find they are less effective in fraud detection tasks due to the low homophily in graphs. In this work, we propose GAGA, a novel Group AGgregation enhanced TrAnsformer, to tackle the above challenges. Specifically, the group aggregation provides a portable method to cope with the low homophily issue. Such an aggregation explicitly integrates the label information to generate distinguishable neighborhood information. Along with group aggregation, an attempt towards end-to-end trainable group encoding is proposed which augments the original feature space with the class labels. Meanwhile, we devise two additional learnable encodings to recognize the structural and relational context. Then, we combine the group aggregation and the learnable encodings into a Transformer encoder to capture the semantic information. Experimental results clearly show that GAGA outperforms other competitive graph-based fraud detectors by up to 24.39% on two trending public datasets and a real-world industrial dataset from Baidu. Even more, the group aggregation is demonstrated to outperform other label utilization methods (e.g., C&S, BoT/UniMP) in the low homophily setting.",
        "publication_year": "2023",
        "authors": [
            "Yuchen Wang",
            "Jinghui Zhang",
            "Zhengjie Huang",
            "Weibin Li",
            "Shi Feng",
            "Ziheng Ma",
            "Yu Sun",
            "Dianhai Yu",
            "Fang Dong",
            "Jiahui Jin",
            "Beilun Wang",
            "Junzhou Luo"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "34",
        "references": [
            "/paper/Enhancing-Graph-Neural-Network-based-Fraud-against-Dou-Liu/14156438bafed28a626738630b5181b83ed5d79c",
            "/paper/Alleviating-the-Inconsistency-Problem-of-Applying-Liu-Dou/8cf8e7fe56f26e9e811cf409e1ceeb7c9d7fb60b",
            "/paper/Pick-and-Choose%3A-A-GNN-based-Imbalanced-Learning-Liu-Ao/7487499f91f0c198347a8ebc747ad8d220bdd155",
            "/paper/H2-FDetector%3A-A-GNN-based-Fraud-Detector-with-and-Shi-Cao/414668b64b026ff50e4d91d14fbe7b8327cfe026",
            "/paper/FRAUDRE%3A-Fraud-Detection-Dual-Resistant-to-Graph-Zhang-Wu/748c865ebf0845827ca23fa5874decce9646b226",
            "/paper/Beyond-Homophily-in-Graph-Neural-Networks%3A-Current-Zhu-Yan/21e33bd0ad95ee1f79d8b778e693fd316cbb72d4",
            "/paper/A-Comprehensive-Survey-on-Graph-Anomaly-Detection-Ma-Wu/35067cc8153b7e6270797fffaefc5c9cefdfe515",
            "/paper/Anomaly-Detection-in-Dynamic-Graphs-via-Transformer-Liu-Pan/ddb842d2d609ddd535c4d15637e4bcd2c6d834b2",
            "/paper/Prohibited-Item-Detection-via-Risk-Graph-Structure-Ji-Chu/29026991e05d548ad6419b7b325db8008a18cfec",
            "/paper/Spam-Review-Detection-with-Graph-Convolutional-Li-Qin/69813821ea86d630a4e63f65ef1030f799662410"
        ]
    },
    {
        "id": "bab40171eafbcf1bc372627c94b500e0f4ec6691",
        "title": "Deep Learning for Automatic Vision-Based Recognition of Industrial Surface Defects: A Survey",
        "abstract": "The results of this analysis highlight a growing research interest in defect representation power enrichment, especially by transferring pre-trained layers to an optimized network and by explaining the network decisions to suggest trustworthy retention or rejection of the products being evaluated. Automatic vision-based inspection systems have played a key role in product quality assessment for decades through the segmentation, detection, and classification of defects. Historically, machine learning frameworks, based on hand-crafted feature extraction, selection, and validation, counted on a combined approach of parameterized image processing algorithms and explicated human knowledge. The outstanding performance of deep learning (DL) for vision systems, in automatically discovering a feature representation suitable for the corresponding task, has exponentially increased the number of scientific articles and commercial products aiming at industrial quality assessment. In such a context, this article reviews more than 220 relevant articles from the related literature published until February 2023, covering the recent consolidation and advances in the field of fully-automatic DL-based surface defects inspection systems, deployed in various industrial applications. The analyzed papers have been classified according to a bi-dimensional taxonomy, that considers both the specific defect recognition task and the employed learning paradigm. The dependency on large and high-quality labeled datasets and the different neural architectures employed to achieve an overall perception of both well-visible and subtle defects, through the supervision of fine or/and coarse data annotations have been assessed. The results of our analysis highlight a growing research interest in defect representation power enrichment, especially by transferring pre-trained layers to an optimized network and by explaining the network decisions to suggest trustworthy retention or rejection of the products being evaluated.",
        "publication_year": "2023",
        "authors": [
            "Michela Prunella",
            "Roberto M. Scardigno",
            "D. Buongiorno",
            "Antonio Brunetti",
            "N. Longo",
            "Raffaele Carli",
            "M. Dotoli",
            "Vitoantonio Bevilacqua"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "316",
        "references": [
            "/paper/Automated-surface-defect-detection-framework-using-Singh-Desai/06a0ecac6c017a543982d7010cba7f925d4b6815",
            "/paper/Automated-surface-defect-detection-in-metals%3A-a-of-Usamentiaga-Lema/9c06aae54db232de76b2e8a51cf5565d6688b86c",
            "/paper/A-Generic-Deep-Learning-Based-Approach-for-Surface-Ren-Hung/1d2105616d122389efbd1b0ac7c04c0c2f8ac996",
            "/paper/A-Review-on-Recent-Advances-in-Vision-based-Defect-Gao-Li/4936c8c03c7d9720530ce29b47b5266a7d79efd9",
            "/paper/A-Deep-Learning-Based-Surface-Defect-Inspection-and-Yang-Fu/7c08fa254918d323c865c32626115799336319b2",
            "/paper/Deep-learning-object-detection-applied-to-defect-of-Huang-Ting/ad8848b837e8610e57b801d2520523974dad59c0",
            "/paper/Reliable-and-Robust-Weakly-Supervised-Attention-for-Zhang-Lv/77c2843a171941f15534bf1744bb46f8ff7cbbe9",
            "/paper/CADN%3A-A-weakly-supervised-learning-based-object-for-Zhang-Su/e5014a547281b5d64c89cb14825757c565f02639",
            "/paper/TLU-Net%3A-A-Deep-Learning-Approach-for-Automatic-Damacharla-AchuthRaoM./71ab1aaecefb699d064e9a75d973d23894f7a75b",
            "/paper/EDDs%3A-A-series-of-Efficient-Defect-Detectors-for-Zhou-Zhang/6cac1a97e6c6277dfd556db6c967babc701c96f9"
        ]
    },
    {
        "id": "e50f35840c6f9bbfeb468bede9201df2619769e3",
        "title": "Self-Supervised Surface Defect Localization via Joint De-Anomaly Reconstruction and Saliency-Guided Segmentation",
        "abstract": "A self-supervised surface defect localization method via joint de-anomaly reconstruction and saliency-guided segmentation, also named JDRSS is proposed, in which the residuals from the reconstructed image and input are dexterously injected into each segmentation layer as spatial attention, thus enhancing the sensitivity to anomalies. Anomaly localization plays one of the significant role in practical industrial applications but still faces some unique challenges due to the rarity and diversity of anomalies. To address this issue, we propose a self-supervised surface defect localization method via joint de-anomaly reconstruction and saliency-guided segmentation, also named JDRSS. Considering the severe lack of anomalous images, an approach for synthesizing anomalous samples is proposed to simulate different types of anomalies, which results in a variety of realistic and diverse anomalous images. To promote the reconstruction quality to the normal reference, we develop a novel autoencoder-based reconstruction network by applying the bundled de-anomaly constraint to refrain both the embedding space and the reconstruction space from the interference of abnormality. Furthermore, in order to accurately localize the surface defect, an anomalous saliency map-guided segmentation network is proposed, in which the residuals from the reconstructed image and input are dexterously injected into each segmentation layer as spatial attention, thus enhancing the sensitivity to anomalies. We have conducted extensive experiments on the MVTec anomaly detection (MVTec AD) dataset and the proposed model achieves considerable performance for different classes of anomaly localization.",
        "publication_year": "2023",
        "authors": [
            "Hanyue Yang",
            "Zhenfeng Zhu",
            "Chen Lin",
            "Wenjun Hui",
            "Shenghui Wang",
            "Yao Zhao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "36",
        "references": [
            "/paper/AnoSeg%3A-Anomaly-Segmentation-Network-Using-Learning-Song-Kong/d08775cf2bebcffa05c6fa506f687ef56953f128",
            "/paper/Reconstruction-by-inpainting-for-visual-anomaly-Zavrtanik-Kristan/2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "/paper/Improving-Unsupervised-Defect-Segmentation-by-to-Bergmann-L%C3%B6we/9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "/paper/A-Novel-Pixel-Wise-Defect-Inspection-Method-Based-Lv-Shen/d67b9dafcf94017784c266e021fe29baf2ffd572",
            "/paper/DR%C3%86M-%E2%80%93-A-discriminatively-trained-reconstruction-Zavrtanik-Kristan/95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "/paper/EDRNet%3A-Encoder%E2%80%93Decoder-Residual-Network-for-Object-Song-Song/31bc0d4ec9a5bfc2152c4928ac2c3864959c0342",
            "/paper/Superpixel-Masking-and-Inpainting-for-Anomaly-Li-Li/e13d3f39cb9d03c57fef1344a825c163160dd8e7",
            "/paper/Segmentation-based-deep-learning-approach-for-Tabernik-Sela/b77b1fc188f3834541efbb75add8f1ea80fd6225",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af"
        ]
    },
    {
        "id": "1f96460299f3c74965b4fe8e64c28957ada06c74",
        "title": "JUMP Cell Painting dataset: morphological impact of 136,000 chemical and genetic perturbations",
        "abstract": "Data generated by the Joint Undertaking for Morphological Profiling (JUMP)-Cell Painting Consortium, a collaboration between 10 pharmaceutical companies, six supporting technology companies, and two non-profit partners, is presented. Image-based profiling has emerged as a powerful technology for various steps in basic biological and pharmaceutical discovery, but the community has lacked a large, public reference set of data from chemical and genetic perturbations. Here we present data generated by the Joint Undertaking for Morphological Profiling (JUMP)-Cell Painting Consortium, a collaboration between 10 pharmaceutical companies, six supporting technology companies, and two non-profit partners. When completed, the dataset will contain images and profiles from the Cell Painting assay for over 116,750 unique compounds, over-expression of 12,602 genes, and knockout of 7,975 genes using CRISPR-Cas9, all in human osteosarcoma cells (U2OS). The dataset is estimated to be 115 TB in size and capturing 1.6 billion cells and their single-cell profiles. File quality control and upload is underway and will be completed over the coming months at the Cell Painting Gallery: https://registry.opendata.aws/cellpainting-gallery. A portal to visualize a subset of the data is available at https://phenaid.ardigen.com/jumpcpexplorer/.",
        "publication_year": "2023",
        "authors": [
            "S. Chandrasekaran",
            "Jeanelle Ackerman",
            "Eric Alix",
            "D. M. Ando",
            "John Arevalo",
            "Melissa Bennion",
            "Nicolas Boisseau",
            "Adriana Borowa",
            "Justin D. Boyd",
            "L. Brino",
            "Patrick Byrne",
            "H. Ceulemans",
            "C. Ch'ng",
            "B. Cimini",
            "Djork-Arn\u00e9 Clevert",
            "N. Deflaux",
            "J. Doench",
            "T. Dorval",
            "R. Doyonnas",
            "Vincenza Dragone",
            "O. Engkvist",
            "P. Faloon",
            "Briana Fritchman",
            "Florian Fuchs",
            "S. Garg",
            "Tamara Gilbert",
            "David Glazer",
            "D. Gnutt",
            "A. Goodale",
            "Jeremy Grignard",
            "J. Guenther",
            "Y. Han",
            "Zahra Hanifehlou",
            "S. Hariharan",
            "D. Hernandez",
            "S. R. Horman",
            "Gisela Hormel",
            "Michael Huntley",
            "Ilknur Icke",
            "Makiyo Iida",
            "Christina B. Jacob",
            "Steffen Jaensch",
            "Jawahar Khetan",
            "M. Kost-Alimova",
            "T. Krawiec",
            "Daniel Kuhn",
            "Charles-Hugues Lardeau",
            "Amanda Lembke",
            "Francis Lin",
            "Kevin D. Little",
            "Kenneth R. Lofstrom",
            "Sofia Lotfi",
            "David J. Logan",
            "Yi Luo",
            "Franck Madoux",
            "Paula A. Marin Zapata",
            "Brittany A. Marion",
            "Glynn Martin",
            "N. McCarthy",
            "Lewis H. Mervin",
            "Lisa Miller",
            "Haseeb Mohamed",
            "Tiziana Monteverde",
            "E. Mouchet",
            "B. Nicke",
            "Arnaud Ogier",
            "Anne-Laure Ong",
            "M. Osterland",
            "M. Otrocka",
            "P. Peeters",
            "J. Pilling",
            "S. Prechtl",
            "Chen Qian",
            "K. Rataj",
            "D. Root",
            "S. Sakata",
            "Simon F. Scrace",
            "H. Shimizu",
            "David Simon",
            "Peter Sommer",
            "Craig Spruiell",
            "I. Sumia",
            "Susanne E. Swalley",
            "H. Terauchi",
            "Amandine Thibaudeau",
            "A. Unruh",
            "Jelle Van de Waeter",
            "M. Van Dyck",
            "C. V. van Staden",
            "M. Warcho\u0142",
            "Erin Weisbart",
            "Am\u00e9lie Weiss",
            "Nicolas Wiest-Daessl\u00e9",
            "Guy B. Williams",
            "Shan Yu",
            "Bolek Zapiec",
            "M. \u017by\u0142a",
            "Shantanu Singh",
            "Anne E Carpenter"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "5",
        "reference_count": "32",
        "references": [
            "/paper/Three-million-images-and-morphological-profiles-of-Chandrasekaran-Cimini/3e173f19037739ae6e84bc3b9f97957c42412660",
            "/paper/Self-supervision-advances-morphological-profiling-Kim-Adaloglou/7bfc47f93c5b48222cc553883d24a4f0be291328",
            "/paper/High-resolution-genome-wide-mapping-of-truncations-Lazar-Celik/d798d90b55122bede19569e76cce33fb81a7673f",
            "/paper/Unbiased-single-cell-morphology-with-vision-Doron-Moutakanni/cba82aa85450344a37c6004c973ba58004c6d282",
            "/paper/Out-of-Distribution-Generalization-via-Style-in-Pernice-Doron/ade6cfe42892f4a9621c6a10e632ae283cf6885b",
            "/paper/Optimizing-the-Cell-Painting-assay-for-image-based-Cimini-Chandrasekaran/42be3e7f9b95fcfa4455988a27dd17cf01d68507",
            "/paper/A-dataset-of-images-and-morphological-profiles-of-Bray-G%C3%BAstafsd%C3%B3ttir/05ba3c532b7b98c9448da0bee52d7cba0ef29621",
            "/paper/Three-million-images-and-morphological-profiles-of-Chandrasekaran-Cimini/3e173f19037739ae6e84bc3b9f97957c42412660",
            "/paper/Cell-Painting-predicts-impact-of-lung-cancer-Caicedo-Arevalo/c5dd04fdd9e9e55cc172e4e1316b58ff1fb7aa45",
            "/paper/Morphology-and-gene-expression-profiling-provide-Way-Natoli/1f7bb6a080c1db96c778793514bf2b1638b623ab",
            "/paper/Integrating-deep-learning-and-unbiased-automated-to-Schiff-Migliori/f08c5a30f1f0c9d79861f7eb993bf89fa9ef1074",
            "/paper/Systematic-morphological-profiling-of-human-gene-Rohban-Singh/c6bf43a2bfffec64989baa2d193a6a845defa59e",
            "/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Assessing-the-performance-of-the-Cell-Painting-Jamali-Tromans-Coia/dbe577b3cdc30f0f1b264a86affc9db96c6065a7"
        ]
    },
    {
        "id": "a721d255ce68659b8aeb6119f26db1cdd7df2e8f",
        "title": "Improved NSAF Algorithms with Variable Control Parameter Against Impulsive Noises",
        "abstract": "In the contexts of system identification and acoustic echo cancellation, simulation results testified the improved performance of these proposed VCP algorithms in terms of the convergence rate, steady-state error, and tracking capability. Some improved normalized subband adaptive filter algorithms derived from nonlinear cost functions, such as the logarithmic function and the arctangent function, have shown splendid robustness against the impulsive noises. However, due to the usage of the constant control parameter in their cost functions, these algorithms need to make a balance between the steady-state error and the convergence rate, especially when the unknown impulse response changes suddenly. For settling this trade-off issue, a way of obtaining the variable control parameter (VCP) recursively is constructed by an exponential function in this paper. In the contexts of system identification and acoustic echo cancellation, simulation results testified the improved performance of these proposed VCP algorithms in terms of the convergence rate, steady-state error, and tracking capability.",
        "publication_year": "2020",
        "authors": [
            "Zijie Shen",
            "Tianmin Huang",
            "Li Yang",
            "Xueqin Li"
        ],
        "related_topics": [
            "Engineering"
        ],
        "citation_count": 0,
        "reference_count": "28",
        "references": [
            "/paper/Robust-gain-combined-proportionate-normalized-with-Shen-Shi/96d7bd865f90dbac943b40b6c9bd56fec22c6162",
            "/paper/NLMS-Algorithm-Based-on-a-Variable-Parameter-Cost-Huang-Zhang/9fe0346e354f91c6db34fb37e35c194be8be05f7",
            "/paper/Steady-state-mean-square-deviation-analysis-of-the-Yu-Zhao/f2e2d5528cc24433c2cdb55667e2342b0528fa4e",
            "/paper/A-novel-subband-adaptive-filter-algorithm-against-Wen-Zhang/d9e3ecd7d63ac700025f57fdf461a19f4ed643e4",
            "/paper/Variable-Step-Size-Sign-Subband-Adaptive-Filter-Shin-Yoo/3a4eb71e3cd6182d3f24852b662d9de01be72c10",
            "/paper/A-band-dependent-variable-step-size-sign-subband-Yoo-Shin/8d387d2b68f31fb96f06ed9c243bffb150838dcf",
            "/paper/Two-Improved-Normalized-Subband-Adaptive-Filter-Yu-Zhao/90b90513da0c74d2e426ffbac9c4c8701aad1762",
            "/paper/Two-Novel-Arctangent-Normalized-Subband-Adaptive-Shen-Yu/a9998c4a9ad73b9963df053f6d5643e935059a88",
            "/paper/Sign-subband-adaptive-filter-with-%E2%84%931-norm-variable-Kim-Chang/417bd43e223b77b8d622d2f729727f264c9d19ee",
            "/paper/Improving-convergence-of-the-NLMS-algorithm-using-Lee-Gan/48905b7b0149d88ba221afa0f1ef2fb9426a3c12",
            "/paper/A-recursive-least-M-estimate-(RLM)-adaptive-filter-Zou-Chan/45369c0c67b621d3896cfb1f79400f8982551636"
        ]
    },
    {
        "id": "d85b756b8e4d584a53483c6562eb968efdb1fc0c",
        "title": "Discrete neural representations for explainable anomaly detection",
        "abstract": "A method using saliency maps to decouple the explanation of anomalous events from object and action classifiers, and how to improve the quality ofSaliency maps using a novel neural architecture for learning discrete representations of video by predicting future frames. The aim of this work is to detect and automatically generate high-level explanations of anomalous events in video. Understanding the cause of an anomalous event is crucial as the required response is dependant on its nature and severity. Recent works typically use object or action classifier to detect and provide labels for anomalous events. However, this constrains detection systems to a finite set of known classes and prevents generalisation to unknown objects or behaviours. Here we show how to robustly detect anomalies without the use of object or action classifiers yet still recover the high level reason behind the event. We make the following contributions: (1) a method using saliency maps to decouple the explanation of anomalous events from object and action classifiers, (2) show how to improve the quality of saliency maps using a novel neural architecture for learning discrete representations of video by predicting future frames and (3) beat the state-of-the-art anomaly explanation methods by 60% on a subset of the public benchmark X-MAN dataset [25].",
        "publication_year": "2021",
        "authors": [
            "Stanislaw Szymanowicz",
            "James Charles",
            "R. Cipolla"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "28",
        "references": [
            "/paper/Spatio-temporal-predictive-tasks-for-abnormal-event-Naji-Setkov/08485f86df52e9cf9b02394d6a3aae05aff0a799",
            "/paper/Towards-Explainable-Visual-Anomaly-Detection-Wang-Guo/484bbbfe3a4a8cc5fcf3218cac61a7d0efe77490",
            "/paper/DyAnNet%3A-A-Scene-Dynamicity-Guided-Self-Trained-Vijay-Raghuwanshi/e7935d6944ec6ee2f7e2d5f40833300e4daa78d0",
            "/paper/A-self-supervised-algorithm-to-detect-signs-of-in-Prenkaj-Aragona/a9992f1fa5341d3c8a3b681f933d7625750fd6bb",
            "/paper/Toward-Fast-and-Accurate-Violence-Detection-for-Husz%C3%A1r-Adhikarla/9e45f928e499ba2b97d2b396cc402aa842ef159b",
            "/paper/A-Survey-on-Explainable-Anomaly-Detection-Li-Zhu/40fc6787c87d60f3f070281c53c8289230009558",
            "/paper/Fast-Region-of-Interest-Proposals-on-Maritime-UAVs-Kiefer-Zell/459176889454154373c3b368903b3b4f55baae8a",
            "/paper/X-MAN%3A-Explaining-multiple-sources-of-anomalies-in-Szymanowicz-Charles/296a22664daf1a4a39a22697a6e379720646c283",
            "/paper/Joint-Detection-and-Recounting-of-Abnormal-Events-Hinami-Mei/094ac7510d1723cb9c2da01db47291322aa29025",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/6cf1d69e447e9687dbd2d92572f44bddbabd8192",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Detecting-Abnormal-Events-in-Video-Using-Narrowed-Ionescu-Smeureanu/ee1d50a0c6448253eaf8d1f7f6b00d893419589d",
            "/paper/Anomaly-detection-in-crowded-scenes-Mahadevan-Li/9d3f0d47449c7db37d1bae3b70db2928610a8db7",
            "/paper/Likelihood-Ratios-for-Out-of-Distribution-Detection-Ren-Liu/925182b91f51f8f2b747f7829e9d25ffc2729e5d",
            "/paper/Abnormal-Event-Detection-in-Videos-Using-Hybrid-Wang-Zhou/c017a2bc601513a1ec2be2d1155e0384e78b6380"
        ]
    },
    {
        "id": "3d057498bb3dde5f3117b63d9271180b21542683",
        "title": "Disc\u2013condyle relationship alterations following stabilization splint therapy or arthrocentesis plus hyaluronic acid injection in patients with anterior disc displacement: a retrospective cohort study",
        "abstract": "SS was effective in improving the disc\u2013Condyle relationship in ADD subjects, while significant improvement of disc\u2013condyle relationship cannot be achieved through arthrocentesis plus hyaluronic acid injection. Objective The objective of this study was to quantitatively evaluate the efficacy of stabilization splint (SS) therapy or arthrocentesis plus hyaluronic acid (HA) injection in the treatment of anterior disc displacement (ADD) through magnetic resonance imaging (MRI). Methods 99 subjects were collected in this study. 46 subjects received SS treatment (SS group), 53 subjects received arthrocentesis plus HA injection (HA group). Joints with anterior disc displacement with reduction (ADDwR) and anterior disc displacement without reduction (ADDwoR) were compared separately. MRI before the beginning of the treatment and after a set of treatment were used for measurement. Disc\u2013condyle relationship and positions of condyles and discs were determined by disc\u2013condyle angles and X \u2013 Y coordinates. Results The disc\u2013condyle angles decreased significantly in the SS group ( P \u2009<\u2009.0001). Whereas no significant change was found in the HA group. Substantial anteroinferior condyle movement was detected in the SS group, slight anterior movement of condyles was discovered in the HA group. Anterior shift of discs position was observed in HA group and joints with ADDwoR in the SS group. Conclusions SS was effective in improving the disc\u2013condyle relationship in ADD subjects, while significant improvement of disc\u2013condyle relationship cannot be achieved through arthrocentesis plus HA injection.",
        "publication_year": "2022",
        "authors": [
            "Ziyu Li",
            "Jialiang Zhou",
            "Lixia Yu",
            "S. He",
            "Fei Li",
            "Yao Lin",
            "Jingchen Xu",
            "Song Chen"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": 0,
        "reference_count": "38",
        "references": [
            "/paper/Effect-of-simultaneous-application-of-and-occlusal-Altaweel-Ismail/5a820db92ba51c624e72dd748cb60004c5056f32",
            "/paper/Is-Hyaluronic-Acid-Injection-Effective-for-the-of-Korkmaz-Altinta%C5%9F/eaea106b4e8647a3348750345368da8a019afb45",
            "/paper/Evaluation-of-effusion-and-articular-disc-after-two-Pasqual-Poluha/a9c2ea54765af3f4ea0be4afdbbbd9adb0fe82e8",
            "/paper/Comparative-prospective-study-on-splint-therapy-of-Stiesch-Scholz-Kempert/ceb4fa04acc02995780301023638ca8218bb081d",
            "/paper/Conservative-therapy-in-patients-with-anterior-disc-Schmitter-Zahran/8d4248d238634bad1973cf212ca1a9585f0be7a3",
            "/paper/Metrical-analysis-of-disc-condyle-relation-with-in-Liu-Lei/20d95ac93db02787dd0b43a96c51a03950a81b7c",
            "/paper/Evaluation-of-the-position%2C-mobility%2C-and-of-the-by-Ohnuki-Fukuda/7496fcafc07de084ebeb854d4aa5487bfdfab33c",
            "/paper/Clinical-protocol-for-managing-acute-disc-without-a-Lei-Yap/f56d33f5fa0a10b8a352734f2343b25c1d025ba5",
            "/paper/Evaluation-of-the-role-of-splint-therapy-in-the-on-Hasegawa-Kakimoto/a913af3b3c05dbbfe65c4a09d147c2549f169f37",
            "/paper/Comparison-of-the-effectiveness-of-three-different-Tatli-Benlidayi/637ac63555806b8c997c9944ae30319fe7af6d58"
        ]
    },
    {
        "id": "f311c0c066f21838afbadf07d9c834bdd65e496c",
        "title": "Marker-controlled watershed with deep edge emphasis and optimized H-minima transform for automatic segmentation of densely cultivated 3D cell nuclei",
        "abstract": "The use of edge emphasizing U-Nets and optimized H-minima transform can improve the marker-controlled watershed transform for segmentation of densely cultivated 3D cell nuclei. Background The segmentation of 3D cell nuclei is essential in many tasks, such as targeted molecular radiotherapies (MRT) for metastatic tumours, toxicity screening, and the observation of proliferating cells. In recent years, one popular method for automatic segmentation of nuclei has been deep learning enhanced marker-controlled watershed transform. In this method, convolutional neural networks (CNNs) have been used to create nuclei masks and markers, and the watershed algorithm for the instance segmentation. We studied whether this method could be improved for the segmentation of densely cultivated 3D nuclei via developing multiple system configurations in which we studied the effect of edge emphasizing CNNs, and optimized H-minima transform for mask and marker generation, respectively. Results The dataset used for training and evaluation consisted of twelve in vitro cultivated densely packed 3D human carcinoma cell spheroids imaged using a confocal microscope. With this dataset, the evaluation was performed using a cross-validation scheme. In addition, four independent datasets were used for evaluation. The datasets were resampled near isotropic for our experiments. The baseline deep learning enhanced marker-controlled watershed obtained an average of 0.69 Panoptic Quality (PQ) and 0.66 Aggregated Jaccard Index (AJI) over the twelve spheroids. Using a system configuration, which was otherwise the same but used 3D-based edge emphasizing CNNs and optimized H-minima transform, the scores increased to 0.76 and 0.77, respectively. When using the independent datasets for evaluation, the best performing system configuration was shown to outperform or equal the baseline and a set of well-known cell segmentation approaches. Conclusions The use of edge emphasizing U-Nets and optimized H-minima transform can improve the marker-controlled watershed transform for segmentation of densely cultivated 3D cell nuclei. A novel dataset of twelve spheroids was introduced to the public.",
        "publication_year": "2022",
        "authors": [
            "Tuomas Kaseva",
            "Bahareh Omidali",
            "E. Hippel\u00e4inen",
            "T. M\u00e4kel\u00e4",
            "Ulla Wilppu",
            "Alexey Sofiev",
            "Arto Merivaara",
            "M. Yliperttula",
            "S. Savolainen",
            "E. Salli"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "68",
        "references": [
            "/paper/Stiffness-Controlled-Hydrogels-for-3D-Cell-Culture-Merivaara-Koivunotko/d94751a9165af603fa9d3563fa88f7f36ea31fb9",
            "/paper/Integrating-deep-convolutional-neural-networks-with-Xie-Qi/0ea3e5215ac2676a15bef2354b2938704a0789a3",
            "/paper/Cell-Segmentation-by-Combining-Marker-Controlled-Lux-Matula/5d61a6af14d1d66c121f99843a03de6cd45ac51e",
            "/paper/Multi-layer-segmentation-framework-for-cell-nuclei-Jia-Zhang/d35248733e8b0cd8b5e13e7a63af318772f3081a",
            "/paper/CNN-Based-Preprocessing-to-Optimize-Watershed-Based-Eschweiler-Spina/cced09655a03c64a849c354bc534086f468264d5",
            "/paper/Learn-to-segment-single-cells-with-deep-distance-Wang-Taft/f920b0ca3e6113b4b145a0dbc19f9dcc9a0988f7",
            "/paper/MDC-net%3A-A-new-convolutional-neural-network-for-in-Liu-Guo/e177824a15acd20bd2ceb01fb8ca7e5f5c895198",
            "/paper/Segmenting-Clustered-Nuclei-Using-H-minima-Marker-Jung-Kim/7ba18c90be2166a848ab509f9e9de950750a91da",
            "/paper/Iterative-h%E2%80%90minima%E2%80%90based-marker%E2%80%90controlled-for-cell-Koyuncu-Akhan/4c8e87d996826725192d15273c14bc0f16a6f17e",
            "/paper/NuSeT%3A-A-deep-learning-tool-for-reliably-separating-Yang-Ghosh/0ea25f1599fd520c1df29d2bde83f09cb53fb2da",
            "/paper/3D-convolutional-neural-networks-based-segmentation-Tokuoka-Yamada/b3816c29d0a696b4c562284b99bda3d906060d55"
        ]
    },
    {
        "id": "cd12413a9a90ab802497eb2cd0ba162c38c98182",
        "title": "Deep computational pathology in breast cancer.",
        "abstract": "Semantic Scholar extracted view of \"Deep computational pathology in breast cancer.\" by A. Duggento et al.",
        "publication_year": "2020",
        "authors": [
            "A. Duggento",
            "A. Conti",
            "A. Mauriello",
            "M. Guerrisi",
            "N. Toschi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "31",
        "reference_count": "131",
        "references": [
            "/paper/BRACS%3A-A-Dataset-for-BReAst-Carcinoma-Subtyping-in-Brancati-Anniciello/02a8883f756f09327cc134970be71db4dd893843",
            "/paper/Publicly-available-datasets-of-breast-H%26E-images%3A-A-Tafavvoghi-Bongo/58229c28af74d3a0de745aaad0b8d693c197b7c8",
            "/paper/Development-and-Evaluation-of-a-Novel-Framework-for-Haeyeh-Ghazal/290a6382c543058edf2a369389285de138d8be30",
            "/paper/Breast-Cancer-Classification-Based-on-Images-Using-Khikani-Elazab/693b7f7e5703f44eeec1de83fb4bcf3ba110e58f",
            "/paper/Differentiation-of-urothelial-carcinoma-in-images-Mundhada-Sundaram/10d19ddad9c5463a4e8717b5b7c14ba6da53e92c",
            "/paper/Computer-Aided-Cancer-Diagnosis-via-Machine-and-A-Bechelli/838733b65054ab160d9a8e23e60bcfe6050bf48d",
            "/paper/The-state-of-the-art-for-artificial-intelligence-in-Viswanathan-Toro/0a12fc125cde470d81ac01f4fc8d9c55f034d597",
            "/paper/C-Net%3A-A-Reliable-Convolutional-Neural-Network-for-Barzekar-Yu/e835dff0822820429843d366dc30af1edf95be47",
            "/paper/Multi-modality-artificial-intelligence-in-digital-Qiao-Zhao/62ad9173d994ab264b5560f68f9488d9013cc226",
            "/paper/Histopathological-Image-Analysis-for-Oral-Squamous-Amin-Zamir/629c3a99f0f62a12f8aee93aea9934bc61509335",
            "/paper/Deep-learning-for-digital-pathology-image-analysis%3A-Janowczyk-Madabhushi/d847ee63fe234f9cc2a8be851ed511b7d1a8da36",
            "/paper/Clinical-grade-computational-pathology-using-weakly-Campanella-Hanna/addae423490bbe82da4fb2fc265237178686b4e8",
            "/paper/Accurate-and-reproducible-invasive-breast-cancer-in-Cruz-Roa-Gilmore/d5b91f292c611dea61f6e95b007ae53c2766a5f9",
            "/paper/Automated-mitosis-detection-with-deep-regression-Chen-Wang/9ae6c4198c7d55dae13e7294f36ab81899fe4aa2",
            "/paper/BACH%3A-Grand-Challenge-on-Breast-Cancer-Histology-Aresta-Ara%C3%BAjo/2e860259741de4f75311a6af5684510944e29f83",
            "/paper/Pathologist-level-interpretable-whole-slide-cancer-Zhang-Chen/01b1860903518ec9f2acc31a7712fe532838a98b",
            "/paper/Rise-of-the-Machines%3A-Advances-in-Deep-Learning-for-Levine-Schlosser/1c2c5ad8446cb953dae3daaa7156508dfc2cee2d",
            "/paper/Detecting-Cancer-Metastases-on-Gigapixel-Pathology-Liu-Gadepalli/915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7",
            "/paper/Deep-Learning-Technology-for-Improving-Cancer-Care-Coccia/574a35aec7eb12fa4b21242dad4ad5c60a99e999",
            "/paper/A-deep-learning-based-model-of-normal-histology-Sing-Hoefling/c58b9fa7bec19c9c1a91ad16c21073ae331048c3"
        ]
    },
    {
        "id": "5b307b0c9177ac507cbead55d28e5434748e59ca",
        "title": "Interpretable survival prediction for colorectal cancer using deep learning",
        "abstract": "A deep learning system for predicting disease-specific survival for stage II and III colorectal cancer using 3652 cases and clustering embeddings from a deep-learning-based image-similarity model showed that the clustering-derived feature most strongly associated with high DLS scores was also highly prognostic in isolation. Deriving interpretable prognostic features from deep-learning-based prognostic histopathology models remains a challenge. In this study, we developed a deep learning system (DLS) for predicting disease-specific survival for stage II and III colorectal cancer using 3652 cases (27,300 slides). When evaluated on two validation datasets containing 1239 cases (9340 slides) and 738 cases (7140 slides), respectively, the DLS achieved a 5-year disease-specific survival AUC of 0.70 (95% CI: 0.66\u20130.73) and 0.69 (95% CI: 0.64\u20130.72), and added significant predictive value to a set of nine clinicopathologic features. To interpret the DLS, we explored the ability of different human-interpretable features to explain the variance in DLS scores. We observed that clinicopathologic features such as T-category, N-category, and grade explained a small fraction of the variance in DLS scores (R2\u2009=\u200918% in both validation sets). Next, we generated human-interpretable histologic features by clustering embeddings from a deep-learning-based image-similarity model and showed that they explained the majority of the variance (R2 of 73\u201380%). Furthermore, the clustering-derived feature most strongly associated with high DLS scores was also highly prognostic in isolation. With a distinct visual appearance (poorly differentiated tumor cell clusters adjacent to adipose tissue), this feature was identified by annotators with 87.0\u201395.5% accuracy. Our approach can be used to explain predictions from a prognostic deep learning model and uncover potentially-novel prognostic features that can be reliably identified by people for future validation studies.",
        "publication_year": "2020",
        "authors": [
            "Ellery Wulczyn",
            "David F. Steiner",
            "M. Moran",
            "M. Plass",
            "Robert Reihs",
            "Fraser Tan",
            "Isabelle Flament-Auvigne",
            "Trissia Brown",
            "P. Regitnig",
            "Po-Hsuan Cameron Chen",
            "Narayan Hegde",
            "Apaar Sadhwani",
            "Robert MacDonald",
            "Benny Ayalew",
            "G. Corrado",
            "L. Peng",
            "Daniel Tse",
            "Heimo Muller",
            "Zhaoyang Xu",
            "Yun Liu",
            "M. Stumpe",
            "K. Zatloukal",
            "C. Mermel"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "73",
        "reference_count": "67",
        "references": [
            "/paper/Deep-Learning-on-Histopathological-Images-for-A-Davri-Birbas/5aa3760a3000b6966f01850f4535c166f7ebda5e",
            "/paper/Artificial-intelligence-in-digital-pathology%3A-a-and-McGenity-Clarke/3e776e6ae7d584995cb80b6a97ea04dd6e7d5272",
            "/paper/Deep-learning-for-multi-class-semantic-segmentation-Bokhorst-Nagtegaal/f7c9d9a217387d3a73a39b232a3bc14e6706b533",
            "/paper/Predicting-lymph-node-metastasis-from-primary-tumor-Krogue-Azizi/6a57cdefa6c89c339b35ae90d588e78a87f1ce0c",
            "/paper/Histopathology-images-predict-multi-omics-and-in-Tsai-Lee/78eeef335b22d24a5f01a6ee9f872798c71f8b75",
            "/paper/Predicting-Colorectal-Cancer-Using-Machine-and-Deep-Alboaneen-Alqarni/b20b195c772a03a7deb4dd7fb970c810e8b21049",
            "/paper/Explainability-and-causability-in-digital-pathology-Plass-Kargl/98adae1da186b11df8fb0974e996ea3efb097d9d",
            "/paper/From-patterns-to-patients%3A-Advances-in-clinical-for-Swanson-Wu/095378dfef8d2c339af40ca6bfa648eddb210a2c",
            "/paper/Pathologist-Validation-of-a-Machine-Feature-for-L%E2%80%99Imperio-Wulczyn/2459ec3eb36bcdec26d9629bbbb557f4ad0a4a96",
            "/paper/Artificial-intelligence-fusion-for-predicting-of-of-Pham-Ravi/a1adf0cb57e72ff284727bb77669c58c95e7bbff",
            "/paper/Deep-learning-based-survival-prediction-for-cancer-Wulczyn-Steiner/9858f280a7e2d8fb1bdf08bf3a1ec79e4a9d8f41",
            "/paper/Predicting-survival-from-colorectal-cancer-slides-A-Kather-Krisam/a4eb7cc590b65e6be34fb74a4568d661385f28a2",
            "/paper/Deep-learning-based-tissue-analysis-predicts-in-Bychkov-Linder/39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "/paper/Deep-learning-for-prediction-of-colorectal-cancer-a-Skrede-Raedt/dcbc71903e272776777b8fe686c67779307700f2",
            "/paper/Deep-learning-based-classification-of-mesothelioma-Courtiol-Maussion/7f4d596e874cb83894e450bd375bbe731940e20f",
            "/paper/Predicting-non-small-cell-lung-cancer-prognosis-by-Yu-Zhang/94087ad5ed11555c260a42f2f9ca9da183c6f87e",
            "/paper/Predicting-cancer-outcomes-from-histology-and-using-Mobadersany-Yousefi/7b05161938f4e5f89ddd7ab7f432de8ecab1566e",
            "/paper/A-principled-machine-learning-framework-improves-of-Dimitriou-Arandjelovic/a4b8b1c6681528d3ad25a68638597bbd86b7b648",
            "/paper/Perineural-invasion-is-an-independent-predictor-of-Liebig-Ayala/4e6c052422f4a4ad92106fb5ad19e5337fc1b752",
            "/paper/Artificial-Intelligence-Based-Breast-Cancer-Nodal-Liu-Kohlberger/cfa3d45a6fcf704fe7ab6953424481d1698055a4"
        ]
    },
    {
        "id": "d29430adccb805ab57b349afa8553954347b3197",
        "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers",
        "abstract": "This paper deploys a pure transformer to encode an image as a sequence of patches, termed SEgmentation TRansformer (SETR), and shows that SETR achieves new state of the art on ADE20K, Pascal Context, and competitive results on Cityscapes. Most recent semantic segmentation methods adopt a fully-convolutional network (FCN) with an encoder-decoder architecture. The encoder progressively reduces the spatial resolution and learns more abstract/semantic visual concepts with larger receptive fields. Since context modeling is critical for segmentation, the latest efforts have been focused on increasing the receptive field, through either dilated/atrous convolutions or inserting attention modules. However, the encoder-decoder based FCN architecture remains unchanged. In this paper, we aim to provide an alternative perspective by treating semantic segmentation as a sequence-to-sequence prediction task. Specifically, we deploy a pure transformer (i.e., without convolution and resolution reduction) to encode an image as a sequence of patches. With the global context modeled in every layer of the transformer, this encoder can be combined with a simple decoder to provide a powerful segmentation model, termed SEgmentation TRansformer (SETR). Extensive experiments show that SETR achieves new state of the art on ADE20K (50.28% mIoU), Pascal Context (55.83% mIoU) and competitive results on Cityscapes. Particularly, we achieve the first position in the highly competitive ADE20K test server leaderboard on the day of submission.",
        "publication_year": "2020",
        "authors": [
            "Sixiao Zheng",
            "Jiachen Lu",
            "Hengshuang Zhao",
            "Xiatian Zhu",
            "Zekun Luo",
            "Yabiao Wang",
            "Yanwei Fu",
            "Jianfeng Feng",
            "T. Xiang",
            "Philip H. S. Torr",
            "Li Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "1,315",
        "reference_count": "64",
        "references": [
            "/paper/Feature-Selective-Transformer-for-Semantic-Image-Lin-Wu/63049ba1767693afe20c474ede9f891b376c630c",
            "/paper/Automatic-pixel-level-detection-of-tire-defects-on-Sun-Liu/79c75b66c6748bbe20ec101d7cd324948aae2df2",
            "/paper/SeaFormer%3A-Squeeze-enhanced-Axial-Transformer-for-Wan-Huang/11c3bcdf992ffbe00f213569ab996ff431ddf21b",
            "/paper/UperFormer%3A-A-Multi-scale-Transformer-based-Decoder-Xu-Shi/a80fa838a229f8473a5a4c063863b2e49001639b",
            "/paper/Graph-Reasoning-Transformer-for-Image-Parsing-Zhang-Tang/e9767464b82a0cf8899b7ee19e0b39a633f68d8d",
            "/paper/Dynamic-Graph-Message-Passing-Networks-Zhang-Chen/87297d4ae3aa78547c07b69ece13212338bffd41",
            "/paper/An-Access-Control-Method-with-Secret-Key-for-Models-Nagamori-Iijima/5725d6c141cef18ce062ea1e8867adfedc7d6c88",
            "/paper/Context-and-Apparent-Features-Aggregation-Network-Dong-Wang/87a7e598d4d2b7f6b168551fc92c5db70f64d0db",
            "/paper/Context-and-Boundary-Guided-Multi-Scale-Feature-for-Mi-Liang/e757a9ac30fdb650fa7b76afe448969d309dd873",
            "/paper/Multi-Scale-Transformer-with-Explicit-Boundary-for-Mi-Liang/d03508e98f61f08db51058019601261c80f988d6",
            "/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "/paper/The-Role-of-Context-for-Object-Detection-and-in-the-Mottaghi-Chen/3419ccd5c94d301ee08d716d037f0c3c6a62e78e",
            "/paper/Panoptic-DeepLab%3A-A-Simple%2C-Strong%2C-and-Fast-for-Cheng-Collins/ec86ce7f0139e9bb3af7bdf25cba45fbe2a5e93e",
            "/paper/Pyramid-Scene-Parsing-Network-Zhao-Shi/1031a69923b80ad01cf3fbb703d10757a80e699b",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/Panoptic-Feature-Pyramid-Networks-Kirillov-Girshick/a84906dbd4d6640f918d0b6ed2a7313dda0d55f1",
            "/paper/Non-local-Neural-Networks-Wang-Girshick/8899094797e82c5c185a0893896320ef77f60e64",
            "/paper/Attention-is-All-you-Need-Vaswani-Shazeer/204e3073870fae3d05bcbc2f6a8e263d9b72e776"
        ]
    },
    {
        "id": "1f55d35e1d1a148898a756cb0380b22fa8878dcb",
        "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
        "abstract": "A self-emphasizing network to emphasize informative spatial regions in a self-motivated way, with few extra computations and without additional expensive supervision, which achieves new state-of-the-art accuracy on four large-scale datasets. Hand and face play an important role in expressing sign language. Their features are usually especially leveraged to improve system performance. However, to effectively extract visual representations and capture trajectories for hands and face, previous methods always come at high computations with increased training complexity. They usually employ extra heavy pose-estimation networks to locate human body keypoints or rely on additional pre-extracted heatmaps for supervision. To relieve this problem, we propose a self-emphasizing network (SEN) to emphasize informative spatial regions in a self-motivated way, with few extra computations and without additional expensive supervision. Specifically, SEN first employs a lightweight subnetwork to incorporate local spatial-temporal features to identify informative regions, and then dynamically augment original features via attention maps. It's also observed that not all frames contribute equally to recognition. We present a temporal self-emphasizing module to adaptively emphasize those discriminative frames and suppress redundant ones. A comprehensive comparison with previous methods equipped with hand and face features demonstrates the superiority of our method, even though they always require huge computations and rely on expensive extra supervision. Remarkably, with few extra computations, SEN achieves new state-of-the-art accuracy on four large-scale datasets, PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. Visualizations verify the effects of SEN on emphasizing informative spatial and temporal features. Code is available at https://github.com/hulianyuyy/SEN_CSLR",
        "publication_year": "2022",
        "authors": [
            "Lianyu Hu",
            "Liqing Gao",
            "Zekang Liu",
            "Wei Feng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "43",
        "references": [
            "/paper/Conditional-Diffusion-Feature-Refinement-for-Sign-Guo-Xue/314e3cc058b0633a1ca228efa8c455534ed689ca",
            "/paper/Hand-Model-Aware-Sign-Language-Recognition-Hu-Zhou/832298578168aacc3fb1433296a63dbfa849ee4e",
            "/paper/C2SLR%3A-Consistency-enhanced-Continuous-Sign-Zuo-Mak/63399cd601e8f58a833c31d98d87a9c3c144041f",
            "/paper/Self-Mutual-Distillation-Learning-for-Continuous-Hao-Min/609d68085efa9b1da1068639e4850252cc0cf6ae",
            "/paper/SignBERT%3A-Pre-Training-of-Hand-Model-Aware-for-Sign-Hu-Zhao/39c6076a1284324282d6234c033ef1539c959039",
            "/paper/Pose-based-Sign-Language-Recognition-using-GCN-and-Tunga-Nuthalapati/2e0d7289231dc4b1cd822186690b426810da620b",
            "/paper/Fully-Convolutional-Networks-for-Continuous-Sign-Cheng-Yang/6af09da568edee80075ec610f431ffa91bfce061",
            "/paper/SF-Net%3A-Structured-Feature-Network-for-Continuous-Yang-Shi/bd712a873ae4eefb6c623c8e605e42c5a0173e3e",
            "/paper/Visual-Alignment-Constraint-for-Continuous-Sign-Min-Hao/2d2d5bb1d025c5e17abe13716599c93e1f131927",
            "/paper/Boosting-Continuous-Sign-Language-Recognition-via-Pu-Zhou/ce50fa888551b640fe3dddc57289c27f325c029b",
            "/paper/A-Deep-Neural-Framework-for-Continuous-Sign-by-Cui-Liu/f96ffd8c71b97e46eb3ba48263c9012d197494d4"
        ]
    },
    {
        "id": "08caef75e11e67712e7f71bd14d6baabf057b691",
        "title": "FreMAE: Fourier Transform Meets Masked Autoencoders for Medical Image Segmentation",
        "abstract": "This paper alters the perspective to the frequency domain and presents a new MIM-based framework named FreMAE for self-supervised pre-training for medical image segmentation, and incorporates multi-stage supervision to guide the representation learning during the pre- training phase. The research community has witnessed the powerful potential of self-supervised Masked Image Modeling (MIM), which enables the models capable of learning visual representation from unlabeled data. In this paper, to incorporate both the crucial global structural information and local details for dense prediction tasks, we alter the perspective to the frequency domain and present a new MIM-based framework named FreMAE for self-supervised pre-training for medical image segmentation. Based on the observations that the detailed structural information mainly lies in the high-frequency components and the high-level semantics are abundant in the low-frequency counterparts, we further incorporate multi-stage supervision to guide the representation learning during the pre-training phase. Extensive experiments on three benchmark datasets show the superior advantage of our proposed FreMAE over previous state-of-the-art MIM methods. Compared with various baselines trained from scratch, our FreMAE could consistently bring considerable improvements to the model performance. To the best our knowledge, this is the first attempt towards MIM with Fourier Transform in medical image segmentation.",
        "publication_year": "2023",
        "authors": [
            "Wenxuan Wang",
            "J. Wang",
            "Chen Chen",
            "Jianbo Jiao",
            "Lichao Sun",
            "Yuanxiu Cai",
            "Shanshan Song",
            "Jiangyun Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "50",
        "references": [
            "/paper/Unsupervised-Anomaly-Detection-in-Medical-Images-Iqbal-Khalid/a77ca914695d2989aec40b9d85351b2b021ffa6f",
            "/paper/Self-Pre-training-with-Masked-Autoencoders-for-Zhou-Liu/f203f52c0f4151b89f0a1797c6be750b64af0a02",
            "/paper/Attentive-Symmetric-Autoencoder-for-Brain-MRI-Huang-Li/73f9d37cf8bd4f2bbcf35ab542d32b53804c1b5f",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/TransBTSV2%3A-Wider-Instead-of-Deeper-Transformer-for-Li-Wang/d8efe29581a4a476c567188752faa00b0b6a27f2",
            "/paper/Swin-Unet%3A-Unet-like-Pure-Transformer-for-Medical-Cao-Wang/ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "/paper/Self-Supervised-Pre-Training-of-Swin-Transformers-Tang-Yang/076a8e778f2e9efb3c2fd45fed534ae9e6035f1b",
            "/paper/Siamese-Image-Modeling-for-Self-Supervised-Vision-Tao-Zhu/a2c5e2f70e6441430cf48232da815e0d00653467",
            "/paper/UNETR%3A-Transformers-for-3D-Medical-Image-Hatamizadeh-Yang/7519a1e9e7371df79bd8a21cee871feb0ec597a5",
            "/paper/CPFNet%3A-Context-Pyramid-Fusion-Network-for-Medical-Feng-Zhao/937253956dc6ab942764c13ab1a132238740d5b3",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf"
        ]
    },
    {
        "id": "907d6d24ddf4a74491f611be6fb57fd102c6d9b0",
        "title": "A U-Net Deep Learning Framework for High Performance Vessel Segmentation in Patients With Cerebrovascular Disease",
        "abstract": "The U-net framework was optimized and evaluated with three metrics: Dice coefficient, 95% Hausdorff distance (95HD) and average Hausdorf distance (AVD) and revealed excellent performance in large vessels and sufficient performance in small vessels. Brain vessel status is a promising biomarker for better prevention and treatment in cerebrovascular disease. However, classic rule-based vessel segmentation algorithms need to be hand-crafted and are insufficiently validated. A specialized deep learning method\u2014the U-net\u2014is a promising alternative. Using labeled data from 66 patients with cerebrovascular disease, the U-net framework was optimized and evaluated with three metrics: Dice coefficient, 95% Hausdorff distance (95HD) and average Hausdorff distance (AVD). The model performance was compared with the traditional segmentation method of graph-cuts. Training and reconstruction was performed using 2D patches. A full and a reduced architecture with less parameters were trained. We performed both quantitative and qualitative analyses. The U-net models yielded high performance for both the full and the reduced architecture: A Dice value of ~0.88, a 95HD of ~47 voxels and an AVD of ~0.4 voxels. The visual analysis revealed excellent performance in large vessels and sufficient performance in small vessels. Pathologies like cortical laminar necrosis and a rete mirabile led to limited segmentation performance in few patients. The U-net outperfomed the traditional graph-cuts method (Dice ~0.76, 95HD ~59, AVD ~1.97). Our work highly encourages the development of clinically applicable segmentation tools based on deep learning. Future works should focus on improved segmentation of small vessels and methodologies to deal with specific pathologies.",
        "publication_year": "2019",
        "authors": [
            "Michelle Livne",
            "J. Rieger",
            "O. U. Aydin",
            "A. Taha",
            "E. M. Akay",
            "T. Kossen",
            "J. Sobesky",
            "John D. Kelleher",
            "Kristian Hildebrand",
            "D. Frey",
            "V. Madai"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "147",
        "reference_count": "44",
        "references": [
            "/paper/BRAVE-NET%3A-Fully-Automated-Arterial-Brain-Vessel-in-Hilbert-Madai/8654c84f172e436081a973f1b500e4ac449a0bc0",
            "/paper/Automatic-Segmentation-of-Cerebrovascular-Based-on-Min-Nie/3eecfcdc29ba47730e3cf84caa837e380bf647e2",
            "/paper/Automatic-cerebral-vessel-extraction-in-TOF-MRA-Vos-Timmins/5b19a2bf6c98444dac40f17710861cd2391a20ee",
            "/paper/Dual-U-Net-Based-Conditional-Generative-Adversarial-Quintana-Quintana-Le%C3%B3n-Cuevas/7ee90290f67f014092fe6fc58ff5571e6539ab7c",
            "/paper/DS6%2C-Deformation-Aware-Semi-Supervised-Learning%3A-to-Chatterjee-Mattern/b9c4a09f00c17c65605387e3d2a9f1dbaddc6c4c",
            "/paper/Multi-resolution-CNN-for-brain-vessel-segmentation-Patel-Paliwal/636caf10552e22e855ddd1855a55a6036267891c",
            "/paper/Automated-Cerebral-Vessel-Segmentation-of-Magnetic-Patel-Pint%C3%A9r/19a9461fc7f4289eb8d7d306c0f8fdbffceb1f3a",
            "/paper/Cerebrovascular-segmentation-from-TOF-MRA-based-on-Guo-Xiao/309f2d7ee3c973fec5eca019a3cd600ff9382fab",
            "/paper/Novel-dataset-and-evaluation-of-state-of-the-art-Bizjak-Chien/b9450c4eb65b73a1ab384ba6abd6adab6a767304",
            "/paper/Spider-U-Net%3A-Incorporating-Inter-Slice-Using-LSTM-Lee-Sunwoo/831644f7cbd6bedc2caccf6a252a5c4a62b28a6b",
            "/paper/Vascular-Segmentation-in-TOF-MRA-Images-of-the-a-Phellan-Peixinho/46f9886e62fd80ad5976cc4ab3649c31f26edfeb",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/Robust-Segmentation-of-the-Full-Cerebral-in-4D-CT-Meijs-Patel/fb5c4bf41fd879c9c64028a817db7f7ab6aba429",
            "/paper/DeepVesselNet%3A-Vessel-Segmentation%2C-Centerline-and-Tetteh-Efremov/678d7db924485754f726c1049dd0c49961f26b32",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Robust-liver-vessel-extraction-using-3D-U-Net-with-Huang-Sun/0485745f7470856427b76abe2b68797b9e2a8bd1",
            "/paper/Use-of-2D-U-Net-Convolutional-Neural-Networks-for-Norman-Pedoia/6e5865bb00875421c5cdfdc36f0ff7c5dc35995c",
            "/paper/3D-intracranial-artery-segmentation-using-a-Chen-Xie/0d3b81307e123cdf77eef35b2158f5392fc9bafe",
            "/paper/A-review-of-3D-vessel-lumen-segmentation-Models%2C-Lesage-Angelini/294dd05a7c0077d33936b89f7c918967a622762f",
            "/paper/Prediction-of-Tissue-Outcome-and-Assessment-of-in-Nielsen-Hansen/6dcd3a79802def26242d28103c36da123748c193"
        ]
    },
    {
        "id": "f887e72876126a010587098dca682084c08e968e",
        "title": "Long-Term Quality of Life of Vestibular Schwannoma Patients: A Longitudinal Analysis.",
        "abstract": "On average, the long-term QoL of patients with vestibular schwannoma is comparable for patients under active surveillance and those who have received active treatment, and it remains stable over time, which suggests that, on average, preservation of quality of life (QoL) of Patients with Vestibular Schwannomas is feasible when adequately managed. OBJECTIVE\nVestibular schwannoma management aims to maintain optimal quality of life (QoL) while preventing severe sequelae of the tumor or its treatment. This study assessed long-term QoL of patients with vestibular schwannoma in relation to treatment modality and decisional regret.\n\n\nSTUDY DESIGN\nA longitudinal study, in which clinical and QoL data were used that were cross-sectionally acquired in 2014 and again in 2020 from the same patient group.\n\n\nSETTING\nA tertiary expert center for vestibular schwannoma care in the Netherlands.\n\n\nMETHODS\nQoL was measured by the Penn Acoustic Quality of Life (PANQOL) scale. Changes in time were assed using a linear mixed model. In addition, the Decision Regret Scale was analyzed.\n\n\nRESULTS\nOf 867 patients, 536 responded (62%), with a median follow-up of 11 years. All PANQOL subdomain scores remained stable over time and did not exceed minimal clinically important difference (MCID) levels. Time since treatment did not affect QoL. Patients had comparable average QoL scores and proportions of patients with changing QoL scores (ie, exceeding the MCID) over time, irrespective of the received initial treatment. Female patients and those who required salvage therapy (either by radiotherapy or surgery) reported a lower QoL. The latter patient group reported the highest decisional regret.\n\n\nCONCLUSION\nOn average, the long-term QoL of patients with vestibular schwannoma is comparable for patients under active surveillance and those who have received active treatment, and it remains stable over time. This suggests that, on average, preservation of QoL of patients with vestibular schwannoma is feasible when adequately managed.",
        "publication_year": "2022",
        "authors": [
            "O. M. Neve",
            "J. Jansen",
            "R. Koot",
            "M. Ridder",
            "Peter Paul G van Benthem",
            "A. Stiggelbout",
            "E. Hensen"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "3",
        "reference_count": "17",
        "references": [
            "/paper/Vestibular-Complaints-Impact-on-the-Long-Term-of-of-Fuentealba-Bassaletti-Neve/16713ba75cf3e5f4e21aef525f5ff6f77093c52c",
            "/paper/Quality-of-Life-in-Sporadic-Vestibular-Schwannoma.-Marinelli-Lohse/52e60c68f376cbedb5e360b4f5b6246b2e29e836",
            "/paper/Decision-Making-for-Active-Surveillance-in-Smith-Odeh/a8ff37f4afa542e62292fcefa92262bce84d1c92",
            "/paper/Quality-of-Life-in-807-Patients-with-Vestibular-Soulier-Leeuwen/aa88fa15f92cdd413c481162b7cad303acd8dc4c",
            "/paper/Comparison-of-Long-term-Quality-of-Life-Outcomes-in-Robinett-Walz/40698b032912d301afa310e05e5b7409a6dd3660",
            "/paper/Longitudinal-Changes-of-Quality-of-Life-and-Hearing-Windisch-Tonn/6c1bd115932d1737e42b6bb490211ec7d2891f52",
            "/paper/Defining-the-Minimal-Clinically-Important-for-With-Kerezoudis-Yost/ed1f9048c96946ebb6ae519015cd8b362af885ea",
            "/paper/Patient-quality-of-life-after-vestibular-schwannoma-Kristin-Glaas/50bf12f18af0010afe49c7bed0ad4b30ed9804f6",
            "/paper/The-impact-of-acoustic-neuroma-on-long-term-in-the-Lodder-Laan/e3b1c30aef1d6aeacee20db4b33803b711283788",
            "/paper/Patient-Motivation-and-Long-Term-Satisfaction-with-Carlson-Tveiten/b2037db084893c7a96a79a14ddc6bcc81ed6e394",
            "/paper/Patient-reported-factors-that-influence-the-a-study-Neve-Soulier/e58c15a33806c7e4ac80cbdbd35c53d48f96e886",
            "/paper/What-drives-quality-of-life-in-patients-with-Carlson-Tveiten/e66b0b6ce08deff805885c75afccd6c4a5628e23",
            "/paper/Understanding-sex-differences-in-health-related-of-Pettersen-Reikvam/1c62d4bea6e2a11a1585b21d06f8aa2ee786ed10"
        ]
    },
    {
        "id": "f9282d8871dd3d87a002ffd6e38eefff65978128",
        "title": "Minimizing Labeling Cost for Nuclei Instance Segmentation and Classification with Cross-domain Images and Weak Labels",
        "abstract": "A novel application that considers each cancer type as an individual domain and apply domain adaptation techniques to improve the segmentation/classification performance among different cancer types is proposed. Nucleus instance segmentation and classification in histopathological images is an essential prerequisite in pathology diagnosis/prognosis. However, nucleus annotations (e.g., segmentation and labeling) require domain experts, and annotating nuclei at pixel-level is time-consuming and labor-intensive. Moreover, nuclei from different cancer types vary in shapes and appearances. These inter-cancer variations require careful annotations for specific cancer types. Therefore, to minimize the labeling cost, we propose a novel application that considers each cancer type as an individual domain and apply domain adaptation techniques to improve the segmentation/classification performance among different cancer types. Unlike the previous studies that focus on unsupervised or weakly-supervised domain adaptation independently, we would like to discover what kinds of labeling can achieve the most cost-effective domain adaptation performance in nucleus instance segmentation and classification. Specifically, we propose a unified framework that is applicable to different level annotations: no annotations, image-level, and point-level annotations. Cyclic adaptation with pseudo labels and adversarial discriminator are utilized for unsupervised domain alignment. Image-level or point-level annotations are additionally adopted to supervise the nucleus classification and refine the pseudo labels. Experiments demonstrate the effectiveness and efficacy of the proposed framework (jointly using unsupervised and weakly supervised learning) on adapting the segmentation and classification model from one cancer type to 18 other cancer types.",
        "publication_year": "2021",
        "authors": [
            "Siqi Yang",
            "Jun Zhang",
            "Junzhou Huang",
            "B. Lovell",
            "Xiao Han"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "57",
        "references": [
            "/paper/Cyclic-Learning%3A-Bridging-Image-level-Labels-and-Zhou-Wu/ea1e445e610822786ee7322885edfec66dfe421b",
            "/paper/Domain-Adaptive-Nuclei-Instance-Segmentation-and-Li-Liu/66731f14a22a11b1467297e6b1fcedb50ec1377a",
            "/paper/NuSegDA%3A-Domain-adaptation-for-nuclei-segmentation-Haq-Ma/9f32ec899ce4078597a4a72118cb81b6b5e25ea4",
            "/paper/MaNi%3A-Maximizing-Mutual-Information-for-Nuclei-Sharma-Syed/3204034db9687dcf7e7fb1931ac5482639cecd72",
            "/paper/Weakly-Supervised-Nuclei-Segmentation-Via-Instance-Liu-He/41d93b3a5740fc48af22d1d6043b759a1ee9e5be",
            "/paper/Learning-to-Model-Pixel-Embedded-Affinity-for-Huang-Deng/eb8348f95373bb6c391ef55417fb32b348b892c1",
            "/paper/CellTranspose%3A-Few-shot-Domain-Adaptation-for-Keaton-Zaveri/729d7ccc0054a5c56e3e6d774d31d11b587288ac",
            "/paper/Weakly-Supervised-Nucleus-Segmentation-Based-on-A-Tian-Zhang/2af96daa1456fdb2a004f62a3fa28986e76e7fa4",
            "/paper/PseudoEdgeNet%3A-Nuclei-Segmentation-only-with-Point-Yoo-Yoo/8500d2883a31e2aae12bcaa4cdf6b13df84419a0",
            "/paper/Unsupervised-Instance-Segmentation-in-Microscopy-Liu-Zhang/974ffaf2775a8c32e405c551436a111714a5dc3c",
            "/paper/Semantic-Transferable-Weakly-Supervised-Endoscopic-Dong-Cong/56d0b88ffe62467ed5b8dc6fd36e081454682d75",
            "/paper/Weakly-Supervised-Deep-Nuclei-Segmentation-using-in-Qu-Wu/2b60f01e916725a8f0b5dddc44b4cb9bd3e5e8c3",
            "/paper/Domain-Adaptive-Semantic-Segmentation-Using-Weak-Paul-Tsai/9d528f6d0f4a1f17683d07e8e80d93a896c663fb",
            "/paper/Hover-Net%3A-Simultaneous-segmentation-and-of-nuclei-Graham-Vu/5986547c7380f5a8fb6028093f827b3662f838a2",
            "/paper/PanNuke%3A-An-Open-Pan-Cancer-Histology-Dataset-for-Gamper-Koohbanani/b218b13756f3aacadf5f06d09652058d024dc9d4",
            "/paper/Epithelium-Stroma-Classification-via-Convolutional-Huang-Zheng/a791277cd596d68a293386dca660a576776cec13",
            "/paper/From-image-level-to-pixel-level-labeling-with-Pinheiro-Collobert/d46bc623f5eecb44c5a053587f841dac5cc9b743"
        ]
    },
    {
        "id": "5f1e6b38d476773bebd09e15a7c8f7bffde66674",
        "title": "CSI-Based Wireless Localization and Activity Recognition Using Support Vector Machine",
        "abstract": "A new activity recognition and localization algorithm using channel state information (CSI) measurement is proposed, using the SVM technique for activity based classification learning and position based regression learning. With the development of the information technology, human activity recognition and localization has received much attentions, since they can be utilized in many fields. In this paper, a new activity recognition and localization algorithm using channel state information (CSI) measurement is proposed. The problem of activity recognition and localization are formulated as the problem of machine learning which are solve with the support vector machine (SVM) approach. In the off-line phase, after the data normalization and principal component analysis (PCA) preprocessing of the CSI measurements, the (CSI measurement, label of activity) training data set and the (CSI measurement, position information) training data set for each activity can be formed. The SVM technique are utilized for activity based classification learning and position based regression learning. At last, the activity classification function and position regression function are obtained. In the on-line phase, after the data preprocessing of the received CSI measurements, the activity is estimated by the activity classification function at first. Then, the position regression function correspond to the estimated activity result is chosen for position estimation. Experimental results illustrated the activity recognition and localization performance of the proposed algorithm.",
        "publication_year": "2019",
        "authors": [
            "Kang Wu",
            "Mengwei Yang",
            "Chuanhui Ma",
            "Jun Yan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "6",
        "reference_count": "20",
        "references": [
            "/paper/Multidimensional-Information-Recognition-Algorithm-Tian-Chen/d875b9eb9fc89a8ceeabdd195820f0f137cb3c5f",
            "/paper/Human-Activity-Recognition-Based-on-CSI-fragment-Chen-Zhang/61c235074fad55fadf3d84043ac5f47e6947d3f7",
            "/paper/A-Comprehensive-Survey-of-Machine-Learning-Based-Burghal-Ravi/00c941f2f6b1e5180a6ad2823046e30241de6113",
            "/paper/A-Survey-of-Machine-Learning-in-Pedestrian-Systems%3A-Miram%C3%A1-D%C3%ADez/7168d1dcf7f6d0020c3329ab3a12c27af69914dd",
            "/paper/Joint-activity-recognition-and-indoor-localization-Yan-Cheng/a895cdbdab009e7cca74676df83cf4cf1f0778e6",
            "/paper/Applications-of-RSSI-Preprocessing-in-Multi-Domain-Sarsodia-Bhatt/532ce2b97ba81e8017f6d581a03107ad946a65ec",
            "/paper/CSI-Based-Device-Free-Wireless-Localization-and-Gao-Wang/6c1bd2f72daaee0136f605a43ae21a08de48421b",
            "/paper/Device-Free-Presence-Detection-and-Localization-SVM-Zhou-Lu/9b78914473d445868b1ec76a3efc5d1aa2aac685",
            "/paper/Device-Free-Wireless-Localization-and-Activity-A-Wang-Zhang/29f4a957802fa54c5e23a170121e46f5f1e7a49b",
            "/paper/An-Improved-CSI-Based-Device-Free-Indoor-Using-Sanam-Godrich/af8b44eb60e136b625eb500d97d6f0a7e4c52990",
            "/paper/Literature-Review-on-Wireless-Sensing%E2%80%94Wi-Fi-of-Wang-Chen/3b60d6920cc5bc7b3ebe48630cb40436aae6839f",
            "/paper/Improving-the-accuracy-of-complex-activities-using-Mobark-Chuprat/63564b066baf1b31daac5f8d1463d847d42bfc55",
            "/paper/Pilot%3A-Passive-Device-Free-Indoor-Localization-Xiao-Wu/db692f7c9250d4478f4040860e087715a96a43f5",
            "/paper/A-Closed-Form-Localization-Algorithm-Using-and-Time-Li-Li/cc7e1d84cc8f69a1135737bd6b16f8b40a8417b3",
            "/paper/Comparative-Analysis-of-Approximate-Point-in-(APIT)-Anthrayose-Payal/1902736a8fab704f34cf52a48486d099b287a70a",
            "/paper/Achieving-privacy-preservation-in-WiFi-localization-Li-Sun/0766511167faf980a42d2dc438244b421088ef00"
        ]
    },
    {
        "id": "355b4e74774798c177c82943eef925d66a2bb2ce",
        "title": "A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes",
        "abstract": "A novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a one-class classifier, and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods. How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations\u2019 diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.",
        "publication_year": "2020",
        "authors": [
            "Peng Wu",
            "Jing Liu",
            "Fang Shen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "94",
        "reference_count": "59",
        "references": [
            "/paper/SLSG%3A-Industrial-Image-Anomaly-Detection-by-Better-Yang-Liu/5c04ce7f8510af40f2931535feeaf220832ab548",
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/Ano-Graph%3A-Learning-Normal-Scene-Contextual-Graphs-PourReza-Salehi/12ebe64bf81b85b2331875895bd3a2b5978dabd8",
            "/paper/Review-on-Deep-Learning-Approaches-for-Anomaly-in-Jebur-Hussein/a469cb515cd9a2e1923a7a9b3b3fca3690881b19",
            "/paper/Unsupervised-video-anomaly-detection-via-flows-with-Cho-Kim/e4b4349d19124be609622b75585d158055c1a0b3",
            "/paper/A-Self-Trained-Spatial-Graph-Convolutional-Network-Li-Chang/dbe1eb127c20920eaaa66d642098be26684930d4",
            "/paper/Anomaly-Detection-in-Video-via-Self-Supervised-and-Georgescu-B%C4%83rb%C4%83l%C4%83u/57b2198f9a8df773425aa6cc88c9870cb07779e2",
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "/paper/Unsupervised-Deep-One-Class-Classification-with-on-Kim-Kim/1c825f19567fe421ac81a760ac84898b6849063d",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/Learning-Deep-Features-for-One-Class-Classification-Perera-Patel/732c21998e251d64cd58b6a86886ee5907efeaa5",
            "/paper/Detecting-anomalous-events-in-videos-by-learning-of-Xu-Yan/e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/Object-Detection-With-Deep-Learning%3A-A-Review-Zhao-Zheng/7998468d99ab07bb982294d1c9b53a3bf3934fa6",
            "/paper/Deep-Appearance-Features-for-Abnormal-Behavior-in-Smeureanu-Ionescu/992847be33f4bf7afbe66e198cb20a53e00dfa76",
            "/paper/Deep-Learning-with-a-Spatiotemporal-Descriptor-of-Gunale-Mukherji/e98adbecca61777bf4a2789715f156f55af3091f",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "/paper/A-Revisit-of-Sparse-Coding-Based-Anomaly-Detection-Luo-Liu/99dff291f260b3cc3ff190106b0c2e3e685223a4",
            "/paper/Real-World-Anomaly-Detection-in-Surveillance-Videos-Sultani-Chen/598fe25743f9492c5c1ba30274ea446f65426d85"
        ]
    },
    {
        "id": "09c958fa8e755ccb5a5f2ca22f9834e7e0a045ff",
        "title": "HVNet: Hybrid Voxel Network for LiDAR Based 3D Object Detection",
        "abstract": "An attentive voxel feature encoding that outperforms plain VFE and a feature fusion pyramid network to aggregate multi-scale information at feature map level and project into multiple pseudo-image feature maps are proposed. We present Hybrid Voxel Network (HVNet), a novel one-stage unified network for point cloud based 3D object detection for autonomous driving. Recent studies show that 2D voxelization with per voxel PointNet style feature extractor leads to accurate and efficient detector for large 3D scenes. Since the size of the feature map determines the computation and memory cost, the size of the voxel becomes a parameter that is hard to balance. A smaller voxel size gives a better performance, especially for small objects, but a longer inference time. A larger voxel can cover the same area with a smaller feature map, but fails to capture intricate features and accurate location for smaller objects. We present a Hybrid Voxel network that solves this problem by fusing voxel feature encoder (VFE) of different scales at point-wise level and project into multiple pseudo-image feature maps. We further propose an attentive voxel feature encoding that outperforms plain VFE and a feature fusion pyramid network to aggregate multi-scale information at feature map level. Experiments on the KITTI benchmark show that a single HVNet achieves the best mAP among all existing methods with a real time inference speed of 31Hz.",
        "publication_year": "2020",
        "authors": [
            "Maosheng Ye",
            "Shuangjie Xu",
            "Tongyi Cao"
        ],
        "related_topics": [
            "Computer Science",
            "Physics"
        ],
        "citation_count": "119",
        "reference_count": "36",
        "references": [
            "/paper/DVFENet%3A-Dual-branch-voxel-feature-extraction-for-He-Xia/fb675e55eb7abe9be5009fa57d0114a85f324afc",
            "/paper/HVPR%3A-Hybrid-Voxel-Point-Representation-for-3D-Noh-Lee/61502aa4665add575eced99ccd159758ad5a8c4b",
            "/paper/VS-Net%3A-A-Voxel-Encoding-and-Sparse-Convolution-for-Liu-Niu/f0a32283217a78ada5d5dc42e0317d15eafd96d6",
            "/paper/VPFusion%3A-Towards-Robust-Vertical-Representation-3D-Huang-Zhou/e4a5c0e4827c0738e834d8f1529e7fe96360c49b",
            "/paper/CBi-GNN%3A-Cross-Scale-Bilateral-Graph-Neural-Network-Chen-Li/7d27fc8ff82ac6ad7ad3c2e5f57ae2bb4220e340",
            "/paper/Voxel-Transformer-for-3D-Object-Detection-Mao-Xue/813b03e123d448d53d93a087a2d34a04dfe70c5c",
            "/paper/Voxel-R-CNN%3A-Towards-High-Performance-Voxel-based-Deng-Shi/e216ac339cbb4a8accdc266be8f26b554c37a284",
            "/paper/Dense-Voxel-Fusion-for-3D-Object-Detection-Mahmoud-Hu/4e158d089924e1c7fd184026cc868a49fe9bd579",
            "/paper/PV-RCNN%2B%2B%3A-Point-Voxel-Feature-Set-Abstraction-With-Shi-Jiang/3c3fe084caa8fd3798c1ae1a48909b9eb2d4dc5f",
            "/paper/PV-RCNN%2B%2B%3A-semantical-point-voxel-feature-for-3D-Wu-Gu/06fff0d2ef35ab2b662cdd325993da127d3b9f96",
            "/paper/VoxelNet%3A-End-to-End-Learning-for-Point-Cloud-Based-Zhou-Tuzel/80f5ee8578ee76e2c17824f211762ffec7e029d4",
            "/paper/Voxel-FPN%3A-multi-scale-voxel-feature-aggregation-in-Wang-An/2ba1ca08540b77c7b5c4318e989050774aaca8d2",
            "/paper/Multi-view-3D-Object-Detection-Network-for-Driving-Chen-Ma/dc200ab22bf63e10e8b2af328a9e072d82cf75b7",
            "/paper/Joint-3D-Proposal-Generation-and-Object-Detection-Ku-Mozifian/675784f097dbf87cd75a5640019d4469e7bd7905",
            "/paper/End-to-End-Multi-View-Fusion-for-3D-Object-in-LiDAR-Zhou-Sun/b63b861cb907331dfd5d7dbfbb0a1563f25f2c5a",
            "/paper/STD%3A-Sparse-to-Dense-3D-Object-Detector-for-Point-Yang-Sun/f23bf58437140927ee7b2107597568e23a398ba1",
            "/paper/PointRCNN%3A-3D-Object-Proposal-Generation-and-From-Shi-Wang/7ce6eca495909de2ffa0b6d9c16993757208764e",
            "/paper/Fast-Point-R-CNN-Chen-Liu/ffaaf30b1013352ebccf81d924f351863dbc2025",
            "/paper/PIXOR%3A-Real-time-3D-Object-Detection-from-Point-Yang-Luo/2bcfce1e68e9adb5f1547307e66a7b23c16d319a",
            "/paper/HDNET%3A-Exploiting-HD-Maps-for-3D-Object-Detection-Yang-Liang/bcfe57e2d05648c7ace15f3e96bb899b3fa262f2"
        ]
    },
    {
        "id": "6af440915b8a0718c93be1cf61905e41e620484a",
        "title": "Deep One-Class Classification",
        "abstract": "This paper introduces a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective and shows the effectiveness of the method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs. Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective. In this paper we introduce a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs.",
        "publication_year": "2018",
        "authors": [
            "Lukas Ruff",
            "Nico G\u00f6rnitz",
            "Lucas Deecke",
            "Shoaib Ahmed Siddiqui",
            "Robert A. Vandermeulen",
            "Alexander Binder",
            "Emmanuel M\u00fcller",
            "M. Kloft"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "1,096",
        "reference_count": "55",
        "references": [
            "/paper/Anomaly-Detection-by-One-Class-Latent-Regularized-Chen-Chen/a17a7926dc5ec33a36e0a3f1eda86a1404f458cd",
            "/paper/Image-Anomaly-Detection-with-Generative-Adversarial-Deecke-Vandermeulen/3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "/paper/Double-Adversarial-Activation-Anomaly-Detection%3A-Schulze-Sperl/ba1d8720d23d467fc44d6adae9c7216b815b6281",
            "/paper/Solving-Challenges-in-Deep-Unsupervised-Methods-for-Khazaie/98d1178c5190c73e70770c5c87b9bbcc1a0e9eae",
            "/paper/Anomaly-Detection-by-Latent-Regularized-Dual-Chen-Chen/06f565d668b77fb4cd228d497b86d70a44ca44e7",
            "/paper/Deep-Domain-Adversarial-Anomaly-Detection-With-Mao-Wang/099312ed4588644287364363e0d4b209895bdb13",
            "/paper/Supervised-Anomaly-Detection-via-Conditional-and-Chen-Duan/d094c10a596308130258f4fbd786ac132577b0e7",
            "/paper/Unsupervised-anomaly-detection-with-adversarial-Somepalli-Wu/4b83e9a048e677ff9fab226e8f7fbaa33fd32024",
            "/paper/Anomaly-Detection-with-Adversarially-Learned-of-Khazaie-Wong/2c487159d7d712c195449f9a5fa77419c9d700e6",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078",
            "/paper/Explaining-and-Harnessing-Adversarial-Examples-Goodfellow-Shlens/bee044c8e8903fb67523c1f8c105ab4718600cdb",
            "/paper/High-dimensional-and-large-scale-anomaly-detection-Erfani-Rajasegarar/f076e4355c0facf111716dcab2837803367dd2d8",
            "/paper/Fully-Convolutional-Neural-Network-for-Fast-Anomaly-Sabokrou-Fayyaz/8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6",
            "/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214",
            "/paper/Decision-Based-Adversarial-Attacks%3A-Reliable-Models-Brendel-Rauber/1b225474e7a5794f98cdfbde8b12ccbc56799409",
            "/paper/Stacked-Denoising-Autoencoders%3A-Learning-Useful-in-Vincent-Larochelle/e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "/paper/Extracting-and-composing-robust-features-with-Vincent-Larochelle/843959ffdccf31c6694d135fad07425924f785b1",
            "/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/abd1c342495432171beb7ca8fd9551ef13cbd0ff"
        ]
    },
    {
        "id": "14156438bafed28a626738630b5181b83ed5d79c",
        "title": "Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters",
        "abstract": "This paper introduces two types of camouflages based on recent empirical studies, i.e., the feature camouflage and the relation camouflage and proposes a new model named CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation process with three unique modules against camouflages. Graph Neural Networks (GNNs) have been widely applied to fraud detection problems in recent years, revealing the suspiciousness of nodes by aggregating their neighborhood information via different relations. However, few prior works have noticed the camouflage behavior of fraudsters, which could hamper the performance of GNN-based fraud detectors during the aggregation process. In this paper, we introduce two types of camouflages based on recent empirical studies, i.e., the feature camouflage and the relation camouflage. Existing GNNs have not addressed these two camouflages, which results in their poor performance in fraud detection problems. Alternatively, we propose a new model named CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation process with three unique modules against camouflages. Concretely, we first devise a label-aware similarity measure to find informative neighboring nodes. Then, we leverage reinforcement learning (RL) to find the optimal amounts of neighbors to be selected. Finally, the selected neighbors across different relations are aggregated together. Comprehensive experiments on two real-world fraud datasets demonstrate the effectiveness of the RL algorithm. The proposed CARE-GNN also outperforms state-of-the-art GNNs and GNN-based fraud detectors. We integrate all GNN-based fraud detectors as an opensource toolbox https://github.com/safe-graph/DGFraud. The CARE-GNN code and datasets are available at https://github.com/YingtongDou/CARE-GNN.",
        "publication_year": "2020",
        "authors": [
            "Yingtong Dou",
            "Zhiwei Liu",
            "Li Sun",
            "Yutong Deng",
            "Hao Peng",
            "Philip S. Yu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "155",
        "reference_count": "53",
        "references": [
            "/paper/Improving-Fraud-Detection-via-Hierarchical-Graph-Liu-Sun/320c6bf28a2a8e2cab7aa7b491708b522f99a4b6",
            "/paper/CGDF-GNN%3A-Cascaded-GNN-fraud-detector-with-dual-Wan-Wang/71347530f0c343e0e5e2402f9d9c514e3f7524e5",
            "/paper/Dual-Augment-Graph-Neural-Network-for-Fraud-Li-He/8ae96115d2af72677fd65d06c402452c49f0eb72",
            "/paper/Label-Information-Enhanced-Fraud-Detection-against-Wang-Zhang/a73137f4c21e2fb1845d5f50dc7bf286036a8b67",
            "/paper/RLC-GNN%3A-An-Improved-Deep-Architecture-for-Graph-to-Zeng-Tang/07d8705dcf2ec1ecf35d680c80e6bef519ca967b",
            "/paper/Improved-Aggregating-and-Accelerating-Training-for-Zeng-Tang/bd76a4d60647eb1b77e90ecb7a457f808f67f5d1",
            "/paper/The-Devil-is-in-the-Conflict%3A-Disentangled-Graph-Li-Chen/6955237f5d604251e6156562da1e43fb7332430a",
            "/paper/Pick-and-Choose%3A-A-GNN-based-Imbalanced-Learning-Liu-Ao/7487499f91f0c198347a8ebc747ad8d220bdd155",
            "/paper/Bi-Level-Selection-via-Meta-Gradient-for-Fraud-Dong-Liu/75876006c7b54626677c62896f79ced54af40c6d",
            "/paper/Explainable-Graph-based-Fraud-Detection-via-Neural-Qin-Liu/5b50aa69dc0eddc552aa43f7e96504479651275b",
            "/paper/Alleviating-the-Inconsistency-Problem-of-Applying-Liu-Dou/8cf8e7fe56f26e9e811cf409e1ceeb7c9d7fb60b",
            "/paper/Deep-Structure-Learning-for-Fraud-Detection-Wang-Zhou/f818d937724469aaf301243bd6bc7526f4c7f6c9",
            "/paper/A-Semi-Supervised-Graph-Attentive-Network-for-Fraud-Wang-Qi/0353c467cb380025d8ef927996436b8e9cfedccc",
            "/paper/ASA%3A-Adversary-Situation-Awareness-via-Graph-Wen-Wang/8f80fcc31071d056e91c66e504823bb1f4639a82",
            "/paper/FdGars%3A-Fraudster-Detection-via-Graph-Convolutional-Wang-Wen/3bfdb516a68eced068701ac6ade535300da1d2f5",
            "/paper/Heterogeneous-Graph-Neural-Networks-for-Malicious-Liu-Chen/a5b5dde1da8ac8d9247a32172f76d5d1831309a0",
            "/paper/Spam-Review-Detection-with-Graph-Convolutional-Li-Qin/69813821ea86d630a4e63f65ef1030f799662410",
            "/paper/Label-Aware-Graph-Convolutional-Network-Not-All-Chen-Wang/e5796f483f48f26d517aebe6b5de26cff84b190a",
            "/paper/Rumor-Detection-on-Social-Media-with-Graph-Learning-Yang-Lyu/83f83990e39758f58aa8819cddf86c5ace6bfcf5",
            "/paper/Label-Aware-Graph-Convolutional-Networks-Chen-Xu/832dbadab16629f6811b91ed8646403af2f43c0d"
        ]
    },
    {
        "id": "06a0ecac6c017a543982d7010cba7f925d4b6815",
        "title": "Automated surface defect detection framework using machine vision and convolutional neural networks",
        "abstract": "An image-based framework considering pre-trained Convolutional Neural Network, ResNet-101 to detect surface defects with the minimum training datasets and computational requirements is developed and testing trials demonstrate that the proposed framework effectively performs image classification, achieving 100% precision for the \u2018Good' class components. Machine vision-based inspection technologies are gaining considerable importance for automated monitoring and quality control of manufactured products in recent years due to the advent of Industry 4.0. The involvement of advanced deep learning methods is a significant factor contributing to the advent of robust vision-based solutions for improving inspection accuracy at a significantly lower cost in manufacturing industries. The requirement of computational resources and large training datasets hinders the deployment of these solutions to manufacturing shop floors. The present research work develops an image-based framework considering pre-trained Convolutional Neural Network (CNN), ResNet-101 to detect surface defects with the minimum training datasets and computational requirements. The outcomes of the proposed framework are substantiated through a case study of detecting commonly observed surface defects during the centerless grinding of tapered rollers. The image datasets consisting of standard tapered rollers and three common defect classes are captured and enriched further with the help of the data augmentation technique. The present work employs ResNet-101 for feature extraction combined with and multi-class Support Vector Machine (SVM) as a classifier to detect defective images. The effects of the feature extraction layer ( fc1000 ) and pooling layer ( pool5 ) activation are explored to achieve the desired prediction abilities. The testing trials demonstrate that the proposed framework effectively performs image classification, achieving 100% precision for the \u2018Good\u2019 class components. The study showed that the proposed approach could overcome the requirements of large training datasets and higher computational power for deep learning models. The proposed system can be of significant importance for Micro, Small, and Medium Enterprises (MSMEs) and Small and Medium-sized Enterprises (SMEs) as an alternative to conventional labor-intensive manual inspection techniques.",
        "publication_year": "2022",
        "authors": [
            "Swarit Anand Singh",
            "K. Desai"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "15",
        "reference_count": "55",
        "references": [
            "/paper/Deep-Learning-for-Automatic-Vision-Based-of-Surface-Prunella-Scardigno/bab40171eafbcf1bc372627c94b500e0f4ec6691",
            "/paper/Magnetic-Tile-Surface-Defect-Detection-Methodology-Ling-Wu/9e4dda9d146c8b0afe3075810584d99313558aaa",
            "/paper/LFF-YOLO%3A-A-YOLO-Algorithm-With-Lightweight-Feature-Qian-Wang/937e123eae3eeb9568f5931d5154237872435f64",
            "/paper/Detection-Method-of-Crushing-Mouth-Loose-Material-Yao-Wang/811725468465d572925ea2c99b1f57b240556bd8",
            "/paper/Machine-Learning-in-Manufacturing-towards-Industry-Chen-Sampath/d5d634629463c74a32f45ec77a5282d4ba8b21cd",
            "/paper/Federated-transfer-learning-for-auxiliary-networks%3A-Guo-Wang/20c60441427e72257263ba5d1cfebf96d2da26ca",
            "/paper/The-Role-of-Machine-Learning-and-Design-of-in-the-Al-Kharusi-Dunne/b5b4a84559d6525e24372241be72d95f060b652b",
            "/paper/Adaptive-convolutional-neural-network-for-aluminum-Wang-Wei/726ef243640d8acbefe124e5393cfe8c74a4299b",
            "/paper/Vision-based-System-for-Automated-Image-Dataset-and-Singh-Kumar/191ebc2d63098c82e9cb49da24103a2c5fad4fee",
            "/paper/An-efficient-DNN-splitting-scheme-for-edge-AI-smart-Gauttam-Pattanaik/235e94e2c54de4c324c9aa33f5a21f5c0df54bf3",
            "/paper/Machine-vision-intelligence-for-product-defect-on-Wang-Fu/97ec22e0c2f7eee796cecec6374a0b284c4d0cb9",
            "/paper/Automated-defect-inspection-system-for-metal-based-Yun-Shin/6edc23999d72b03f309a0b680beafc859ac21329",
            "/paper/A-deep-learning-based-approach-for-fast-and-robust-Fu-Peize/31db339dfe02a42923cfab7d103a0372c5aa7ddb",
            "/paper/A-Review-on-Industrial-Surface-Defect-Detection-on-Qi-Yang/845533e69456e8d52996acb550cc50d2aabc3d8e",
            "/paper/A-learning-based-approach-for-surface-defect-using-Le-Mei/3c433b7f69026f6d4e5bbfff966e637b0863073f",
            "/paper/A-vision-based-method-for-lap-weld-defects-of-steel-Ma-Yu/0ef002eb9b0959257d6af4ff4c4044b6192e03fc",
            "/paper/Automated-defect-inspection-of-LED-chip-using-deep-Lin-Li/358b9707c2d45c06e23a264d21390c2ed5a1d7ee",
            "/paper/State-of-the-Art-in-Defect-Detection-Based-on-Ren-Fang/680fb04e5c62ff24e7308e75c86300195e9e9053",
            "/paper/Object-Detection-and-Classification-of-Metal-Shaft-Jiang-Tan/b919a6e2f13873be7bec163c24fb0b521d605c13",
            "/paper/Segmentation-based-deep-learning-approach-for-Tabernik-Sela/b77b1fc188f3834541efbb75add8f1ea80fd6225"
        ]
    },
    {
        "id": "d08775cf2bebcffa05c6fa506f687ef56953f128",
        "title": "AnoSeg: Anomaly Segmentation Network Using Self-Supervised Learning",
        "abstract": "The experiments show that the proposed AnoSeg outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset and compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks. Anomaly segmentation, which localizes defective areas, is an important component in large-scale industrial manufacturing. However, most recent researches have focused on anomaly detection. This paper proposes a novel anomaly segmentation network (AnoSeg) that can directly generate an accurate anomaly map using self-supervised learning. For highly accurate anomaly segmentation, the proposed AnoSeg considers three novel techniques: Anomaly data generation based on hard augmentation, self-supervised learning with pixel-wise and adversarial losses, and coordinate channel concatenation. First, to generate synthetic anomaly images and reference masks for normal data, the proposed method uses hard augmentation to change the normal sample distribution. Then, the proposed AnoSeg is trained in a self-supervised learning manner from the synthetic anomaly data and normal data. Finally, the coordinate channel, which represents the pixel location information, is concatenated to an input of AnoSeg to consider the positional relationship of each pixel in the image. The estimated anomaly map can also be utilized to improve the performance of anomaly detection. Our experiments show that the proposed method outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset. In addition, we compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks and demonstrated the superiority of our method for anomaly segmentation.",
        "publication_year": "2021",
        "authors": [
            "J. Song",
            "Kyeongbo Kong",
            "Ye In Park",
            "Seonggyun Kim",
            "Suk-Ju Kang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "18",
        "reference_count": "26",
        "references": [
            "/paper/Self-Supervised-Surface-Defect-Localization-via-and-Yang-Zhu/e50f35840c6f9bbfeb468bede9201df2619769e3",
            "/paper/DeSTSeg%3A-Segmentation-Guided-Denoising-for-Anomaly-Zhang-Li/d17df33c9b6453d61d01353e94592f1757caee8a",
            "/paper/Deep-Industrial-Image-Anomaly-Detection%3A-A-Survey-Liu-Xie/1312e46326f7e36fc82d16098b824540fe2dca66",
            "/paper/Deep-Learning-for-Unsupervised-Anomaly-Localization-Tao-Gong/51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
            "/paper/SLSG%3A-Industrial-Image-Anomaly-Detection-by-Better-Yang-Liu/5c04ce7f8510af40f2931535feeaf220832ab548",
            "/paper/Asymmetric-Distillation-Post-Segmentation-Method-Xing-Li/61840de4d9610558d510cfcf32986e93511a4cef",
            "/paper/Deep-Visual-Anomaly-Detection-in-Industrial-A-Liu-Xie/c39aac50bc5dbaf1ea14eef48043156b51884238",
            "/paper/A-Survey-on-Unsupervised-Anomaly-Detection-for-Cui-Liu/92822a2072b3ed906ccb450374341a7d56138582",
            "/paper/CFA%3A-Coupled-Hypersphere-Based-Feature-Adaptation-Lee-Lee/5de172c1031a38184a431b6e704f040f6f509064",
            "/paper/A-Survey-on-Unsupervised-Visual-Industrial-Anomaly-Cui-Liu/19aaeec8a81a711eb9a497c7d158068b27cb7b75",
            "/paper/Attention-Guided-Anomaly-Localization-in-Images-Venkataramanan-Peng/211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Adversarial-Discriminative-Attention-for-Robust-Kimura-Chaudhury/1a00dc525da31292e3734cbae2de681f114e30b1",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Image-Anomaly-Detection-with-Generative-Adversarial-Deecke-Vandermeulen/3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "/paper/Superpixel-Masking-and-Inpainting-for-Anomaly-Li-Li/e13d3f39cb9d03c57fef1344a825c163160dd8e7"
        ]
    },
    {
        "id": "7bfc47f93c5b48222cc553883d24a4f0be291328",
        "title": "Self-supervision advances morphological profiling by unlocking powerful image representations",
        "abstract": "DINO surpassed the widely used profiling tool CellProfiler by 29% in mean average precision (mAP) on classifying chemical perturbations and significantly accelerated feature extraction by 50x, at a lower cost. Morphological profiling is a powerful technology that enables unbiased characterization of cellular states through image-based screening. Inspired by recent progress in self-supervised learning (SSL), we sought to explore the potential benefits of using SSL in this domain and conducted a comprehensive benchmark study of recent SSL methods for learning representations from Cell Painting images without segmentation. We trained DINO, MAE, and SimCLR on subsets of the JUMP-CP consortium data, one of the largest publicly available Cell Painting image sets, and observed improved model performance with larger and more heterogeneous training sets. Our best model (DINO) surpassed the widely used profiling tool CellProfiler by 29% in mean average precision (mAP) on classifying chemical perturbations and significantly accelerated feature extraction by 50x, at a lower cost. Moreover, DINO outperformed CellProfiler in clustering gene families on an independent gene overexpression dataset. Our findings indicate that SSL methods can improve the efficiency and performance of morphological profiling, offering the potential to expedite drug discovery and reduce compute costs.",
        "publication_year": "2023",
        "authors": [
            "Vladislav Kim",
            "Nikolaos Adaloglou",
            "M. Osterland",
            "Flavio M. Morelli",
            "Paula A. Marin Zapata"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "63",
        "references": [
            "/paper/Unbiased-single-cell-morphology-with-vision-Doron-Moutakanni/cba82aa85450344a37c6004c973ba58004c6d282",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Self-Supervised-Learning-of-Phenotypic-from-Cell-Cross-Zamirski-Williams/98496b462b6a0406e41a956e68319ac17344a739",
            "/paper/Classifying-and-segmenting-microscopy-images-with-Kraus-Ba/d1f788e9ac58de5d2dc6a3928939b411cf9ec5a6",
            "/paper/Fully-unsupervised-deep-mode-of-action-learning-for-Janssens-Zhang/469636449a996299e43176a6ecca36dcbbb9e669",
            "/paper/Weakly-Supervised-Learning-of-Single-Cell-Feature-Caicedo-McQuin/b802bb5ffeba07f05d6095672dbdb8b8f58f9497",
            "/paper/Improving-Phenotypic-Measurements-in-High-Content-Ando-McLean/463b1c43dfd689841d2fd43d24058e68b7224dcf",
            "/paper/Self-Supervised-Vision-Transformers-Learn-Visual-in-Chen-Krishnan/ac9659baf2574010f8989715420f252af59c2fcb",
            "/paper/Capturing-Single-Cell-Phenotypic-Variation-via-Lafarge-Caicedo/ffc2ce1cb183bfb78a9ca354f79b643e8fd0b66d",
            "/paper/Learning-unsupervised-feature-representations-for-Lu-Kraus/4588b1d60c812d1072ea341189a0300877aeb797",
            "/paper/Single-Cell-Phenotype-Classification-Using-Deep-D%C3%BCrr-Sick/c1b727ea6b8818fe90d190bb339be76447151212"
        ]
    },
    {
        "id": "96d7bd865f90dbac943b40b6c9bd56fec22c6162",
        "title": "Robust gain-combined proportionate normalized subband adaptive filter algorithm with a variable control parameter step-size scaler",
        "abstract": "IN order to improve performance of the original normalized subband adaptive filter algorithm with the step-size scaler (SSS-NSAF) when identifying sparse impulsive response, the proportionate SSS-NSAF (SSS-PNSAF) algorithm and improved proportionate SSS-NSAF (SSS-IPNSAF) algorithms are given by utilizing common proportionate strategy. Even though the performance of the SSS-PNSAF algorithm is improved in sparse system, its convergence rate even slower than the original SSS-NSAF algorithm when the impulse response is disperse. For possessing great performance of the SSS-PNSAF algorithm in sparse impulse response and retaining merit of the SSS-NSAF algorithm in dispersive impulse response, the gain-combined proportionate SSS-NSAF (GC-SSS-PNSAF) algorithm is proposed by combining weight coefficient vectors of these two algorithms with a variable mixing parameter. The mixing parameter is indirectly updated through a modified sigmoidal activation function by using stochastic gradient method which minimizes the power of the system output errors. Furthermore, variable control parameter (VCP) mechanism is introduced to the GC-SSS-PNSAF algorithm to overcome the trade-off issue between fast convergence rate and low steady-state error. Numerous simulation experiments confirm the superiority of these proposed algorithms.",
        "publication_year": "2023",
        "authors": [
            "Zijie Shen",
            "Linna Shi",
            "Lin Tang"
        ],
        "related_topics": [
            "Engineering"
        ],
        "citation_count": 0,
        "reference_count": "38",
        "references": [
            "/paper/Robust-Normalized-Subband-Adaptive-Filter-Algorithm-Shen-Tang/4dd7d3d93d79fadeb34597d27c2461bd6f9a527d",
            "/paper/A-family-of-proportionate-normalized-subband-filter-Abadi-Kadkhodazadeh/5571f56c517c454d76515c849ae89c21a911b3f1",
            "/paper/Combined-Step-Size-Normalized-Subband-Adaptive-With-Huang-Zhang/ed7ebe0059ea966e8e9589be1b26edb016433078",
            "/paper/A-Variable-Step-Size-Matrix-Normalized-Subband-Ni-Li/8f64798dffa4f901e6730ab2d92d3915e1fd70bb",
            "/paper/A-Variable-Step-Size-Normalized-Subband-Adaptive-a-Hur-Song/4e81a2fd72000928cb2dc93c1646332b9dd1ee1b",
            "/paper/Variable-Step-Size-Sign-Subband-Adaptive-Filter-Shin-Yoo/3a4eb71e3cd6182d3f24852b662d9de01be72c10",
            "/paper/Improved-NSAF-Algorithms-with-Variable-Control-Shen-Huang/a721d255ce68659b8aeb6119f26db1cdd7df2e8f",
            "/paper/Sign-subband-adaptive-filter-with-%E2%84%931-norm-variable-Kim-Chang/417bd43e223b77b8d622d2f729727f264c9d19ee",
            "/paper/Normalized-Subband-Spline-Adaptive-Filter%3A-and-Wen-Zhang/5452910bb955c3af53b1f0d2588b6abdc12b7089",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/50b98cc888fd59742d535f8c20f7975322dbe7d3"
        ]
    },
    {
        "id": "08485f86df52e9cf9b02394d6a3aae05aff0a799",
        "title": "Spatio-temporal predictive tasks for abnormal event detection in videos",
        "abstract": "This paper proposes new constrained pretext tasks to learn object level normality patterns and consists in learning a mapping between down-scaled visual queries and their corresponding normal appearance and motion characteristics at the original resolution. Abnormal event detection in videos is a challenging problem, partly due to the multiplicity of abnormal patterns and the lack of their corresponding annotations. In this paper, we propose new constrained pretext tasks to learn object level normality patterns. Our approach consists in learning a mapping between down-scaled visual queries and their corresponding normal appearance and motion characteristics at the original resolution. The proposed tasks are more challenging than reconstruction and future frame prediction tasks which are widely used in the literature, since our model learns to jointly predict spatial and temporal features rather than reconstructing them. We believe that more constrained pretext tasks induce a better learning of normality patterns. Experiments on several benchmark datasets demonstrate the effectiveness of our approach to localize and track anomalies as it outperforms or reaches the current state-of-the-art on spatio-temporal evaluation metrics.",
        "publication_year": "2022",
        "authors": [
            "Yassine Naji",
            "Aleksandr Setkov",
            "Angelique Loesch",
            "M. Gouiff\u00e8s",
            "Romaric Audigier"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "34",
        "references": [
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Real-World-Anomaly-Detection-in-Surveillance-Videos-Sultani-Chen/598fe25743f9492c5c1ba30274ea446f65426d85",
            "/paper/Plug-and-Play-CNN-for-Crowd-Motion-Analysis%3A-An-in-Ravanbakhsh-Nabi/b9bdc61d63d75d82f24de21be26f61879df5a01b",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Detecting-Abnormal-Events-in-Video-Using-Narrowed-Ionescu-Smeureanu/ee1d50a0c6448253eaf8d1f7f6b00d893419589d",
            "/paper/A-Background-Agnostic-Framework-With-Adversarial-in-Georgescu-Ionescu/51548f7f7493b8ae758925a924df0394051b8ba8",
            "/paper/Discrete-neural-representations-for-explainable-Szymanowicz-Charles/d85b756b8e4d584a53483c6562eb968efdb1fc0c",
            "/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d"
        ]
    },
    {
        "id": "5a820db92ba51c624e72dd748cb60004c5056f32",
        "title": "Effect of simultaneous application of arthrocentesis and occlusal splint versus splint in management of non-reducing TMJ disc displacement",
        "abstract": "Semantic Scholar extracted view of \"Effect of simultaneous application of arthrocentesis and occlusal splint versus splint in management of non-reducing TMJ disc displacement\" by A. A. Altaweel et al.",
        "publication_year": "2020",
        "authors": [
            "A. A. Altaweel",
            "H. Ismail",
            "Mostafa I. Fayad",
            "Mostafa I. Fayad"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "4",
        "reference_count": "30",
        "references": [
            "/paper/Disc%E2%80%93condyle-relationship-alterations-following-or-Li-Zhou/3d057498bb3dde5f3117b63d9271180b21542683",
            "/paper/Arthrocentesis-vs-conservative-therapy-for-the-of-A-Hu-Liu/68fc022550246d8b76e41c778c7af926ab60dc5a",
            "/paper/A-systematic-review-and-meta-analysis-of-randomized-Thorpe-Haddad/11db5c672bc6791bf0909b186c830e312e9e4c23",
            "/paper/Efficacy-of-Arthrocentesis-and-Anterior-Splints-in-Navaneetham-Vaibhav/80e4c15cb8b7b76303247fca68bf2e0b99b70d94",
            "/paper/Effect-of-simultaneous-therapy-of-arthrocentesis-on-Lee-Baek/535da9c138982b26204c32b7859af669d172b660",
            "/paper/Evaluation-of-combined-splint-and-arthrocentesis-of-Elmohandes-Altaweel/0f03e0b1e52cc22dde7b194d0c28fa5708825519",
            "/paper/Comparison-of-the-effectiveness-of-three-different-Tatli-Benlidayi/637ac63555806b8c997c9944ae30319fe7af6d58",
            "/paper/Conservative-therapy-in-patients-with-anterior-disc-Schmitter-Zahran/8d4248d238634bad1973cf212ca1a9585f0be7a3",
            "/paper/Arthrocentesis-versus-nonsurgical-methods-in-the-of-D%C4%B1ra%C3%A7o%C4%9Flu-Saral/49023ac42bcba3da4f7173ceb8f215588ef78f00",
            "/paper/Efficacy-of-temporomandibular-joint-arthrocentesis-Alpaslan-Alpaslan/a2fef36ecf7f02c1c2b7ff067900c0fe14a74139",
            "/paper/Does-the-use-of-soft-or-hard-splints-affect-the-of-Alpaslan-Kahraman/3a81c85dd6188ebbfb665f81831d616b2f274b56",
            "/paper/Long-term-evaluation-of-arthrocentesis-for-the-of-Carvajal-Laskin/e6928911454c38632caba1cc5aba53bf587475f3",
            "/paper/Long-Term-Outcome-of-Arthrocentesis-Plus-Hyaluronic-Ungor-Atasoy/b194a7b5a2b23c2f450485cf3cd93b021e7a7505",
            "/paper/Management-of-nonreducing-temporomandibular-joint-Sato-Kawamura/4b2fac1fc329d1141b0ccf41cd61af1f187b37de"
        ]
    },
    {
        "id": "d94751a9165af603fa9d3563fa88f7f36ea31fb9",
        "title": "Stiffness-Controlled Hydrogels for 3D Cell Culture Models",
        "abstract": "It is shown that freeze-dried NFC hydrogel can be used for one-step 3D cell spheroid culturing of primary mesenchymal stem/stromal cells, prostate cancer cells (PC3), and hepatocellular carcinoma cells (HepG2) and a convolutional neural network (CNN) based automatic nuclei segmentation approach is applied to automatically segment individual cells of 3D cultured PC3 and HepG2 spheroids. Nanofibrillated cellulose (NFC) hydrogel is a versatile biomaterial suitable, for example, for three-dimensional (3D) cell spheroid culturing, drug delivery, and wound treatment. By freeze-drying NFC hydrogel, highly porous NFC structures can be manufactured. We freeze-dried NFC hydrogel and subsequently reconstituted the samples into a variety of concentrations of NFC fibers, which resulted in different stiffness of the material, i.e., different mechanical cues. After the successful freeze-drying and reconstitution, we showed that freeze-dried NFC hydrogel can be used for one-step 3D cell spheroid culturing of primary mesenchymal stem/stromal cells, prostate cancer cells (PC3), and hepatocellular carcinoma cells (HepG2). No difference was observed in the viability or morphology between the 3D cell spheroids cultured in the freeze-dried and reconstituted NFC hydrogel and fresh NFC hydrogel. Furthermore, the 3D cultured spheroids showed stable metabolic activity and nearly 100% viability. Finally, we applied a convolutional neural network (CNN)-based automatic nuclei segmentation approach to automatically segment individual cells of 3D cultured PC3 and HepG2 spheroids. These results provide an application to culture 3D cell spheroids more readily with the NFC hydrogel and a step towards automatization of 3D cell culturing and analysis.",
        "publication_year": "2022",
        "authors": [
            "Arto Merivaara",
            "Elle Koivunotko",
            "K. Manninen",
            "T. Kaseva",
            "Julia Monola",
            "E. Salli",
            "R. Koivuniemi",
            "S. Savolainen",
            "S. Valkonen",
            "M. Yliperttula"
        ],
        "related_topics": [
            "Biology",
            "Engineering",
            "Materials Science"
        ],
        "citation_count": "2",
        "reference_count": "48",
        "references": [
            "/paper/Angiogenic-Potential-of-Human-Adipose-Derived-Cells-Koivunotko-Snirvi/dea97b27e858cce6cbbde2294688cd3262dd16a6",
            "/paper/3D-Tumor-Models-in-Urology-Neuhaus-Rabien/44569d9a592a6ea3b98e5ce69aa7f6584b3a6440",
            "/paper/Nanofibrillar-cellulose-hydrogel-promotes-liver-Bhattacharya-Malinen/7d6bd8c1ae15fe1a0f0dd38ec6cf72fcf0d9776f",
            "/paper/Bioinspired-Tuning-of-Hydrogel-Dependency-for-3D-Lee-Rich/e8c43542362c761bd7907f1270206edb12f902a8",
            "/paper/Nanofibrillar-cellulose-hydrogels-and-reconstructed-Paukkonen-Kunnari/05e668911470bcc670946a9611ea7315d7055022",
            "/paper/%E2%80%AFMechanisms-of-pore-formation-in-hydrogel-scaffolds-Grenier-Duval/010fa179478998f2ecf3f1cb62f4b33d59057770",
            "/paper/Polymer-coating-on-a-micropillar-chip-for-robust-of-Roth-Lama/e39b6bdb6a2c813350e639f9b14dfdae4d534540",
            "/paper/Bioengineered-3D-platform-to-explore-cell-ECM-and-Loessner-Stok/73429d3175b8535e8bb53535a96f8f1f9bf94136",
            "/paper/Differentiation-of-liver-progenitor-cell-line-to-in-Malinen-Kanninen/51257ad3a7e8516ee53bf9bcde3648f769ce914e",
            "/paper/Preparation-of-aligned-porous-gelatin-scaffolds-by-Wu-Liu/a40fc28943f5d65b9451e772995726c581752ac3",
            "/paper/Enzymatically-crosslinked-silk-and-silk-gelatin-and-Hasturk-Jordan/dceae4af22b958a787a05411053ac4f801fb2a64",
            "/paper/3D-hydrogel-breast-cancer-models-for-studying-the-Wang-Mirza/3c00dca355a8b3e6b504349538294c169325224d"
        ]
    },
    {
        "id": "02a8883f756f09327cc134970be71db4dd893843",
        "title": "BRACS: A Dataset for BReAst Carcinoma Subtyping in H&E Histology Images",
        "abstract": "This paper introduces the BReAst Carcinoma Subtyping (BRACS) dataset, a large cohort of annotated Hematoxylin and Eosin (H&E)-stained images to advance AI development in the automatic characterization of breast lesions, and encourages AI practitioners to develop and evaluate novel algorithms on the BRACS dataset to further breast cancer diagnosis and patient care. Abstract Breast cancer is the most commonly diagnosed cancer and registers the highest number of deaths for women. Advances in diagnostic activities combined with large-scale screening policies have significantly lowered the mortality rates for breast cancer patients. However, the manual inspection of tissue slides by pathologists is cumbersome, time-consuming and is subject to significant inter- and intra-observer variability. Recently, the advent of whole-slide scanning systems has empowered the rapid digitization of pathology slides and enabled the development of Artificial Intelligence (AI)-assisted digital workflows. However, AI techniques, especially Deep Learning, require a large amount of high-quality annotated data to learn from. Constructing such task-specific datasets poses several challenges, such as data-acquisition level constraints, time-consuming and expensive annotations and anonymization of patient information. In this paper, we introduce the BReAst Carcinoma Subtyping (BRACS) dataset, a large cohort of annotated Hematoxylin and Eosin (H&E)-stained images to advance AI development in the automatic characterization of breast lesions. BRACS contains 547 Whole-Slide Images (WSIs) and 4539 Regions Of Interest (ROIs) extracted from the WSIs. Each WSI and respective ROIs are annotated by the consensus of three board-certified pathologists into different lesion categories. Specifically, BRACS includes three lesion types, i.e., benign, malignant and atypical, which are further subtyped into seven categories. It is, to the best of our knowledge, the largest annotated dataset for breast cancer subtyping both at WSI and ROI levels. Furthermore, by including the understudied atypical lesions, BRACS offers a unique opportunity for leveraging AI to better understand their characteristics. We encourage AI practitioners to develop and evaluate novel algorithms on the BRACS dataset to further breast cancer diagnosis and patient care. Database URL: https://www.bracs.icar.cnr.it/",
        "publication_year": "2021",
        "authors": [
            "N. Brancati",
            "A. Anniciello",
            "Pushpak Pati",
            "D. Riccio",
            "G. Scognamiglio",
            "Guillaume Jaume",
            "G. Pietro",
            "M. Bonito",
            "A. Foncubierta",
            "G. Botti",
            "M. Gabrani",
            "F. Feroce",
            "Maria Frucci"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "13",
        "reference_count": "46",
        "references": [
            "/paper/Publicly-available-datasets-of-breast-H%26E-images%3A-A-Tafavvoghi-Bongo/58229c28af74d3a0de745aaad0b8d693c197b7c8",
            "/paper/A-Multi-Task-Multiple-Instance-Learning-Algorithm-Marini-Wodzinski/8b57cd8a8e8d82c99110770ccef8246b1a1af2eb",
            "/paper/Segmentation-of-Breast-Tubules-in-H%26E-Images-Based-Chen-Zhou/fef79211929c629781d9bcd10b901ff45fc500d7",
            "/paper/Stain-invariant-self-supervised-learning-for-image-Tiard-Wong/983181623ab4d083d101212229b28d918a383e8d",
            "/paper/Breast-Tumor-Image-Classification-in-Bright-VIA-and-Zhan-Bian/9702368c1e0a0fb447ef7047e8c13760f16054bc",
            "/paper/Multiple-Instance-Learning-with-Efficient-for-Tumor-Wentai-Jinbo/d72a025e73701e4a3279fa8e94336660303a1f57",
            "/paper/KS-GNNExplainer%3A-Global-Model-Interpretation-On-Abdous-Abdollahzadeh/a3c2d89d82dabdb9969796439e04a65d8ba7eb8f",
            "/paper/Prompt-MIL%3A-Boosting-Multi-Instance-Learning-via-Zhang-Kapse/223154b3837a75160875fa9ef7bfb31fed31fa5f",
            "/paper/BEL%3A-A-Bag-Embedding-Loss-for-Transformer-enhances-Sens-Sadafi/69f8e99f2a27b4c11219378da887c3fb467d05e8",
            "/paper/Differentiable-Zooming-for-Multiple-Instance-on-Thandiackal-Chen/1e29047e719cb8551751bf98a3d6fa180af4e253",
            "/paper/BACH%3A-Grand-Challenge-on-Breast-Cancer-Histology-Aresta-Ara%C3%BAjo/2e860259741de4f75311a6af5684510944e29f83",
            "/paper/Deep-computational-pathology-in-breast-cancer.-Duggento-Conti/cd12413a9a90ab802497eb2cd0ba162c38c98182",
            "/paper/Classification-of-breast-cancer-histology-images-Ara%C3%BAjo-Aresta/61244d24d769fb6c9626becd58204e766c059513",
            "/paper/Multiple-instance-learning-for-histopathological-Sudharshan-Petitjean/7bfc41af5653255df067395928f164210f71d7f9",
            "/paper/BreakHis-based-breast-cancer-automatic-diagnosis-Benhammou-Achchab/c969e7dec8838365fa5dad1e3048f8a142e4d50d",
            "/paper/Predicting-breast-tumor-proliferation-from-images%3A-Veta-Heng/c377304af802f1ea67c6d696806a69f516a4472f",
            "/paper/Machine-Learning-Methods-for-Histopathological-A-Matos-Ataky/5387d5a5decfde74bf19528cf30a4f5b893cbf67",
            "/paper/PathProfiler%3A-Automated-Quality-Assessment-of-Image-Haghighat-Browning/16a1d12b5dfbce72af25cc5b667a36aaf7224672",
            "/paper/A-Dataset-for-Breast-Cancer-Histopathological-Image-Spanhol-Oliveira/86f0b58404a264a6216e29c78a5c113d900ca461",
            "/paper/Survey-on-Machine-Learning-and-Deep-Learning-in-Chugh-Kumar/90d88c630346e1819240a7d54015b969b8e707fe"
        ]
    },
    {
        "id": "5aa3760a3000b6966f01850f4535c166f7ebda5e",
        "title": "Deep Learning on Histopathological Images for Colorectal Cancer Diagnosis: A Systematic Review",
        "abstract": "This work aims to systematically review the current research on AI in CRC image analysis to assist in diagnosis, predict clinically relevant molecular phenotypes and microsatellite instability, identify histological features related to prognosis and correlated to metastasis, and assess the specific components of the tumor microenvironment. Colorectal cancer (CRC) is the second most common cancer in women and the third most common in men, with an increasing incidence. Pathology diagnosis complemented with prognostic and predictive biomarker information is the first step for personalized treatment. The increased diagnostic load in the pathology laboratory, combined with the reported intra- and inter-variability in the assessment of biomarkers, has prompted the quest for reliable machine-based methods to be incorporated into the routine practice. Recently, Artificial Intelligence (AI) has made significant progress in the medical field, showing potential for clinical applications. Herein, we aim to systematically review the current research on AI in CRC image analysis. In histopathology, algorithms based on Deep Learning (DL) have the potential to assist in diagnosis, predict clinically relevant molecular phenotypes and microsatellite instability, identify histological features related to prognosis and correlated to metastasis, and assess the specific components of the tumor microenvironment.",
        "publication_year": "2022",
        "authors": [
            "Athena Davri",
            "Effrosyni Birbas",
            "Theofilos Kanavos",
            "G. Ntritsos",
            "N. Giannakeas",
            "A. Tzallas",
            "A. Batistatou"
        ],
        "related_topics": [
            "Medicine",
            "Biology"
        ],
        "citation_count": "13",
        "reference_count": "121",
        "references": [
            "/paper/Colon-Cancer-Diagnosis-Based-on-Machine-Learning-Tharwat-Sakr/f499dfe48c1886e1bb7a5bf00a29b613f041c9e6",
            "/paper/Predicting-Colorectal-Cancer-Using-Machine-and-Deep-Alboaneen-Alqarni/b20b195c772a03a7deb4dd7fb970c810e8b21049",
            "/paper/Computer-Assisted-Diagnosis-of-Lymph-Node-in-Using-Khan-Brouwer/f7ffc466251ae8b781fa49eab913edb5f3b76765",
            "/paper/iMIL4PATH%3A-A-Semi-Supervised-Interpretable-Approach-Neto-Oliveira/e7a8e979511dccacec5918ea86bfd27fa8a1f1f6",
            "/paper/Impact-of-Image-Preprocessing-Methods-and-Deep-for-Murcia-G%C3%B3mez-Rojas-Valenzuela/fb52c9004eb8f2bef2d58df6febdba2f60d70b4f",
            "/paper/Domain-specific-transfer-learning-in-the-automated-Pet%C3%A4inen-V%C3%A4yrynen/341bc7d6498bdb2283dd88b07e059f975dbbbbff",
            "/paper/A-CAD-System-for-Colorectal-Cancer-from-WSI%3A-A-Neto-Montezuma/bb3cb1f396efb6bbba064819cc9b444d46b3c260",
            "/paper/Role-of-artificial-intelligence-in-risk-prediction%2C-Mansur-Saleem/2467f497a13139ed501e25e06f5961615944681e",
            "/paper/xDEEP-MSI%3A-Explainable-Bias-Rejecting-Instability-Bustos-Pay%C3%A1/c4ffd0b1d072bf33287ac69157cde58429a12008",
            "/paper/Investigation-of-artificial-intelligence-integrated-Kim-Kim/5c09161e7d76b96b673efb9c37447019df32df72",
            "/paper/Image-based-consensus-molecular-subtype-(imCMS)-of-Sirinukunwattana-Domingo/9531fb91f6876c57e3cf9bcb77ec79cc6f2a84d3",
            "/paper/Accurate-diagnosis-of-colorectal-cancer-based-on-Wang-Yu/4d2d58af2b8a1288d5452fe75d0cbad95eb8cfc7",
            "/paper/Prediction-of-clinically-actionable-genetic-from-Jang-Lee/356e321fef99253f1cc01504a6dd2d4c7f8668e9",
            "/paper/Deep-learning-based-tumor-microenvironment-analysis-Jiao-Li/c08fceb62442574a8ec2c6ed0a0dd3624da471e3",
            "/paper/Predicting-survival-from-colorectal-cancer-slides-A-Kather-Krisam/a4eb7cc590b65e6be34fb74a4568d661385f28a2",
            "/paper/Histopathological-characteristics-and-artificial-Shimada-Okuda/7db4ca90fb4b36b27f987eb837c5263f128a3b52",
            "/paper/Deep-learning-model-for-the-prediction-of-in-a-Yamashita-Long/c29bbcd4116408fce055798bc5bfaeee5010eac1",
            "/paper/Deep-learning-for-prediction-of-colorectal-cancer-a-Skrede-Raedt/dcbc71903e272776777b8fe686c67779307700f2",
            "/paper/Deep-Learning-Prediction-of-Metastasis-in-Locally-Schiele-Arndt/5561647733128b1f6931cca1c3facadebb997d75",
            "/paper/Histopathology-classification-and-localization-of-Zhou-Jin/016dc879654cb4faa6430f9740fb9480ef8d702a"
        ]
    },
    {
        "id": "63049ba1767693afe20c474ede9f891b376c630c",
        "title": "Feature Selective Transformer for Semantic Image Segmentation",
        "abstract": "This work focuses on fusing multi-scale features from Transformer-based backbones for semantic segmentation, and proposes a Feature Selective Transformer (FeSeFormer), which aggregates features from all scales (or levels) for each query feature. Recently, it has attracted more and more attentions to fuse multi-scale features for semantic image segmentation. Various works were proposed to employ progressive local or global fusion, but the feature fusions are not rich enough for modeling multi-scale context features. In this work, we focus on fusing multi-scale features from Transformer-based backbones for semantic segmentation, and propose a Feature Selective Transformer (FeSeFormer), which aggregates features from all scales (or levels) for each query feature. Specifically, we first propose a Scale-level Feature Selection (SFS) module, which can choose an informative subset from the whole multi-scale feature set for each scale, where those features that are important for the current scale (or level) are selected and the redundant are discarded. Furthermore, we propose a Full-scale Feature Fusion (FFF) module, which can adaptively fuse features of all scales for queries. Based on the proposed SFS and FFF modules, we develop a Feature Selective Transformer (FeSeFormer), and evaluate our FeSeFormer on four challenging semantic segmentation benchmarks, including PASCAL Context, ADE20K, COCO-Stuff 10K, and Cityscapes, outperforming the state-of-the-art.",
        "publication_year": "2022",
        "authors": [
            "Fangjian Lin",
            "Tianyi Wu",
            "Sitong Wu",
            "Sheng Tian",
            "Guodong Guo"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "52",
        "references": [
            "/paper/StructToken-%3A-Rethinking-Semantic-Segmentation-with-Lin-Liang/aae20d8092ebd15d73cdcdf89a331bb689c947ce",
            "/paper/Vision-Based-Semantic-Segmentation-in-Scene-for-and-Muhammad-Hussain/cc982540fe75856d6cc02ff0e19ae974a2b5c47c",
            "/paper/Gated-Fully-Fusion-for-Semantic-Segmentation-Li-Zhao/00e7abfade8b6b560bef8026a4f6493d69b2c11d",
            "/paper/Multi-scale-Context-Intertwining-for-Semantic-Lin-Ji/174cd8e98f17b3f5bda1c8e16cb39e3dec800f74",
            "/paper/Dual-Attention-Network-for-Scene-Segmentation-Fu-Liu/ad655c25e052fa4eeed53421344aca6f239c4c9d",
            "/paper/Fully-Transformer-Networks-for-Semantic-Image-Wu-Wu/fbcbe5a222786f38a1c69c3487b4edf8ca469934",
            "/paper/Adaptive-Pyramid-Context-Network-for-Semantic-He-Deng/60f791a926ed64830736d3d25ae0dbd89e60671d",
            "/paper/Region-aware-Contrastive-Learning-for-Semantic-Hu-Cui/a51407ab566711e6238b80ca9b85d72052a7ef11",
            "/paper/EfficientFCN%3A-Holistically-guided-Decoding-for-Liu-He/6b4b3777eb0e50d56463b58f344e30efc4271e17",
            "/paper/Segmenter%3A-Transformer-for-Semantic-Segmentation-Strudel-Pinel/68f080e0ac836ea230cb5316fbed273c70422d75",
            "/paper/Segmenting-Transparent-Object-in-the-Wild-with-Xie-Wang/2c34833c35c81135d9b32f92c4cf8f83b0c8b6e1",
            "/paper/Context-Encoding-for-Semantic-Segmentation-Zhang-Dana/e746c8eec81384bd37dede9700be9c8a3700f936"
        ]
    },
    {
        "id": "832298578168aacc3fb1433296a63dbfa849ee4e",
        "title": "Hand-Model-Aware Sign Language Recognition",
        "abstract": "The hand prior is introduced and a new hand-model-aware framework for isolated SLR with the modeling hand as the intermediate representation is proposed, which guides its learning by utilizing multiple weakly-supervised losses to constrain its spatial and temporal consistency. Hand gestures play a dominant role in the expression of sign language. Current deep-learning based video sign language recognition (SLR) methods usually follow a data-driven paradigm under the supervision of the category label. However, those methods suffer limited interpretability and may encounter the overfitting issue due to limited sign data sources. In this paper, we introduce the hand prior and propose a new hand-model-aware framework for isolated SLR with the modeling hand as the intermediate representation. We first transform the cropped hand sequence into the latent semantic feature. Then the hand model introduces the hand prior and provides a mapping from the semantic feature to the compact hand pose representation. Finally, the inference module enhances the spatio-temporal pose representation and performs the final recognition. Due to the lack of annotation on the hand pose under current sign language datasets, we further guide its learning by utilizing multiple weakly-supervised losses to constrain its spatial and temporal consistency. To validate the effectiveness of our method, we perform extensive experiments on four benchmark datasets, including NMFs-CSL, SLR500, MSASL and WLASL. Experimental results demonstrate that our method achieves state-of-the-art performance on all four popular benchmarks with a notable margin.",
        "publication_year": "2021",
        "authors": [
            "Hezhen Hu",
            "Wen-gang Zhou",
            "Houqiang Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "11",
        "reference_count": "62",
        "references": [
            "/paper/SignBERT%3A-Pre-Training-of-Hand-Model-Aware-for-Sign-Hu-Zhao/39c6076a1284324282d6234c033ef1539c959039",
            "/paper/SignBERT%2B%3A-Hand-model-aware-Self-supervised-for-Hu-Zhao/0fcc797aeed56bcc127476d5b68836dc402021ea",
            "/paper/Sign-Language-Recognition-via-Skeleton-Aware-Jiang-Sun/c7ba1a2b7363301328162bb31ea6d2155cf4977b",
            "/paper/Self-Emphasizing-Network-for-Continuous-Sign-Hu-Gao/1f55d35e1d1a148898a756cb0380b22fa8878dcb",
            "/paper/StepNet%3A-Spatial-temporal-Part-aware-Network-for-Shen-Zheng/dc75e95a9e8d34e450fb910c84c7ca8cb6192e97",
            "/paper/Cross-Transferring-Activity-Recognition-to-Word-Radhakrishnan-Mohan/18b8675237185c3272f727b5c9e6a63db15833a4",
            "/paper/BEST%3A-BERT-Pre-Training-for-Sign-Language-with-Zhao-Hu/919efc30ab8c45456ab72fb4ebeb5e25f2ad7642",
            "/paper/SLGTformer%3A-An-Attention-Based-Approach-to-Sign-Song-Xiang/ce6ded430dd3bdc01a12ef4ca14ee8e350d531dc",
            "/paper/Two-stream-lightweight-sign-language-transformer-Chen-Mei/14b5740f5f1d64dcc9bf09964b63d29bbb13a856",
            "/paper/Sign-language-recognition-via-dimensional-shift-and-Guo-Hou/356d2b911a83c6685efd884d4769eb2d8a87b3e2",
            "/paper/Global-Local-Enhancement-Network-for-NMF-Aware-Sign-Hu-Zhou/9023437b9bfb741094f9ff50323093573c9f8e60",
            "/paper/BSL-1K%3A-Scaling-up-co-articulated-sign-language-Albanie-Varol/0b2538f9c22273db62b205402864062bf222b68c",
            "/paper/Word-level-Deep-Sign-Language-Recognition-from-A-Li-Rodriguez-Opazo/874063b6c71aef8382eb66a66d8a1c1188e78a9a",
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e",
            "/paper/Spatial-Temporal-Multi-Cue-Network-for-Continuous-Zhou-Zhou/a1e2665ac39dcb389e12f3f993004b4b4651826d",
            "/paper/Attention-Based-3D-CNNs-for-Large-Vocabulary-Sign-Huang-Zhou/91a8da0d5429b0be63b2495587908d4583931ab5",
            "/paper/Weakly-Supervised-Learning-with-Multi-Stream-to-in-Koller-Camgoz/964502ea316fe9049c464a0925e3dc4246023a0d",
            "/paper/MS-ASL%3A-A-Large-Scale-Data-Set-and-Benchmark-for-Joze-Koller/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e",
            "/paper/A-Deep-Neural-Framework-for-Continuous-Sign-by-Cui-Liu/f96ffd8c71b97e46eb3ba48263c9012d197494d4",
            "/paper/Learning-sign-language-by-watching-TV-(using-weakly-Buehler-Zisserman/d6b47a0ee5149be524aa585aef6ca35e6a903fe6"
        ]
    },
    {
        "id": "a77ca914695d2989aec40b9d85351b2b021ffa6f",
        "title": "Unsupervised Anomaly Detection in Medical Images Using Masked Diffusion Model",
        "abstract": "This study presents a method called masked-DDPM (mDPPM), which introduces masking-based regularization to reframe the generation task of diffusion models and introduces Masked Image Modeling and Masked Frequency Modeling in this self-supervised approach that enables models to learn visual representations from unlabeled data. It can be challenging to identify brain MRI anomalies using supervised deep-learning techniques due to anatomical heterogeneity and the requirement for pixel-level labeling. Unsupervised anomaly detection approaches provide an alternative solution by relying only on sample-level labels of healthy brains to generate a desired representation to identify abnormalities at the pixel level. Although, generative models are crucial for generating such anatomically consistent representations of healthy brains, accurately generating the intricate anatomy of the human brain remains a challenge. In this study, we present a method called masked-DDPM (mDPPM), which introduces masking-based regularization to reframe the generation task of diffusion models. Specifically, we introduce Masked Image Modeling (MIM) and Masked Frequency Modeling (MFM) in our self-supervised approach that enables models to learn visual representations from unlabeled data. To the best of our knowledge, this is the first attempt to apply MFM in DPPM models for medical applications. We evaluate our approach on datasets containing tumors and numerous sclerosis lesions and exhibit the superior performance of our unsupervised method as compared to the existing fully/weakly supervised baselines. Code is available at https://github.com/hasan1292/mDDPM.",
        "publication_year": "2023",
        "authors": [
            "H. Iqbal",
            "Umar Khalid",
            "Jing Hua",
            "Chen Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "32",
        "references": [
            "/paper/Patched-Diffusion-Models-for-Unsupervised-Anomaly-Behrendt-Bhattacharya/86fe4904650db35c8e33da4deda7a66ff0e41455",
            "/paper/Autoencoders-for-Unsupervised-Anomaly-Segmentation-Baur-Denner/d82800c79dd335297336fe10b1a60d47706e4296",
            "/paper/Fast-Unsupervised-Brain-Anomaly-Detection-and-with-Pinaya-Graham/bacfa58d33e53efc40bffd87094f8731371277f2",
            "/paper/Diffusion-Models-for-Medical-Anomaly-Detection-Wolleb-Bieder/dc21d8ee24038e99ddfd0fe88b263e0eabc54337",
            "/paper/Denoising-Autoencoders-for-Unsupervised-Anomaly-in-Kascenas-Pugeault/988a5fc8111bcb15aaa4b9f220b49872b005ead3",
            "/paper/Unsupervised-Detection-of-Lesions-in-Brain-MRI-Chen-Konukoglu/83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476",
            "/paper/Three-dimensional-deep-learning-with-spatial-for-in-Bengs-Behrendt/1fbbe6fcf6465bab87b9ae55bc5fd23c528f24b9",
            "/paper/f%E2%80%90AnoGAN%3A-Fast-unsupervised-anomaly-detection-with-Schlegl-Seeb%C3%B6ck/f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "/paper/Unsupervised-Region-Based-Anomaly-Detection-In-MRI-Nguyen-Feldman/cb3d43139c682518b1e05e64df6239b7c26527ff",
            "/paper/Constrained-unsupervised-anomaly-segmentation-Silva-Rodr'iguez-Naranjo/7e2a0e481177799f50f9d2776162c6ded6eb970c"
        ]
    },
    {
        "id": "8654c84f172e436081a973f1b500e4ac449a0bc0",
        "title": "BRAVE-NET: Fully Automated Arterial Brain Vessel Segmentation in Patients With Cerebrovascular Disease",
        "abstract": "The BRAVE-NET model is a multiscale 3-D convolutional neural network model developed on a dataset of 264 patients from three different studies enrolling patients with cerebrovascular diseases and validated using high-quality manual labels as ground truth and is the most resistant toward false labelings as revealed by the visual analysis. Introduction: Arterial brain vessel assessment is crucial for the diagnostic process in patients with cerebrovascular disease. Non-invasive neuroimaging techniques, such as time-of-flight (TOF) magnetic resonance angiography (MRA) imaging are applied in the clinical routine to depict arteries. They are, however, only visually assessed. Fully automated vessel segmentation integrated into the clinical routine could facilitate the time-critical diagnosis of vessel abnormalities and might facilitate the identification of valuable biomarkers for cerebrovascular events. In the present work, we developed and validated a new deep learning model for vessel segmentation, coined BRAVE-NET, on a large aggregated dataset of patients with cerebrovascular diseases. Methods: BRAVE-NET is a multiscale 3-D convolutional neural network (CNN) model developed on a dataset of 264 patients from three different studies enrolling patients with cerebrovascular diseases. A context path, dually capturing high- and low-resolution volumes, and deep supervision were implemented. The BRAVE-NET model was compared to a baseline Unet model and variants with only context paths and deep supervision, respectively. The models were developed and validated using high-quality manual labels as ground truth. Next to precision and recall, the performance was assessed quantitatively by Dice coefficient (DSC); average Hausdorff distance (AVD); 95-percentile Hausdorff distance (95HD); and via visual qualitative rating. Results: The BRAVE-NET performance surpassed the other models for arterial brain vessel segmentation with a DSC = 0.931, AVD = 0.165, and 95HD = 29.153. The BRAVE-NET model was also the most resistant toward false labelings as revealed by the visual analysis. The performance improvement is primarily attributed to the integration of the multiscaling context path into the 3-D Unet and to a lesser extent to the deep supervision architectural component. Discussion: We present a new state-of-the-art of arterial brain vessel segmentation tailored to cerebrovascular pathology. We provide an extensive experimental validation of the model using a large aggregated dataset encompassing a large variability of cerebrovascular disease and an external set of healthy volunteers. The framework provides the technological foundation for improving the clinical workflow and can serve as a biomarker extraction tool in cerebrovascular diseases.",
        "publication_year": "2020",
        "authors": [
            "A. Hilbert",
            "V. Madai",
            "E. M. Akay",
            "O. U. Aydin",
            "Jonas Behland",
            "J. Sobesky",
            "I. Galinovic",
            "A. Khalil",
            "A. Taha",
            "J. Wuerfel",
            "P. Du\u0161ek",
            "T. Niendorf",
            "J. Fiebach",
            "D. Frey",
            "Michelle Livne"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "36",
        "reference_count": "86",
        "references": [
            "/paper/Automated-Cerebral-Vessel-Segmentation-of-Magnetic-Patel-Pint%C3%A9r/19a9461fc7f4289eb8d7d306c0f8fdbffceb1f3a",
            "/paper/Anatomical-labeling-of-intracranial-arteries-with-Hilbert-Rieger/6e96438d4ed2467cfba2833c98c7cdb6a0bcac87",
            "/paper/Automatic-Segmentation-of-Cerebrovascular-Based-on-Min-Nie/3eecfcdc29ba47730e3cf84caa837e380bf647e2",
            "/paper/High-throughput-3DRA-segmentation-of-brain-and-deep-Lin-Xia/f6cbf70ea872c74c29ab69d5c952fb0a7b08e10a",
            "/paper/Brain-Vessel-Segmentation-Using-Deep-Learning%E2%80%94A-Goni-Ruhaiyem/58b5d5173a31f0c7c9960fd3d006d1f7d11d2b45",
            "/paper/Novel-dataset-and-evaluation-of-state-of-the-art-Bizjak-Chien/b9450c4eb65b73a1ab384ba6abd6adab6a767304",
            "/paper/A-nested-parallel-multiscale-convolution-for-Xia-Xie/9cc202a2154693c8c175a9dfbdb28f118600cddb",
            "/paper/CAVE%3A-Cerebral-Artery-Vein-Segmentation-in-Digital-Su-Sluijs/b3647c4b4f9d0a777a416c5811babb1def8f5e4b",
            "/paper/Cerebrovascular-Segmentation-via-Vessel-Oriented-Guo-Luan/4cc1b701f42953ddb473e6b0bcbf78b655828f4a",
            "/paper/Spider-U-Net%3A-Incorporating-Inter-Slice-Using-LSTM-Lee-Sunwoo/831644f7cbd6bedc2caccf6a252a5c4a62b28a6b",
            "/paper/A-U-Net-Deep-Learning-Framework-for-High-Vessel-in-Livne-Rieger/907d6d24ddf4a74491f611be6fb57fd102c6d9b0",
            "/paper/Multi-resolution-CNN-for-brain-vessel-segmentation-Patel-Paliwal/636caf10552e22e855ddd1855a55a6036267891c",
            "/paper/Global-channel-attention-networks-for-intracranial-Ni-Wu/958aebc86388e7625fb8df4b0882bc3b764364a8",
            "/paper/Dilated-Deeply-Supervised-Networks-for-Hippocampus-Folle-Vesal/dd8a2ef642059bc48d91f928274207001bdec924",
            "/paper/Automatic-Brain-Tumor-Detection-and-Segmentation-Dong-Yang/e0067a9c3f30aab46d9e6f8844dc36e83c85869f",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/Accurate-Segmentation-of-Cerebrovasculature-From-Taher-Soliman/3000a3e87802380039f8d8d6e8687d121bb92269",
            "/paper/3D-intracranial-artery-segmentation-using-a-Chen-Xie/0d3b81307e123cdf77eef35b2158f5392fc9bafe",
            "/paper/Blood-vessel-segmentation-algorithms-Review-of-and-Moccia-Momi/7b7991db1e251ded0a7f0091a4fd958ca5715ef4",
            "/paper/Robust-Segmentation-of-the-Full-Cerebral-in-4D-CT-Meijs-Patel/fb5c4bf41fd879c9c64028a817db7f7ab6aba429"
        ]
    },
    {
        "id": "16713ba75cf3e5f4e21aef525f5ff6f77093c52c",
        "title": "Vestibular Complaints Impact on the Long-Term Quality of Life of Vestibular Schwannoma Patients",
        "abstract": "Even mild dizziness can have a significant and clinically relevant effect on the QoL of patients with unilateral vestibular schwannoma in the long term, and the DHI emotional subdomain was the most prominent determinant of poorerQoL. Objective To analyze the effect of dizziness-related symptoms on the long-term quality of life (QoL) of patients with unilateral vestibular schwannoma. Methods In this cross-sectional study, patients with a unilateral vestibular schwannoma diagnosed between 2004 and 2013 completed a disease-specific QoL questionnaire (Penn Acoustic Neuroma Quality of Life [PANQOL]) and the Dizziness Handicap Inventory (DHI) in 2020. Linear regression was performed to assess the correlation between QoL and the DHI total score, and the scores of the DHI functional, emotional, and physical subdomains. Potential confounders such as age, sex, tumor size at baseline, and treatment modality (active surveillance, surgery, or radiotherapy) were included in the model. Results In total, 287 of 479 patients (59%) experienced dizziness with a median follow-up of 10 years. The DHI total score was significantly associated with the PANQOL total score. On average, we found a reduction of 0.7 points on the PANQOL for each additional point on the DHI. The DHI emotional subdomain was the most prominent determinant of poorer QoL. Each point on the DHI emotional subscale was associated with a reduction of 1.3 on the PANQOL score. Treatment modality did not have a clinically relevant effect on dizziness-related QoL. Conclusions Even mild dizziness can have a significant and clinically relevant effect on the QoL of patients with unilateral vestibular schwannoma in the long term. This holds true for all treatment modalities. Addressing the vestibular problems may improve QoL in vestibular schwannoma patients, and DHI subscale analysis may help tailor the optimal vestibular intervention.",
        "publication_year": "2022",
        "authors": [
            "Constanza Fuentealba-Bassaletti",
            "O. M. Neve",
            "B. V. van Esch",
            "Jeroen C. Jansen",
            "R. Koot",
            "P. V. van Benthem",
            "E. Hensen"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "3",
        "reference_count": "33",
        "references": [
            "/paper/Digital-Patient-Reported-Outcome-Measures-Assessing-Steiert-Lambeck/05a942d2d585b44a47a511802a3f0cc2e40f03d5",
            "/paper/Radiation-for-Sporadic-Vestibular-Schwannoma%3A-An-on-Woodson/21db66a912d65b66f5c9e9a2fcfd52b3aa170e72",
            "/paper/Guiding-Patients-Through-Decision-Making-in-of-Choi-Venteicher/93bb83ab47a35ee648f0d1f55209b6a45d386566",
            "/paper/Long-Term-Quality-of-Life-of-Vestibular-Schwannoma-Neve-Jansen/f887e72876126a010587098dca682084c08e968e",
            "/paper/UNTREATED-VESTIBULAR-SCHWANNOMA%3A-VERTIGO-IS-A-OF-Myrseth-M%C3%B8ller/70068616c7042e7e73c216226be50d061d2826d7",
            "/paper/Quality-of-Life-in-807-Patients-with-Vestibular-Soulier-Leeuwen/aa88fa15f92cdd413c481162b7cad303acd8dc4c",
            "/paper/Quality-of-Life-in-Vestibular-Schwannoma-Patients-Jufas-Flanagan/89be424e28fb7ed0e0e6c5a469904a182e26f593",
            "/paper/Defining-the-Minimal-Clinically-Important-for-With-Kerezoudis-Yost/ed1f9048c96946ebb6ae519015cd8b362af885ea",
            "/paper/Associations-of-Vestibular-Tests-With-Penn-Acoustic-Brown-Cooper/51e71b0c2130fe731ac86f302a9f68c18ae31ee2",
            "/paper/Long-term-Dizziness-Handicap-in-Patients-with-Carlson-Tveiten/36d95d2f8972d640c56cacb3704136255f55da0a",
            "/paper/Prospective-Study-of-Disease-Specific-in-Sporadic-Carlson-Barnes/e9f42702f018cc45ae185e61cc47a6950f55ab0a",
            "/paper/Vestibular-Deficits-Correlating-to-Dizziness-Score%2C-Kj%C3%A6rsgaard-Szeremet/f1f9bfe36ffafeca2c24f260988d84ebe1914f2d",
            "/paper/Literature-review-of-questionnaires-assessing-and-Duracinsky-Mosnier/f3c00b9d49c5b63e843b86b9a5d7302a7375789f"
        ]
    },
    {
        "id": "66731f14a22a11b1467297e6b1fcedb50ec1377a",
        "title": "Domain Adaptive Nuclei Instance Segmentation and Classification via Category-aware Feature Alignment and Pseudo-labelling",
        "abstract": "This work proposes a novel deep neural network, namely Category-Aware feature alignment and Pseudo-Labelling Network (CAPL-Net) for UDA nuclei instance segmentation and classification and demonstrates that this approach outperforms state-of-the-art UDA methods with a remarkable margin. Unsupervised domain adaptation (UDA) methods have been broadly utilized to improve the models' adaptation ability in general computer vision. However, different from the natural images, there exist huge semantic gaps for the nuclei from different categories in histopathology images. It is still under-explored how could we build generalized UDA models for precise segmentation or classification of nuclei instances across different datasets. In this work, we propose a novel deep neural network, namely Category-Aware feature alignment and Pseudo-Labelling Network (CAPL-Net) for UDA nuclei instance segmentation and classification. Specifically, we first propose a category-level feature alignment module with dynamic learnable trade-off weights. Second, we propose to facilitate the model performance on the target data via self-supervised training with pseudo labels based on nuclei-level prototype features. Comprehensive experiments on cross-domain nuclei instance segmentation and classification tasks demonstrate that our approach outperforms state-of-the-art UDA methods with a remarkable margin.",
        "publication_year": "2022",
        "authors": [
            "Canran Li",
            "Dongnan Liu",
            "Haoran Li",
            "Zheng Zhang",
            "Guangming Lu",
            "Xiaojun Chang",
            "Weidong (Tom) Cai"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "4",
        "reference_count": "19",
        "references": [
            "/paper/Unsupervised-Domain-Adaptive-Fundus-Image-with-Few-Yu-Liu/de3bc68d712eb59c2773af1275a869c6a1210e55",
            "/paper/Unsupervised-Domain-Adaptation-for-Neuron-Membrane-An-Liu/c34889d11513ec621d0aa114d9337da69adaeaa2",
            "/paper/Test-time-Adaptation-vs.-Training-time-A-Case-Study-Azarian-Das/79d244d2bd0e4a5842aee2529b0fb2fe826c7da0",
            "/paper/Curriculum-Based-Augmented-Fourier-Domain-for-Image-Wang-Islam/c64f75b5db7fdad560ec5112c9ad9074105f0367",
            "/paper/Unsupervised-Instance-Segmentation-in-Microscopy-Liu-Zhang/974ffaf2775a8c32e405c551436a111714a5dc3c",
            "/paper/Minimizing-Labeling-Cost-for-Nuclei-Instance-and-Yang-Zhang/f9282d8871dd3d87a002ffd6e38eefff65978128",
            "/paper/CIA-Net%3A-Robust-Nuclei-Instance-Segmentation-with-Zhou-Onder/5fd490e5ceed129a83d16dbda29ab61fe4aa1acb",
            "/paper/Panoptic-Feature-Fusion-Net%3A-A-Novel-Instance-for-Liu-Zhang/b57c925acd708fd7e27facd3e8d11053ea7cca30",
            "/paper/Category-Anchor-Guided-Unsupervised-Domain-for-Zhang-Zhang/7ff4f7701fa4afc9ac20415350efc2087e6776a2",
            "/paper/Boundary-assisted-Region-Proposal-Networks-for-Chen-Ding/bbffe75a1b5c5bc02f3a13bbc4f6700b17686102",
            "/paper/PDAM%3A-A-Panoptic-Level-Feature-Alignment-Framework-Liu-Zhang/90b115737efb108a39e6134035b33b26941cc85f",
            "/paper/Lizard%3A-A-Large-Scale-Dataset-for-Colonic-Nuclear-Graham-Jahanifar/2e71e26bb816c6729e955e3c9e2b1c14906e73b4",
            "/paper/Hover-Net%3A-Simultaneous-segmentation-and-of-nuclei-Graham-Vu/5986547c7380f5a8fb6028093f827b3662f838a2",
            "/paper/Contrastive-Adaptation-Network-for-Unsupervised-Kang-Jiang/675b96a38f37f92043189d7e90377a6b41a2a9cd"
        ]
    },
    {
        "id": "61c235074fad55fadf3d84043ac5f47e6947d3f7",
        "title": "Human Activity Recognition Based on CSI fragment with Action-value Method",
        "abstract": "This paper proposes a novel HAR method based on action-value method, where each complete Channel State Information sample signal of each activity is sliced into piece samples, and these piece samples are trained and tested to improve the real-time performance and reduce the number of training samples. The application of Human Activity Recognition (HAR) technology makes human life more convenient. As an emerging HAR technology, WiFi based wireless sensor can sense the state of the target, such as body movement, gesture, position and so on. Aiming at the problem that the current WIFi based HAR methods need more training samples and have low real-time performance, this paper proposes a novel HAR method based on action-value method. In this method, each complete Channel State Information (CSI) sample signal of each activity is sliced into piece samples, and these piece samples are trained and tested to improve the real-time performance and reduce the number of training samples. The piece sample and the sequence of piece samples are respectively regarded as the state information and environment, and the classification of each piece sample is regarded as the execution of the classification-action. A deep neural network is used to simulate the reward of classification-actions in each state, and the recognition model is established by the action-value method. We tested our approach on SignFi data set. The highest recognition accuracy rate of active is 99% and 91% respectively.",
        "publication_year": "2022",
        "authors": [
            "Hongxin Chen",
            "Yong Zhang",
            "Yuqing Yin",
            "Fei He"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "21",
        "references": [
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/WiDriver%3A-Driver-Activity-Recognition-System-Based-Duan-Yu/45fd2181ebf90a273d816f508aefaa9e6f5d0da8",
            "/paper/Channel-Selective-Activity-Recognition-with-WiFi%3A-A-Wang-Gong/d5c30e1fb1a7f98ad3dcdee3cd22ca5e4650d1a7",
            "/paper/Deep-Spatial%E2%80%93Temporal-Model-Based-Cross-Scene-Using-Sheng-Xiao/173a954bab2a7ab531bfb0dca42a3191a691ed12",
            "/paper/CSI-Based-Wireless-Localization-and-Activity-Using-Wu-Yang/5f1e6b38d476773bebd09e15a7c8f7bffde66674",
            "/paper/Higher-Order-Feature-Extraction-and-Selection-for-Ahmed-Ahmad/ba891f1f9fee45b1bb77c5cc543476b81c95c344",
            "/paper/UTD-MHAD%3A-A-multimodal-dataset-for-human-action-a-a-Chen-Jafari/bb4d8ebca96f3c467c660d62339f0828d8442305",
            "/paper/SignFi%3A-Sign-Language-Recognition-Using-WiFi-Ma-Zhou/47899fc484fda880af2168a2e8d91beaf68e7722",
            "/paper/Distances-evolution-analysis-for-online-and-human-Meng-Drira/13b44f818acd5b46265d4dae8025c972e2d94ac8"
        ]
    },
    {
        "id": "c6a3c11da0e45e5a18539752d42751f2a5e63d91",
        "title": "Deep Crowd Anomaly Detection by Fusing Reconstruction and Prediction Networks",
        "abstract": "A generalized framework for proposing a series of deep models by fusing several options of a reconstruction network and a prediction network to detect anomaly in videos efficiently and has capability to confirm better error gap and to extract high quality of features needed for video anomaly detection. Abnormal event detection is one of the most challenging tasks in computer vision. Many existing deep anomaly detection models are based on reconstruction errors, where the training phase is performed using only videos of normal events and the model is then capable to estimate frame-level scores for an unknown input. It is assumed that the reconstruction error gap between frames of normal and abnormal scores is high for abnormal events during the testing phase. Yet, this assumption may not always hold due to superior capacity and generalization of deep neural networks. In this paper, we design a generalized framework (rpNet) for proposing a series of deep models by fusing several options of a reconstruction network (rNet) and a prediction network (pNet) to detect anomaly in videos efficiently. In the rNet, either a convolutional autoencoder (ConvAE) or a skip connected ConvAE (AEc) can be used, whereas in the pNet, either a traditional U-Net, a non-local block U-Net, or an attention block U-Net (aUnet) can be applied. The fusion of both rNet and pNet increases the error gap. Our deep models have distinct degree of feature extraction capabilities. One of our models (AEcaUnet) consists of an AEc with our proposed aUnet has capability to confirm better error gap and to extract high quality of features needed for video anomaly detection. Experimental results on UCSD-Ped1, UCSD-Ped2, CUHK-Avenue, ShanghaiTech-Campus, and UMN datasets with rigorous statistical analysis show the effectiveness of our models.",
        "publication_year": "2023",
        "authors": [
            "Md. Haidar Sharif",
            "Lei Jiao",
            "C. Omlin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "76",
        "references": [
            "/paper/A-cascade-reconstruction-model-with-generalization-Zhong-Chen/7fd052d40660d65c8497599794467812b78e1d0b",
            "/paper/Integrating-prediction-and-reconstruction-for-Tang-Zhao/fe09f7a379944444201552e952b910188c0aeaca",
            "/paper/Spatio-temporal-prediction-and-reconstruction-for-Liu-Zhang/e789f2fbc002baf389fc2300ef5c2fbfb94202bc",
            "/paper/Multi-Channel-Generative-Framework-and-Supervised-Vu-Boonaert/f22f2a4c09a0cdd212039cedb358a6c7818ca3d4",
            "/paper/Unsupervised-Anomaly-Video-Detection-via-a-ConvLSTM-Wang-Tan/a0e4296b9e3dc5584ac0550cc18019efb181610f",
            "/paper/Human-Machine-Cooperative-Video-Anomaly-Detection-Yang-Yu/40705d94f532f909b2a95cabcdaa97e603515247",
            "/paper/Unsupervised-video-anomaly-detection-via-flows-with-Cho-Kim/e4b4349d19124be609622b75585d158055c1a0b3",
            "/paper/Surveillance-video-anomaly-detection-via-non-local-Zhang-Feng/58a9a798525969cdeeb610a52e6f58cb67b24186",
            "/paper/A-Comparative-Study-of-Transfer-Learning-Approaches-Gutoski-Ribeiro/6c1c586e483ef2385644333976505902b152734b",
            "/paper/Normality-Learning-in-Multispace-for-Video-Anomaly-Zhang-Nie/1028c987f9d2dd0a1249714382e79f5c986e1804"
        ]
    },
    {
        "id": "fb675e55eb7abe9be5009fa57d0114a85f324afc",
        "title": "DVFENet: Dual-branch voxel feature extraction network for 3D object detection",
        "abstract": "Semantic Scholar extracted view of \"DVFENet: Dual-branch voxel feature extraction network for 3D object detection\" by Yunqian He et al.",
        "publication_year": "2021",
        "authors": [
            "Yunqian He",
            "Guihua Xia",
            "Yongkang Luo",
            "Li Su",
            "Zhi Zhang",
            "Wanyi Li",
            "Peng Wang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "13",
        "reference_count": "46",
        "references": [
            "/paper/MVTr%3A-multi-feature-voxel-transformer-for-3D-object-Ai-Xie/d0f56fbe02512194ea7321b50f88094d1ecae214",
            "/paper/AFE-RCNN%3A-Adaptive-Feature-Enhancement-RCNN-for-3D-Shuang-Huang/5ad0dc22dc16c56c847f47c036f6de67757a19f6",
            "/paper/Point-Voxel-and-Bird-Eye-View-Representation-for-3D-Ning-Liu/c79aaf2a0b8407438af6c6b6b1d62af9f108a5c1",
            "/paper/Improving-3D-Vulnerable-Road-User-Detection-With-Lu-Zhao/a1ea6e836fda42bf33f80d0a1268af505ca70428",
            "/paper/CVPCG%3A-Centrosymmetric-Virtual-Point-Cloud-For-3D-Ai-Xie/cd4cda9a3b843c9ca8c697f59b4d53cb1564a867",
            "/paper/SRIF-RCNN%3A-Sparsely-represented-inputs-fusion-of-3D-Li-Kong/bb5a06ea18d0a1f4b10b2950b1cc285147af271b",
            "/paper/Keypoint-Aware-Single-Stage-3D-Object-Detector-for-Xu-Hu/fa9c5e362ead588310413add62e4809c46eddcfd",
            "/paper/3D-Human-Pose-Estimation-Based-on-Transformer-Chen/892b37c45d860226b49b8dfa85e5d68fa3f29fb8",
            "/paper/Deep-Collaborative-Online-Learning-Resource-Based-Hao-Yang/806863dbf222eaaae0b4a629d2044696dcf5d516",
            "/paper/R-VPCG%3A-RGB-image-feature-fusion-based-virtual-for-Ai-Xie/9c6df268cf110ad6359ba4c2b4aee633c94705c6",
            "/paper/HVNet%3A-Hybrid-Voxel-Network-for-LiDAR-Based-3D-Ye-Xu/09c958fa8e755ccb5a5f2ca22f9834e7e0a045ff",
            "/paper/Voxel-FPN%3A-Multi-Scale-Voxel-Feature-Aggregation-3D-Kuang-Wang/5ab019173eef5b83138743b1c4431638bef8e065",
            "/paper/VoxelNet%3A-End-to-End-Learning-for-Point-Cloud-Based-Zhou-Tuzel/80f5ee8578ee76e2c17824f211762ffec7e029d4",
            "/paper/SARPNET%3A-Shape-attention-regional-proposal-network-Ye-Chen/86c613cff08dccc6c69eb204b27390f1b7bf3797",
            "/paper/PointRGCN%3A-Graph-Convolution-Networks-for-3D-Zarzar-Giancola/6e77287f1ee0e8cddc6d891e1054f3b646a1dd64",
            "/paper/Joint-3D-Proposal-Generation-and-Object-Detection-Ku-Mozifian/675784f097dbf87cd75a5640019d4469e7bd7905",
            "/paper/Multi-view-3D-Object-Detection-Network-for-Driving-Chen-Ma/dc200ab22bf63e10e8b2af328a9e072d82cf75b7",
            "/paper/STD%3A-Sparse-to-Dense-3D-Object-Detector-for-Point-Yang-Sun/f23bf58437140927ee7b2107597568e23a398ba1",
            "/paper/SECOND%3A-Sparsely-Embedded-Convolutional-Detection-Yan-Mao/5125a16039cabc6320c908a4764f32596e018ad3",
            "/paper/Frustum-PointNets-for-3D-Object-Detection-from-Data-Qi-Liu/526cf249c2760b7bdbb28f2a2a7c85851d3c2727"
        ]
    },
    {
        "id": "a17a7926dc5ec33a36e0a3f1eda86a1404f458cd",
        "title": "Anomaly Detection by One Class Latent Regularized Networks",
        "abstract": "A novel adversarial dual autoencoder network is proposed, in which the underlying structure of training data is not only captured in latent feature space, but also can be further restricted in the space of latent representation in a discriminant manner, leading to a more accurate detector. Anomaly detection is a fundamental problem in computer vision area with many real-world applications. Given a wide range of images belonging to the normal class, emerging from some distribution, the objective of this task is to construct the model to detect out-of-distribution images belonging to abnormal instances. Semi-supervised Generative Adversarial Networks (GAN)-based methods have been gaining popularity in anomaly detection task recently. However, the training process of GAN is still unstable and challenging. To solve these issues, a novel adversarial dual autoencoder network is proposed, in which the underlying structure of training data is not only captured in latent feature space, but also can be further restricted in the space of latent representation in a discriminant manner, leading to a more accurate detector. In addition, the auxiliary autoencoder regarded as a discriminator could obtain an more stable training process. Experiments show that our model achieves the state-of-the-art results on MNIST and CIFAR10 datasets as well as GTSRB stop signs dataset.",
        "publication_year": "2020",
        "authors": [
            "Chengwei Chen",
            "Pan Chen",
            "Haichuan Song",
            "Y. Tao",
            "Yuan Xie",
            "Shouhong Ding",
            "Lizhuang Ma"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "17",
        "references": [
            "/paper/Anomaly-Detection-with-Adversarial-Dual-Vu-Ueta/1856809b8bcd0ba7b2c294201718018ead419cb7",
            "/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a",
            "/paper/q-Space-Novelty-Detection-with-Variational-Vasilev-Golkov/68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/Decision-Based-Adversarial-Attacks%3A-Reliable-Models-Brendel-Rauber/1b225474e7a5794f98cdfbde8b12ccbc56799409",
            "/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d",
            "/paper/BEGAN%3A-Boundary-Equilibrium-Generative-Adversarial-Berthelot-Schumm/aa6f7ad0a06b52a8be89dbd8d056561418276ff2",
            "/paper/Energy-based-Generative-Adversarial-Network-Zhao-Mathieu/2ba23d9b46027e47b4483243871760e315213ffe",
            "/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214"
        ]
    },
    {
        "id": "320c6bf28a2a8e2cab7aa7b491708b522f99a4b6",
        "title": "Improving Fraud Detection via Hierarchical Attention-based Graph Neural Network",
        "abstract": "Semantic Scholar extracted view of \"Improving Fraud Detection via Hierarchical Attention-based Graph Neural Network\" by Yajing Liu et al.",
        "publication_year": "2022",
        "authors": [
            "Yajing Liu",
            "Zhengya Sun",
            "Wensheng Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "50",
        "references": [
            "/paper/HITS-GNN%3A-A-Simplified-Propagation-Scheme-for-Graph-Khan-Mello/33e7f916daef8d17427a08b992ba7c6044f445c4",
            "/paper/Medicare-fraud-detection-using-graph-neural-Yoo-Shin/9e11c6037664b9ed4968caca85b342dc49924e02",
            "/paper/Fraud-detection-on-multi-relation-graphs-via-and-Wang-Liu/3407dd5a763b6afc1898bfe8f377ecdeedcb6e4d",
            "/paper/Enhancing-Graph-Neural-Network-based-Fraud-against-Dou-Liu/14156438bafed28a626738630b5181b83ed5d79c",
            "/paper/Alleviating-the-Inconsistency-Problem-of-Applying-Liu-Dou/8cf8e7fe56f26e9e811cf409e1ceeb7c9d7fb60b",
            "/paper/A-Semi-Supervised-Graph-Attentive-Network-for-Fraud-Wang-Qi/0353c467cb380025d8ef927996436b8e9cfedccc",
            "/paper/Pick-and-Choose%3A-A-GNN-based-Imbalanced-Learning-Liu-Ao/7487499f91f0c198347a8ebc747ad8d220bdd155",
            "/paper/Cash-Out-User-Detection-Based-on-Attributed-Network-Hu-Zhang/e96899777544e9494ccae0536f77e693bb8ace2a",
            "/paper/Towards-Anomaly-resistant-Graph-Neural-Networks-via-Ding-Shan/9c0fc1e5503c12f8487d40859ebc1f4cf1a3b5f5",
            "/paper/A-Synergistic-Approach-for-Graph-Anomaly-Detection-Zhao-Jiang/6000cda023f9e096f3692df94c3f17a98e0c030b",
            "/paper/Intention-aware-Heterogeneous-Graph-Attention-for-Liu-Sun/27313cb7a36d419b49b6c81b39d815c9b660bfef",
            "/paper/FdGars%3A-Fraudster-Detection-via-Graph-Convolutional-Wang-Wen/3bfdb516a68eced068701ac6ade535300da1d2f5",
            "/paper/Heterogeneous-Graph-Neural-Networks-for-Malicious-Liu-Chen/a5b5dde1da8ac8d9247a32172f76d5d1831309a0"
        ]
    },
    {
        "id": "9e4dda9d146c8b0afe3075810584d99313558aaa",
        "title": "Magnetic Tile Surface Defect Detection Methodology Based on Self-Attention and Self-Supervised Learning",
        "abstract": "An efficient multihead self-attention method which can automatically locate single or multiple defect areas of magnetic tile and extract features of the magnetic tile defects is proposed and the experimental results show that the features extracted by the SSL method can get richer and more detailed features than the supervised learning model gets. As the core component of permanent magnet motor, the magnetic tile defects seriously affect the quality of industrial motor. Automatic recognition of the surface defects of the magnetic tile is a difficult job since the patterns of the defects are complex and diverse. The existing defect recognition methods result in difficulty in practical application due to the complicated system structure and the low accuracy of the image segmentation and the target detection for the diversity of the defect patterns. A self-supervised learning (SSL) method, which benefits from its nonlinear feature extraction performance, is proposed in this study to improve the existing approaches. We proposed an efficient multihead self-attention method, which can automatically locate single or multiple defect areas of magnetic tile and extract features of the magnetic tile defects. We also designed an accurate full-connection classifier, which can accurately classify different defects of magnetic tile defects. A knowledge distillation process without labeling is proposed, which simplifies the self-supervised training process. The process of our method is as follows. A feature extraction model consists of standard vision transformer (ViT) backbone, which is trained by contrast learning without labeled dataset that is used to extract global and local features from the input magnetic tile images. Then, we use a full-connection neural network, which is trained by using labeled dataset to classify the known defect types. Finally, we combined the feature extraction model and defect classification model together to form a relatively simple integrated system. The public magnetic tile surface defect dataset, which holds 5 defect categories and 1 nondefect category, is used in the process of training, validating, and testing. We also use online data augmentation techs to increase training samples to make the model converge and achieve high classification accuracy. The experimental results show that the features extracted by the SSL method can get richer and more detailed features than the supervised learning model gets. The composite model reaches to a high testing accuracy of 98.3%, and gains relatively strong robustness and good generalization ability.",
        "publication_year": "2022",
        "authors": [
            "Xufeng Ling",
            "Yapeng Wu",
            "Rahman Ali",
            "Huaizhong Zhu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "33",
        "references": [
            "/paper/A-Lightweight-Transfer-Learning-Model-with-Pruned-Huang-Zhou/d8a3a938740f235201d7b76fa27740a04576460e",
            "/paper/An-Self-supervised-Learning-%26-Self-attention-Based-Zhou-Ling/18a018f49ec9862a4d38e80bf67245071c4d022d",
            "/paper/A-Survey-of-Surface-Defect-Detection-of-Industrial-Jin-Chen/2a719e05f9fab58bad6c461e77ac4d315e84abe7",
            "/paper/Automated-surface-defect-detection-framework-using-Singh-Desai/06a0ecac6c017a543982d7010cba7f925d4b6815",
            "/paper/A-Multitarget-Visual-Attention-Based-Algorithm-on-Xu-Shi/25858fefef01c7d81995afc69af3a7929dd02240",
            "/paper/A-Pavement-Crack-Detection-Method-Based-on-and-HFS-Li-Wen/ca048414792249a0a5cc04b328d8fc0f82c24eac",
            "/paper/Objects-Classification-by-Learning-Based-Visual-and-Li-Zhao/19d11ac87bf1894572fc5adc92861ff157bb9387",
            "/paper/Emerging-Properties-in-Self-Supervised-Vision-Caron-Touvron/ad4a0938c48e61b7827869e4ac3baffd0aefab35",
            "/paper/Set-Transformer%3A-A-Framework-for-Attention-based-Lee-Lee/512b8ef0002e0bfd0ecb5ab17d533c1762eb9786",
            "/paper/Self-Supervised-Visual-Feature-Learning-With-Deep-A-Jing-Tian/4c94ee7df6bc2bfcac76703be4f059a79010f7e5",
            "/paper/Unsupervised-Pre-Training-of-Image-Features-on-Data-Caron-Bojanowski/37c59035e9985cda2321b2bdcb4849335210ac85"
        ]
    },
    {
        "id": "d17df33c9b6453d61d01353e94592f1757caee8a",
        "title": "DeSTSeg: Segmentation Guided Denoising Student-Teacher for Anomaly Detection",
        "abstract": "An improved model called DeSTSeg, which integrates a pre-trained teacher network, a denoising student encoder-decoder, and a segmentation network into one framework, is proposed, which achieves state-of-the-art performance. Visual anomaly detection, an important problem in computer vision, is usually formulated as a one-class classification and segmentation task. The student-teacher (S-T) framework has proved to be effective in solving this challenge. However, previous works based on S-T only empirically applied constraints on normal data and fused multi-level information. In this study, we propose an improved model called DeSTSeg, which integrates a pre-trained teacher network, a denoising student encoder-decoder, and a segmentation network into one framework. First, to strengthen the constraints on anomalous data, we introduce a denoising procedure that allows the student network to learn more robust representations. From synthetically corrupted normal images, we train the student network to match the teacher network feature of the same images without corruption. Second, to fuse the multi-level S-T features adaptively, we train a segmentation network with rich supervision from synthetic anomaly masks, achieving a substantial performance improvement. Experiments on the industrial inspection benchmark dataset demonstrate that our method achieves state-of-the-art performance, 98.6% on image-level AUC, 75.8% on pixel-level average precision, and 76.4% on instance-level average precision.",
        "publication_year": "2022",
        "authors": [
            "Xuan Zhang",
            "Shiyu Li",
            "Xi Li",
            "Ping-Chia Huang",
            "Jiulong Shan",
            "Ting Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "42",
        "references": [
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/No-Free-Lunch%3A-The-Hazards-of-Over-Expressive-in-Reiss-Cohen/9b09c3424456c587aa8239d108116d1e2afd4992",
            "/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "/paper/Student-Teacher-Feature-Pyramid-Matching-for-Wang-Han/931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "/paper/Reconstruction-Student-with-Attention-for-Pyramid-Yamada-Hotta/6517f92d519fc126cc18924231bafd8945a554d1",
            "/paper/CutPaste%3A-Self-Supervised-Learning-for-Anomaly-and-Li-Sohn/78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "/paper/AnoSeg%3A-Anomaly-Segmentation-Network-Using-Learning-Song-Kong/d08775cf2bebcffa05c6fa506f687ef56953f128",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Inpainting-Transformer-for-Anomaly-Detection-Pirnay-Chai/19862af96b6af51e879e6e3f1d3d421af5427005",
            "/paper/Anomaly-Detection-via-Reverse-Distillation-from-Deng-Li/3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596"
        ]
    },
    {
        "id": "cba82aa85450344a37c6004c973ba58004c6d282",
        "title": "Unbiased single-cell morphology with self-supervised vision transformers",
        "abstract": "DINO, a vision-transformer based, self-supervised algorithm, has a remarkable ability for learning rich representations of cellular morphology without manual annotations or any other type of supervision, making it an excellent tool for image-based biological discovery. Accurately quantifying cellular morphology at scale could substantially empower existing single-cell approaches. However, measuring cell morphology remains an active field of research, which has inspired multiple computer vision algorithms over the years. Here, we show that DINO, a vision-transformer based, self-supervised algorithm, has a remarkable ability for learning rich representations of cellular morphology without manual annotations or any other type of supervision. We evaluate DINO on a wide variety of tasks across three publicly available imaging datasets of diverse specifications and biological focus. We find that DINO encodes meaningful features of cellular morphology at multiple scales, from subcellular and single-cell resolution, to multi-cellular and aggregated experimental groups. Importantly, DINO successfully uncovers a hierarchy of biological and technical factors of variation in imaging datasets. The results show that DINO can support the study of unknown biological variation, including single-cell heterogeneity and relationships between samples, making it an excellent tool for image-based biological discovery.",
        "publication_year": "2023",
        "authors": [
            "Michael Doron",
            "T. Moutakanni",
            "Zitong S. Chen",
            "Nikita Moshkov",
            "Mathilde Caron",
            "Hugo Touvron",
            "Piotr Bojanowski",
            "Wolfgang M. Pernice",
            "Juan C. Caicedo"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "82",
        "references": [
            "/paper/Out-of-Distribution-Generalization-via-Style-in-Pernice-Doron/ade6cfe42892f4a9621c6a10e632ae283cf6885b",
            "/paper/Self-supervision-advances-morphological-profiling-Kim-Adaloglou/7bfc47f93c5b48222cc553883d24a4f0be291328",
            "/paper/High-resolution-genome-wide-mapping-of-truncations-Lazar-Celik/d798d90b55122bede19569e76cce33fb81a7673f",
            "/paper/DINOv2%3A-Learning-Robust-Visual-Features-without-Oquab-Darcet/5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891",
            "/paper/Self-supervision-for-medical-image-classification%3A-Nielsen-Wenderoth/c2d2a9ef2bacc4d73ec659774b855e35d06a30fe",
            "/paper/JUMP-Cell-Painting-dataset%3A-morphological-impact-of-Chandrasekaran-Ackerman/1f96460299f3c74965b4fe8e64c28957ada06c74",
            "/paper/Self-supervised-Distillation-for-Computer-Vision-Goh-Ward/356aeafad108a52a6f8a150c97eb4672cae85c22",
            "/paper/Cut-and-Learn-for-Unsupervised-Object-Detection-and-Wang-Girdhar/c74b5d298cd5fe735f2c8bc18a94f28010a2ccfc",
            "/paper/Self-supervised-vision-transformers-accurately-Pfaendler-Hanimann/e32e2068310f5f525df06518a212525acc256d80",
            "/paper/Integrated-intracellular-organization-and-its-in-Viana-Chen/4300aa6b2938554b0b7dd426e94acc7a1f76ab93"
        ]
    },
    {
        "id": "4dd7d3d93d79fadeb34597d27c2461bd6f9a527d",
        "title": "Robust Normalized Subband Adaptive Filter Algorithm with a Sigmoid-Function-Based Step-Size Scaler and Its Convex Combination Version",
        "abstract": "In this paper, by inserting the logarithm cost function of the normalized subband adaptive filter algorithm with the step-size scaler (SSS-NSAF) into the sigmoid function structure, the proposed sigmoid-function-based SSS-NSAF algorithm yields improved robustness against impulsive interferences and lower steady-state error. In order to identify sparse impulse response further, a series of sparsity-aware algorithms, including the sigmoid L0 norm constraint SSS-NSAF (SL0-SSS-NSAF), sigmoid step-size scaler improved proportionate NSAF (S-SSS-IPNSAF), and sigmoid L0 norm constraint step-size scaler improved proportionate NSAF (SL0-SSS-IPNSAF), is derived by inserting the logarithm cost function into the sigmoid function structure as well as the L0 norm of the weight coefficient vector to act as a new cost function. Since the use of the fix step size in the proposed SL0-SSS-IPNSAF algorithm, it needs to make a trade-off between fast convergence rate and low steady-state error. Thus, the convex combination version of the SL0-SSS-IPNSAF (CSL0-SSS-IPNSAF) algorithm is proposed. Simulations in acoustic echo cancellation (AEC) scenario have justified the improved performance of these proposed algorithms in impulsive interference environments and even in the impulsive interference-free condition.",
        "publication_year": "2021",
        "authors": [
            "Zijie Shen",
            "Lin Tang",
            "Li Yang"
        ],
        "related_topics": [
            "Engineering"
        ],
        "citation_count": 0,
        "reference_count": "38",
        "references": [
            "/paper/Robust-gain-combined-proportionate-normalized-with-Shen-Shi/96d7bd865f90dbac943b40b6c9bd56fec22c6162",
            "/paper/A-Variable-Step-Size-Normalized-Subband-Adaptive-a-Hur-Song/4e81a2fd72000928cb2dc93c1646332b9dd1ee1b",
            "/paper/A-family-of-proportionate-normalized-subband-filter-Abadi-Kadkhodazadeh/5571f56c517c454d76515c849ae89c21a911b3f1",
            "/paper/Two-variants-of-the-sign-subband-adaptive-filter-Ni-Chen/f996114a22f29227ca147c4bdf378f1f359d7786",
            "/paper/Robust-variable-step-size-sign-subband-adaptive-Wen-Zhang/e87f942b9b37a4fcb1bd7799f7823def5bf7c37f",
            "/paper/Sign-subband-adaptive-filter-with-%E2%84%931-norm-variable-Kim-Chang/417bd43e223b77b8d622d2f729727f264c9d19ee",
            "/paper/Sparsity-aware-SSAF-algorithm-with-individual-and-Yu-Yang/7b2ab099ec4b6e07ec330c352387337ec48af6e4",
            "/paper/M-Estimate-Based-Normalized-Subband-Adaptive-Filter-Yu-He/1d389fb433bdda22cfb604010b0bc9e900d61b68",
            "/paper/A-family-of-robust-adaptive-filtering-algorithms-on-Huang-Zhang/1ad02c229f464e7e3db8447fb124f9853cc0cb2e",
            "/paper/Subband-Adaptive-Filtering-with-Norm-Constraint-for-Choi/60a603f4e1486514c96380504e580ac7a2996e23",
            "/paper/%24%24L_%7B0%7D%24%24L0-norm-constraint-normalized-logarithmic-Shen-Huang/bed4e2c6ad4f9754192e3fa9b84b8a96c40e7522"
        ]
    },
    {
        "id": "53599f3748b73f5d3bbddab646905b5b8e7d3210",
        "title": "Anomaly Detection in Video Sequence With Appearance-Motion Correspondence",
        "abstract": "A deep convolutional neural network that addresses this problem by learning a correspondence between common object appearances and their associated motions by designed as a combination of a reconstruction network and an image translation model that share the same encoder. Anomaly detection in surveillance videos is currently a challenge because of the diversity of possible events. We propose a deep convolutional neural network (CNN) that addresses this problem by learning a correspondence between common object appearances (e.g. pedestrian, background, tree, etc.) and their associated motions. Our model is designed as a combination of a reconstruction network and an image translation model that share the same encoder. The former sub-network determines the most significant structures that appear in video frames and the latter one attempts to associate motion templates to such structures. The training stage is performed using only videos of normal events and the model is then capable to estimate frame-level scores for an unknown input. The experiments on 6 benchmark datasets demonstrate the competitive performance of the proposed approach with respect to state-of-the-art methods.",
        "publication_year": "2019",
        "authors": [
            "Trong-Nguyen Nguyen",
            "J. Meunier"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "217",
        "reference_count": "57",
        "references": [
            "/paper/Joint-Representation-Learning-for-Anomaly-Detection-Saypadith-Onoye/8ad02e32318ec54c1918b5f99280ef0a6fd6b8c5",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/Anomaly-Detection-in-Surveillance-Videos-via-Frame-Yang-Li/74863ff04ca4654d5c2861f5d8d85dc488eb65cc",
            "/paper/Anomaly-Detection-in-Surveillance-Videos-by-Future-Vu-Ambellouis/0a7fbc80202b255fa8c57fe5a295ba948b24e1a7",
            "/paper/Appearance-Motion-Memory-Consistency-Network-for-Cai-Zhang/08c4fa2132dda85c5f02a88fddfb7f17973f3978",
            "/paper/Object-Class-Aware-Video-Anomaly-Detection-through-Baradaran-Bergevin/be089bf77c9df64e2ef258a50f29924949f08aa2",
            "/paper/Predicting-Next-Local-Appearance-for-Video-Anomaly-Roy-Bilodeau/b441bc847e30a6b018f45a3d04071cd13f85eb5e",
            "/paper/Video-anomaly-detection-with-spatio-temporal-Chang-Tu/2e6088d5f1081f2b46295d8783a5c2642ec35041",
            "/paper/A-New-Unsupervised-Video-Anomaly-Detection-Using-Taghinezhad-Yazdi/6b1c013e1de3346c4cfe1da631be1a5f61f044c1",
            "/paper/Dual-branch-network-with-memory-for-video-anomaly-Wang-Hu/01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
            "/paper/Detecting-anomalous-events-in-videos-by-learning-of-Xu-Yan/e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d",
            "/paper/Video-Anomaly-Detection-and-Localization-in-Crowded-Gnouma-Ejbali/9b849a35f45a543aa9bbcf71f7c709761a798299",
            "/paper/Deep-Appearance-Features-for-Abnormal-Behavior-in-Smeureanu-Ionescu/992847be33f4bf7afbe66e198cb20a53e00dfa76",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Real-World-Anomaly-Detection-in-Surveillance-Videos-Sultani-Chen/598fe25743f9492c5c1ba30274ea446f65426d85",
            "/paper/Deep-multi-scale-video-prediction-beyond-mean-error-Mathieu-Couprie/17fa1c2a24ba8f731c8b21f1244463bc4b465681",
            "/paper/A-Discriminative-Framework-for-Anomaly-Detection-in-Giorno-Bagnell/84f7f9e121c1285e15cefbfc44bcb3322f73b6aa"
        ]
    },
    {
        "id": "68fc022550246d8b76e41c778c7af926ab60dc5a",
        "title": "Arthrocentesis vs conservative therapy for the management of TMJ disorders: A systematic review and meta-analysis.",
        "abstract": "Semantic Scholar extracted view of \"Arthrocentesis vs conservative therapy for the management of TMJ disorders: A systematic review and meta-analysis.\" by Yingshun Hu et al.",
        "publication_year": "2022",
        "authors": [
            "Yingshun Hu",
            "Siyan Liu",
            "Fang Fang"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "25",
        "references": [
            "/paper/Comparison-of-the-Efficacy-of-Two-Protocol-in-with-Almeida-Botelho/c8341d4d88e3e4ebc0846227d0d6c0ddb7defeb4",
            "/paper/The-hierarchy-of-different-treatments-for-A-network-Al-Moraissi-Wolford/97b9f3eb335071171e145691b04bfb6b6504dea8",
            "/paper/Arthrocentesis-of-the-Temporomandibular-Joint%3A-and-Guarda-Nardini-Almeida/41dcbf158891fb46195555318d1d20f2ddaea2ad",
            "/paper/A-comparison-of-the-outcomes-of-four-minimally-for-Hosgor-Ba%C5%9F/13903ad8d490f4b8eb32b86c281e3edced8707d8",
            "/paper/Arthrocentesis-in-the-management-of-internal-of-the-Briggs-Breik/ad0a00b080b5922ffff97a06f3797b5b7c6f6948",
            "/paper/Arthrocentesis-as-initial-treatment-for-joint-a-Vos-Slater/40929c17a060b665683244f0793bef5574d31afc",
            "/paper/Temporomandibular-Lavage-Versus-Nonsurgical-for-A-Bouchard-Goulet/cd2c9bf3a5715f7b7852309f1bacf4b27d5e4ef4",
            "/paper/Single-puncture-versus-standard-double-needle-for-A-Nagori-Chowdhury/26a3d38bbb5b6235548e9bb5f46496348aa141a4",
            "/paper/Conservative-therapy-versus-arthrocentesis-for-the-Malekzadeh-Cahlin/c06e476580231cc34d17de26de8ba542a3f94d17",
            "/paper/Arthrocentesis-versus-nonsurgical-methods-in-the-of-D%C4%B1ra%C3%A7o%C4%9Flu-Saral/49023ac42bcba3da4f7173ceb8f215588ef78f00",
            "/paper/Effect-of-simultaneous-application-of-and-occlusal-Altaweel-Ismail/5a820db92ba51c624e72dd748cb60004c5056f32"
        ]
    },
    {
        "id": "dea97b27e858cce6cbbde2294688cd3262dd16a6",
        "title": "Angiogenic Potential of Human Adipose-Derived Mesenchymal Stromal Cells in Nanofibrillated Cellulose Hydrogel",
        "abstract": "NFC hydrogel is recommended for future use as an animal-free biomaterial scaffold for hASCs in therapeutic angiogenesis and other cell therapy purposes. Adipose-derived mesenchymal stromal cells (ASCs) hold great potential for cellular therapies by having immunomodulatory behavior and tissue regenerative properties. Due to the capability of ASCs to differentiate into endothelial cells (ECs) and other angiogenic cell types, such as pericytes, ASCs are a highly valuable source for stimulating angiogenesis. However, cellular therapies in tissue engineering have faced challenges in poor survival of the cells after transplantation, which is why a protective biomaterial scaffold is required. In this work, we studied the potential of nanofibrillated cellulose (NFC) hydrogel to be utilized as a suitable matrix for three-dimensional (3D) cell culturing of human-derived ASCs (hASCs) and studied their angiogenic properties and differentiation potential in ECs and pericytes. In addition, we tested the effect of hASC-conditioned medium and stimulation with angiopoietin-1 (Ang-1) on human umbilical vein endothelial cells (HUVECs) to induce blood vessel-type tube formation in NFC hydrogel. The hASCs were successfully 3D cell cultured in NFC hydrogel as they formed spheroids and had high cell viability with angiogenic features. Most importantly, they showed angiogenic potential by having pericyte-like characteristics when differentiated in EC medium, and their conditioned medium improved HUVEC viability and tube formation, which recalls the active paracrine properties. This study recommends NFC hydrogel for future use as an animal-free biomaterial scaffold for hASCs in therapeutic angiogenesis and other cell therapy purposes.",
        "publication_year": "2022",
        "authors": [
            "Elle Koivunotko",
            "Jasmi Snirvi",
            "Arto Merivaara",
            "Riina Harjum\u00e4ki",
            "Swarna Rautiainen",
            "Minna Kelloniemi",
            "K. Kuismanen",
            "S. Miettinen",
            "M. Yliperttula",
            "R. Koivuniemi"
        ],
        "related_topics": [
            "Biology",
            "Engineering",
            "Materials Science"
        ],
        "citation_count": 0,
        "reference_count": "81",
        "references": [
            "/paper/Angiogenic-Effects-and-Crosstalk-of-Adipose-Derived-Rautiainen-Laaksonen/84f24118658a9b4dea4020650945e7ab7d239929",
            "/paper/Porous-Membranes-Promote-Endothelial-of-Stem-Cells-Mazzocchi-Man/098f09b1e29b433b1e1324bd6c6aff4f2f3b3cf0",
            "/paper/Characterization-of-vasculogenic-potential-of-human-Klar-G%C3%BCven/194db7dc4b13a3fc302b7c9daf4aaa67495fba35",
            "/paper/Endothelial-Differentiation-and-Vasculogenesis-by-Park-Kim/c9e1a8cae4b368c25aa146018dd3e9e1b4800cbf",
            "/paper/Wound-healing-effect-of-adipose-derived-stem-cells%3A-Kim-Park/ab5736857e8357744e9a22a08f448bf9118fab74",
            "/paper/Effects-of-FGF-2-on-human-adipose-tissue-derived-in-Kabiri-Esfandiari/514c93fb3492bf3152b906c9e24ea48984dc0b14",
            "/paper/Adipose-Derived-Stem-Cells-in-Bone-Tissue-Useful-Storti-Scioli/15d03ad4ec1e5f37190c9ea6b61c58ad445686de",
            "/paper/Secretion-of-Angiogenic-and-Antiapoptotic-Factors-Rehman-Traktuev/046a7ff4881898e2fd8b2a9c73972873bb66d155",
            "/paper/Nanofibrillar-cellulose-wound-dressing-supports-the-Kiiskinen-Merivaara/cfa55a70b72ef3325e5e37fe3e299cba0ec8e680",
            "/paper/Paracrine-Effects-of-Mesenchymal-Stromal-Cells-in-Wobma-Liu/ab8196e01ec26c905fb123df3fe7df157532d1d8"
        ]
    },
    {
        "id": "58229c28af74d3a0de745aaad0b8d693c197b7c8",
        "title": "Publicly available datasets of breast histopathology H&E whole-slide images: A systematic review",
        "abstract": "This systematic review identified the publicly available datasets of breast H&E stained whole-slide images (WSI) that can be used to develop deep learning algorithms and reported image metadata and characteristics for each dataset to assist researchers in selecting proper datasets for specific tasks in breast cancer computational pathology. Advancements in digital pathology and computing resources have made a significant impact in the field of computational pathology for breast cancer diagnosis and treatment. However, access to high-quality labeled histopathological images of breast cancer is a big challenge that limits the development of accurate and robust deep learning models. In this systematic review, we identified the publicly available datasets of breast H&E stained whole-slide images (WSI) that can be used to develop deep learning algorithms. We systematically searched nine scientific literature databases and nine research data repositories. We found twelve publicly available datasets, containing 5153 H&E WSIs of breast cancer. Moreover, we reported image metadata and characteristics for each dataset to assist researchers in selecting proper datasets for specific tasks in breast cancer computational pathology. In addition, we compiled a list of patch and private datasets that were used in the included articles as a supplementary resource for researchers. Notably, 22% of the included articles utilized multiple datasets, and only 12% of the articles used an external validation set, suggesting that the performance of other developed models may be susceptible to overestimation. The TCGA-BRCA was used in 47.4% of the selected studies. This dataset has a considerable selection bias that can impact the robustness and generalizability of the trained algorithms. There is also a lack of consistent metadata reporting of breast WSI datasets that can be an issue in developing accurate deep learning models, indicating the necessity of establishing explicit guidelines for documenting breast WSI dataset characteristics and metadata.",
        "publication_year": "2023",
        "authors": [
            "M. Tafavvoghi",
            "L. A. Bongo",
            "N. Shvetsov",
            "L. Busund",
            "Kajsa Mollersen Department of Community Medicine",
            "UiT The Arctic University of Norway",
            "Tromso",
            "Norway",
            "Department of Materials Science",
            "Department of Biology"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "164",
        "references": [
            "/paper/BRACS%3A-A-Dataset-for-BReAst-Carcinoma-Subtyping-in-Brancati-Anniciello/02a8883f756f09327cc134970be71db4dd893843",
            "/paper/Clinical-grade-computational-pathology-using-weakly-Campanella-Hanna/addae423490bbe82da4fb2fc265237178686b4e8",
            "/paper/DeepBatch%3A-A-hybrid-deep-learning-model-for-of-in-Zeiser-Costa/2058cecce6832084f853f5eceeab94cbbae88baf",
            "/paper/A-generalized-deep-learning-framework-for-image-and-Khened-Kori/4c4065be13921a0a21aa1417b01acd23ae192a0f",
            "/paper/Deep-computational-pathology-in-breast-cancer.-Duggento-Conti/cd12413a9a90ab802497eb2cd0ba162c38c98182",
            "/paper/BACH%3A-Grand-Challenge-on-Breast-Cancer-Histology-Aresta-Ara%C3%BAjo/2e860259741de4f75311a6af5684510944e29f83",
            "/paper/Resolving-challenges-in-deep-learning-based-of-H%C3%A4gele-Seegerer/a98052e633627ea7aa6eaddb7cae0c2730320f6a",
            "/paper/Accurate-and-reproducible-invasive-breast-cancer-in-Cruz-Roa-Gilmore/d5b91f292c611dea61f6e95b007ae53c2766a5f9",
            "/paper/Characteristics-of-publicly-available-skin-cancer-a-Wen-Khan/376fab5f7886ad389cb341a587796ca4df9ba016",
            "/paper/Similar-image-search-for-histopathology%3A-SMILY-Hegde-Hipp/de23cf4c78ac347066aad7ac0e474cba2b6500dc"
        ]
    },
    {
        "id": "f499dfe48c1886e1bb7a5bf00a29b613f041c9e6",
        "title": "Colon Cancer Diagnosis Based on Machine Learning and Deep Learning: Modalities and Analysis Techniques",
        "abstract": "A comprehensive review of the current studies on colon cancer, classified into deep-learning (DL) and machine- learning (ML) techniques, and their main strengths and limitations are identified. The treatment and diagnosis of colon cancer are considered to be social and economic challenges due to the high mortality rates. Every year, around the world, almost half a million people contract cancer, including colon cancer. Determining the grade of colon cancer mainly depends on analyzing the gland\u2019s structure by tissue region, which has led to the existence of various tests for screening that can be utilized to investigate polyp images and colorectal cancer. This article presents a comprehensive survey on the diagnosis of colon cancer. This covers many aspects related to colon cancer, such as its symptoms and grades as well as the available imaging modalities (particularly, histopathology images used for analysis) in addition to common diagnosis systems. Furthermore, the most widely used datasets and performance evaluation metrics are discussed. We provide a comprehensive review of the current studies on colon cancer, classified into deep-learning (DL) and machine-learning (ML) techniques, and we identify their main strengths and limitations. These techniques provide extensive support for identifying the early stages of cancer that lead to early treatment of the disease and produce a lower mortality rate compared with the rate produced after symptoms develop. In addition, these methods can help to prevent colorectal cancer from progressing through the removal of pre-malignant polyps, which can be achieved using screening tests to make the disease easier to diagnose. Finally, the existing challenges and future research directions that open the way for future work in this field are presented.",
        "publication_year": "2022",
        "authors": [
            "Mai Tharwat",
            "Nehal A. Sakr",
            "Shaker El-Sappagh",
            "Hassan H. Soliman",
            "K. Kwak",
            "M. Elmogy"
        ],
        "related_topics": [
            "Computer Science",
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "131",
        "references": [
            "/paper/Using-DUCK-Net-for-polyp-image-segmentation-Dumitru-Peteleaza/bb61e505ea1f874f3590d69706eabc4c72009403",
            "/paper/Lung-and-colon-cancer-classification-using-medical-Chehade-Abdallah/e141f55115793d217f3dc3338a7f75b85af108e8",
            "/paper/A-comprehensive-review-of-deep-learning-in-colon-Pacal-Karabo%C4%9Fa/8e932280b044b5ad33d6eeb658e49ece909bcbe9",
            "/paper/Machine-Learning-based-Lung-and-Colon-Cancer-using-Talukder-Islam/0e67255fdec1d4f463d05380064058f960f0e69e",
            "/paper/A-Machine-Learning-Approach-to-Diagnosing-Lung-and-Masud-Sikder/ccd16a7f755c3a1691d4596e1e0acecb25f6eedf",
            "/paper/Colon-cancer-prediction-on-histological-images-deep-Babu-Singh/9118bea7ba8e1b681ba33dfbc4438bed7f8a3da3",
            "/paper/Deep-Learning-on-Histopathological-Images-for-A-Davri-Birbas/5aa3760a3000b6966f01850f4535c166f7ebda5e",
            "/paper/Detection-of-effective-genes-in-colon-cancer%3A-A-Fahami-Roshanzamir/1bacb6a55aa540f1bf974589235212fcd20dc0f8",
            "/paper/Predicting-survival-from-colorectal-cancer-slides-A-Kather-Krisam/a4eb7cc590b65e6be34fb74a4568d661385f28a2",
            "/paper/Deep-learning-for-colon-cancer-histopathological-Hamida-Devanne/6184e4069b8dc3d70af4b93aaa1868a2edf2ac61",
            "/paper/A-Recent-Survey-on-Colon-Cancer-Detection-Rathore-Hussain/93025dd25a580daa07af2caae14f6cc356fbe985"
        ]
    },
    {
        "id": "aae20d8092ebd15d73cdcdf89a331bb689c947ce",
        "title": "StructToken : Rethinking Semantic Segmentation with Structural Prior",
        "abstract": "This paper presents a new paradigm for semantic segmentation, named structure-aware extraction, which generates the segmentation results via the interactions between a set of learned structure tokens and the image feature, which aims to progressively extract the structural information of each category from the feature. In previous deep-learning-based methods, semantic segmentation has been regarded as a static or dynamic per-pixel classification task, \\textit{i.e.,} classify each pixel representation to a specific category. However, these methods only focus on learning better pixel representations or classification kernels while ignoring the structural information of objects, which is critical to human decision-making mechanism. In this paper, we present a new paradigm for semantic segmentation, named structure-aware extraction. Specifically, it generates the segmentation results via the interactions between a set of learned structure tokens and the image feature, which aims to progressively extract the structural information of each category from the feature. Extensive experiments show that our StructToken outperforms the state-of-the-art on three widely-used benchmarks, including ADE20K, Cityscapes, and COCO-Stuff-10K.",
        "publication_year": "2022",
        "authors": [
            "Fangjian Lin",
            "Zhanhao Liang",
            "Junjun He",
            "Miao Zheng",
            "Sheng Tian",
            "Kaibing Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "11",
        "reference_count": "59",
        "references": [
            "/paper/Exploring-vision-transformer-layer-choosing-for-Lin-Ma/83dbc15934831ce98a265db526f4c380ce9e04bb",
            "/paper/SegViT%3A-Semantic-Segmentation-with-Plain-Vision-Zhang-Tian/e92a62da0ab6b9769f84dd9ea195debd3254243b",
            "/paper/Representation-Separation-for-Semantic-Segmentation-Hong-Pan/9981debf3a3c35f0731732a45ac3d58bb522deab",
            "/paper/SegViTv2%3A-Exploring-Efficient-and-Continual-with-Zhang-Liu/e830995cfb0e5d219a0a93ecc037654018eb23fb",
            "/paper/AxWin-Transformer%3A-A-Context-Aware-Vision-Backbone-Lin-Ma/84499860fe6a8d1be31c535be69a3ec38ce9afe9",
            "/paper/PRSeg%3A-A-Lightweight-Patch-Rotate-MLP-Decoder-for-Ma-Lin/ba212ac65a49e92b30e5f46a5d1284faa07b1958",
            "/paper/Transformer-Based-Visual-Segmentation%3A-A-Survey-Li-Ding/d203076c28587895aa344d088b2788dbab5e82a1",
            "/paper/DDP%3A-Diffusion-Model-for-Dense-Visual-Prediction-Ji-Chen/2b50e72ffd2db2915dd1c6bddab710195cc64583",
            "/paper/Vision-Transformer-Adapter-for-Dense-Predictions-Chen-Duan/5598c4ece8ffc69a7eb584d16f6de6629044e76a",
            "/paper/CMX%3A-Cross-Modal-Fusion-for-RGB-X-Semantic-with-Liu-Zhang/31a29fabcfdd7f05995431124f56cede89febae3",
            "/paper/Vision-Transformers-for-Dense-Prediction-Ranftl-Bochkovskiy/8e33914d6051dd031a5e096962b9398fc1d16067",
            "/paper/Attention-is-All-you-Need-Vaswani-Shazeer/204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "/paper/Semantic-Understanding-of-Scenes-Through-the-ADE20K-Zhou-Zhao/88512be44744615f4baa8e14f600f036db4c2433",
            "/paper/Segmenter%3A-Transformer-for-Semantic-Segmentation-Strudel-Pinel/68f080e0ac836ea230cb5316fbed273c70422d75",
            "/paper/Learning-Statistical-Texture-for-Semantic-Zhu-Ji/19c79ca9898266404623312dfbdad9b4331ee051",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/Pyramid-Scene-Parsing-Network-Zhao-Shi/1031a69923b80ad01cf3fbb703d10757a80e699b",
            "/paper/Identity-Mappings-in-Deep-Residual-Networks-He-Zhang/77f0a39b8e02686fd85b01971f8feb7f60971f80",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7"
        ]
    },
    {
        "id": "39c6076a1284324282d6234c033ef1539c959039",
        "title": "SignBERT: Pre-Training of Hand-Model-Aware Representation for Sign Language Recognition",
        "abstract": "This paper introduces the first self-supervised pre-trainable SignBERT with incorporated hand prior for SLR, and attempts to incorporate hand prior in a model-aware method to better model hierarchical context over the hand sequence. Hand gesture serves as a critical role in sign language. Current deep-learning-based sign language recognition (SLR) methods may suffer insufficient interpretability and overfitting due to limited sign data sources. In this paper, we introduce the first self-supervised pre-trainable SignBERT with incorporated hand prior for SLR. Sign-BERT views the hand pose as a visual token, which is derived from an off-the-shelf pose extractor. The visual tokens are then embedded with gesture state, temporal and hand chirality information. To take full advantage of available sign data sources, SignBERT first performs self-supervised pre-training by masking and reconstructing visual tokens. Jointly with several mask modeling strategies, we attempt to incorporate hand prior in a model-aware method to better model hierarchical context over the hand sequence. Then with the prediction head added, SignBERT is fine-tuned to perform the downstream SLR task. To validate the effectiveness of our method on SLR, we perform extensive experiments on four public benchmark datasets, i.e., NMFs-CSL, SLR500, MSASL and WLASL. Experiment results demonstrate the effectiveness of both self-supervised learning and imported hand prior. Furthermore, we achieve state-of-the-art performance on all benchmarks with a notable gain.",
        "publication_year": "2021",
        "authors": [
            "Hezhen Hu",
            "Weichao Zhao",
            "Wen-gang Zhou",
            "Yuechen Wang",
            "Houqiang Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "11",
        "reference_count": "61",
        "references": [
            "/paper/SignBERT%2B%3A-Hand-model-aware-Self-supervised-for-Hu-Zhao/0fcc797aeed56bcc127476d5b68836dc402021ea",
            "/paper/BEST%3A-BERT-Pre-Training-for-Sign-Language-with-Zhao-Hu/919efc30ab8c45456ab72fb4ebeb5e25f2ad7642",
            "/paper/Self-Emphasizing-Network-for-Continuous-Sign-Hu-Gao/1f55d35e1d1a148898a756cb0380b22fa8878dcb",
            "/paper/Natural-Language-Assisted-Sign-Language-Recognition-Zuo-Wei/6648bbbb7ad41397d315d1c83ac02a39ac875b19",
            "/paper/StepNet%3A-Spatial-temporal-Part-aware-Network-for-Shen-Zheng/dc75e95a9e8d34e450fb910c84c7ca8cb6192e97",
            "/paper/Jointly-Harnessing-Prior-Structures-and-Temporal-Suo-Zheng/bc64a21ee79b730660cfcd51dc656c61f817b5d8",
            "/paper/Continuous-Sign-Language-Recognition-with-Network-Hu-Gao/d9c38e7957c10252cc0e66b20c55d5be615db10d",
            "/paper/Vector-Quantized-Diffusion-Model-with-CodeUnet-for-Xie-Zhang/47d61b881d770818ecb13fc1c45ea036625a3ee6",
            "/paper/P-STMO%3A-Pre-Trained-Spatial-Temporal-Many-to-One-3D-Shan-Liu/8127d7f49663526964ac6c80b49816f88c54568a",
            "/paper/Automatic-dense-annotation-of-large-vocabulary-sign-Momeni-Bull/dd964ffeb47efb9a3691b5d233e02284ee8228a7",
            "/paper/Hand-Model-Aware-Sign-Language-Recognition-Hu-Zhou/832298578168aacc3fb1433296a63dbfa849ee4e",
            "/paper/Pose-based-Sign-Language-Recognition-using-GCN-and-Tunga-Nuthalapati/2e0d7289231dc4b1cd822186690b426810da620b",
            "/paper/BSL-1K%3A-Scaling-up-co-articulated-sign-language-Albanie-Varol/0b2538f9c22273db62b205402864062bf222b68c",
            "/paper/Global-Local-Enhancement-Network-for-NMF-Aware-Sign-Hu-Zhou/9023437b9bfb741094f9ff50323093573c9f8e60",
            "/paper/Transferring-Cross-Domain-Knowledge-for-Video-Sign-Li-Yu/efe28238909dc5c1877297fa830d85e9daecc29f",
            "/paper/Attention-Based-3D-CNNs-for-Large-Vocabulary-Sign-Huang-Zhou/91a8da0d5429b0be63b2495587908d4583931ab5",
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e",
            "/paper/Word-level-Deep-Sign-Language-Recognition-from-A-Li-Rodriguez-Opazo/874063b6c71aef8382eb66a66d8a1c1188e78a9a",
            "/paper/Fully-Convolutional-Networks-for-Continuous-Sign-Cheng-Yang/6af09da568edee80075ec610f431ffa91bfce061",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f"
        ]
    },
    {
        "id": "86fe4904650db35c8e33da4deda7a66ff0e41455",
        "title": "Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI",
        "abstract": "This paper proposes a method that reformulates the generation task of diffusion models as a patch-based estimation of healthy brain anatomy, using spatial context to guide and improve reconstruction. The use of supervised deep learning techniques to detect pathologies in brain MRI scans can be challenging due to the diversity of brain anatomy and the need for annotated data sets. An alternative approach is to use unsupervised anomaly detection, which only requires sample-level labels of healthy brains to create a reference representation. This reference representation can then be compared to unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To accomplish this, generative models are needed to create anatomically consistent MRI scans of healthy brains. While recent diffusion models have shown promise in this task, accurately generating the complex structure of the human brain remains a challenge. In this paper, we propose a method that reformulates the generation task of diffusion models as a patch-based estimation of healthy brain anatomy, using spatial context to guide and improve reconstruction. We evaluate our approach on data of tumors and multiple sclerosis lesions and demonstrate a relative improvement of 25.1% compared to existing baselines.",
        "publication_year": "2023",
        "authors": [
            "Finn Behrendt",
            "Debayan Bhattacharya",
            "Julia Kruger",
            "R. Opfer",
            "A. Schlaefer"
        ],
        "related_topics": [
            "Medicine",
            "Computer Science"
        ],
        "citation_count": "4",
        "reference_count": "41",
        "references": [
            "/paper/Unsupervised-Anomaly-Detection-in-Medical-Images-Iqbal-Khalid/a77ca914695d2989aec40b9d85351b2b021ffa6f",
            "/paper/Diffusion-models-in-medical-imaging%3A-A-survey.-Kazerouni-Aghdam/ca9adbc1fa8919d8cb7e3aa58d622e069131b60b",
            "/paper/Diffusion-Models-for-Medical-Image-Analysis%3A-A-Kazerouni-Aghdam/b57b8b6b8052bf2e7f6fe5c8e91cdcb385b75ab6",
            "/paper/Mask%2C-Stitch%2C-and-Re-Sample%3A-Enhancing-Robustness-Bercea-Neumayr/71ff5bb5b6206cfda2790627cc446fe1fcc03bab",
            "/paper/Autoencoders-for-Unsupervised-Anomaly-Segmentation-Baur-Denner/d82800c79dd335297336fe10b1a60d47706e4296",
            "/paper/Scale-Space-Autoencoders-for-Unsupervised-Anomaly-Baur-Wiestler/673377fa6f2cd6f013c095b3e4c05ce48482ab38",
            "/paper/Three-dimensional-deep-learning-with-spatial-for-in-Bengs-Behrendt/1fbbe6fcf6465bab87b9ae55bc5fd23c528f24b9",
            "/paper/Unsupervised-Detection-of-Lesions-in-Brain-MRI-Chen-Konukoglu/83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476",
            "/paper/Fast-Unsupervised-Brain-Anomaly-Detection-and-with-Pinaya-Graham/bacfa58d33e53efc40bffd87094f8731371277f2",
            "/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "/paper/Unsupervised-Region-Based-Anomaly-Detection-In-MRI-Nguyen-Feldman/cb3d43139c682518b1e05e64df6239b7c26527ff",
            "/paper/Denoising-Autoencoders-for-Unsupervised-Anomaly-in-Kascenas-Pugeault/988a5fc8111bcb15aaa4b9f220b49872b005ead3",
            "/paper/Bayesian-Skip-Autoencoders-for-Unsupervised-Anomaly-Baur-Wiestler/2a64030d34abc67343bbacdcdb0748d104203a32",
            "/paper/Challenging-Current-Semi-supervised-Anomaly-Methods-Meissen-Kaissis/13c1e50d2bd916e6d33987d29acbe7ef57c6e9a7"
        ]
    },
    {
        "id": "19a9461fc7f4289eb8d7d306c0f8fdbffceb1f3a",
        "title": "Automated Cerebral Vessel Segmentation of Magnetic Resonance Imaging in Patients with Intracranial Atherosclerotic Diseases",
        "abstract": "While BRAVE-NET consistently reported higher precision, DeepMedic generally overpredicted and could better visualize the smaller and distal arteries, which could accelerate the translation of vessel status-based biomarkers into the clinical setting. Time-of-flight (TOF) magnetic resonance angiography is a non-invasive imaging modality for the diagnosis of intracranial atherosclerotic diseases (ICAD). Evaluation of the degree of the stenosis and status of posterior and anterior communicating arteries to supply enough blood flow to the distal arteries is very critical, which requires accurate evaluation of arteries. Recently, deep-learning methods have been firmly established as a robust tool in medical image segmentation, which has been resulted in developing multiple customized algorithms. For instance, BRAVE-NET, a context-based successor of U-Net\u2014has shown promising results in MRA cerebrovascular segmentation. Another widely used context-based 3D CNN\u2014DeepMedic\u2014has been shown to outperform U-Net in cerebrovascular segmentation of 3D digital subtraction angiography. In this study, we aim to train and compare the two state-of-the-art deep-learning networks, BRAVE-NET and DeepMedic, for automated and reliable brain vessel segmentation from TOF-MRA images in ICAD patients. Using specially labeled data\u2014labeled on TOF MRA and corrected on high-resolution black-blood MRI, of 51 patients with ICAD due to severe stenosis, we trained and tested both models. On an independent test dataset of 11 cases, DeepMedic slightly outperformed BRAVE-NET in terms of DSC (0.905\u00b10.012 vs 0.893\u00b10.015, p: 0.539) and 95HD (0.754\u00b10.223 vs 1.768\u00b10.609, p: 0.134), and significantly outperformed BRAVE-NET in terms of Recall (0.940\u00b10.023 vs 0.855\u00b10.030, p: 0.036). Qualitative assessment confirmed the superiority of DeepMedic in capturing the small and distal arteries. While BRAVE-NET consistently reported higher precision, DeepMedic generally overpredicted and could better visualize the smaller and distal arteries. In future studies, ensemble models that can leverage best of both should be developed and tested on larger datasets.Clinical Relevance\u2014 This study helps elevate the state-of-the-art for brain vessel segmentation from non-invasive MRA, which could accelerate the translation of vessel status-based biomarkers into the clinical setting.",
        "publication_year": "2021",
        "authors": [
            "T. Patel",
            "N. Pint\u00e9r",
            "S. Sarayi",
            "A. Siddiqui",
            "V. Tutino",
            "H. Rajabzadeh-Oghaz"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "2",
        "reference_count": "13",
        "references": [
            "/paper/Evaluating-a-3D-deep-learning-pipeline-for-cerebral-Patel-Patel/efe77e08cf7133628cf15d74d7489b27d02a2e18",
            "/paper/Brain-Vessel-Segmentation-Using-Deep-Learning%E2%80%94A-Goni-Ruhaiyem/58b5d5173a31f0c7c9960fd3d006d1f7d11d2b45",
            "/paper/BRAVE-NET%3A-Fully-Automated-Arterial-Brain-Vessel-in-Hilbert-Madai/8654c84f172e436081a973f1b500e4ac449a0bc0",
            "/paper/Multi-resolution-CNN-for-brain-vessel-segmentation-Patel-Paliwal/636caf10552e22e855ddd1855a55a6036267891c",
            "/paper/A-U-Net-Deep-Learning-Framework-for-High-Vessel-in-Livne-Rieger/907d6d24ddf4a74491f611be6fb57fd102c6d9b0",
            "/paper/A-review-of-3D-vessel-lumen-segmentation-Models%2C-Lesage-Angelini/294dd05a7c0077d33936b89f7c918967a622762f",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/IterNet%3A-Retinal-Image-Segmentation-Utilizing-in-Li-Verma/2576cae4e65d8b4853fd371289e2916417c74587",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Efficient-multi%E2%80%90scale-3D-CNN-with-fully-connected-Kamnitsas-Ledig/7c2bcf6f32b05a04cd3444c030db743e5666af88",
            "/paper/Intravascular-Imaging-and-Computer-Assisted-and-of-Cardoso-Arbel/441281c07b5e5949aeb56375e25623ddbdab94f4",
            "/paper/Atherosclerotic-intracranial-arterial-stenosis%3A-and-Holmstedt-Turan/691d10c5c69466e43a0d93f8e442f8f8915f6bc7"
        ]
    },
    {
        "id": "05a942d2d585b44a47a511802a3f0cc2e40f03d5",
        "title": "Digital Patient-Reported Outcome Measures Assessing Health-Related Quality of Life in Skull Base Diseases\u2014Analysis of Feasibility and Pitfalls Two Years after Implementation",
        "abstract": "The strategy of conducting digital PROMs appears suitable for assessing HRQoL in skull base diseases and response rates during follow-up tended to be higher both with younger age and after recent surgery. Health-related quality of life (HRQoL) assessment is becoming increasingly important in neurosurgery following the trend toward patient-centered care, especially in the context of skull base diseases. The current study evaluates the systematic assessment of HRQoL using digital patient-reported outcome measures (PROMs) in a tertiary care center specialized in skull base diseases. The methodology and feasibility to conduct digital PROMs using both generic and disease-specific questionnaires were investigated. Infrastructural and patient-specific factors affecting participation and response rates were analyzed. Since August 2020, 158 digital PROMs were implemented in skull base patients presenting for specialized outpatient consultations. Reduced personnel capacity led to significantly fewer PROMs being conducted during the second versus (vs.) the first year after introduction (mean: 0.77 vs. 2.47 per consultation day, p = 0.0002). The mean age of patients not completing vs. those completing long-term assessments was significantly higher (59.90 vs. 54.11 years, p = 0.0136). Follow-up response rates tended to be increased with recent surgery rather than with the wait-and-scan strategy. Our strategy of conducting digital PROMs appears suitable for assessing HRQoL in skull base diseases. The availability of medical personnel for implementation and supervision was essential. Response rates during follow-up tended to be higher both with younger age and after recent surgery.",
        "publication_year": "2023",
        "authors": [
            "C. Steiert",
            "J. Lambeck",
            "T. Grauvogel",
            "J. Beck",
            "J. Grauvogel"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": 0,
        "reference_count": "44",
        "references": [
            "/paper/Incorporating-patient-centered-quality-of-life-for-Savchuk-Jin/6b935a3dde229ddc3f9bb74e1b90050e6e371ca8",
            "/paper/Long-term-health-related-quality-of-life-and-after-Fisher-Najafabadi/7a54197003809bf1a6c7feaef00ce46ccd0ec57f",
            "/paper/Patient-related-and-radiographic-predictors-of-in-Passias-Alas/f5a2edb67b839ed830bce734fee491cca6f45027",
            "/paper/Quality-of-Life-After-Vestibular-Schwannoma-A-of-Bender-Tatagiba/da4fbd5b776eaa044b1b57f1f9bf87dd7b2d8aaf",
            "/paper/Patient-Reported-Outcome-Measures-in-Neurosurgery%3A-Ghimire-Hasegawa/5df2d52a098f3519428455e121d964041491daa8",
            "/paper/Comparison-of-Long-term-Quality-of-Life-Outcomes-in-Robinett-Walz/40698b032912d301afa310e05e5b7409a6dd3660",
            "/paper/Development-and-validation-of-a-patient-centered%2C-Baba-Saha/7f839fb9d6eb09c0620b1d221982cc0600f48721",
            "/paper/Functional-Outcomes-and-Health-Related-Quality-of-Hamer-Klein/c75ccab2a60344b7839ee0a2dd7cabafd2b51d42",
            "/paper/Vestibular-Complaints-Impact-on-the-Long-Term-of-of-Fuentealba-Bassaletti-Neve/16713ba75cf3e5f4e21aef525f5ff6f77093c52c",
            "/paper/Systematic-review-on-the-use-of-patient-reported-in-Dirven-Vos/3b97235b457f5861e7a808894e85eae4ea6355f9"
        ]
    },
    {
        "id": "de3bc68d712eb59c2773af1275a869c6a1210e55",
        "title": "Unsupervised Domain Adaptive Fundus Image Segmentation with Few Labeled Source Data",
        "abstract": "This method has outperformed several state-of-the-art UDA segmentation methods under the UDA fundus segmentation with few labeled source data and a cross-style self-supervised learning stage is designed to improve the segmentation performance on the target images. Deep learning-based segmentation methods have been widely employed for automatic glaucoma diagnosis and prognosis. In practice, fundus images obtained by different fundus cameras vary significantly in terms of illumination and intensity. Although recent unsupervised domain adaptation (UDA) methods enhance the models' generalization ability on the unlabeled target fundus datasets, they always require sufficient labeled data from the source domain, bringing auxiliary data acquisition and annotation costs. To further facilitate the data efficiency of the cross-domain segmentation methods on the fundus images, we explore UDA optic disc and cup segmentation problems using few labeled source data in this work. We first design a Searching-based Multi-style Invariant Mechanism to diversify the source data style as well as increase the data amount. Next, a prototype consistency mechanism on the foreground objects is proposed to facilitate the feature alignment for each kind of tissue under different image styles. Moreover, a cross-style self-supervised learning stage is further designed to improve the segmentation performance on the target images. Our method has outperformed several state-of-the-art UDA segmentation methods under the UDA fundus segmentation with few labeled source data.",
        "publication_year": "2022",
        "authors": [
            "Qian Yu",
            "Dongnan Liu",
            "Chaoyi Zhang",
            "Xinwen Zhang",
            "Weidong (Tom) Cai"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "46",
        "references": [
            "/paper/Unsupervised-Domain-Adaptation-for-Neuron-Membrane-An-Liu/c34889d11513ec621d0aa114d9337da69adaeaa2",
            "/paper/SynthMix%3A-Mixing-up-Aligned-Synthesis-for-Medical-Zhang-Zhang/9afbd717de63f01d8915a0af120b303f222d80b6",
            "/paper/Source-Free-Domain-Adaptive-Fundus-Image-with-Chen-Liu/cb321bc38a6f6135de16436e0f9412d00e028767",
            "/paper/Unsupervised-Instance-Segmentation-in-Microscopy-Liu-Zhang/974ffaf2775a8c32e405c551436a111714a5dc3c",
            "/paper/Unsupervised-Domain-Adaptive-Fundus-Image-with-Feng-Wang/05cdbd30751f649b892cc730d3287d9bd6cca56f",
            "/paper/Boundary-and-Entropy-driven-Adversarial-Learning-Wang-Yu/f2b3de7f036f8f35294d7c8008622f7d3ad2b4eb",
            "/paper/Domain-Adaptive-Nuclei-Instance-Segmentation-and-Li-Liu/66731f14a22a11b1467297e6b1fcedb50ec1377a",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/ECSD-Net%3A-A-joint-optic-disc-and-cup-segmentation-Liu-Pan/9c0e4e03d2c9a2f62ea6b58fc69d9dc03232eec2",
            "/paper/Patch-Based-Output-Space-Adversarial-Learning-for-Wang-Yu/ba62442fc88eb4da204e98899214c45960341fa5",
            "/paper/A-Novel-Domain-Adaptation-Framework-for-Medical-Gholami-Subramanian/58a72b40a3af91f5ecfa934566ef5c288a38aecd",
            "/paper/MT-UDA%3A-Towards-Unsupervised-Cross-modality-Medical-Zhao-Xu/17134a53c9ce22f8b2b9e7f8fefd563f443c213c"
        ]
    },
    {
        "id": "0017ece1f39a0ed3a054697e87bc4d92c52a3658",
        "title": "WiFi CSI Based Passive Human Activity Recognition Using Attention Based BLSTM",
        "abstract": "This paper proposes a new deep learning based approach, i.e., attention based bi-directional long short-term memory (ABLSTM) for passive human activity recognition using WiFi CSI signals, employed to learn representative features in two directions from raw sequential CSI measurements. Human activity recognition can benefit various applications including healthcare services and context awareness. Since human actions will influence WiFi signals, which can be captured by the channel state information (CSI) of WiFi, WiFi CSI based human activity recognition has gained more and more attention. Due to the complex relationship between human activities and WiFi CSI measurements, the accuracies of current recognition systems are far from satisfactory. In this paper, we propose a new deep learning based approach, i.e., attention based bi-directional long short-term memory (ABLSTM), for passive human activity recognition using WiFi CSI signals. The BLSTM is employed to learn representative features in two directions from raw sequential CSI measurements. Since the learned features may have different contributions for final activity recognition, we leverage on an attention mechanism to assign different weights for all the learned features. Real experiments have been carried out to evaluate the performance of the proposed ABLSTM for human activity recognition. The experimental results show that our proposed ABLSTM is able to achieve the best recognition performance for all activities when compared with some benchmark approaches.",
        "publication_year": "2019",
        "authors": [
            "Zhenghua Chen",
            "Le Zhang",
            "Chaoyang Jiang",
            "Zhiguang Cao",
            "Wei Cui"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "191",
        "reference_count": "36",
        "references": [
            "/paper/CSI-Based-Human-Activity-Recognition-using-Neural-Moshiri-Nabati/4406d6b8810965d31b721d59255305d5430b55ef",
            "/paper/WiFi-Sensing-for-Drastic-Activity-Recognition-with-Liu-Li/cd56c698449580467a0e99d7fd95d2c0b87c421c",
            "/paper/WiFi-CSI-Based-Human-Activity-Recognition-Using-Ding-Wang/8024433b38c8051c25b811bcf9b543e1c73f3a29",
            "/paper/Data-Augmentation-and-Dense-LSTM-for-Human-Activity-Zhang-Wu/91bfa0458e09f094e110ca657a3fa10284761e8d",
            "/paper/Towards-CSI-based-diversity-activity-recognition-Guo-Zhang/21242acafa3cb57e4455bd23868f5598e1a6a804",
            "/paper/Two-Stream-Convolution-Augmented-Transformer-for-Li-Cui/a3196e65467b80f4755968923b382e40c02ccb51",
            "/paper/Utilizing-deep-learning-models-in-CSI-based-human-Shalaby-Elshennawy/aa5069cd1675d513cf874038dc7457cf309e5583",
            "/paper/A-CSI-Based-Human-Activity-Recognition-Using-Deep-Moshiri-Shahbazian/97fd011e2b6f67f5e32575c3f81eb774ef1a6be3",
            "/paper/CSI-Based-Location-Independent-Human-Activity-Using-Zhang-Liu/d88f92840f600f6d35bcf42ad021c1d9be2acc3f",
            "/paper/Using-GAN-to-Enhance-the-Accuracy-of-Indoor-Human-Moshiri-Navidan/5e956e96b93716589884be7a6efe45109b409bc8",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/Device-Free-Human-Activity-Recognition-Using-WiFi-Wang-Liu/f312682ae93523de41a4f1e2bc0ca30e4345c8a4",
            "/paper/Understanding-and-Modeling-of-WiFi-Signal-Based-Wang-Liu/539b28563ecd9fa14be7134bc17ec942958d00db",
            "/paper/WiFi-assisted-human-activity-recognition-Gu-Quan/4cc906f0fcf2f648001db1f6466920a0b11e770b",
            "/paper/Device-Free-Wireless-Localization-and-Activity-A-Wang-Zhang/29f4a957802fa54c5e23a170121e46f5f1e7a49b",
            "/paper/Robust-Human-Activity-Recognition-Using-Smartphone-Chen-Zhu/13b53a507b5849df318cb30fc8971683e2a8ccc1",
            "/paper/E-eyes%3A-device-free-location-oriented-activity-WiFi-Wang-Liu/62efd4e8913ac5c4cd3a771fdd02e5abb51afc30",
            "/paper/A-Survey-on-Human-Activity-Recognition-using-Lara-Labrador/8d3041129b500b90521c7d768996fc2de11b0e47",
            "/paper/Learning-from-less-for-better%3A-semi-supervised-via-Yao-Nie/ce017fea1e01e85d750d2699d597b90885b4be30",
            "/paper/A-Trained-once-Crowd-Counting-Method-Using-WiFi-Domenico-Sanctis/0c94e465c495586a323dfdea9784d747d0bdd318"
        ]
    },
    {
        "id": "7fd052d40660d65c8497599794467812b78e1d0b",
        "title": "A cascade reconstruction model with generalization ability evaluation for anomaly detection in videos",
        "abstract": "Semantic Scholar extracted view of \"A cascade reconstruction model with generalization ability evaluation for anomaly detection in videos\" by Yuanhong Zhong et al.",
        "publication_year": "2022",
        "authors": [
            "Yuanhong Zhong",
            "Xia Chen",
            "Jinyang Jiang",
            "Fan Ren"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "15",
        "reference_count": "39",
        "references": [
            "/paper/Bidirectional-Spatio-Temporal-Feature-Learning-With-Zhong-Chen/9e875a417b411bc2923db87cc1b80df4b705bc1c",
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/Anomaly-Detection-by-Predicting-Future-Frames-using-Patrikar-Parate/a66b466fbea9cc11324b270395f79c7d817e4102",
            "/paper/Hierarchical-Scene-Normality-Binding-Modeling-for-Bao-Liu/0c9add302abbc4efc853fd6766fdf0bb40c91e2b",
            "/paper/Video-Event-Restoration-Based-on-Keyframes-for-Yang-Liu/173cc12234e34d65ee4e9a53d3cddedde7b4b544",
            "/paper/Multi-memory-video-anomaly-detection-based-on-scene-Li-Chen/c5386effca34bdf0a99d97004d72dab8b71dc1b5",
            "/paper/Predicting-skeleton-trajectories-using-a-for-video-Pang-He/e06fff74e048526b5c4141517216216a283c7830",
            "/paper/Predicting-skeleton-trajectories-using-a-for-video-Pang-He/a412398394cdc7a8c11733a2df1ca57a9a884a88",
            "/paper/A-Self-Trained-Spatial-Graph-Convolutional-Network-Li-Chang/dbe1eb127c20920eaaa66d642098be26684930d4",
            "/paper/Efficient-anomaly-recognition-using-surveillance-Saleem-Bajwa/63474535e6e0f1650707dd02c01f6e14d0756a10",
            "/paper/Integrating-prediction-and-reconstruction-for-Tang-Zhao/fe09f7a379944444201552e952b910188c0aeaca",
            "/paper/Attention-Driven-Loss-for-Anomaly-Detection-in-Zhou-Zhang/945b53ede48dae40af9870030fc4985a119cd1b8",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/AnoPCN%3A-Video-Anomaly-Detection-via-Deep-Predictive-Ye-Peng/3c439ef038419f9db396628ed9766af568625f31",
            "/paper/Video-anomaly-detection-with-multi-scale-feature-Cai-Liu/d8663556aa1a875dcdc4f15ad1fd31933e724348",
            "/paper/Video-Anomaly-Detection-and-Localization-Based-on-Xu-Sun/32323526b61685d007f4d2a62b23b8669e602fa8",
            "/paper/Spatio-Temporal-Unity-Networking-for-Video-Anomaly-Li-Cai/1be10a34f619e203651036d2609fc0d9780525c5",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210"
        ]
    },
    {
        "id": "d0f56fbe02512194ea7321b50f88094d1ecae214",
        "title": "MVTr: multi-feature voxel transformer for 3D object detection",
        "abstract": "The problem with a multi-feature voxel transformer (MVTr) is resolved, an architecture that extracts long-range relationship features through self-attention between multi- feature voxels and has significant advantages compared to other similar feature fusion-based methods. Convolutional neural networks have become a powerful tool for partial 3D object detection. However, their power has not been fully realized for focusing on global information, which is crucial for object detection. In this paper, we resolve the problem with a multi-feature voxel transformer (MVTr), an architecture that extracts long-range relationship features through self-attention between multi-feature voxels. In general, converting a point cloud to a voxel representation can reduce a lot of computation, but it would take a long process for the attention network to pay attention to the car voxels in a huge 3D real scene. To this end, we propose a semantic voxel module which takes semantic voxels as input and cooperates with a sparse and a non-empty voxel module to extract features. And the semantic voxels are generated from image segmentation and point cloud projection, which only retains a large number of car voxels. To further enlarge the attention range while maintaining a favorable computational, we propose two attention mechanisms for multi-head attention: local attention and stumpy attention. Finally, we propose the fusion attention module, which can add channel attention and spatial attention to the 2D backbone network. MVTr combines the semantic information of the image and the 3D information of the point cloud and can be applied to most 3D object detection tasks. Experimental results on KITTI dataset show that our method is effective, and the precision has significant advantages compared to other similar feature fusion-based methods.",
        "publication_year": "2023",
        "authors": [
            "Lingmei Ai",
            "Zhuoyu Xie",
            "R. Yao",
            "Mengyao Yang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "16",
        "references": [
            "/paper/Voxel-R-CNN%3A-Towards-High-Performance-Voxel-based-Deng-Shi/e216ac339cbb4a8accdc266be8f26b554c37a284",
            "/paper/DVFENet%3A-Dual-branch-voxel-feature-extraction-for-He-Xia/fb675e55eb7abe9be5009fa57d0114a85f324afc",
            "/paper/SARPNET%3A-Shape-attention-regional-proposal-network-Ye-Chen/86c613cff08dccc6c69eb204b27390f1b7bf3797",
            "/paper/3D-Object-Detection-Using-Scale-Invariant-and-Zhao-Liu/6f4d8061c5491335f83d238c4917edccfce7d15b",
            "/paper/TANet%3A-Robust-3D-Object-Detection-from-Point-Clouds-Liu-Zhao/d8fc74db276e3f2630fcf95e26b0f82ab73d3d87",
            "/paper/SECOND%3A-Sparsely-Embedded-Convolutional-Detection-Yan-Mao/5125a16039cabc6320c908a4764f32596e018ad3",
            "/paper/A-survey-on-Deep-Learning-based-Panoptic-Li-Chen/d8dbaf83fc2b82269221e391e280491659d43315",
            "/paper/Blind-light-field-image-quality-assessment-by-Cui-Yu/aec826fccf6eb25fb34a6564d21ec1df0513ee9f",
            "/paper/Positioning-and-perception-in-LIDAR-point-clouds-Benedek-Majdik/64a9e7b3d5260e496c6ab857368483245ae85627",
            "/paper/ResNeXt-convolution-neural-network-topology-based-Pant-Yadav/b59ae9c7700374fbda35c2be278a745896f1c55a"
        ]
    },
    {
        "id": "1856809b8bcd0ba7b2c294201718018ead419cb7",
        "title": "Anomaly Detection with Adversarial Dual Autoencoders",
        "abstract": "A GAN-based anomaly detection framework that consists of two autoencoders as generator and discriminator to increase training stability and employ discriminator reconstruction error as anomaly score for better detection performance is introduced. Semi-supervised and unsupervised Generative Adversarial Networks (GAN)-based methods have been gaining popularity in anomaly detection task recently. However, GAN training is somewhat challenging and unstable. Inspired from previous work in GAN-based image generation, we introduce a GAN-based anomaly detection framework - Adversarial Dual Autoencoders (ADAE) - consists of two autoencoders as generator and discriminator to increase training stability. We also employ discriminator reconstruction error as anomaly score for better detection performance. Experiments across different datasets of varying complexity show strong evidence of a robust model that can be used in different scenarios, one of which is brain tumor detection.",
        "publication_year": "2019",
        "authors": [
            "Ha Son Vu",
            "D. Ueta",
            "Kiyoshi Hashimoto",
            "Kazuki Maeno",
            "Sugiri Pranata",
            "S. Shen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "28",
        "reference_count": "19",
        "references": [
            "/paper/Anomaly-Detection-by-Latent-Regularized-Dual-Chen-Chen/06f565d668b77fb4cd228d497b86d70a44ca44e7",
            "/paper/Double-Adversarial-Activation-Anomaly-Detection%3A-Schulze-Sperl/ba1d8720d23d467fc44d6adae9c7216b815b6281",
            "/paper/Anomaly-Detection-by-One-Class-Latent-Regularized-Chen-Chen/a17a7926dc5ec33a36e0a3f1eda86a1404f458cd",
            "/paper/Robust-Semi-Supervised-Anomaly-Detection-via-Noise-Barker-Bhowmik/69244cd6455392f7eb0dec90119d5c689ee6f1ba",
            "/paper/Discriminative-Semi-Supervised-Generative-Network-Jiang-Xie/efdfcb7f91330e3d0a41618db01cd5db7c401afd",
            "/paper/Machine-Learning-in-NextG-Networks-via-Generative-Ayanoglu-Davaslioglu/63207e9edaf55b24bb587ac0102a128389aead50",
            "/paper/CVAE-AN%3A-Atypical-Attack-Flow-Detection-Using-Sabeel-Shah-Heydari/139cb0307a7b0740006d037b4913378686cd6780",
            "/paper/New-Perspective-on-Progressive-GANs-Distillation-Zhang-Dong/665aef21052fa31d6cbdd2fdfc336bf3b951828e",
            "/paper/Denoising-Adversarial-Autoencoder-for-Obfuscated-Salman-Elhajj/84aadbd2c9a1337e8a9e7b956d19227d232c0786",
            "/paper/PANDA%3A-Perceptually-Aware-Neural-Detection-of-Barker-Breckon/49130e2084f99c59150a86d4f1be6623a694386b",
            "/paper/Efficient-GAN-Based-Anomaly-Detection-Zenati-Foo/b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Context-encoding-Variational-Autoencoder-for-Zimmerer-Kohl/ae97c81b45780dc91e18eb84236d8a40a290b329",
            "/paper/Energy-based-Generative-Adversarial-Network-Zhao-Mathieu/2ba23d9b46027e47b4483243871760e315213ffe",
            "/paper/Generative-adversarial-interpolative-autoencoding%3A-Sainburg-Thielk/5e6668c4163f356ebc25f8e825dde1edb1b9c24a",
            "/paper/BEGAN%3A-Boundary-Equilibrium-Generative-Adversarial-Berthelot-Schumm/aa6f7ad0a06b52a8be89dbd8d056561418276ff2",
            "/paper/Adversarial-Feature-Learning-Donahue-Kr%C3%A4henb%C3%BChl/1db6e3078597386ac4222ba6c3f4f61b61f53539",
            "/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078",
            "/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "/paper/Improved-Techniques-for-Training-GANs-Salimans-Goodfellow/571b0750085ae3d939525e62af510ee2cee9d5ea"
        ]
    },
    {
        "id": "33e7f916daef8d17427a08b992ba7c6044f445c4",
        "title": "HITS-GNN: A Simplified Propagation Scheme for Graph Neural Networks",
        "abstract": "Experimental results demonstrate that the proposed method outperforms baseline methods on graph benchmark datasets with a significant margin for semi-supervised node classification. In recent years, Graph Neural Networks (GNNs) have gained popularity for solving a wide range of problems, primarily due to the proliferation of graph data across various domains. GNNs offer expressive power but are computationally expensive at the same time. Some studies have suggested that altering their traditional message passing mechanism with Personalized PageRank as a propagation scheme reduces the computational complexity, improves performance, and optimizes scalability in semi-supervised learning problems. This paper presents a propagation mechanism based on the Hyperlink-Induced Topic Search (HITS) algorithm. The HITS-based approach propagates information in a graph by using a recursive update of authority and hub scores. Using this terminology, Personalized PageRank based propagation considers only in-links, thus, embraces the concept of authority (in-links) scores while ignoring the important concept of hub (out-links), which leads to trailing down some valuable information. According to our approach, a Multi-Layer Perceptron (MLP) is applied in combination with a HITS-based propagation algorithm to separate node prediction and propagation. Experimental results demonstrate that the proposed method outperforms baseline methods on graph benchmark datasets with a significant margin for semi-supervised node classification.",
        "publication_year": "2022",
        "authors": [
            "Mehak Khan",
            "Gustavo B. M. Mello",
            "P. Engelstad",
            "Laurence Habib",
            "A. Yazidi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "34",
        "references": [
            "/paper/Scaling-Graph-Neural-Networks-with-Approximate-Bojchevski-Klicpera/3da4626411d83c19c9919bb41dba94fff88da90e",
            "/paper/Predict-then-Propagate%3A-Graph-Neural-Networks-meet-Klicpera-Bojchevski/ac225094aab9e7b629bc5b3343e026dea0200c70",
            "/paper/Deep-Gaussian-Embedding-of-Graphs%3A-Unsupervised-via-Bojchevski-G%C3%BCnnemann/2b76b6e766547b3c6dbc2785a084ec3b72cb760d",
            "/paper/Improving-Fraud-Detection-via-Hierarchical-Graph-Liu-Sun/320c6bf28a2a8e2cab7aa7b491708b522f99a4b6",
            "/paper/Graph-Attention-Networks-Velickovic-Cucurull/33998aff64ce51df8dee45989cdca4b6b1329ec4",
            "/paper/Node-Classification-and-Link-Prediction-in-Social-Molokwu-Shuvo/8eef32d2f75604fc829a169d671b08fb48fff947",
            "/paper/SNAP%3A-A-General-Purpose-Network-Analysis-and-Leskovec-Sosi%C4%8D/10aa9ee7caaf9381b6a0468ae899a9729824a6b7",
            "/paper/Enhancing-Graph-Neural-Networks-via-auxiliary-for-Wu-Song/d2c34737e20d005820abe6f1b82bd191205a87f2",
            "/paper/Ranking-hubs-and-authorities-using-matrix-functions-Benzi-Estrada/53667f0491e2d4c53098ced5bfaf170d359d102c",
            "/paper/HIPRank%3A-Ranking-Nodes-by-Influence-Propagation-on-Zhang-Wang/50cae99cfd6b3ef223107d92f31487bb3dace540"
        ]
    },
    {
        "id": "d8a3a938740f235201d7b76fa27740a04576460e",
        "title": "A Lightweight Transfer Learning Model with Pruned and Distilled YOLOv5s to Identify Arc Magnet Surface Defects",
        "abstract": "A lightweight YOLOv5s-based transfer learning model with network pruning and knowledge distillation that has high accuracy in defect identification applications besides arc magnets and is higher than other regular lightweight models. Surface defects in arc magnets constitute the main culprit for performance degradation and safety hazards in permanent magnet motors. Machine-vision methods offer the possibility to identify surface defects automatically. However, the current methods still do not adequately solve the problems of low identification accuracy, excessive dependency on training data, and sizeable computational complexity. This paper proposes a lightweight YOLOv5s-based transfer learning model with network pruning and knowledge distillation to address these issues. Our model was derived from a pre-trained YOLOv5s for general object detection. A transfer learning mechanism was designed to obtain the optimal surface defect identification accuracy of the model from fewer training samples. Network pruning and knowledge distillation were combined to compress the transferred model. The transferred model serves as the teacher model of knowledge distillation, while its pruned model acts as the student model. To weaken the loss of the accuracy after model compression, a new \u03bb factor was introduced into the confidence loss function of the student model to increase the sensitivity of identifying the defects. The experimental results show that our model\u2019s performance is higher than other regular lightweight models. The identification accuracy for different defective arc magnets could reach 100%, the model size could achieve 1.921 MB, and the average inference time was 9.46 ms. Our model also has high accuracy in other defect identification applications besides arc magnets.",
        "publication_year": "2023",
        "authors": [
            "Qinyuan Huang",
            "Ying Zhou",
            "Tian Yang",
            "Kun Yang",
            "Lijia Cao",
            "Yan Xia"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "41",
        "references": [
            "/paper/A-semi-supervised-learning-method-for-surface-of-Liu-Ye/aac03568de0225fed4a3d46a6fec538ece19a09b",
            "/paper/Segmentation-Method-of-Magnetic-Tile-Surface-Based-An-Lu/e90220e977eff2860667e64dc83e28689733b7d7",
            "/paper/Magnetic-Tile-Surface-Defect-Detection-Methodology-Ling-Wu/9e4dda9d146c8b0afe3075810584d99313558aaa",
            "/paper/ELCNN%3A-A-Deep-Neural-Network-for-Small-Object-of-Liang-Sun/575c64a8bc688162d5648b491e382ff5bcc2f56a",
            "/paper/Knowledge-Distillation%3A-A-Survey-Gou-Yu/1728cb805a9573b59330890ba9723e73d6c3c974",
            "/paper/KDnet-RUL%3A-A-Knowledge-Distillation-Framework-to-Xu-Chen/a32ec5656d7cc05d770f401c78fbca759aa52b08",
            "/paper/Detection-of-Power-Line-Insulator-Defects-Using-Tao-Zhang/b0e5ec93c2648ec25a5afd51dc6ba9f171615abd",
            "/paper/Unsupervised-Defect-Segmentation-of-Magnetic-Tile-Cao-Chen/c9ac3dddef9a4c366bb40376c0bc801a1c7d51ad",
            "/paper/FFCNN%3A-A-Deep-Neural-Network-for-Surface-Defect-of-Xie-Xiang/04a420199b43f5ecdc703aa4e661af802c706218",
            "/paper/Knowledge-Distillation-and-Student-Teacher-Learning-Wang-Yoon/2528a82dd2266600d4ee2b54165556a984de94d4"
        ]
    },
    {
        "id": "ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
        "title": "Efficient Anomaly Detection with Budget Annotation Using Semi-Supervised Residual Transformer",
        "abstract": "A sliding vision transformer is trained over the residuals generated by a novel position-constrained patch-matching, and the conventional pixel-wise segmentation problem is cast into a block-wise classification problem, so that the sliding transformer can attain even higher accuracy with much less annotation labor. Anomaly Detection is challenging as usually only the normal samples are seen during training and the detector needs to discover anomalies on-the-fly. The recently proposed deep-learning-based approaches could somehow alleviate the problem but there is still a long way to go in obtaining an industrial-class anomaly detector for real-world applications. On the other hand, in some particular AD tasks, a few anomalous samples are labeled manually for achieving higher accuracy. However, this performance gain is at the cost of considerable annotation efforts, which can be intractable in many practical scenarios. In this work, the above two problems are addressed in a unified framework. Firstly, inspired by the success of the patch-matching-based AD algorithms, we train a sliding vision transformer over the residuals generated by a novel position-constrained patch-matching. Secondly, the conventional pixel-wise segmentation problem is cast into a block-wise classification problem. Thus the sliding transformer can attain even higher accuracy with much less annotation labor. Thirdly, to further reduce the labeling cost, we propose to label the anomalous regions using only bounding boxes. The unlabeled regions caused by the weak labels are effectively exploited using a highly-customized semi-supervised learning scheme equipped with two novel data augmentation methods. The proposed method outperforms all the state-of-the-art approaches using all the evaluation metrics in both the unsupervised and supervised scenarios. On the popular MVTec-AD dataset, our SemiREST algorithm obtains the Average Precision (AP) of 81.2% in the unsupervised condition and 84.4% AP for supervised anomaly detection. Surprisingly, with the bounding-box-based semi-supervisions, SemiREST still outperforms the SOTA methods with full supervision (83.8% AP) on MVTec-AD.",
        "publication_year": "2023",
        "authors": [
            "Hanxi Li",
            "Jing Wu",
            "Hao Chen",
            "Mingwen Wang",
            "Chunhua Shen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "91",
        "references": [
            "/paper/Self-Supervised-Predictive-Convolutional-Attentive-Ristea-Madan/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "/paper/DeSTSeg%3A-Segmentation-Guided-Denoising-for-Anomaly-Zhang-Li/d17df33c9b6453d61d01353e94592f1757caee8a",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Mixed-supervision-for-surface-defect-detection%3A-to-Bozic-Tabernik/7eb24c2109f75c614cc7aa4c1cac8b643c05e70c",
            "/paper/FastFlow%3A-Unsupervised-Anomaly-Detection-and-via-2D-Yu1-Zheng/11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "/paper/Explicit-Boundary-Guided-Semi-Push-Pull-Contrastive-Yao-Li/62d49fa60b54fed1e2a2cde3cb49d3639db76768",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Patch-SVDD%3A-Patch-level-SVDD-for-Anomaly-Detection-Yi-Yoon/62b77e5cb85fc61b84edd532f6d65714be152596",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/Unsupervised-anomaly-segmentation-via-deep-feature-Shi-Yang/4dd78b8d466b4cfe55a1bbdc694291197ce62541"
        ]
    },
    {
        "id": "ade6cfe42892f4a9621c6a10e632ae283cf6885b",
        "title": "Out of Distribution Generalization via Interventional Style Transfer in Single-Cell Microscopy",
        "abstract": "A new method is introduced, Interventional Style Transfer (IST), that substantially improves OOD generalization by generating interventional training distributions in which spurious correlations between biological causes and nuisances are mitigated. Real-world deployment of computer vision systems, including in the discovery processes of biomedical research, requires causal representations that are invariant to contextual nuisances and generalize to new data. Leveraging the internal replicate structure of two novel single-cell fluorescent microscopy datasets, we propose generally applicable tests to assess the extent to which models learn causal representations across increasingly challenging levels of OOD-generalization. We show that despite seemingly strong performance, as assessed by other established metrics, both naive and contemporary baselines designed to ward against confounding, collapse on these tests. We introduce a new method, Interventional Style Transfer (IST), that substantially improves OOD generalization by generating interventional training distributions in which spurious correlations between biological causes and nuisances are mitigated. We publish our code and datasets.",
        "publication_year": "2023",
        "authors": [
            "Wolfgang M. Pernice",
            "Michael Doron",
            "A. Quach",
            "A. Pratapa",
            "Sultan Kenjeyev",
            "N. Veaux",
            "Michio Hirano",
            "Juan C. Caicedo"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "46",
        "references": [
            "/paper/Unbiased-single-cell-morphology-with-vision-Doron-Moutakanni/cba82aa85450344a37c6004c973ba58004c6d282",
            "/paper/Domain-Generalization-with-MixStyle-Zhou-Yang/4f6eafafc9563a5b904535078df7e74afe39ef59",
            "/paper/Generative-Interventions-for-Causal-Learning-Mao-Gupta/945aa2eb4b7ceecebf0562dfc12fcadb8fd38970",
            "/paper/StarGAN-v2%3A-Diverse-Image-Synthesis-for-Multiple-Choi-Uh/5474ddca920f59c4ec3c243345a5b9248e64065b",
            "/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "/paper/Fast%2C-sensitive%2C-and-accurate-integration-of-single-Korsunsky-Fan/3ea71ab8877a3e96ce82daf24aacd3ccbcd19138",
            "/paper/JUMP-Cell-Painting-dataset%3A-morphological-impact-of-Chandrasekaran-Ackerman/1f96460299f3c74965b4fe8e64c28957ada06c74",
            "/paper/RxRx3%3A-Phenomics-Map-of-Biology-Fay-Kraus/a4040560bed2818f9e64293c462627858d99cf3e",
            "/paper/Morphology-and-gene-expression-profiling-provide-Way-Natoli/1f7bb6a080c1db96c778793514bf2b1638b623ab",
            "/paper/Learning-representations-for-image-based-profiling-Moshkov-Bornholdt/6c26c1c68782bb2b4821f9f2343431d3785b3b59",
            "/paper/Integrating-deep-learning-and-unbiased-automated-to-Schiff-Migliori/f08c5a30f1f0c9d79861f7eb993bf89fa9ef1074"
        ]
    },
    {
        "id": "4e81a2fd72000928cb2dc93c1646332b9dd1ee1b",
        "title": "A Variable Step-Size Normalized Subband Adaptive Filter With a Step-Size Scaler Against Impulsive Measurement Noise",
        "abstract": "Simulations using the proposed VSS NSAF show an excellent transient and steady-state behavior with colored input in impulsive-noise environments and removes a possibility of updating weight estimates based on defective information of the subband output errors due to impulsive measurement noise. This brief introduces a variable step-size (VSS) normalized subband adaptive filter (NSAF) using a step-size scaler to improve the robustness against impulsive measurement noise. When impulsive measurement noise appears, the step size of the proposed VSS NSAF is scaled down by the step-size scaler, which is suitable for application in the NSAF. This removes a possibility of updating weight estimates based on defective information of the subband output errors due to impulsive measurement noise. In the proposed VSS NSAF, the equations for updating the step size are constructed by interpreting the behavior of the mean square deviation of the conventional NSAF and applying the step-size scaler. The step-size scaler utilizes the sum of the subband output errors, which can be influenced by impulsive measurement noise. Simulations using the proposed VSS NSAF show an excellent transient and steady-state behavior with colored input in impulsive-noise environments.",
        "publication_year": "2017",
        "authors": [
            "Junwoong Hur",
            "Insun Song",
            "P. Park"
        ],
        "related_topics": [
            "Engineering",
            "Physics"
        ],
        "citation_count": "31",
        "reference_count": "9",
        "references": [
            "/paper/A-filtered-x-VSS-NSAF-active-noise-control-robust-Park-Kim/5fdbb81992d1db84e0e6e3243be75a126d2a4ad2",
            "/paper/A-filtered-x-VSS-NSAF-active-noise-control-robust-Park-Kim/c5e3b3b5ff261a08f4b52a173b421a6a25ab31da",
            "/paper/Combined-Step-Size-Normalized-Subband-Adaptive-With-Huang-Zhang/ed7ebe0059ea966e8e9589be1b26edb016433078",
            "/paper/Scheduled-Step-Size-Subband-Adaptive-Filter-With-Park-Lee/e09f45e59dcd455ab9105393703999110a488d4f",
            "/paper/Robust-Normalized-Subband-Adaptive-Filter-Algorithm-Shen-Tang/4dd7d3d93d79fadeb34597d27c2461bd6f9a527d",
            "/paper/Variable-step-size-sign-subband-adaptive-filter-Cho-Baek/7b61333d086b2c81fe091e62da0f94899411adbe",
            "/paper/Robust-gain-combined-proportionate-normalized-with-Shen-Shi/96d7bd865f90dbac943b40b6c9bd56fec22c6162",
            "/paper/Robust-normalized-subband-adaptive-filter-algorithm-Zheng-Liu/849f843d480920aa1421c9c07cf30960bbbd54ac",
            "/paper/Study-of-General-Robust-Subband-Adaptive-Filtering-Yu-He/a6382dc10f31868653fc743e58680b3a69a6b426",
            "/paper/Mean-Square-Analysis-of-Multi-Sampled-Subband-Zhang-Zheng/f0d73109c2457945596a08c32e36357e6b30ca24",
            "/paper/A-Normalized-Least-Mean-Squares-Algorithm-With-a-Song-Park/98a56025b90612c8f214f6b5551057e43e9991c5",
            "/paper/Variable-Step-Size-Sign-Subband-Adaptive-Filter-Shin-Yoo/3a4eb71e3cd6182d3f24852b662d9de01be72c10",
            "/paper/Normalised-subband-adaptive-filter-with-variable-Shin-Kong/a9082ed8f0e7cfd16c4d917b6c95064e9d6d85bc",
            "/paper/Selective-Normalized-Subband-Adaptive-Filter-With-Song-Kim/ad21bfc4e779e8b7e74318e31833e7d2d5e462cd",
            "/paper/Normalized-Subband-Adaptive-Filtering-Algorithm-Petraglia-Haddad/9c01e052dbaf6cf0f6373a033ba3d8a485c4bd00",
            "/paper/A-New-Robust-Variable-Step-Size-NLMS-Algorithm-Vega-Rey/2bde3e5067726b559357487cdacdbf0965fc9a02",
            "/paper/Improving-convergence-of-the-NLMS-algorithm-using-Lee-Gan/48905b7b0149d88ba221afa0f1ef2fb9426a3c12",
            "/paper/Variable-regularisation-parameter-sign-subband-Ni-Li/efdccb5ebbdd69eeb70a17a5019174090336a623",
            "/paper/Adaptive-Filter-Theory-4th-Edition-Haykin/58afd19190dfa172df90d7ef6b8bad0535662950"
        ]
    },
    {
        "id": "8ad02e32318ec54c1918b5f99280ef0a6fd6b8c5",
        "title": "Joint Representation Learning for Anomaly Detection in Surveillance Videos",
        "abstract": "A joint representation learning structure for video anomaly detection that extracts features from the object appearance and their associate motion features via different encoders based on ResNet network architecture. Video anomaly detection in the unconstrained environment is challenging due to various background scenes, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve remarkable performance on video anomaly detection. In this paper, we propose a joint representation learning structure for video anomaly detection. The proposed architecture extracts features from the object appearance and their associate motion features via different encoders based on ResNet network architecture. Our network architecture is designed to combine spatial and temporal features, which share the same decoder. Using a joint representation learning approach, the proposed architecture effectively learn both appearance and motion features to detect anomalies in various scene scenarios. The experiments on three benchmark datasets demonstrate the remarkable detection accuracy with respect to existing state-of-the-art methods, which achieve 96.5%, 86.9%, and 73.4% in UCSD Pedestrian, CHUK Avenue, and ShanghaiTech datasets, respectively.",
        "publication_year": "2022",
        "authors": [
            "Savath Saypadith",
            "T. Onoye"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "25",
        "references": [
            "/paper/Object-Motion-Tracking-and-Detection-in-Videos-Ahmed-Naib/b0fc464d967b407a9d52c1b9e79e920f7c8a1312",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429",
            "/paper/An-adaptive-training-less-framework-for-anomaly-in-Sikdar-Chowdhury/d06f803819418b7188596257a361800e51093bf4",
            "/paper/Abnormal-Event-Detection-in-Videos-using-Chong-Tay/527cc8cd2af06a9ac2e5cded806bab5c3faad9cf",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Future-Frame-Prediction-Using-Convolutional-VRNN-Lu-MaheshKumar/16e1bdb834340b0fd7a5737dfb87abda373f72ca",
            "/paper/AnomalyNet%3A-An-Anomaly-Detection-Network-for-Video-Zhou-Du/b20e564edbef25009fa1baa2c369437c89147e61",
            "/paper/Spatiotemporal-Anomaly-Detection-Using-Deep-for-Nawaratne-Alahakoon/3a16085d520502077558e90c0d7228fb718c8488",
            "/paper/Video-Anomaly-Detection-and-Localization-via-Fully-Fan-Wen/d880d303ee0bfdbc80fc34df0978088cd15ce861",
            "/paper/Anomaly-detection-in-crowded-scenes-Mahadevan-Li/9d3f0d47449c7db37d1bae3b70db2928610a8db7"
        ]
    },
    {
        "id": "c8341d4d88e3e4ebc0846227d0d6c0ddb7defeb4",
        "title": "Comparison of the Efficacy of Two Protocol Treatments in Patients with Symptomatic Disc Displacement without Reduction: A Randomized Controlled Trial",
        "abstract": "ASH treatment did not reduce pain or improve mandibular range of motion more than physical therapy in patients with symptomatic disc displacement without reduction, but ASH could be preferable given its positive long-term effects on patients\u2019 quality of life. The aim of this study was to compare the effectiveness of arthrocentesis followed by hyaluronic acid infiltration treatment (ASH) and mandibular exercise therapy (MET) in patients with symptomatic disc displacement without reduction (DDwoR) by examining pain intensity (VAS), mandibular range of motion (MO), and quality of life (QoL). Fifty-two patients were randomly allocated into two groups, MET (N = 26) and ASH (N = 26), and therapy was applied at the baseline and one month after. Patients were followed up at 1 and 12 months after the baseline assessment. Clinical and patient-reported outcomes were compared at the baseline, 1-month follow-up, and 12-month follow-up. The study found no significant differences in VAS and MO between the ASH and MET groups at the baseline. However, while not significant, it was noted that the ASH group showed higher values for MO. Regarding OHIP-14 at 1 month of follow-up, the ASH group showed significant improvements in physical pain (p > 0.01), physical and psychological disability (p = 0.043 and p = 0.029), and handicap (p = 0.033). At the 12-month follow-up, the ASH group showed significant improvements in functional limitation, psychological discomfort, psychological disability, and handicap (p = 0.008, p = 0.001, p = 0.001, p = 0.005, respectively). ASH treatment did not reduce pain or improve mandibular range of motion more than physical therapy in patients with symptomatic DDwoR. However, ASH could be preferable given its positive long-term effects on patients\u2019 quality of life. The clinician\u2019s main objective is to prioritize the treatment plan order with a focus on the patient\u2019s quality of life. Accordingly, healthcare professionals should consider ASH as a treatment option for patients with symptomatic DDwoR who desire long-term improvement in their quality of life.",
        "publication_year": "2023",
        "authors": [
            "A. M. de Almeida",
            "J. Botelho",
            "V. Machado",
            "J. Mendes",
            "C. Manso",
            "S. Gonz\u00e1lez-L\u00f3pez"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": 0,
        "reference_count": "42",
        "references": [
            "/paper/Conservative-therapy-versus-arthrocentesis-for-the-Malekzadeh-Cahlin/c06e476580231cc34d17de26de8ba542a3f94d17",
            "/paper/Randomized-Effectiveness-Study-of-Four-Therapeutic-Schiffman-Look/af624107c85d9c2816b4b60a45d40df263280d24",
            "/paper/Clinical-and-radiological-follow-up-results-of-with-Imirzalio%C4%9Flu-Biler/06a54ba6c5633283ac6e287719a846c164141297",
            "/paper/The-impact-of-arthrocentesis-with-and-without-acid-Ozdamar-Alev/5a54325a367de2535c9c72badc1a7cfd3a1c5c1e",
            "/paper/TMJ-Disc-Displacement-without-Reduction-Management-Al-Baghdadi-Durham/c624f5a55a23123d6ffbf85ead69fed3aacd70cb",
            "/paper/Manual-therapy-and-exercise-in-temporomandibular-A-Touche-Boo-Mallo/b990d34339074ae720a13e0978ad1ce5b4665d0c",
            "/paper/Myofascial-trigger-points-in-patients-with-joint-a-Poluha-Grossmann/95b2b516e38fdd929aa3f6e9bcf92b9e527b178b",
            "/paper/Long-term-oral-health-related-quality-of-life-after-Casta%C3%B1o-Joaqui-Muela/8700263a9bea406772159e860b3a188c1dd9e9d9",
            "/paper/Natural-Course-of-Untreated-Symptomatic-Joint-Disc-Kurita-Westesson/13dcb153a5ddd4ec88603dd452771218ee7e141e",
            "/paper/Timing-of-arthrocentesis-in-the-management-of-an-Li-Wong/f197805d72438761e833d9c7a5dbf2ace726f6b9"
        ]
    },
    {
        "id": "84f24118658a9b4dea4020650945e7ab7d239929",
        "title": "Angiogenic Effects and Crosstalk of Adipose-Derived Mesenchymal Stem/Stromal Cells and Their Extracellular Vesicles with Endothelial Cells",
        "abstract": "Adipose tissue as a cell source for both mesenchymal stem cells and ECs for co-transplantation serves as a prominent option for therapeutic angiogenesis and blood perfusion in vivo. Adipose-derived mesenchymal stem/stromal cells (ASCs) are an adult stem cell population able to self-renew and differentiate into numerous cell lineages. ASCs provide a promising future for therapeutic angiogenesis due to their ability to promote blood vessel formation. Specifically, their ability to differentiate into endothelial cells (ECs) and pericyte-like cells and to secrete angiogenesis-promoting growth factors and extracellular vesicles (EVs) makes them an ideal option in cell therapy and in regenerative medicine in conditions including tissue ischemia. In recent angiogenesis research, ASCs have often been co-cultured with an endothelial cell (EC) type in order to form mature vessel-like networks in specific culture conditions. In this review, we introduce co-culture systems and co-transplantation studies between ASCs and ECs. In co-cultures, the cells communicate via direct cell\u2013cell contact or via paracrine signaling. Most often, ASCs are found in the perivascular niche lining the vessels, where they stabilize the vascular structures and express common pericyte surface proteins. In co-cultures, ASCs modulate endothelial cells and induce angiogenesis by promoting tube formation, partly via secretion of EVs. In vivo co-transplantation of ASCs and ECs showed improved formation of functional vessels over a single cell type transplantation. Adipose tissue as a cell source for both mesenchymal stem cells and ECs for co-transplantation serves as a prominent option for therapeutic angiogenesis and blood perfusion in vivo.",
        "publication_year": "2021",
        "authors": [
            "Swarna Rautiainen",
            "T. Laaksonen",
            "R. Koivuniemi"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "22",
        "reference_count": "176",
        "references": [
            "/paper/Angiogenic-Potential-of-Human-Adipose-Derived-Cells-Koivunotko-Snirvi/dea97b27e858cce6cbbde2294688cd3262dd16a6",
            "/paper/Therapeutic-Strategy-of-Extracellular-Vesicles-as-Matsuzaka-Yashiro/83fff0ea583937b6ad1486a3b6ca52498c8a5a00",
            "/paper/Mesenchymal-stem-cells-derived-secretome-and-and-in-Gemayel-Chaker/93a21a162cbfe6e1ea3e0c0be1e7997af41a6a89",
            "/paper/Regenerative-Potential-of-Mesenchymal-Stem-Cells%E2%80%99-Nazarie-Gharbia/6581d6c1b0bd052bf0c37248a437bf0c430890f0",
            "/paper/Adipose-Stromal-Stem-Cell-Derived-Extracellular-Zuccarini-Giuliani/6d15890a60f727b20bfa1bfaccac8cbc40defd58",
            "/paper/Comparison-of-the-Behavior-of-Perivascular-Cells-in-D%C3%ADaz-Flores-Guti%C3%A9rrez/3e40fe76e9ec98524c4a4679bc68245d552662ce",
            "/paper/Potential-angiogenic%2C-immunomodulatory%2C-and-effects-Zhao-Kong/cbb6fbc4b6e3a0df8fe91fe70508e65268141ab2",
            "/paper/Effect-of-Co-culture-of-mesenchymal-stem-cell-and-Choi-Yang/f4ffaa6fc995dcffdec41919b2d70b887c0b46fa",
            "/paper/Adipose-Derived-Stromal-Cells-for-Chronic-Wounds%3A-Brembilla-Vuagnat/bb2d46a1c25f392379f9939b2111fc761443e63f",
            "/paper/A-Drop-on-Demand-Bioprinting-Approach-to-Spatially-Weygant-Koch/a153cbc17d3f42d2de3e16670b57ad3cd505b504",
            "/paper/Microvascular-Networks-From-Endothelial-Cells-and-A-Pill-Melke/7278b2de8b37e5bbc77248d3c946ba6a7b0c2ca9",
            "/paper/Pre-culture-in-endothelial-growth-medium-enhances-Souza-Beckenkamp/6a06baf51265e80f122cffadcfd2ff6a0f830b9f",
            "/paper/Human-adipose-tissue-derived-stem-cells-into-cells-Cao-Sun/7d4a23cf9b30495ba042eecbc8ce8aaf7fb0f2de",
            "/paper/Adipose-Stromal-Cell-Contact-with-Endothelial-Cells-Merfeld%E2%80%90Clauss-Lupov/085c2c9571d54086ee32e047abf7ee50ff03a555",
            "/paper/Plasticity-of-Human-Adipose-Lineage-Cells-Toward-Planat-B%C3%A9nard-Silvestre/84e22ce1d05b61718cb0e4b904c240c8bf04ba20",
            "/paper/Plasticity-of-Human-Adipose-Lineage-Cells-Toward-Vale%CC%81riePlanat-Benard-Jean-Se%CC%81bastienSilvestre/046e707eb66676604fed74bd0e694b27509efd23",
            "/paper/Exosomes-secreted-by-mesenchymal-stem-cells-promote-Liang-Zhang/365e8934b65a4441005e0f1e67d63587c47e7631",
            "/paper/Adipose%E2%80%90derived-stem-cells-induce-vascular-tube-of-Holnthoner-Hohenegger/b91571368abd73dbaa3f267173d2daa585d32f67",
            "/paper/Human-adipose-derived-stem-cells-enhance-the-of-but-Strassburg-Nienhueser/cb57eeff9e584ae7dfc16dc47407f133ff43f18b",
            "/paper/Endothelial-Differentiation-and-Vasculogenesis-by-Park-Kim/c9e1a8cae4b368c25aa146018dd3e9e1b4800cbf"
        ]
    },
    {
        "id": "addae423490bbe82da4fb2fc265237178686b4e8",
        "title": "Clinical-grade computational pathology using weakly supervised deep learning on whole slide images",
        "abstract": "A multiple instance learning-based deep learning system that uses only the reported diagnoses as labels for training, thereby avoiding expensive and time-consuming pixel-wise manual annotations, and has the ability to train accurate classification models at unprecedented scale. The development of decision support systems for pathology and their deployment in clinical practice have been hindered by the need for large manually annotated datasets. To overcome this problem, we present a multiple instance learning-based deep learning system that uses only the reported diagnoses as labels for training, thereby avoiding expensive and time-consuming pixel-wise manual annotations. We evaluated this framework at scale on a dataset of 44,732 whole slide images from 15,187 patients without any form of data curation. Tests on prostate cancer, basal cell carcinoma and breast cancer metastases to axillary lymph nodes resulted in areas under the curve above 0.98 for all cancer types. Its clinical application would allow pathologists to exclude 65\u201375% of slides while retaining 100% sensitivity. Our results show that this system has the ability to train accurate classification models at unprecedented scale, laying the foundation for the deployment of computational decision support systems in clinical practice.A deep learning model trained on real-world digital pathology data achieves clinical performance in cancer diagnosis.",
        "publication_year": "2019",
        "authors": [
            "Gabriele Campanella",
            "M. Hanna",
            "Luke Geneslaw",
            "Allen P. Miraflor",
            "Vitor Werneck Krauss Silva",
            "K. Busam",
            "E. Brogi",
            "V. Reuter",
            "D. Klimstra",
            "Thomas J. Fuchs"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "1,086",
        "reference_count": "41",
        "references": [
            "/paper/An-Annotation-free-Whole-slide-Training-Approach-to-Chen-Chen/59b3899a8fc3b34c278f21e7989e2d1ecea534b3",
            "/paper/Detection-of-lung-cancer-metastases-in-lymph-nodes-Gwerder-Khan/b753a6424a95b6469321264ec2b6852d7f6fd229",
            "/paper/Automatic-diagnosis-and-grading-of-Prostate-Cancer-Xiang-Wang/47ba0fffa132177ff9c1900fbd02e202663636ba",
            "/paper/An-annotation-free-whole-slide-training-approach-to-Chen-Chen/378ba59aa19b4e4591972988b753509f95126a2a",
            "/paper/High-accuracy-prostate-cancer-pathology-using-deep-Tolkach-Dohmg%C3%B6rgen/8ec6aa40c7b9020ef3dd5f2e02863efaac7a4d58",
            "/paper/High-accuracy-prostate-cancer-pathology-using-deep-Tolkach-Dohmg%C3%B6rgen/d8bdf72c2ccfcce5ee3e6f6064b65ffe7a43cad9",
            "/paper/Deep-learning-based-breast-cancer-grading-and-on-Wetstein-Jong/5cfbff0383bb6ec2c6f0780252bbae53678529c0",
            "/paper/Weakly-Supervised-Convolutional-Neural-Network-for-Kamareh-Helfroush/ffd6380fb77b399d86558c980b34d3c9fe46e1f7",
            "/paper/Deep-Learning-for-Prostate-Pathology-Eminaga-Tolkach/80c5265faae660df0487bed8bcc0f63bdaaec4df",
            "/paper/Histology-segmentation-using-active-learning-on-of-Folmsbee-Zhang/3811172f22edf3f37e676f50f1010b9773abee3a",
            "/paper/Deep-Learning-for-Identifying-Metastatic-Breast-Wang-Khosla/21ba757bf394720e0b66b86e7638ae28742d6570",
            "/paper/Deep-learning-as-a-tool-for-increased-accuracy-and-Litjens-S%C3%A1nchez/47262a72c9c7bf5070b97e70b55c6190d1079260",
            "/paper/Deep-learning-based-tissue-analysis-predicts-in-Bychkov-Linder/39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "/paper/Diagnostic-Assessment-of-Deep-Learning-Algorithms-Bejnordi-Veta/ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
            "/paper/Deep-learning-for-digital-pathology-image-analysis%3A-Janowczyk-Madabhushi/d847ee63fe234f9cc2a8be851ed511b7d1a8da36",
            "/paper/Classification-and-mutation-prediction-from-cell-Coudray-Ocampo/769149c0dc0ed308eca8bc916f4326b2e2f57a1f",
            "/paper/Classifying-histopathology-whole-slides-using-of-on-Das-Karri/29c7193c7f8aea85dd7e2c4acb9c3646eba065a7",
            "/paper/Clinically-applicable-deep-learning-for-diagnosis-Fauw-Ledsam/b2d952fbd6951cbed68ea13003a045300970731a",
            "/paper/Using-deep-convolutional-neural-networks-to-and-in-Bejnordi-Mullooly/a58015a59562caf325a3f05288147704c055ce8d",
            "/paper/Diagnostic-Performance-of-Deep-Learning-Algorithms-Olsen-Jackson/f429816e4561150b7b26684e606880815f2c3d3f"
        ]
    },
    {
        "id": "bb61e505ea1f874f3590d69706eabc4c72009403",
        "title": "Using DUCK-Net for polyp image segmentation",
        "abstract": "This paper presents a novel supervised convolutional neural network architecture, \u201cDUCK-Net\u201d, capable of effectively learning and generalizing from small amounts of medical images to perform accurate segmentation tasks. Our model utilizes an encoder-decoder structure with a residual downsampling mechanism and a custom convolutional block to capture and process image information at multiple resolutions in the encoder segment. We employ data augmentation techniques to enrich the training set, thus increasing our model's performance. While our architecture is versatile and applicable to various segmentation tasks, in this study, we demonstrate its capabilities specifically for polyp segmentation in colonoscopy images. We evaluate the performance of our method on several popular benchmark datasets for polyp segmentation, Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, and ETIS-LARIBPOLYPDB showing that it achieves state-of-the-art results in terms of mean Dice coefficient, Jaccard index, Precision, Recall, and Accuracy. Our approach demonstrates strong generalization capabilities, achieving excellent performance even with limited training data.",
        "publication_year": "2023",
        "authors": [
            "R. Dumitru",
            "Darius Peteleaza",
            "Catalin Craciun"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "40",
        "references": [
            "/paper/ColonFormer%3A-An-Efficient-Transformer-Based-Method-Duc-Oanh/42f1d7d46b52d06dfb07060be65889a98b03cad1",
            "/paper/Stepwise-Feature-Fusion%3A-Local-Guides-Global-Wang-Huang/dac5ad2509fe9886d25ad1dd75bf5b6c6c5e48ed",
            "/paper/FCN-Transformer-Feature-Fusion-for-Polyp-Sanderson-Matuszewski/8d732f0ecb290c022de6ad9061bebe377b00b5d9",
            "/paper/ResUNet%2B%2B%3A-An-Advanced-Architecture-for-Medical-Jha-Smedsrud/80f4c7c360d1150ba58c3bacf5c35718ebdd0c10",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/Kvasir-SEG%3A-A-Segmented-Polyp-Dataset-Jha-Smedsrud/349461d60b4d3d34dc97147e4b9ec2b9bd611be8",
            "/paper/PraNet%3A-Parallel-Reverse-Attention-Network-for-Fan-Ji/89c6badea0d7bf834d4c069517116dd99c4cc0fd",
            "/paper/MSRF-Net%3A-A-Multi-Scale-Residual-Fusion-Network-for-Srivastava-Jha/75808111f4b554d3d99563c8f2b22359bc011c45",
            "/paper/A-Benchmark-for-Endoluminal-Scene-Segmentation-of-V%C3%A1zquez-Bernal/8b008beb62007504aed4234980b5481edda644b0"
        ]
    },
    {
        "id": "83dbc15934831ce98a265db526f4c380ce9e04bb",
        "title": "Exploring vision transformer layer choosing for semantic segmentation",
        "abstract": "This paper designs a neck network for adaptive fusion and feature selection, called ViTController, and proves the effectiveness of the method on different datasets and models and surpasses previous state-of-the-art methods. Extensive work has demonstrated the effectiveness of Vision Transformers. The plain Vision Transformer tends to obtain multi-scale features by selecting fixed layers, or the last layer of features aiming to achieve higher performance in dense prediction tasks. However, this selection is often based on manual operation. And different samples often exhibit different features at different layers (e.g., edge, structure, texture, detail, etc.). This requires us to seek a dynamic adaptive fusion method to filter different layer features. In this paper, unlike previous encoder and decoder work, we design a neck network for adaptive fusion and feature selection, called ViTController. We validate the effectiveness of our method on different datasets and models and surpass previous state-of-the-art methods. Finally, our method can also be used as a plug-in module and inserted into different networks.",
        "publication_year": "2023",
        "authors": [
            "Fangjian Lin",
            "Yizhe Ma",
            "Sheng Tian"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "20",
        "references": [
            "/paper/Exploring-Plain-Vision-Transformer-Backbones-for-Li-Mao/a09cbcaac305884f043810afc4fa4053099b5970",
            "/paper/Segmenter%3A-Transformer-for-Semantic-Segmentation-Strudel-Pinel/68f080e0ac836ea230cb5316fbed273c70422d75",
            "/paper/Vision-Transformer-Adapter-for-Dense-Predictions-Chen-Duan/5598c4ece8ffc69a7eb584d16f6de6629044e76a",
            "/paper/Rethinking-Semantic-Segmentation-from-a-Perspective-Zheng-Lu/d29430adccb805ab57b349afa8553954347b3197",
            "/paper/SegViT%3A-Semantic-Segmentation-with-Plain-Vision-Zhang-Tian/e92a62da0ab6b9769f84dd9ea195debd3254243b",
            "/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "/paper/Vision-Transformers-for-Dense-Prediction-Ranftl-Bochkovskiy/8e33914d6051dd031a5e096962b9398fc1d16067",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/BEiT%3A-BERT-Pre-Training-of-Image-Transformers-Bao-Dong/722ad6ac92286507437b31486f47987d6ece05c9",
            "/paper/Feature-Pyramid-Networks-for-Object-Detection-Lin-Doll%C3%A1r/b9b4e05faa194e5022edd9eb9dd07e3d675c2b36"
        ]
    },
    {
        "id": "0fcc797aeed56bcc127476d5b68836dc402021ea",
        "title": "SignBERT+: Hand-model-aware Self-supervised Pre-training for Sign Language Understanding",
        "abstract": "This paper proposes the first self-supervised pre-trainable SignBERT+ framework with model-aware hand prior incorporated, and achieves new state-of-the-art performance with a notable gain. Hand gesture serves as a crucial role during the expression of sign language. Current deep learning based methods for sign language understanding\u00a0(SLU) are prone to over-fitting due to insufficient sign data resource and suffer limited interpretability. In this paper, we propose the first self-supervised pre-trainable SignBERT+ framework with model-aware hand prior incorporated. In our framework, the hand pose is regarded as a visual token, which is derived from an off-the-shelf detector. Each visual token is embedded with gesture state and spatial-temporal position encoding. To take full advantage of current sign data resource, we first perform self-supervised learning to model its statistics. To this end, we design multi-level masked modeling strategies\u00a0(joint, frame and clip) to mimic common failure detection cases. Jointly with these masked modeling strategies, we incorporate model-aware hand prior to better capture hierarchical context over the sequence. After the pre-training, we carefully design simple yet effective prediction heads for downstream tasks. To validate the effectiveness of our framework, we perform extensive experiments on three main SLU tasks, involving isolated and continuous sign language recognition\u00a0(SLR), and sign language translation\u00a0(SLT). Experimental results demonstrate the effectiveness of our method, achieving new state-of-the-art performance with a notable gain.",
        "publication_year": "2023",
        "authors": [
            "Hezhen Hu",
            "Weichao Zhao",
            "Wen-gang Zhou",
            "Houqiang Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "98",
        "references": [
            "/paper/SignBERT%3A-Pre-Training-of-Hand-Model-Aware-for-Sign-Hu-Zhao/39c6076a1284324282d6234c033ef1539c959039",
            "/paper/Hand-Model-Aware-Sign-Language-Recognition-Hu-Zhou/832298578168aacc3fb1433296a63dbfa849ee4e",
            "/paper/Global-Local-Enhancement-Network-for-NMF-Aware-Sign-Hu-Zhou/9023437b9bfb741094f9ff50323093573c9f8e60",
            "/paper/SignBERT%3A-A-BERT-based-Deep-Learning-Framework-for-Zhou-Tam/4f1d1921ad91699ac076763de968eac549f32847",
            "/paper/Pose-based-Sign-Language-Recognition-using-GCN-and-Tunga-Nuthalapati/2e0d7289231dc4b1cd822186690b426810da620b",
            "/paper/PiSLTRc%3A-Position-Informed-Sign-Language-With-Xie-Zhao/87e823d2cb58e741230c0fa3b83f3459c7e32241",
            "/paper/BSL-1K%3A-Scaling-up-co-articulated-sign-language-Albanie-Varol/0b2538f9c22273db62b205402864062bf222b68c",
            "/paper/Spatial-Temporal-Multi-Cue-Network-for-Sign-and-Zhou-Zhou/d76e2a01f914b81afacec214c302e82c000c65ef",
            "/paper/MS-ASL%3A-A-Large-Scale-Data-Set-and-Benchmark-for-Joze-Koller/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e",
            "/paper/Transferring-Cross-Domain-Knowledge-for-Video-Sign-Li-Yu/efe28238909dc5c1877297fa830d85e9daecc29f"
        ]
    },
    {
        "id": "ca9adbc1fa8919d8cb7e3aa58d622e069131b60b",
        "title": "Diffusion models in medical imaging: A comprehensive survey.",
        "abstract": "Semantic Scholar extracted view of \"Diffusion models in medical imaging: A comprehensive survey.\" by A. Kazerouni et al.",
        "publication_year": "2023",
        "authors": [
            "A. Kazerouni",
            "Ehsan Khodapanah Aghdam",
            "Moein Heidari",
            "Reza Azad",
            "Mohsen Fayyaz",
            "I. Hacihaliloglu",
            "D. Merhof"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "117",
        "references": [
            "/paper/Diffusion-Models-for-Medical-Image-Analysis%3A-A-Kazerouni-Aghdam/b57b8b6b8052bf2e7f6fe5c8e91cdcb385b75ab6",
            "/paper/MR-Image-Denoising-and-Super-Resolution-Using-Chung-Lee/2b009e12a42efe77b8daeffd218b912fd23c19aa",
            "/paper/Towards-performant-and-reliable-undersampled-MR-via-Peng-Guo/6a0bc6e194608b9e41cbf69794343888edb54378",
            "/paper/DDM2%3A-Self-Supervised-Diffusion-MRI-Denoising-with-Xiang-Yurt/0949978a51943a8547632b273496375616a9931b",
            "/paper/Score-based-diffusion-models-for-accelerated-MRI-Chung-Ye/ff85a9d7182063bb71b47ab239d662fd2975c4fc",
            "/paper/Brain-Imaging-Generation-with-Latent-Diffusion-Pinaya-Tudosiu/e924a5cc4739f18fb225b7a8b506099042567ffa",
            "/paper/Fast-Unsupervised-Brain-Anomaly-Detection-and-with-Pinaya-Graham/bacfa58d33e53efc40bffd87094f8731371277f2",
            "/paper/Unsupervised-denoising-of-retinal-OCT-with-model-Hu-Tao/a32fa13941f9c9beaa86000f8873e7c6422825e2",
            "/paper/Diffusion-Deformable-Model-for-4D-Temporal-Medical-Kim-Ye/69fe2ed78956f22a36ccb2029b8315cd3bbc36da",
            "/paper/Diffusion-Adversarial-Representation-Learning-for-Kim-Oh/e84ed70a8e00a2feec0e8462bf72af0a30cff2a9",
            "/paper/Denoising-Diffusion-Implicit-Models-Song-Meng/014576b866078524286802b1d0e18628520aa886"
        ]
    },
    {
        "id": "efe77e08cf7133628cf15d74d7489b27d02a2e18",
        "title": "Evaluating a 3D deep learning pipeline for cerebral vessel and intracranial aneurysm segmentation from computed tomography angiography\u2013digital subtraction angiography image pairs",
        "abstract": "This CTA segmentation network (DeepMedic trained on DSA-segmented vessels) provides a high-fidelity solution for CTA vessel segmentation, particularly for vessels and IAs in the carotid cavernous region. \n\nComputed tomography angiography (CTA) is the most widely used imaging modality for intracranial aneurysm (IA) management, yet it remains inferior to digital subtraction angiography (DSA) for IA detection, particularly of small IAs in the cavernous carotid region. The authors evaluated a deep learning pipeline for segmentation of vessels and IAs from CTA using coregistered, segmented DSA images as ground truth.\n\n\n\nUsing 50 paired CTA-DSA images, the authors trained (n = 27), validated (n = 3), and tested (n = 20) a deep learning model (3D DeepMedic) for cerebrovasculature segmentation from CTA. A landmark-based coregistration algorithm was used for registration and upsampling of CTA images to paired DSA images. Segmented vessels from the DSA were used as the ground truth. Accuracy of the model for vessel segmentation was evaluated using conventional metrics (dice similarity coefficient [DSC]) and vessel segmentation\u2013specific metrics, like connectivity-area-length (CAL). On the test cases (20 IAs), 3 expert raters attempted to detect and segment IAs. For each rater, the authors recorded the rate of IA detection, and for detected IAs, raters segmented and calculated important IA morphology parameters to quantify the differences in IA segmentation by raters to segmentations by DeepMedic. The agreement between raters, DeepMedic, and ground truth was assessed using Krippendorf\u2019s alpha.\n\n\n\nIn testing, the DeepMedic model yielded a CAL of 0.971 \u00b1 0.007 and a DSC of 0.868 \u00b1 0.008. The model prediction delineated all IAs and resulted in average error rates of < 10% for all IA morphometrics. Conversely, average IA detection accuracy by the raters was 0.653 (undetected IAs were present to a significantly greater degree on the ICA, likely due to those in the cavernous region, and were significantly smaller). Error rates for IA morphometrics in rater-segmented cases were significantly higher than in DeepMedic-segmented cases, particularly for neck (p = 0.003) and surface area (p = 0.04). For IA morphology, agreement between the raters was acceptable for most metrics, except for the undulation index (\u03b1 = 0.36) and the nonsphericity index (\u03b1 = 0.69). Agreement between DeepMedic and ground truth was consistently higher compared with that between expert raters and ground truth.\n\n\n\nThis CTA segmentation network (DeepMedic trained on DSA-segmented vessels) provides a high-fidelity solution for CTA vessel segmentation, particularly for vessels and IAs in the carotid cavernous region.\n",
        "publication_year": "2023",
        "authors": [
            "T. Patel",
            "Aakash Patel",
            "S. Veeturi",
            "Munjal Shah",
            "M. Waqas",
            "A. Monteiro",
            "A. Baig",
            "N. Pint\u00e9r",
            "E. Levy",
            "A. Siddiqui",
            "V. Tutino"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "29",
        "references": [
            "/paper/Multi-resolution-CNN-for-brain-vessel-segmentation-Patel-Paliwal/636caf10552e22e855ddd1855a55a6036267891c",
            "/paper/Automated-Cerebral-Vessel-Segmentation-of-Magnetic-Patel-Pint%C3%A9r/19a9461fc7f4289eb8d7d306c0f8fdbffceb1f3a",
            "/paper/Intra-and-inter-observer-variability-in-aneurysm-CT-D'Argento-Pedicelli/068adb4a137f317150b9037381f91d16e26e4d78",
            "/paper/Fully-automated-detection-and-segmentation-of-in-on-Shahzad-Pennig/edf218c6ed87c59c0b022f1cc94d3a51f6925e92",
            "/paper/Rapid-vessel-segmentation-and-reconstruction-of-and-Fu-Wei/53a93716144efcc1daf6899830c63ccd23a3fba1",
            "/paper/Global-channel-attention-networks-for-intracranial-Ni-Wu/958aebc86388e7625fb8df4b0882bc3b764364a8",
            "/paper/Accuracy-of-computed-tomography-angiography-in-the-Pradilla-Wicks/85a13982141135eb504b33337bf98f34b35117de",
            "/paper/Meta-analysis-of-computed-tomography-angiography-Chen-Liu/773337a6f0fa2e988434ad94d2cbbbe9e12a60ac",
            "/paper/Deep-Learning%E2%80%93Assisted-Diagnosis-of-Cerebral-Using-Park-Chute/e81700d0cc3f0a1872131a2425c22e4600a5b34f",
            "/paper/A-Publicly-Available%2C-High-Resolution%2C-Unbiased-CT-Muschelli/697cf4c1c860dd9e2d569eb095601a141a0391ca"
        ]
    },
    {
        "id": "6b935a3dde229ddc3f9bb74e1b90050e6e371ca8",
        "title": "Incorporating patient-centered quality-of-life measures for outcome assessment after Chiari malformation type I decompression in a pediatric population: a pilot study.",
        "abstract": "Moderate improvement of HRQOL is observed, when measured using a modified panel of PROMIS question banks, in this pilot cohort of pediatric CM-I patients after PFD. OBJECTIVE\nOptimal management of pediatric Chiari malformation type I (CM-I) is much debated, chiefly due to the lack of validated tools for outcome assessment, with very few tools incorporating patient-centered measures of health-related quality of life (HRQOL). Although posterior fossa decompression (PFD) benefits a subset of patients, prediction of its impact across patients is challenging. The primary aim of this study was to investigate the role of patient-centered HRQOL measures in the assessment and prediction of outcomes after PFD.\n\n\nMETHODS\nThe authors collected HRQOL data from a cohort of 20 pediatric CM-I patients before and after PFD. The surveys included assessments of selected Patient-Reported Outcomes Measurement Information System (PROMIS) health domains and were used to generate the PROMIS preference (PROPr) score, which is a measure of HRQOL. PROMIS is a reliable standardized measure of HRQOL domains such as pain, fatigue, depression, and physical function, which are all relevant to CM-I. The authors then compared the PROPr scores with Chicago Chiari Outcome Scale (CCOS) scores derived from time-matched clinical documentation. Finally, the authors used the PROPr scores as an outcome measure to predict postsurgical HRQOL improvement at 1 year on the basis of patient demographic characteristics, comorbidities, and radiological and physical findings. The Wilcoxon signed-rank test, Mann-Whitney U-test, and Kendall's correlation were used for statistical analysis.\n\n\nRESULTS\nAggregate analysis revealed improvement of pain severity after PFD (p = 0.007) in anatomical patterns characteristic of CM-I. Most PROMIS domain scores trended toward improvement after surgery, with anxiety and pain interference reaching statistical significance (p < 0.002 and p < 0.03, respectively). PROPr scores also significantly improved after PFD (p < 0.008). Of the baseline patient characteristics, preexisting scoliosis was the most accurate negative predictor of HRQOL improvement after PFD (median -0.095 vs 0.106, p < 0.001). A correlation with modest magnitude (Kendall's tau range 0.19-0.47) was detected between the patient-centered measures and CCOS score.\n\n\nCONCLUSIONS\nThe authors observed moderate improvement of HRQOL, when measured using a modified panel of PROMIS question banks, in this pilot cohort of pediatric CM-I patients after PFD. Further investigations are necessary to validate this tool for children with CM-I and to determine whether these scores correlate with clinical and radiographic findings.",
        "publication_year": "2021",
        "authors": [
            "Solomiia Savchuk",
            "Michael C. Jin",
            "Stephanie K. Y. Choi",
            "L. Kim",
            "J.L. Quon",
            "A. Bet",
            "L. Prolo",
            "D. Hong",
            "Kelly B. Mahaney",
            "G. Grant"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "2",
        "reference_count": 0,
        "references": [
            "/paper/Digital-Patient-Reported-Outcome-Measures-Assessing-Steiert-Lambeck/05a942d2d585b44a47a511802a3f0cc2e40f03d5",
            "/paper/Assessing-Clinical-Outcome-Measures-in-Chiari-I-Mummareddy-Bhamidipati/81cdd6b280c197e1dd88986a77d7a5d9bcb7933d"
        ]
    },
    {
        "id": "f5a2edb67b839ed830bce734fee491cca6f45027",
        "title": "Patient-related and radiographic predictors of inferior health-related quality-of-life measures in adult patients with nonoperative spinal deformity.",
        "abstract": "When controlling for baseline deformity in N-Op versus Op patients, subsequent deterioration in frailty, BMI, and radiographic progression over a 2-year follow-up were found to drive suboptimal patient-reported outcome measures in N -Op cohorts as measured by validated ODI and SRS clinical instruments. OBJECTIVE\nPatients with nonoperative (N-Op) adult spinal deformity (ASD) have inferior long-term spinopelvic alignment and clinical outcomes. Predictors of lower quality-of-life measures in N-Op populations have yet to be sufficiently investigated. The aim of this study was to identify patient-related factors and radiographic parameters associated with inferior health-related quality-of-life (HRQOL) scores in N-Op ASD patients.\n\n\nMETHODS\nN-Op ASD patients with complete radiographic and outcome data at baseline and 2 years were included. N-Op patients and operative (Op) patients were propensity score matched for baseline disability and deformity. Patient-related factors and radiographic alignment parameters (pelvic tilt [PT], sagittal vertical axis [SVA], pelvic incidence [PI]-lumbar lordosis [LL] mismatch, mismatch between cervical lordosis and T1 segment slope [TS-CL], cervical-thoracic pelvic angle [PA], and others) at baseline and 2 years were analyzed as predictors for moderate to severe 2-year Oswestry Disability Index (ODI > 20) and failing to meet the minimal clinically importance difference (MCID) for 2-year Scoliosis Research Society Outcomes Questionnaire (SRS) scores (< 0.4 increase from baseline). Conditional inference decision trees identified predictors of each HRQOL measure and established cutoffs at which factors have a global effect. Random forest analysis (RFA) generated 5000 conditional inference trees to compute a variable importance table for top predictors of inferior HRQOL. Statistical significance was set at p < 0.05.\n\n\nRESULTS\nSix hundred sixty-two patients with ASD (331 Op patients and 331 N-Op patients) with complete radiographic and HRQOL data at their 2-year follow-up were included. There were no differences in demographics, ODI, and Schwab deformity modifiers between groups at baseline (all p > 0.05). N-Op patients had higher 2-year ODI scores (27.9 vs 20.3, p < 0.001), higher rates of moderate to severe disability (29.3% vs 22.4%, p = 0.05), lower SRS total scores (3.47 vs 3.91, p < 0.001), and higher rates of failure to reach SRS MCID (35.3% vs 15.7%, p < 0.001) than Op patients at 2 years. RFA ranked the top overall predictors for moderate to severe ODI at 2 years for N-Op patients as follows: 1) frailty index > 2.8, 2) BMI > 35 kg/m2, T4PA > 28\u00b0, and 4) Charlson Comorbidity Index > 1. Top radiographic predictors were T4PA > 28\u00b0 and C2-S1 SVA > 93 mm. RFA also ranked the top overall predictors for failure to reach 2-year SRS MCID for N-Op patients, as follows: 1) T12-S1 lordosis > 53\u00b0, 2) cervical SVA (cSVA) > 28 mm, 3) C2-S1 angle > 14.5\u00b0, 4) TS-CL > 12\u00b0, and 5) PT > 23\u00b0. The top radiographic predictors were T12-S1 Cobb angle, cSVA, C2-S1 angle, and TS-CL.\n\n\nCONCLUSIONS\nWhen controlling for baseline deformity in N-Op versus Op patients, subsequent deterioration in frailty, BMI, and radiographic progression over a 2-year follow-up were found to drive suboptimal patient-reported outcome measures in N-Op cohorts as measured by validated ODI and SRS clinical instruments.",
        "publication_year": "2021",
        "authors": [
            "P. Passias",
            "Haddy Alas",
            "S. Bess",
            "Breton G. Line",
            "V. Lafage",
            "R. Lafage",
            "C. Ames",
            "D. Burton",
            "Avery E. Brown",
            "Cole Bortz",
            "K. Pierce",
            "Waleed Ahmad",
            "Sara A. Naessig",
            "M. Kelly",
            "R. Hostin",
            "K. Kebaish",
            "K. Than",
            "P. Nunley",
            "C. Shaffrey",
            "E. Klineberg",
            "Justin S. Smith",
            "F. Schwab"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "3",
        "reference_count": 0,
        "references": [
            "/paper/Digital-Patient-Reported-Outcome-Measures-Assessing-Steiert-Lambeck/05a942d2d585b44a47a511802a3f0cc2e40f03d5",
            "/paper/%E2%80%9CReverse-roussouly%E2%80%9D%3A-cervicothoracic-curvature-in-Passias-Pierce/de49d99bf08dcc0cd77a2c5421fe2b764cf9083a",
            "/paper/Classification(s)-of-Cervical-Deformity-Kaidi-Kim/a7e6557899f7eb19e12f163a2cf9102a469e4a45"
        ]
    },
    {
        "id": "40698b032912d301afa310e05e5b7409a6dd3660",
        "title": "Comparison of Long-term Quality-of-Life Outcomes in Vestibular Schwannoma Patients",
        "abstract": "Long-term (>5 years) quality-of-life outcomes measured by the PANQOL in vestibular schwannoma patients show no significant differences between stereotactic radiation, observation, and microsurgical intervention. Objective To compare long-term quality-of-life outcomes in vestibular schwannoma patients managed with observation, microsurgery, or stereotactic radiation. Study Design ross-sectional survey with retrospective chart review. Setting Tertiary care center. Subjects and Methods The Penn Acoustic Neuroma Quality of Life (PANQOL) survey was mailed to 600 patients treated for vestibular schwannoma. Patients were separated by treatment and subsequently subdivided by years of follow-up (0-5, 6-10, and >10 years). Composite quality-of-life (cQOL) scores and subscores for hearing, balance, facial nerve, pain, anxiety, energy, and general health were calculated. Scores were compared among treatment groups as a whole, among treatment groups at each time interval, and within treatment groups over time using a 2-tailed analysis of variance and paired t test. Results The survey return rate was 49%, and the mean follow-up was 7.9 years. The only significant difference in cQOL occurred at 0 to 5 years, where stereotactic radiation scores were better than both microsurgery and observation (P = .009). No significant differences were detected in cQOL after 5 years. Within the radiation group, cQOL was significantly lower at 6 to 10 years than at 0 to 5 years (P = .013). At no point was cQOL for stereotactic radiation less than that for observation or microsurgery. Conclusions Long-term (>5 years) quality-of-life outcomes measured by the PANQOL in vestibular schwannoma patients show no significant differences between stereotactic radiation, observation, and microsurgical intervention. Studies are needed to fully evaluate very-long-term QOL for patients with vestibular schwannoma.",
        "publication_year": "2014",
        "authors": [
            "Zachary N. Robinett",
            "P. Walz",
            "Beth A. Miles-Markley",
            "A. Moberly",
            "D. Welling"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "57",
        "reference_count": "30",
        "references": [
            "/paper/Long-term-quality-of-life-in-patients-with-managed-Maria-Maria/f1fdc50bbdb70a635ec30b6d6835060cd16dd15c",
            "/paper/Long-Term-Quality-of-Life-of-Vestibular-Schwannoma-Neve-Jansen/f887e72876126a010587098dca682084c08e968e",
            "/paper/Quality-of-Life-in-Patients-With-Vestibular-to-Kim-Roh/7e0b9ebd83643d91e3997a5a83fa43acc5ae4bf2",
            "/paper/Quality-of-Life-in-807-Patients-with-Vestibular-Soulier-Leeuwen/aa88fa15f92cdd413c481162b7cad303acd8dc4c",
            "/paper/Disease-Specific-Quality-of-Life-in-Vestibular-A-Chweya-Tombers/de3cb4048338111ad010fc03dd35a1d94eb28e1e",
            "/paper/Quality-of-life-in-patients-of-unilateral-treated-A-Pattankar-Churi/e28ed0ff4c0eb05b67f9a51ebf0c75ffe64c04b1",
            "/paper/Quality-of-Life-Within-the-First-6-Months-of-With-Carlson-Tombers/18cc616713bd3ad78dbf51ef158e37a39634ce63",
            "/paper/Quality-of-Life-in-Acoustic-Neuroma-Patients-McLaughlin-Bigelow/a3711983671315b4345e847351c122ac9d720aa2",
            "/paper/Prospective-Study-of-Disease-Specific-in-Sporadic-Carlson-Barnes/e9f42702f018cc45ae185e61cc47a6950f55ab0a",
            "/paper/Outcome-Measures-and-Quality-of-Life-in-Vestibular-Chartrand-Al-Tamami/4ff3a409def9dfe9bb88ee9808c1eb8ebfc2126d",
            "/paper/The-Effect-of-Observation-versus-Microsurgical-on-A-Sandooram-Hornigold/f92e32c7df9eca8b10bbd1df7b3ab660b241cfb6",
            "/paper/Conservative-Treatment-of-Vestibular-Schwannoma%3A-A-Godefroy-Kaptein/94275749bd2c05f2080ba455f9ae728fc30453e1",
            "/paper/Prospective-comparison-of-quality-of-life-before-or-Maio-Akagami/81394e40bbb59ebcccae4a010e1332c1e2adc806",
            "/paper/Vestibular-Schwannomas%3A-Clinical-Results-and-of-or-Myrseth-M%C3%B8ller/608156e2bae124b16b12c13e4485e75db8c335dd",
            "/paper/Conservative-management-of-vestibular-schwannoma--a-Breivik-Varughese/d308fc6b5537c5e5db6238e049e2ae43cebe2e66",
            "/paper/Longitudinal-Assessment-of-Quality-of-Life-and-Test-Park-Grills/f847cf7215bc063f705d3393a65e8a885688db1e",
            "/paper/The-patient's-perspective-after-vestibular-removal%3A-Irving-Beynon/786baba477038f4d232df47ca4643adac167912c",
            "/paper/Systematic-review-of-quality-of-life-in-the-of-Gauden-Weir/ea2e2bd633917f823eba2f100acfe1df9b41edcd",
            "/paper/VESTIBULAR-SCHWANNOMA%3A-SURGERY-OR-GAMMA-KNIFE-A-Myrseth-M%C3%B8ller/77d4235f8a387e28dc7fd9a6d33dfad4f189268e",
            "/paper/Patient-outcomes-after-vestibular-schwannoma-a-of-Pollock-Driscoll/1bbc5e671591c1d74a9deb165bf0a575104b2e0a"
        ]
    },
    {
        "id": "f2b3de7f036f8f35294d7c8008622f7d3ad2b4eb",
        "title": "Boundary and Entropy-driven Adversarial Learning for Fundus Image Segmentation",
        "abstract": "The proposed BEAL frame-work utilizes the adversarial learning to encourage the boundary prediction and mask probability entropy map of the target domain to be similar to the source ones, generating more accurate boundaries and suppressing the high uncertainty predictions of OD and OC segmentation. Accurate segmentation of the optic disc (OD) and cup (OC)in fundus images from different datasets is critical for glaucoma disease screening. The cross-domain discrepancy (domain shift) hinders the generalization of deep neural networks to work on different domain this http URL this work, we present an unsupervised domain adaptation framework,called Boundary and Entropy-driven Adversarial Learning (BEAL), to improve the OD and OC segmentation performance, especially on the ambiguous boundary regions. In particular, our proposed BEAL frame-work utilizes the adversarial learning to encourage the boundary prediction and mask probability entropy map (uncertainty map) of the target domain to be similar to the source ones, generating more accurate boundaries and suppressing the high uncertainty predictions of OD and OC segmentation. We evaluate the proposed BEAL framework on two public retinal fundus image datasets (Drishti-GS and RIM-ONE-r3), and the experiment results demonstrate that our method outperforms the state-of-the-art unsupervised domain adaptation methods. Codes will be available at this https URL.",
        "publication_year": "2019",
        "authors": [
            "Shujun Wang",
            "Lequan Yu",
            "Kang Li",
            "Xin Yang",
            "Chi-Wing Fu",
            "P. Heng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "80",
        "reference_count": "14",
        "references": [
            "/paper/Convolutional-autoencoder-joint-boundary-and-mask-Zhang-Song/d44e3d1dc6bd08351a885a4ed3d6bb35931fffe0",
            "/paper/Joint-optic-disc-and-optic-cup-segmentation-based-Luo-Xue/52291fecbeb1af12bfcd0987487c50406edee5d0",
            "/paper/MEAL%3A-Meta-enhanced-Entropy-driven-Adversarial-for-Ma-Yang/b934c6ea9a2f0bd719e120e0cef051672ce56ae8",
            "/paper/Minimizing-Entropy-and-Fourier-Consistency-Network-Xu-Li/7e2c0f64431f2e8235eeff6fc093a212f514a6a3",
            "/paper/Self-training-adversarial-learning-for-cross-domain-Li-Niu/766f1c39771ddddf940d49f4f22e0d7c3d97c6fc",
            "/paper/An-Efficient-Hierarchical-Optic-Disc-and-Cup-with-Wang-Yu/ef345a62e9a05263eb2a495af845d7f41e0774d0",
            "/paper/Unsupervised-Domain-Adaptation-Based-Image-and-for-Liu-Lei/fe739fb2c3f83df9f16fd3fae9320a53bdf60d07",
            "/paper/GDCSeg-Net%3A-general-optic-disc-and-cup-segmentation-Ianlong-Hu/17d1bfc59cff24c21da40913de0bda483530d8b9",
            "/paper/Reconstruction-driven-Dynamic-Refinement-based-for-Chen-Pan/a0111fbbc51b990597b1b3235a91038d3595b9aa",
            "/paper/IOSUDA%3A-an-unsupervised-domain-adaptation-with-and-Chen-Wang/f6dce3d63f8e4a0bfb14aeecb0925cbfff15cde5",
            "/paper/Patch-Based-Output-Space-Adversarial-Learning-for-Wang-Yu/ba62442fc88eb4da204e98899214c45960341fa5",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/Unsupervised-Cross-Modality-Domain-Adaptation-of-Dou-Ouyang/1af573c96c2c0bc46a4ee01dfa303c43fcc11274",
            "/paper/Learning-to-Adapt-Structured-Output-Space-for-Tsai-Hung/193b518bc3025804c6d587c74cbc154d91478417",
            "/paper/Semantic-Aware-Generative-Adversarial-Nets-for-in-Chen-Dou/0c03e4c17ca4eb1c7fa8c22bee0a59afd139ca3a",
            "/paper/Domain-adaptation-for-biomedical-image-segmentation-Javanmardi-Tasdizen/c087773ab02786fe0aab67ec49607d1a9edac757",
            "/paper/FCNs-in-the-Wild%3A-Pixel-level-Adversarial-and-Hoffman-Wang/762a75cc06ff35ce026182d1907300e75f9d24c6",
            "/paper/Unsupervised-domain-adaptation-in-brain-lesion-with-Kamnitsas-Baumgartner/c1cc356ae6303b254ce88919ade3907221a5b58d",
            "/paper/ADVENT%3A-Adversarial-Entropy-Minimization-for-Domain-Vu-Jain/1365b4a286e607a4902ef11c84a1f309719d946c",
            "/paper/A-Comprehensive-Retinal-Image-Dataset-for-the-of-Sivaswamy-Chakravarty/04b45aeaa59a19340652ad28d650429054d3e7fd"
        ]
    },
    {
        "id": "a3196e65467b80f4755968923b382e40c02ccb51",
        "title": "Two-Stream Convolution Augmented Transformer for Human Activity Recognition",
        "abstract": "A novel Two-stream Convolution Augmented Human Activity Transformer model that uses a two-stream structure to capture both time-over-channel and channel- over-time features, and uses the multi-scale convolution augmented transformer to capture range-based patterns. Recognition of human activities is an important task due to its far-reaching applications such as healthcare system, context-aware applications, and security monitoring. Recently, WiFi based human activity recognition (HAR) is becoming ubiquitous due to its non-invasiveness. Existing WiFi-based HAR methods regard WiFi signals as a temporal sequence of channel state information (CSI), and employ deep sequential models (e.g., RNN, LSTM) to automatically capture channel-over-time features. Although being remarkably effective, they suffer from two major drawbacks. Firstly, the granularity of a single temporal point is blindly elementary for representing meaningful CSI patterns. Secondly, the time-over-channel features are also important, and could be a natural data augmentation. To address the drawbacks, we propose a novel Two-stream Convolution Augmented Human Activity Transformer (THAT) model. Our model proposes to utilize a two-stream structure to capture both time-over-channel and channel-over-time features, and use the multi-scale convolution augmented transformer to capture range-based patterns. Extensive experiments on four real experiment datasets demonstrate that our model outperforms state-of-the-art models in terms of both effectiveness and efficiency.",
        "publication_year": "2021",
        "authors": [
            "Bing Li",
            "Wei Cui",
            "Wen Wang",
            "Le Zhang",
            "Zhenghua Chen",
            "Min Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "45",
        "reference_count": "28",
        "references": [
            "/paper/Multi-scale-Convolution-Transformer-for-Human-Gao-Wang/97b03dbc329d1c18adea23a6c81558a5abeb3d12",
            "/paper/Dual-Stream-Contrastive-Learning-for-Channel-State-Xu-Wang/e624c652f094e4478f31325b7286b028da402228",
            "/paper/Recurrent-ConFormer-for-WiFi-Activity-Recognition-Shang-Hong/2313b22beecf4bd1c69f7cebce2bac61e35bf74b",
            "/paper/A-Deep-Dilated-Convolutional-Self-attention-Model-Wang-Xiao/f1983237c325ed8fa15710dff826ad9e51282126",
            "/paper/Multi-View-Fusion-Transformer-for-Sensor-Based-Wang-Yu/cab882ea5322e3af28854fe4b3df1219e6f6258c",
            "/paper/TCN-AA%3A-A-Wi-Fi-based-Temporal-Convolution-Network-Lin-Liu/600c76554c1fc26ff8c8cb0be2a4f1ea87f5766e",
            "/paper/Towards-WiFi-based-Real-time-Sensing-Model-Deployed-Lu-Wang/e505a777370fb9a9d2bb8ea3d1d6818627514cd0",
            "/paper/WiTransformer%3A-A-Novel-Robust-Gesture-Recognition-Yang-Zhu/97f287a817355ec4f3f864edb18070dd5a5379ae",
            "/paper/Context-Aware-Faster-RCNN-for-CSI-Based-Human-Sheng-Xiao/9c6afedcac93929b3e5f46b5ddd75b34e8abb3b8",
            "/paper/Device-Free-Human-Activity-Recognition-Based-on-Gu-He/c503f54e890f4d92dc4ca098a16910dce0fa46d6",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/Deep-Learning-Networks-for-Human-Activity-with-CSI-Shi-Zhang/a65b07970e4deb8b237e043a669912682a1e015a",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/Using-Wi-Fi-channel-state-information-(CSI)-for-and-Chowdhury/6415cbbdb171433e081f84b90897043e4c2a37dd",
            "/paper/Human-Activity-Recognition%3A-A-Survey-Jobanputra-Bavishi/1c9f47519b998dd8f9f49b0fb8477035b63a6bd1",
            "/paper/Understanding-and-Modeling-of-WiFi-Signal-Based-Wang-Liu/539b28563ecd9fa14be7134bc17ec942958d00db",
            "/paper/Device-Free-Human-Activity-Recognition-Using-WiFi-Wang-Liu/f312682ae93523de41a4f1e2bc0ca30e4345c8a4",
            "/paper/RT-Fall%3A-A-Real-Time-and-Contactless-Fall-Detection-Wang-Zhang/ca117d143e0e3f6a073ac6705b472072c8f676e5",
            "/paper/A-Survey-on-Human-Behavior-Recognition-Using-State-Wang-Jiang/0200e8f470ff6692effabdd76b3154735055944e",
            "/paper/SignFi%3A-Sign-Language-Recognition-Using-WiFi-Ma-Zhou/47899fc484fda880af2168a2e8d91beaf68e7722"
        ]
    },
    {
        "id": "c5386effca34bdf0a99d97004d72dab8b71dc1b5",
        "title": "Multi-memory video anomaly detection based on scene object distribution",
        "abstract": "A multi-memory video anomaly detection algorithm based on scene object distribution that attains competitive detection accuracy and considers the difficulty of anomaly positioning, a new anomaly location method that combines global anomalies and local anomalies is proposed. With the popularity of surveillance equipment and the rise of intelligent surveillance, video anomaly detection has gradually become a research hotspot. Among them, for video processing, the three-channel video frame data can be directly used as the input of model, or some motion information can be extracted from the video frame, such as calculating optical flow, and then motion information and video frame can be input into the model together for anomaly detection. However, since the amount of background information in the overall situation is far greater than that of object information, abnormal objects are not concerned. In addition, there ia a phenomenon that objects close to the camera are more likely to be judged as anomalous due to the difference in viewpoint resulting in different sizes of objects captured in the scene. This paper proposes a multi-memory video anomaly detection algorithm based on scene object distribution. Firstly, add local anomaly branch to the model, and use memory modules to explicitly model the multiple normal modes of the global frame and the local object; secondly, scale the object to the same measurement standard according to the scene object distribution, which alleviates the impact of the view difference; finally, considering the difficulty of anomaly positioning, a new anomaly location method that combines global anomalies and local anomalies is proposed. The experimental results on the UCSD Ped2, CUHK Avenue and ShanghaiTech datasets have obtained AUC values of 96.75%, 84.34% and 77.08% respectively, which shows that the proposed method attains competitive detection accuracy.",
        "publication_year": "2023",
        "authors": [
            "Hongjun Li",
            "Jinyi Chen",
            "Xiaohu Sun",
            "Chaobo Li",
            "Junjie Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "20",
        "references": [
            "/paper/Video-anomaly-detection-with-multi-scale-feature-Cai-Liu/d8663556aa1a875dcdc4f15ad1fd31933e724348",
            "/paper/Improved-Anomaly-Detection-in-Surveillance-Videos-Xu-Zeng/346f0144f12b58ac161afe9ab7a778f45e32fd44",
            "/paper/Anomaly-detection-in-surveillance-video-based-on-Chen-Wang/7207721ba8e12750758269722668ccb03707ddd0",
            "/paper/A-comparative-study-between-single-and-multi-frame-Bahrami-Pourahmadi/11e1df865497805435881f7cf9e45fe6917149b0",
            "/paper/Improving-video-anomaly-detection-performance-by-Wu-Li/a024ac49a2b3272ee174ef2a991d3515359fe148",
            "/paper/Decoupled-Appearance-and-Motion-Learning-for-in-Li-Leroux/dae4243c7e45f0d73c56cb58898ece8c9693469b",
            "/paper/A-cascade-reconstruction-model-with-generalization-Zhong-Chen/7fd052d40660d65c8497599794467812b78e1d0b",
            "/paper/An-explainable-and-efficient-deep-learning-for-Wu-Shao/a6d4a926600645ca591b3d8ac88a3eeaf10d5130",
            "/paper/D-CAD%3A-Deep-and-Crowded-Anomaly-Detection-Kumar-Kumar/eea203899d89d9047b7cf88090331551895b49a4",
            "/paper/Online-Anomaly-Detection-in-Surveillance-Videos-on-Doshi-Yilmaz/e0e25f7bc95afd3c7fa8097f8db7fb83238de243"
        ]
    },
    {
        "id": "d8dbaf83fc2b82269221e391e280491659d43315",
        "title": "A survey on Deep Learning-based Panoptic Segmentation",
        "abstract": "Semantic Scholar extracted view of \"A survey on Deep Learning-based Panoptic Segmentation\" by Xin-Yan Li et al.",
        "publication_year": "2021",
        "authors": [
            "Xin-Yan Li",
            "Ding Chen"
        ],
        "related_topics": [
            "Physics"
        ],
        "citation_count": "10",
        "reference_count": "97",
        "references": [
            "/paper/Semantic-Segmentation-of-Remote-Sensing-Imagery-on-Cheng-Lei/06b002e1ba39fa5a3fb1642a79ee971e2d1e95af",
            "/paper/MVTr%3A-multi-feature-voxel-transformer-for-3D-object-Ai-Xie/d0f56fbe02512194ea7321b50f88094d1ecae214",
            "/paper/Physics-Informed-Computer-Vision%3A-A-Review-and-Banerjee-Nguyen/763fd38d01fb5804aa576ebcb28d123e643d1874",
            "/paper/An-efficient-image-segmentation-method-based-on-and-Ehsaeyan/3483f862e6c8d603d0e5b60ad720f860b1a9d532",
            "/paper/An-interpretable-machine-learning-framework-for-Liu-Chen/c4426f7ffb557562d9ff5d28b80b8e34d90e3e1f",
            "/paper/Region-of-interest-image-encryption-method-based-on-Zhang-Hu/7a1125cdbd18d57a6cea747e42ce5584d18bc33e",
            "/paper/Fast-DC-Optimal-Power-Flow-Based-on-Deep-Neural-Wu-Xu/d1df03d2287d6c63919ff08140c3de1da13661d7",
            "/paper/Active-Constraint-Identification-Assisted-DC-Power-Wu-Wang/8930dbcc2ccb15f41898f9fcd2f1e5e682e4c469",
            "/paper/R-VPCG%3A-RGB-image-feature-fusion-based-virtual-for-Ai-Xie/9c6df268cf110ad6359ba4c2b4aee633c94705c6",
            "/paper/A-novel-edge-detection-method-based-on-dynamic-P-Yan-Zhang/221b2b14352ac777b5ff1704b95eb84c69683478",
            "/paper/Multi-task-Network-for-Panoptic-Segmentation-in-Petrovai-Nedevschi/8488066920ade4644d3561cb1601b2107a95d18d",
            "/paper/REFINE%3A-Prediction-Fusion-Network-for-Panoptic-Ren-Yu/78a79a7cb5f4d39f7a87980ed7c41c5cd7d990cc",
            "/paper/Single-Network-Panoptic-Segmentation-for-Street-Geus-Meletis/313874e7655927fc1c40585ae21d884de5e126d8",
            "/paper/EPSNet%3A-Efficient-Panoptic-Segmentation-Network-Chang-Chang/1faf3477c1dac16623720c47339822497679e0bc",
            "/paper/Panoptic-Segmentation-Kirillov-He/dce916351ef589afa7a63452648dd8acba931e92",
            "/paper/UPSNet%3A-A-Unified-Panoptic-Segmentation-Network-Xiong-Liao/0fa49ec594ad49cee218543d0d1491425801e1a3",
            "/paper/Panoster%3A-End-to-End-Panoptic-Segmentation-of-LiDAR-Gasperini-Mahani/06a741d894655045e327f8819575a8b3ccbd8a52",
            "/paper/Fully-Convolutional-Networks-for-Panoptic-Li-Zhao/58b4202b7174ed4cfae24c284d4003d74ac5371f",
            "/paper/Video-Panoptic-Segmentation-Kim-Woo/02ebf1827a1cb08eea241e2fc80f8269f4d5a041",
            "/paper/Fast-Panoptic-Segmentation-Network-Geus-Meletis/f289f3ada9d0f3216e556460775ea162746d114a"
        ]
    },
    {
        "id": "63207e9edaf55b24bb587ac0102a128389aead50",
        "title": "Machine Learning in NextG Networks via Generative Adversarial Networks",
        "abstract": "As a use case of GAN for NextG communications, it is shown that a GAN can be effectively applied for anomaly detection in signal classification outperforming another state-of-the-art ML technique, an autoencoder. Generative Adversarial Networks (GANs) are Machine Learning (ML) algorithms that have the ability to address competitive resource allocation problems together with detection and mitigation of anomalous behavior. In this paper, we investigate their use in next-generation (NextG) communications within the context of cognitive networks to address i) spectrum sharing, ii) detecting anomalies, and iii) mitigating security attacks. GANs have the following advantages. First, they can learn and synthesize field data, which can be costly, time consuming, and nonrepeatable. Second, they enable pre-training classifiers by using semi-supervised data. Third, they facilitate increased resolution. Fourth, they enable the recovery of corrupted bits in the spectrum. The paper provides the basics of GANs, a comparative discussion on different kinds of GANs, performance measures for GANs in computer vision and image processing as well as wireless applications, a number of datasets for wireless applications, performance measures for general classifiers, a survey of the literature on GANs for i)\u2013iii) above, and future research directions. As a use case of GAN for NextG communications, we show that a GAN can be effectively applied for anomaly detection in signal classification (e.g., user authentication) outperforming another state-of-the-art ML technique, an autoencoder.",
        "publication_year": "2022",
        "authors": [
            "E. Ayanoglu",
            "Kemal Davaslioglu",
            "Y. Sagduyu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "180",
        "references": [
            "/paper/Adversarial-Machine-Learning-in-Wireless-Using-RF-A-Adesina-Hsieh/85b063ab7990c2a54ab2f009988cd1af4b84df6d",
            "/paper/Sensing-Throughput-Tradeoffs-with-Generative-for-Shi-Sagduyu/2739efa693df35c9b9cd5f7e6002947a6cea756f",
            "/paper/Adversarial-Machine-Learning-Based-Anticipation-of-Omara-Kantarci/9e537ce577fc680adde9abc38fc93b94e534ed4a",
            "/paper/Self-Supervised-RF-Signal-Representation-Learning-Davaslioglu-Bozta%C5%9F/b7c4968ba4cbb4a3ceb45571e0fae75731beebaf",
            "/paper/Model-Based-Data-Augmentation-Applied-to-Deep-for-Rojhani-Passafiume/97a3c25186626434391ce1cf8a6622c62efc4a92",
            "/paper/A-novel-hardware-authentication-primitive-against-Liu-Cheng/53b634165ce7ce9cd2c3dffaa74bd8c5122f4088",
            "/paper/Spectrum-Anomaly-Detection-Based-on-Spatio-Temporal-Peng-Hu/d4ad700850cd7a02944f996adc3a72cfc3fca884",
            "/paper/Unlocking-Metaverse-as-a-Service-The-three-pillars-Ahsani-Rahimi/071de7472b63d03dacb51eb239ca1e2f219584e2",
            "/paper/Generative-Adversarial-Networks-Based-Automatic-for-Li-Li/9019e38f66d97241e476924f66dc9e3bb7a457c6",
            "/paper/Generative-Adversarial-Learning-for-Spectrum-Davaslioglu-Sagduyu/5e2d9d7e94b4587c452df573b9b8ed05fa9ac828",
            "/paper/MDGAN%3A-Boosting-Anomaly-Detection-Using-Generative-Intrator-Katz/cd85bd61e6cfd477e104a8b4dde723c0e0e7ad3d",
            "/paper/Digital-Signal-Modulation-Classification-With-Data-Tang-Tu/8315c4fdcd976315d061f4451493198829e2b348",
            "/paper/GanDef%3A-A-GAN-based-Adversarial-Training-Defense-Liu-Khalil/13f8a836c61f316cade2a5b027e359b41e4396b7",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Evaluating-Adversarial-Evasion-Attacks-in-the-of-Flowers-Buehrer/a18bfcd9b3bdc8d9e1f771e5809f22d965ec4ceb",
            "/paper/DOPING%3A-Generative-Data-Augmentation-for-Anomaly-Lim-Loo/a47f8794d88c5c27123153c4eb9e08046e2b0c9d",
            "/paper/Model-Partition-Defense-against-GAN-Attacks-on-via-Ching-Lin/55a7188fa69a1a78e735a056991db8ca1f82ba06",
            "/paper/Defense-GAN%3A-Protecting-Classifiers-Against-Attacks-Samangouei-Kabkab/f7bb1636ced9036b3d0edafc7d82ad43164d41a3"
        ]
    },
    {
        "id": "8eef32d2f75604fc829a169d671b08fb48fff947",
        "title": "Node Classification and Link Prediction in Social Graphs using RLVECN",
        "abstract": "This paper has proposed a unique hybrid model: Representation Learning via Knowledge-Graph Embeddings and ConvNet (RLVECN), designed for analyzing and extracting expressive feature representations from social network structures to aid in link prediction, node classification and community detection tasks. Node classification and link prediction problems in Social Network Analysis (SNA) remain open research problems with respect to Artificial Intelligence (AI). Inherent representations about social network structures can be effectively harnessed for training AI models in a bid to detect clusters via classification of actors as well as predict ties with regard to a given social network. In this paper, we have proposed a unique hybrid model: Representation Learning via Knowledge-Graph Embeddings and ConvNet (RLVECN). Our proposition is designed for analyzing and extracting expressive feature representations from social network structures to aid in link prediction, node classification and community detection tasks. RLVECN utilizes an edge sampling technique for exploiting features of a given social network via learning the context of each actor with respect to its associate actors.",
        "publication_year": "2020",
        "authors": [
            "Bonaventure C. Molokwu",
            "Shaon Bhatta Shuvo",
            "N. Kar",
            "Ziad Kobti"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "42",
        "references": [
            "/paper/The-Influence-of-Network-Structural-Preference-on-Mohammed-G%C3%BCnd%C3%BC%C3%A7/1fc134c0cc82632a7c28479a4ff430f3988f1da4",
            "/paper/A-deep-learning-and-heuristic-methodology-for-in-Molokwu-Shuvo/77089019b91e2af43ad9fd046bd001c62dc2838e",
            "/paper/HITS-GNN%3A-A-Simplified-Propagation-Scheme-for-Graph-Khan-Mello/33e7f916daef8d17427a08b992ba7c6044f445c4",
            "/paper/TPM%3A-Transition-Probability-Matrix-Graph-Structural-Mohammed-Gunducc/37e76cc4d5810903f69614a2d284110b39164029",
            "/paper/HRotatE%3A-Hybrid-Relational-Rotation-Embedding-for-Shah-Molokwu/2928e5157a13fcdb386aa3921c8382dd84ac44ed",
            "/paper/Deep-learning-model-construction-for-a-with-feature-Mandapati-Kadry/7d76d47f6df7e84d40f38ac42414a9031b88d2eb",
            "/paper/Deep-graph-neural-network-for-video-based-facial-Patania-Boccignone/c799a47cdb19e16efe5997884ed5e1491a70e369",
            "/paper/Event-Prediction-in-Complex-Social-Graphs-using-Molokwu/722620692e742a4f279c5471a9dc17c8abf70777",
            "/paper/Event-Prediction-in-Social-Graphs-Using-Neural-Molokwu/bead92b0fe3aecf9ded8dedf0ececf5bd5623657",
            "/paper/Spatial-Event-Prediction-via-Multivariate-Time-of-Molokwu-Kobti/8a19aa94a3b5cea49d79a8b12e7324b5ec1466e7",
            "/paper/node2vec%3A-Scalable-Feature-Learning-for-Networks-Grover-Leskovec/36ee2c8bd605afd48035d15fdc6b8c8842363376",
            "/paper/Collective-Classification-in-Network-Data-Sen-Namata/43d2ed5c3c55c1100450cd74dc1031afa24d37b2",
            "/paper/Multi-scale-Attributed-Node-Embedding-Rozemberczki-Allen/135334ea7fdef8eef0367e862797cac7dcd232a4",
            "/paper/LINE%3A-Large-scale-Information-Network-Embedding-Tang-Qu/0834e74304b547c9354b6d7da6fa78ef47a48fa8",
            "/paper/Entity-and-Relationship-Labeling-in-Affiliation-Zhao-Sen/c047f91ece3e9ec74bf42b8f69f375e27498a54a",
            "/paper/DeepWalk%3A-online-learning-of-social-representations-Perozzi-Al-Rfou/fff114cbba4f3ba900f33da574283e3de7f26c83",
            "/paper/Social-Network-Data-Analytics-Aggarwal/f5a059e8f50ae137e0146fbf32e199d8c6dcb83a"
        ]
    },
    {
        "id": "a32ec5656d7cc05d770f401c78fbca759aa52b08",
        "title": "KDnet-RUL: A Knowledge Distillation Framework to Compress Deep Neural Networks for Machine Remaining Useful Life Prediction",
        "abstract": "A knowledge distillation framework, entitled KDnet-RUL, to compress a complex LSTM-based method for RUL prediction and demonstrates that the proposed method significantly outperforms state-of-the-art KD methods. Machine remaining useful life (RUL) prediction is vital in improving the reliability of industrial systems and reducing maintenance cost. Recently, long short-term memory (LSTM) based algorithms have achieved state-of-the-art performance for RUL prediction due to their strong capability of modeling sequential sensory data. In many cases, the RUL prediction algorithms are required to be deployed on edge devices to support real-time decision making, reduce the data communication cost, and preserve the data privacy. However, the powerful LSTM-based methods which have high complexity cannot be deployed to edge devices with limited computational power and memory. To solve this problem, we propose a knowledge distillation framework, entitled KDnet-RUL, to compress a complex LSTM-based method for RUL prediction. Specifically, it includes a generative adversarial network based knowledge distillation (GAN-KD) for disparate architecture knowledge transfer, a learning-during-teaching based knowledge distillation (LDT-KD) for identical architecture knowledge transfer, and a sequential distillation upon LDT-KD for complicated datasets. We leverage simple and complicated datasets to verify the effectiveness of the proposed KDnet-RUL. The results demonstrate that the proposed method significantly outperforms state-of-the-art KD methods. The compressed model with 12.8 times less weights and 46.2 times less total float point operations even achieves a comparable performance with the complex LSTM model for RUL prediction.",
        "publication_year": "2021",
        "authors": [
            "Qing Xu",
            "Zhenghua Chen",
            "Keyu Wu",
            "Chao Wang",
            "Min Wu",
            "Xiaoli Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "20",
        "reference_count": "44",
        "references": [
            "/paper/Bi-LSTM-Based-Two-Stream-Network-for-Machine-Useful-Jin-Chen/e751128df94f367eea17933e9dbe218f3ef1f724",
            "/paper/AI-Techniques-for-Applications-of-Equipment-Useful-Xiaoli/59bf9eacb5d9fca6de4b08dbb93fb48776cb11d3",
            "/paper/Domain-Knowledge-Distillation-and-Supervised-for-Ai-Xie/e866371809149f8bb4eb8b60f8fba4e46a63fd0e",
            "/paper/Dual-Channel-Feature-Attention-Based-Approach-for-Gao-Li/f60e50df0674dc8446c507395ce4343495d2b5ff",
            "/paper/Process-Operation-Performance-Assessment-Based-on-Bu-Liu/ec0abc6cc2fbe70c0e88c8e42b3c5a6e2ddc9f24",
            "/paper/A-Lightweight-Transfer-Learning-Model-with-Pruned-Huang-Zhou/d8a3a938740f235201d7b76fa27740a04576460e",
            "/paper/Remaining-Useful-Life-Prediction-of-Aeroengines-on-Nie-Xu/723218098246622705092709acdc2da67aa24fb5",
            "/paper/A-%24T%5E%7B2%7D%24-Tensor-Aided-Multiscale-Transformer-for-Ren-Jia/9031bc8591886005f1aa2e7f27847c68b07bb975",
            "/paper/An-industrial-grade-solution-for-agricultural-image-Peng-Wang/33f5913a2d499e7de12b1d645636902265297374",
            "/paper/A-Survey-on-AI-Sustainability%3A-Emerging-Trends-on-Chen-Wu/0af1e03219f841852d558172661ecc60697ef55a",
            "/paper/Contrastive-Adversarial-Domain-Adaptation-for-Life-Ragab-Chen/b7eceaa1ecaf36748cd564212cda8414024c85d3",
            "/paper/Machine-Remaining-Useful-Life-Prediction-via-an-Chen-Wu/64aff4bac4dd205861488adade6c651085ce6b32",
            "/paper/Deep-Transfer-Learning-Based-on-Sparse-Autoencoder-Sun-Ma/217c1c0c67a007ee1ccb4d602702fd1f560b20e3",
            "/paper/Long-Short-Term-Memory-Network-for-Remaining-Useful-Zheng-Ristovski/e66afb33d246dbe3199fd57bcfc1b611136d96c2",
            "/paper/Knowledge-Distillation-with-Feature-Maps-for-Image-Chen-Chang/0d737e86745903d6a9ab5c6c21d2ce74fe10164f",
            "/paper/Remaining-Useful-Life-Prediction-Based-on-a-Neural-Yang-Liu/60f317f7e5ddba6789535db49e309bc39b604135",
            "/paper/Born-Again-Neural-Networks-Furlanello-Lipton/2444be7584d1f5a7e2aa9f65078de09154f14ea1",
            "/paper/Deep-Learning-Based-Machinery-Fault-Diagnostics-at-Li-Zhang/bc3245f3aa9810c2dedc43dff9b8085c3dda7663",
            "/paper/Learning-Efficient-Object-Detection-Models-with-Chen-Choi/16161051ee13dd3d836a39a280df822bf6442c84",
            "/paper/Estimation-of-Bearing-Remaining-Useful-Life-Based-Zhu-Chen/9c38986568db937527c3a6c8d847c317136eac74"
        ]
    },
    {
        "id": "62d49fa60b54fed1e2a2cde3cb49d3639db76768",
        "title": "Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for Supervised Anomaly Detection",
        "abstract": "This paper proposes a novel explicit boundary guided semi-push-pull contrastive learning mechanism, which can enhance model's discriminability while mitigating the bias issue and form a more explicit and discriminative decision boundary to distinguish known and also unseen anomalies from normal samples more effectively. Most anomaly detection (AD) models are learned using only normal samples in an unsupervised way, which may result in ambiguous decision boundary and insufficient discriminability. In fact, a few anomaly samples are often available in real-world applications, the valuable knowledge of known anomalies should also be effectively exploited. However, utilizing a few known anomalies during training may cause another issue that the model may be biased by those known anomalies and fail to generalize to unseen anomalies. In this paper, we tackle supervised anomaly detection, i.e., we learn AD models using a few available anomalies with the objective to detect both the seen and unseen anomalies. We propose a novel explicit boundary guided semi-push-pull contrastive learning mechanism, which can enhance model's discriminability while mitigating the bias issue. Our approach is based on two core designs: First, we find an explicit and compact separating boundary as the guidance for further feature learning. As the boundary only relies on the normal feature distribution, the bias problem caused by a few known anomalies can be alleviated. Second, a boundary guided semi-push-pull loss is developed to only pull the normal features together while pushing the abnormal features apart from the separating boundary beyond a certain margin region. In this way, our model can form a more explicit and discriminative decision boundary to distinguish known and also unseen anomalies from normal samples more effectively. Code will be available at https://github.com/xcyao00/BGAD.",
        "publication_year": "2022",
        "authors": [
            "Xincheng Yao",
            "Ruoqing Li",
            "Jing Zhang",
            "Jun Sun",
            "Chongyang Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "54",
        "references": [
            "/paper/Efficient-Anomaly-Detection-with-Budget-Annotation-Li-Wu/ad4a998b7b2af6e607ea917d5e6974b0a097cc54",
            "/paper/No-Free-Lunch%3A-The-Hazards-of-Over-Expressive-in-Reiss-Cohen/9b09c3424456c587aa8239d108116d1e2afd4992",
            "/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "/paper/Catching-Both-Gray-and-Black-Swans%3A-Open-set-Ding-Pang/6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "/paper/VT-ADL%3A-A-Vision-Transformer-Network-for-Image-and-Mishra-Verk/913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e",
            "/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "/paper/Randaugment%3A-Practical-automated-data-augmentation-Cubuk-Zoph/87f6a7c014ce206ac5b57299c07e10667d194b39",
            "/paper/DR%C3%86M-%E2%80%93-A-discriminatively-trained-reconstruction-Zavrtanik-Kristan/95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "/paper/Explainable-Deep-Few-shot-Anomaly-Detection-with-Pang-Ding/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "/paper/CFLOW-AD%3A-Real-Time-Unsupervised-Anomaly-Detection-Gudovskiy-Ishizaka/fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "/paper/PaDiM%3A-a-Patch-Distribution-Modeling-Framework-for-Defard-Setkov/2e8d62277e40d465343e8dfb32ecc246f320540e",
            "/paper/Explainable-Deep-One-Class-Classification-Liznerski-Ruff/16a67491ed4bdb6293d1c2be35b0e8bae962cdeb"
        ]
    },
    {
        "id": "3ea71ab8877a3e96ce82daf24aacd3ccbcd19138",
        "title": "Fast, sensitive, and accurate integration of single cell data with Harmony",
        "abstract": "Harmony, for the integration of single-cell transcriptomic data, identifies broad and fine-grained populations, scales to large datasets, and can integrate sequencing- and imaging-based data. The emerging diversity of single-cell RNA-seq datasets allows for the full transcriptional characterization of cell types across a wide variety of biological and clinical conditions. However, it is challenging to analyze them together, particularly when datasets are assayed with different technologies, because biological and technical differences are interspersed. We present Harmony (https://github.com/immunogenomics/harmony), an algorithm that projects cells into a shared embedding in which cells group by cell type rather than dataset-specific conditions. Harmony simultaneously accounts for multiple experimental and biological factors. In six analyses, we demonstrate the superior performance of Harmony to previously published algorithms while requiring fewer computational resources. Harmony enables the integration of ~106 cells on a personal computer. We apply Harmony to peripheral blood mononuclear cells from datasets with large experimental differences, five studies of pancreatic islet cells, mouse embryogenesis datasets and the integration of scRNA-seq with spatial transcriptomics data.Harmony, for the integration of single-cell transcriptomic data, identifies broad and fine-grained populations, scales to large datasets, and can integrate sequencing- and imaging-based data.",
        "publication_year": "2018",
        "authors": [
            "I. Korsunsky",
            "Jean Fan",
            "Kamil Slowikowski",
            "Fan Zhang",
            "K. Wei",
            "Y. Baglaenko",
            "M. Brenner",
            "Po-ru Loh",
            "S. Raychaudhuri"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "2,049",
        "reference_count": "63",
        "references": [
            "/paper/Robust-integration-of-multiple-single-cell-RNA-a-Liu-Wang/6138553d7919172ac500d4ce24ec50b1a0ba812b",
            "/paper/Unbiased-integration-of-single-cell-multi-omics-Dou-Liang/014df485e731b8af31ef0609aee387c3be7886a1",
            "/paper/Construction-of-continuously-expandable-single-cell-Xiong-Tian/38fe1305e704bdd5852226b8c109b7b6eb4253b1",
            "/paper/Fast-model-free-standardization-and-integration-of-Xu-Kramann/67a42d0eb5565b64ad692c8cfd6172b300f0f8d3",
            "/paper/Integration-of-Single-Cell-RNA-Seq-Datasets%3A-A-of-Ryu-Han/d9084620a15a94d0853c5f94ff29767362176185",
            "/paper/A-comparison-of-data-integration-methods-for-RNA-of-Richards-Riverin/3ade37352a8d63048528d67badff5e4090ee019a",
            "/paper/MASI-enables-fast-model-free-standardization-and-of-Xu-Kramann/feee5eb3dc2603cba83f7a139b69611668830c08",
            "/paper/Single-cell-RNA-sequencing-(scRNA-seq)-studies-now-Hie-Cho/e0b10d90ee717d9b12b84c0f4bdfe850c6710e65",
            "/paper/Panpipes%3A-a-pipeline-for-multiomic-single-cell-data-Rich-Griffin-Curion/f342394d98a878200901be61902c1ab5e36c2437",
            "/paper/BATMAN%3A-Fast-and-Accurate-Integration-of-RNA-Seq-Mandric-Hill/cf3636e3a33b15e7423c7c13bcd6d69df0a58044",
            "/paper/Integrating-single-cell-transcriptomic-data-across-Butler-Hoffman/458c8ca3c2818b479d91dbdb83f2d10ded3708fa",
            "/paper/Panoramic-stitching-of-heterogeneous-single-cell-Hie-Bryson/4fa8467208a4ba0d1770766944467fc3e2e6c9da",
            "/paper/Fast-Batch-Alignment-of-Single-Cell-Transcriptomes-Park-Pola%C5%84ski/7f68da146ba5d4eb0fbf267b07b68d7c402253b8",
            "/paper/Massively-parallel-digital-transcriptional-of-cells-Zheng-Terry/17422a9fcf3f05408f7f2f270b127aa812e9b2b3",
            "/paper/A-step-by-step-workflow-for-low-level-analysis-of-Lun-McCarthy/d2ace21f80a8ac89a07159247762623a1738cd55",
            "/paper/A-step-by-step-workflow-for-low-level-analysis-of-Lun-McCarthy/74e86a3375ac2c2ffe89577fbf16456eb39ff581",
            "/paper/BBKNN%3A-fast-batch-alignment-of-single-cell-Pola%C5%84ski-Young/e6368f1cb43fb26b0f006ebd711984d5a8cd530f",
            "/paper/Human-Cell-Kataoka/14f0406e615c001aae413fc28d65475f7853da1e",
            "/paper/A-Single-Cell-Transcriptome-Atlas-of-the-Human-Muraro-Dharmadhikari/c75f827cefef8da91be9e88d8a99ab308428084a",
            "/paper/A-Single-Cell-Transcriptomic-Map-of-the-Human-and-Baron-Veres/25a15f29e54fad3b3451b13be3eed80e4888d486"
        ]
    },
    {
        "id": "7b61333d086b2c81fe091e62da0f94899411adbe",
        "title": "Variable step-size sign subband adaptive filter with subband filter selection",
        "abstract": "Semantic Scholar extracted view of \"Variable step-size sign subband adaptive filter with subband filter selection\" by Jaegeol Cho et al.",
        "publication_year": "2018",
        "authors": [
            "Jaegeol Cho",
            "H. Baek",
            "B. Park",
            "Jaewook Shin"
        ],
        "related_topics": [
            "Engineering"
        ],
        "citation_count": "10",
        "reference_count": "22",
        "references": [
            "/paper/Delayless-Block-Individual-Weighting-Factors-Sign-Kim-Choi/ec230350b307cde84583a2b5d97da38cc009eae5",
            "/paper/Two-Low-Computational-Complexity-Improved-Multiband-Abadi-Hus%C3%B8y/78802de2085e250c36c90da8f85100aede454a5b",
            "/paper/Variable-step-size-normalized-subband-adaptive-for-Lu-Zhang/6c5f2c4764dbb436933b821d2261c736388066d2",
            "/paper/A-novel-normalized-subband-adaptive-filter-based-on-Shin-Park/bd3fd27d2a7f6b8e58db3ae07f3a772fbf90c4c4",
            "/paper/Sparsity-aware-normalized-subband-adaptive-filters-Ji-Ni/aae369697b10bd7eb2e9c21a8c1911a4359707f0",
            "/paper/Weighted-Improved-Multiband-Structured-Sub-Band-Abadi-Ahmadi/e0de0bed782b1eb8cd061c947538d8472753d864",
            "/paper/Design-of-a-Narrowband-Adaptable-Filter-in-Domain-Mao-Gao/17d19ff35adf28d46d074e03b0f93e510ea7cee2",
            "/paper/A-New-Approach-of-Adaptive-Filtering-Updating-for-Hamidia-Amrouche/49ec0f8f1d39b606432f4007a2c2472db1abe8b8",
            "/paper/Robust-and-sparsity-aware-adaptive-filters%3A-A-Kumar-Pandey/bdd4e52c88601085cfffa63493f4f5b95eed6034",
            "/paper/A-family-of-variable-step-size-sparsity-aware-SSAF-Liu-Zhao/db1c634a9b3eaf628cbfde78b70794dcc37178c3",
            "/paper/Variable-Step-Size-Sign-Subband-Adaptive-Filter-Shin-Yoo/3a4eb71e3cd6182d3f24852b662d9de01be72c10",
            "/paper/Sign-subband-adaptive-filter-with-selection-of-of-Jeong-Kim/562d1ce1bdbc9502caa51d4696da74fa8334cc5c",
            "/paper/A-band-dependent-variable-step-size-sign-subband-Yoo-Shin/8d387d2b68f31fb96f06ed9c243bffb150838dcf",
            "/paper/Novel-sign-subband-adaptive-filter-algorithms-with-Yu-Zhao/f60191030674a718604f4b9051704337d9a57ef5",
            "/paper/A-Subband-Adaptive-Filtering-Algorithm-Employing-of-Kim-Choi/1eb2da956a1db86eb3b4816715b4e010c18f274f",
            "/paper/Combined-Step-Size-Normalized-Subband-Adaptive-With-Huang-Zhang/ed7ebe0059ea966e8e9589be1b26edb016433078",
            "/paper/A-Low-Complexity-NSAF-Algorithm-Rabiee-Ahmadian-Attari/82fc72e6a84577e91617571f7c515edef725a329",
            "/paper/Selective-partial-update-and-set-membership-subband-Abadi-Hus%C3%B8y/bc4ad3176ce94f3d15c0ab54a9d51e566e7bef4d",
            "/paper/A-Variable-Step-Size-Normalized-Subband-Adaptive-a-Hur-Song/4e81a2fd72000928cb2dc93c1646332b9dd1ee1b",
            "/paper/Variable-regularisation-parameter-sign-subband-Ni-Li/efdccb5ebbdd69eeb70a17a5019174090336a623"
        ]
    },
    {
        "id": "792250ae660b7c25f85eeea7dcae623e4301d97c",
        "title": "Remembering history with convolutional LSTM for anomaly detection",
        "abstract": "This paper proposes a ConvLSTM-AE framework which better encodes the change of appearance and motion for normal events, respectively, in videos, and results show that this method can easily identify the change in appearance andmotion. This paper tackles anomaly detection in videos, which is an extremely challenging task because anomaly is unbounded. We approach this task by leveraging a Convolutional Neural Network (CNN or ConvNet) for appearance encoding for each frame, and leveraging a Convolutional Long Short Term Memory (ConvLSTM) for memorizing all past frames which corresponds to the motion information. Then we integrate ConvNet and ConvLSTM with Auto-Encoder, which is referred to as ConvLSTM-AE, to learn the regularity of appearance and motion for the ordinary moments. Compared with 3D Convolutional Auto-Encoder based anomaly detection, our main contribution lies in that we propose a ConvLSTM-AE framework which better encodes the change of appearance and motion for normal events, respectively. To evaluate our method, we first conduct experiments on a synthesized Moving-MNIST dataset under controlled settings, and results show that our method can easily identify the change of appearance and motion. Extensive experiments on real anomaly datasets further validate the effectiveness of our method for anomaly detection.",
        "publication_year": "2017",
        "authors": [
            "Weixin Luo",
            "Wen Liu",
            "Shenghua Gao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "313",
        "reference_count": "24",
        "references": [
            "/paper/Detecting-Video-Anomaly-with-a-Stacked-LSTM-Wei-Li/cc0571b3f95f37c669f6e04fa145b7bfed10f037",
            "/paper/Video-Anomaly-Detection-Based-on-Convolutional-Wang-Yang/2b7f4c6ef0bff93236b313ab78dd71ba4723f0b1",
            "/paper/Exploring-Convolutional-Recurrent-architectures-for-Ravi-Karray/69e4b7eb454fcc140b3e0896dacb56642b1db56b",
            "/paper/Future-Frame-Prediction-Using-Convolutional-VRNN-Lu-MaheshKumar/16e1bdb834340b0fd7a5737dfb87abda373f72ca",
            "/paper/Anomaly-Detection-with-Prototype-Guided-Latent-Lai-Han/0e168983a36d0c1246210ebca2d54ebd7190b4e6",
            "/paper/Making-Reconstruction-based-Method-Great-Again-for-Wang-Qin/2f0bbb6cb441002909d1dc7c5a6d235d30c55c88",
            "/paper/An-efficient-deep-neural-model-for-detecting-crowd-Yang-Tian/86bdbcafde6b0d5be048c67ac517f9c045269e19",
            "/paper/A-Dynamic-Convolutional-Generative-Adversarial-for-Zhang-He/448833a6d8b3e564742f1139a322940927ede14d",
            "/paper/CNN-features-with-bi-directional-LSTM-for-real-time-Ullah-Ullah/b51da153a88c70fd48ff1599e67598777589592e",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429",
            "/paper/Convolutional-Two-Stream-Network-Fusion-for-Video-Feichtenhofer-Pinz/9d9aced120e530484609164c836da64548693484",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/A-Discriminative-Framework-for-Anomaly-Detection-in-Giorno-Bagnell/84f7f9e121c1285e15cefbfc44bcb3322f73b6aa",
            "/paper/3D-Convolutional-Neural-Networks-for-Human-Action-Ji-Xu/80bfcf1be2bf1b95cc6f36d229665cdf22d76190",
            "/paper/Learning-Spatiotemporal-Features-with-3D-Networks-Tran-Bourdev/d25c65d261ea0e6a458be4c50c40ffe5bc508f77",
            "/paper/Long-term-recurrent-convolutional-networks-for-and-Donahue-Hendricks/f01fc808592ea7c473a69a6e7484040a435f36d9",
            "/paper/Deep-Convolutional-and-LSTM-Recurrent-Neural-for-Ordonez-Roggen/c8599a64beec9ec141a97c8117aa5b1726c13223",
            "/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "/paper/Convolutional-LSTM-Network%3A-A-Machine-Learning-for-Shi-Chen/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7"
        ]
    },
    {
        "id": "b990d34339074ae720a13e0978ad1ce5b4665d0c",
        "title": "Manual therapy and exercise in temporomandibular joint disc displacement without reduction. A systematic review",
        "abstract": "Results show that interventions based on therapeutic exercise or manual therapy may be beneficial and play a role in the treatment of disc displacement without reduction and limited evidence suggests that exercise significantly improves mouth opening in comparison to splints. ABSTRACT Objective The aim of this systematic review was to analyze the effectiveness of exercise and manual therapy interventions in patients with disc displacement without reduction. Method The authors performed a systematic review of Medline, EMBASE, PEDro, CINAHL, and Google Scholar databases. Two independent reviewers conducted the eligibility and quality assessment of studies. Interventions based on exercise and manual therapy regarding pain intensity and maximum mouth opening as primary outcomes were examined. Results Ten articles were included, according to the inclusion criteria. Most of the interventions showed statistically significant improvements in the primary outcomes. Conclusion Results show that interventions based on therapeutic exercise or manual therapy may be beneficial and play a role in the treatment of disc displacement without reduction. Limited evidence suggests that exercise significantly improves mouth opening in comparison to splints. Due to the heterogeneity of the included studies, these results should be interpreted with caution.",
        "publication_year": "2020",
        "authors": [
            "R. La Touche",
            "Tania Boo-Mallo",
            "Joseba Zarzosa-Rodr\u00edguez",
            "A. Paris\u2010Alemany",
            "F. Cuenca\u2010Mart\u00ednez",
            "L. Suso\u2010Mart\u00ed"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "13",
        "reference_count": "41",
        "references": [
            "/paper/Exercise-therapy-improves-pain-and-mouth-opening-in-Id%C3%A1%C3%B1ez-Robles-Obrero-Gait%C3%A1n/08064909d04c1a9a7529eb0b33c90141bdaa8948",
            "/paper/Comparison-of-the-Efficacy-of-Two-Protocol-in-with-Almeida-Botelho/c8341d4d88e3e4ebc0846227d0d6c0ddb7defeb4",
            "/paper/A-systematic-review-and-meta-analysis-of-randomized-Thorpe-Haddad/11db5c672bc6791bf0909b186c830e312e9e4c23",
            "/paper/Articular-disc-displacement-disorders-and-its-A-Kazi-Kheur/2a9d753341647b1eee629764e15e01185ce91c4b",
            "/paper/Does-the-Use-of-Injectable-Platelet-Rich-Fibrin-for-I%C5%9F%C4%B1k-Ken%C3%A7/1636ab1809019a5a5166c2742b33ed624a950387",
            "/paper/Clinical-Reasoning-for-the-Examination-and-Physical-Fern%C3%A1ndez%E2%80%90de%E2%80%90las%E2%80%90Pe%C3%B1as-Piekartz/2f7029df33308e856b23570c8eb272162a3bea29",
            "/paper/Changes-and-Associations-between-Cervical-Range-of-Lendraitien%C4%97-Smilgiene/2c3d38969126dd01b110a6801996133b54485ea8",
            "/paper/Occlusal-splints-types-and-effectiveness-in-Albagieh-Alomran/da0f9c08d6d2c0ae828268050e20418871bad704",
            "/paper/Conservative-management-of-pediatric-disc-as-a-case-Trager-Vincent/ca9a5fdfccbe1bead53cc17e6aa29f16e213bb9d",
            "/paper/Effectiveness-of-exercise-therapy-versus-occlusal-a-Zhang-Xu/15a9365a88190ff0d50b486d7eb8f2638110e78c",
            "/paper/Effectiveness-of-Manual-Therapy-and-Therapeutic-for-Armijo-Olivo-Pitance/970c02ad04a0ad795616f74333c6bbed0cf81d71",
            "/paper/Randomized-Clinical-Trial-of-Treatment-for-TMJ-Disc-Haketa-Kino/8d34d2f7893aa6294e481e2275f3032bd6e75a2c",
            "/paper/TMJ-Disc-Displacement-without-Reduction-Management-Al-Baghdadi-Durham/c624f5a55a23123d6ffbf85ead69fed3aacd70cb",
            "/paper/Efficacy-of-musculoskeletal-manual-approach-in-the-Martins-Blasczyk/ed5b18a57cd694d2a3bb0aa33977cfeb8665317b",
            "/paper/The-Basic-Conservative-Treatment-of-Joint-Anterior-Miernik-Wi%C4%99ckiewicz/caa2e0ba4d3cc38ec26dbdf5959b482093aab061",
            "/paper/Mandibular-Range-of-Movement-and-Pain-Intensity-in-Alajbeg-Giki%C4%87/54a90a9f1cb2d5b8df8e0bfcbc7e88b540b5bb46",
            "/paper/Randomized-Controlled-Evaluation-of-Non-surgical-Minakuchi-Kuboki/8620d18899ed8becbcdb32576cc1de29d8a208ce",
            "/paper/Temporomandibular-Lavage-Versus-Nonsurgical-for-A-Bouchard-Goulet/cd2c9bf3a5715f7b7852309f1bacf4b27d5e4ef4",
            "/paper/Arthrocentesis-versus-nonsurgical-methods-in-the-of-D%C4%B1ra%C3%A7o%C4%9Flu-Saral/49023ac42bcba3da4f7173ceb8f215588ef78f00",
            "/paper/Effects-of-four-treatment-strategies-for-joint-Schiffman-Velly/caa97af428fccc070392963fb9ceeac6cd6778b2"
        ]
    },
    {
        "id": "3e40fe76e9ec98524c4a4679bc68245d552662ce",
        "title": "Comparison of the Behavior of Perivascular Cells (Pericytes and CD34+ Stromal Cell/Telocytes) in Sprouting and Intussusceptive Angiogenesis",
        "abstract": "In sprouting angiogenesis, proliferating perivascular CD34+SCs/TCs are an important source of stromal cells during repair through granulation tissue formation and of cancer-associated fibroblasts (CAFs) in tumors. Perivascular cells in the pericytic microvasculature, pericytes and CD34+ stromal cells/telocytes (CD34+SCs/TCs), have an important role in angiogenesis. We compare the behavior of these cells depending on whether the growth of endothelial cells (ECs) from the pre-existing microvasculature is toward the interstitium with vascular bud and neovessel formation (sprouting angiogenesis) or toward the vascular lumen with intravascular pillar development and vessel division (intussusceptive angiogenesis). Detachment from the vascular wall, mobilization, proliferation, recruitment, and differentiation of pericytes and CD34+SCs/TCs, as well as associated changes in vessel permeability and functionality, and modifications of the extracellular matrix are more intense, longer lasting over time, and with a greater energy cost in sprouting angiogenesis than in intussusceptive angiogenesis, in which some of the aforementioned events do not occur or are compensated for by others (e.g., sparse EC and pericyte proliferation by cell elongation and thinning). The governing mechanisms involve cell\u2013cell contacts (e.g., peg-and-socket junctions between pericytes and ECs), multiple autocrine and paracrine signaling molecules and pathways (e.g., vascular endothelial growth factor, platelet-derived growth factor, angiopoietins, transforming growth factor B, ephrins, semaphorins, and metalloproteinases), and other factors (e.g., hypoxia, vascular patency, and blood flow). Pericytes participate in vessel development, stabilization, maturation and regression in sprouting angiogenesis, and in interstitial tissue structure formation of the pillar core in intussusceptive angiogenesis. In sprouting angiogenesis, proliferating perivascular CD34+SCs/TCs are an important source of stromal cells during repair through granulation tissue formation and of cancer-associated fibroblasts (CAFs) in tumors. Conversely, CD34+SCs/TCs have less participation as precursor cells in intussusceptive angiogenesis. The dysfunction of these mechanisms is involved in several diseases, including neoplasms, with therapeutic implications.",
        "publication_year": "2022",
        "authors": [
            "L. D\u00edaz-Flores",
            "R. Guti\u00e9rrez",
            "M. Garc\u00eda",
            "M. Gonz\u00e1lez-G\u00f3mez",
            "L. D\u00edaz-Flores",
            "J. L. Carrasco",
            "J. Madrid",
            "Aixa Rodr\u00edguez Bello"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "222",
        "references": [
            "/paper/Delimiting-CD34%2B-Stromal-Cells-Telocytes-Are-Cells-D%C3%ADaz-Flores-Guti%C3%A9rrez/fe7efbe95e45dc15393d488ec7f8755ab8686a45",
            "/paper/Disproportion-in-Pericyte-Endothelial-Cell-and-of-D%C3%ADaz-Flores-Guti%C3%A9rrez/7f6b0b235b1c7301707cc7beee7007540656b9da",
            "/paper/Endothelial-pericyte-interactions-in-angiogenesis-Gerhardt-Betsholtz/1aaffc5017d8b6d37d60f459a58090d7f10b6e7d",
            "/paper/Pericytes.-Morphofunction%2C-interactions-and-in-a-D%C3%ADaz-Flores-Guti%C3%A9rrez/f51387371383b13336ce40fa87370a27b444fcef",
            "/paper/The-role-of-pericytes-in-blood-vessel-formation-and-Bergers-Song/9a73de850d01eb794e7bbe607997f2d6417496eb",
            "/paper/Pericyte-involvement-in-capillary-sprouting-during-Nehls-Denzer/d30aad4dcc37af5425a138230fe166f2ffff4893",
            "/paper/Angiogenesis%3A-an-update.-D%C3%ADaz-Flores-Guti%C3%A9rrez/31ef7cfecf9d2179d8be7086461e7748b31ceea4",
            "/paper/The-complex-mural-cell%3A-pericyte-function-in-health-Dijk-Nieuweboer/deee9fceba581171444281158f4e6d0812a758b4",
            "/paper/Monocytes-macrophages-cooperate-with-progenitor-and-Anghelina-Krishnan/1e1dc99a9f1440634cc83c1f4f15ebf02e6aef10",
            "/paper/CD34%2B-stromal-cells-fibroblasts-fibrocytes-as-a-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/c387d88c70801cd94f51b05cf44dd0d9042a2ee4",
            "/paper/Human-resident-CD34%2B-stromal-cells-telocytes-have-a-D%C3%ADaz-Flores-Guti%C3%A9rrez/7f3ad99786e12be94fa64c9e80570094a0bfe77f"
        ]
    },
    {
        "id": "d8bdf72c2ccfcce5ee3e6f6064b65ffe7a43cad9",
        "title": "High-accuracy prostate cancer pathology using deep learning",
        "abstract": "A deep learning model to recognize and grade prostate cancer, based on a convolution neural network and a dataset with high-quality labels at gland-level precision is developed, which delivers all the relevant tumour metrics for a pathology report. Deep learning (DL) is a powerful methodology for the recognition and classification of tissue structures in digital pathology. Its performance in prostate cancer pathology is still under intensive investigation. Here we develop DL-based models for the detection of prostate cancer tissue in whole-slide images based on a large high-quality annotated training dataset and a modern state-of-the-art convolutional network architecture (NASNetLarge). The overall accuracy of our model for tumour detection in two validation cohorts is comparable to that of pathologists and reaches 97.3% in a native version and more than 98% using the suggested DL-based augmentation strategies. As a second step, we suggest a new biologically meaningful DL-based algorithm for Gleason grading of prostatic adenocarcinomas with high, human-level performance in prognostic stratification of patients when tested in several well-characterized validation cohorts. Furthermore, we determine the optimal minimal tumour size (real size of approximately 560\u2009\u00d7\u2009560\u2009\u00b5m) for robust Gleason grading representative of the whole tumour focus. Our approach is realized in the unified digital pathology pipeline, which delivers all the relevant tumour metrics for a pathology report. Deep learning methods can be a powerful part of digital pathology workflows, provided well-annotated training datasets are available. Tolkach and colleagues develop a deep learning model to recognize and grade prostate cancer, based on a convolution neural network and a dataset with high-quality labels at gland-level precision.",
        "publication_year": "2020",
        "authors": [
            "Y. Tolkach",
            "Tilmann Dohmg\u00f6rgen",
            "M. Toma",
            "G. Kristiansen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "62",
        "reference_count": "36",
        "references": [
            "/paper/A-Review-on-Prediction-and-Prognosis-of-the-Cancer-Kanna-Kumar/cb0c906a45dfbb92f7761b00dd637fa78091bc51",
            "/paper/Histological-grading-of-the-prostate-carcinoma-deep-Bauer-Z%C3%BCrner/7b49ba2b07c2f03c6bd2cf36064218babcce133f",
            "/paper/Automatic-diagnosis-and-grading-of-Prostate-Cancer-Xiang-Wang/47ba0fffa132177ff9c1900fbd02e202663636ba",
            "/paper/The-value-of-artificial-intelligence-for-detection-Kudo-Souza/f72a20ec9cd40a5680763eb61568f0414a494c54",
            "/paper/A-comparative-study-of-the-inter-observer-on-Deep-Marr%C3%B3n-Esquivel-Dur%C3%A1n-L%C3%B3pez/2023e1f721bff83f47dd57f0fe521c81964aadd8",
            "/paper/Role-of-AI-and-Histopathological-Images-in-Prostate-Ayyad-Shehata/63af80a7ad8a3d0e3207f743b91846c1adad99ba",
            "/paper/Archimedes-Optimization-Algorithm-with-Deep-Cancer-Ragab-Kateb/153e6d1a929324a94bc8f15bc49c4b81699d106f",
            "/paper/Deep-learning-can-predict-survival-directly-from-in-Wessels-Schmitt/5c706720303728af0f25ea75cd47ee3b588975c7",
            "/paper/Deep-embeddings-and-logistic-regression-for-rapid-Jiao-Yuan/c0bc9c8b3756b821d96b4769566a4133fca67c99",
            "/paper/ChampKit%3A-A-framework-for-rapid-evaluation-of-deep-Kaczmarzyk-Gupta/9c167051549a6fe7c1084c2a3e735fdee9afc8c6",
            "/paper/Path-R-CNN-for-Prostate-Cancer-Diagnosis-and-of-Li-Li/fd92511012b74333f87dd2b904df201adf184076",
            "/paper/Development-and-validation-of-a-deep-learning-for-Nagpal-Foote/77ac601c30d06782f870f4f9a53b55be2c413347",
            "/paper/Deep-learning-based-tissue-analysis-predicts-in-Bychkov-Linder/39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "/paper/Clinical-grade-computational-pathology-using-weakly-Campanella-Hanna/addae423490bbe82da4fb2fc265237178686b4e8",
            "/paper/Convolutional-neural-networks-for-an-automatic-of-Toro-Atzori/e37ab4e114de7b8ab60ca74e6a89e4fbbed3a625",
            "/paper/Classification-and-mutation-prediction-from-cell-Coudray-Ocampo/769149c0dc0ed308eca8bc916f4326b2e2f57a1f",
            "/paper/Automated-Gleason-grading-of-prostate-cancer-tissue-Arvaniti-Fricker/57a892b9576baeba70277179712d5b09e19224b9",
            "/paper/Deep-learning-for-automatic-Gleason-pattern-for-of-Lucas-Jansen/2c2f461af47644c0c05a62da0739c4bb48b99cdf",
            "/paper/Automated-deep-learning-system-for-Gleason-grading-Bulten-Pinckaers/39a52867ea3d60ec4f28182e0e618b762d3d7909",
            "/paper/Deep-learning-as-a-tool-for-increased-accuracy-and-Litjens-S%C3%A1nchez/47262a72c9c7bf5070b97e70b55c6190d1079260"
        ]
    },
    {
        "id": "a6876ea89e677a7cc42dd43f27165ff6fd414de5",
        "title": "UNet++: A Nested U-Net Architecture for Medical Image Segmentation",
        "abstract": "This paper presents UNet++, a new, more powerful architecture for medical image segmentation where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways, and argues that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. In this paper, we present UNet++, a new, more powerful architecture for medical image segmentation. Our architecture is essentially a deeply-supervised encoder-decoder network where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways. The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks. We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks: nodule segmentation in the low-dose CT scans of chest, nuclei segmentation in the microscopy images, liver segmentation in abdominal CT scans, and polyp segmentation in colonoscopy videos. Our experiments demonstrate that UNet++ with deep supervision achieves an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively.",
        "publication_year": "2018",
        "authors": [
            "Zongwei Zhou",
            "M. R. Siddiquee",
            "Nima Tajbakhsh",
            "Jianming Liang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2,843",
        "reference_count": "14",
        "references": [
            "/paper/N-Net%3A-an-UNet-architecture-with-dual-encoder-for-Liang-Tang/97dd42c101a3d3b77924a58a6fea1968f905c029",
            "/paper/Half-UNet%3A-A-Simplified-U-Net-Architecture-for-Lu-She/b4afdbc4be5c2f626fdc6fe35e4305820290c838",
            "/paper/MDA-Unet%3A-A-Multi-Scale-Dilated-Attention-U-Net-for-Amer-Lambrou/057159cbdca99b6ad047cd63f8c53904eb07e8ca",
            "/paper/UNet-3%2B%3A-A-Full-Scale-Connected-UNet-for-Medical-Huang-Lin/0b444f74dd9cc06c2833dd15f9258ef5e169e6ea",
            "/paper/UNet%2B%2B%3A-Redesigning-Skip-Connections-to-Exploit-in-Zhou-Siddiquee/42b0a8f757e45462e627e57f9af7e9849dcdacdf",
            "/paper/DEA-UNet%3A-a-dense-edge-attention-UNet-architecture-Zeng-Fan/e7d003e2080ef6706850a1b18f9978d09211114c",
            "/paper/ANU-Net%3A-Attention-based-nested-U-Net-to-exploit-Li-Tan/4f78b4ddbfcd26f40a477ae19f028d015134c40f",
            "/paper/Encoding-feature-supervised-UNet%2B%2B%3A-Redesigning-for-Cui-Xiao/541c4e90c41246c66eda138a9d173522cfe38838",
            "/paper/Clinical-target-segmentation-using-a-novel-deep-Chenarlogh-Shabanzadeh/22b5c32df7d7f0dfc91abacc590b9f8349f2fa0f",
            "/paper/GAM-UNet%3A-incorporating-global-attention-mechanism-Xiang-Liu/96eb276dea38697194d44efb762cd0fc09f7b8a9",
            "/paper/H-DenseUNet%3A-Hybrid-Densely-Connected-UNet-for-and-Li-Chen/a86d7289c76d832e83c99539859b7b186e4ea6c8",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/H-DenseUNet%3A-Hybrid-Densely-Connected-UNet-for-and-Li-Chen/f57455c38b89bb5f4a17f762777a0fc0b1aa3239",
            "/paper/Convolutional-Neural-Networks-for-Medical-Image-or-Tajbakhsh-Shin/ccdc50de7a0602d3df5ed9bd9782565bbff2a8eb",
            "/paper/Fine-Tuning-Convolutional-Neural-Networks-for-Image-Zhou-Shin/71cdc2345df62d60a1ed88333a6101ce669663b0",
            "/paper/The-Importance-of-Skip-Connections-in-Biomedical-Drozdzal-Vorontsov/7f167d10e6fb57f4aa95fb7099a76ba9b5671025",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/Residual-Conv-Deconv-Grid-Network-for-Semantic-Fourure-Emonet/1fb5d9c589ea53f25b981673a7a750e854e7d687",
            "/paper/Mask-R-CNN-He-Gkioxari/1a0912bb76777469295bb2c059faee907e7f3258",
            "/paper/Deeply-Supervised-Nets-Lee-Xie/fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd"
        ]
    },
    {
        "id": "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
        "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
        "abstract": "A hierarchical Transformer whose representation is computed with Shifted windows, which has the flexibility to model at various scales and has linear computational complexity with respect to image size and will prove beneficial for all-MLP architectures. This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.",
        "publication_year": "2021",
        "authors": [
            "Ze Liu",
            "Yutong Lin",
            "Yue Cao",
            "Han Hu",
            "Yixuan Wei",
            "Zheng Zhang",
            "Stephen Lin",
            "B. Guo"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "6,227",
        "reference_count": "83",
        "references": [
            "/paper/SimViT%3A-Exploring-a-Simple-Vision-Transformer-with-Li-Xu/41396b28fb56f5699f24ac0a85902165b88c696f",
            "/paper/CBPT%3A-A-New-Backbone-for-Enhancing-Information-of-Yu-Zhang/d5fced09f76f2f7cdc5eef7d0feebfab124315cd",
            "/paper/CSWin-Transformer%3A-A-General-Vision-Transformer-Dong-Bao/800cfb3d23115cdcd4d114234b65bbdf2080f798",
            "/paper/Conmw-Transformer%3A-A-General-Vision-Transformer-Li-Jiao/ef46f254ad6f3ee2b7d5ba1f041b033da1d42c51",
            "/paper/Degenerate-Swin-to-Win%3A-Plain-Window-based-without-Yu-Li/ea67a17edae00652a0b5ea5987e9b0ddf7fd2cb5",
            "/paper/Vision-Transformer-with-Convolutions-Architecture-Zhang-Hao/51dd3023f773ddea40f9358e91aedb791c893f1a",
            "/paper/ResT%3A-An-Efficient-Transformer-for-Visual-Zhang-Yang/76fbecc05f3060ddcbbf65fb6d1305a1278119c7",
            "/paper/HiViT%3A-Hierarchical-Vision-Transformer-Meets-Masked-Zhang-Tian/98e702ef2f64ab2643df9e80b1bd034334142e62",
            "/paper/SepViT%3A-Separable-Vision-Transformer-Li-Wang/dae903091d2c5f82c4595e53e8144ccce93f8fb9",
            "/paper/Vision-Transformer-with-Quadrangle-Attention-Zhang-Zhang/af21d7b29a8b48967d0151a0b86f15d755eba02b",
            "/paper/Toward-Transformer-Based-Object-Detection-Beal-Kim/d2e54b3a596a1dce0def9d035dfe1fb7c0c6142a",
            "/paper/Pyramid-Vision-Transformer%3A-A-Versatile-Backbone-Wang-Xie/3e398bad2d8636491a1034cc938a5e024c7aa881",
            "/paper/Transformer-in-Transformer-Han-Xiao/0ae67202f0584afccefa770865d14a46655d2975",
            "/paper/Bottleneck-Transformers-for-Visual-Recognition-Srinivas-Lin/16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/Tokens-to-Token-ViT%3A-Training-Vision-Transformers-Yuan-Chen/dbe077f8521ecbe0a1477d6148c726d4f053d9c9",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/RelationNet%2B%2B%3A-Bridging-Visual-Representations-for-Chi-Wei/35248e4b63c96067ccf1bc3f3fa0f2e27a0e6cee",
            "/paper/Rethinking-Semantic-Segmentation-from-a-Perspective-Zheng-Lu/d29430adccb805ab57b349afa8553954347b3197",
            "/paper/Do-We-Really-Need-Explicit-Position-Encodings-for-Chu-Zhang/654247d5b184495fca18c6aa7e840e4f4559fef0"
        ]
    },
    {
        "id": "87e823d2cb58e741230c0fa3b83f3459c7e32241",
        "title": "PiSLTRc: Position-Informed Sign Language Transformer With Content-Aware Convolution",
        "abstract": "This work proposes a new model architecture, namely PiSLTRc, with two distinctive characteristics: content-aware and position-aware convolution layers, thus generating robust neighborhood-enhanced sign representation and achieves state-of-the-art performance on translation quality with $+1.6$ BLEU improvements. Since the superiority of Transformer in learning long-term dependency, the sign language Transformer model achieves remarkable progress in Sign Language Recognition (SLR) and Translation (SLT). However, there are several issues with the Transformer that prevent it from better sign language understanding. The first issue is that the self-attention mechanism learns sign video representation in a frame-wise manner, neglecting the temporal semantic structure of sign gestures. Secondly, the attention mechanism with absolute position encoding is direction and distance unaware, thus limiting its ability. To address these issues, we propose a new model architecture, namely PiSLTRc, with two distinctive characteristics: (i) content-aware and position-aware convolution layers. Specifically, we explicitly select relevant features using a novel content-aware neighborhood gathering method. Then we aggregate these features with position-informed temporal convolution layers, thus generating robust neighborhood-enhanced sign representation. (ii) injecting the relative position information to the attention mechanism in the encoder, decoder, and even encoder-decoder cross attention. Compared with the vanilla Transformer model, our model performs consistently better on three large-scale sign language benchmarks: PHOENIX-2014, PHOENIX-2014-T and CSL. Furthermore, extensive experiments demonstrate that the proposed method achieves state-of-the-art performance on translation quality with $+1.6$ BLEU improvements.",
        "publication_year": "2021",
        "authors": [
            "Pan Xie",
            "Mengyi Zhao",
            "Xiaohui Hu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "52",
        "references": [
            "/paper/Locality-Aware-Transformer-for-Video-Based-Sign-Guo-Hou/5e502c618d559ce1e676eea02aff1e797ac3f1ef",
            "/paper/ConSLT%3A-A-Token-level-Contrastive-Framework-for-Fu-Ye/3f8a2addbdab4fddc7455bbc699da0f432a61a4d",
            "/paper/SignBERT%2B%3A-Hand-model-aware-Self-supervised-for-Hu-Zhao/0fcc797aeed56bcc127476d5b68836dc402021ea",
            "/paper/A-Token-Level-Contrastive-Framework-for-Sign-Fu-Ye/1e4421a8278d97027bd03fcf6410e43f47b8c3cb",
            "/paper/Multi-scale-temporal-network-for-continuous-sign-Zhu-Li/3134a48116e9d79fb9c931fd448e8aea30e5dfd4",
            "/paper/Vector-Quantized-Diffusion-Model-with-CodeUnet-for-Xie-Zhang/47d61b881d770818ecb13fc1c45ea036625a3ee6",
            "/paper/DilateFormer%3A-Multi-Scale-Dilated-Transformer-for-Jiao-Tang/0cd526723b87ae37981922992992d203448a2014",
            "/paper/Quality-aware-Part-Models-for-Occluded-Person-Wang-Ding/afbf47e408aabd87fb312ec6baef01cfc31f04b5",
            "/paper/Connectionist-Temporal-Fusion-for-Sign-Language-Wang-Guo/33e309f993023a0384221733dd884e2b891c8311",
            "/paper/Hierarchical-LSTM-for-Sign-Language-Translation-Guo-Zhou/d44c20c48e764a546d00b9155a56b171b0dc04bc",
            "/paper/Dense-Temporal-Convolution-Network-for-Sign-Guo-Wang/f07bef10500f55d4d34bac96bbe93f1120a6ca8d",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/TSPNet%3A-Hierarchical-Feature-Learning-via-Temporal-Li-Xu/16091f0821502b70294ef66671183dadd1afcdc0",
            "/paper/Global-Local-Enhancement-Network-for-NMF-Aware-Sign-Hu-Zhou/9023437b9bfb741094f9ff50323093573c9f8e60",
            "/paper/Boosting-Continuous-Sign-Language-Recognition-via-Pu-Zhou/ce50fa888551b640fe3dddc57289c27f325c029b",
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e",
            "/paper/SF-Net%3A-Structured-Feature-Network-for-Continuous-Yang-Shi/bd712a873ae4eefb6c623c8e605e42c5a0173e3e",
            "/paper/Attention-Based-3D-CNNs-for-Large-Vocabulary-Sign-Huang-Zhou/91a8da0d5429b0be63b2495587908d4583931ab5"
        ]
    },
    {
        "id": "e924a5cc4739f18fb225b7a8b506099042567ffa",
        "title": "Brain Imaging Generation with Latent Diffusion Models",
        "abstract": "This study explores using Latent Diffusion Models to generate synthetic images from high-resolution 3D brain images and found that their models created realistic data, and they could use the conditioning variables to control the data generation effectively. Deep neural networks have brought remarkable breakthroughs in medical image analysis. However, due to their data-hungry nature, the modest dataset sizes in medical imaging projects might be hindering their full potential. Generating synthetic data provides a promising alternative, allowing to complement training datasets and conducting medical image research at a larger scale. Diffusion models recently have caught the attention of the computer vision community by producing photorealistic synthetic images. In this study, we explore using Latent Diffusion Models to generate synthetic images from high-resolution 3D brain images. We used T1w MRI images from the UK Biobank dataset (N=31,740) to train our models to learn about the probabilistic distribution of brain images, conditioned on covariables, such as age, sex, and brain structure volumes. We found that our models created realistic data, and we could use the conditioning variables to control the data generation effectively. Besides that, we created a synthetic dataset with 100,000 brain images and made it openly available to the scientific community.",
        "publication_year": "2022",
        "authors": [
            "W. H. Pinaya",
            "Petru-Daniel Tudosiu",
            "J. Dafflon",
            "P. F. D. Costa",
            "Virginia Fernandez",
            "P. Nachev",
            "S. Ourselin",
            "M. Cardoso"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "43",
        "reference_count": "34",
        "references": [
            "/paper/Spot-the-fake-lungs%3A-Generating-Synthetic-Medical-Ali-Murad/51aafc680ccf6ba7d879e31fce49c55fd299f760",
            "/paper/Deep-Learning-Approaches-for-Data-Augmentation-in-A-Kebaili-Lapuyade-Lahorgue/13afd3c131dbb836bf9c6c65466ca8f5234bca11",
            "/paper/Medical-diffusion-on-a-budget%3A-textual-inversion-Wilde-Saha/41579777836a07a1bd8b4d8593fcda7983b68e67",
            "/paper/Conversion-of-the-Mayo-LDCT-Data-to-Synthetic-the-a-Shi-Wang/fb2826bc74dafcbadd79d78669cb27971b15f2b8",
            "/paper/Diffusion-based-Data-Augmentation-for-Skin-Disease-Akrout-Gyepesi/a69a61b81b31e16339df59cd125027522b11a775",
            "/paper/Denoising-diffusion-probabilistic-models-for-3D-Khader-Mueller-Franzes/4616d468f2ec5b78206f2d00d0c6704b4bda19b4",
            "/paper/Diffusion-models-in-medical-imaging%3A-A-survey.-Kazerouni-Aghdam/ca9adbc1fa8919d8cb7e3aa58d622e069131b60b",
            "/paper/Adapting-Pretrained-Vision-Language-Foundational-to-Chambon-Bluethgen/f5225015bcdad0a1daf7d205c67fc297fb9ec978",
            "/paper/SADM%3A-Sequence-Aware-Diffusion-Model-for-Medical-Yoon-Zhang/5466a6fa708db56300e62c1a9e261f4948800a4d",
            "/paper/Diffusion-Models-for-Medical-Image-Analysis%3A-A-Kazerouni-Aghdam/b57b8b6b8052bf2e7f6fe5c8e91cdcb385b75ab6",
            "/paper/Generation-of-3D-Brain-MRI-Using-Auto-Encoding-Kwon-Han/40bf9de59df11ee2713b29c36a050a3ee31fe0ef",
            "/paper/An-overview-of-deep-learning-in-medical-imaging-on-Lundervold-Lundervold/0ebc300c16f01a4e94c8551997922fdb67ac1951",
            "/paper/SynthSeg%3A-Domain-Randomisation-for-Segmentation-of-Billot-Greve/5049a371e2bba11cd4919f839a759d19f02b9501",
            "/paper/Med3D%3A-Transfer-Learning-for-3D-Medical-Image-Chen-Ma/5bcda431e0b615e094562bf038f1ef4df1865088",
            "/paper/A-Tool-for-Super-Resolving-Multimodal-Clinical-MRI-Brudfors-Balbastre/d57d4128f3deec01912f47684f9191cc550801d9",
            "/paper/Hierarchical-Amortized-GAN-for-3D-High-Resolution-Sun-Chen/d0ac7ed7919a3567d03b70b9b24f8683897471dc",
            "/paper/High-Resolution-Image-Synthesis-with-Latent-Models-Rombach-Blattmann/c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
            "/paper/Denoising-Diffusion-Implicit-Models-Song-Meng/014576b866078524286802b1d0e18628520aa886",
            "/paper/Predicting-brain-age-with-deep-learning-from-raw-in-Cole-Poudel/5d71c918db224e21982d9eb5ab2359735466959b",
            "/paper/Diffusion-Models-Beat-GANs-on-Image-Synthesis-Dhariwal-Nichol/64ea8f180d0682e6c18d1eb688afdb2027c02794"
        ]
    },
    {
        "id": "958aebc86388e7625fb8df4b0882bc3b764364a8",
        "title": "Global channel attention networks for intracranial vessel segmentation",
        "abstract": "Semantic Scholar extracted view of \"Global channel attention networks for intracranial vessel segmentation\" by Jiajia Ni et al.",
        "publication_year": "2020",
        "authors": [
            "Jiajia Ni",
            "Jianhuang Wu",
            "Haoyu Wang",
            "Jing Tong",
            "Zhengming Chen",
            "K. Wong",
            "D. Abbott"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "27",
        "reference_count": "57",
        "references": [
            "/paper/SFA-Net%3A-Scale-and-Feature-Aggregate-Network-for-Ni-Liu/2ef8be98d6f2028fc54cd354bb1fc22d97378125",
            "/paper/A-novel-multi-attention%2C-multi-scale-3D-deep-for-Dong-Xu/6206a661c02b553f279b76debcdb2181e7e6a549",
            "/paper/Dual-Attention-Multiscale-Network-for-Vessel-in-Yin-Fang/96d8a8dc43af5aabc1ec2e2bb51cbcd38354c6c4",
            "/paper/BRAVE-NET%3A-Fully-Automated-Arterial-Brain-Vessel-in-Hilbert-Madai/8654c84f172e436081a973f1b500e4ac449a0bc0",
            "/paper/MDANet%3A-Multi-Direction-Attention-Network-for-of-Chen-Hu/d52cdaa8bdf79243a884cd394f431cda07cc61b9",
            "/paper/Brain-Vessel-Segmentation-Using-Deep-Learning%E2%80%94A-Goni-Ruhaiyem/58b5d5173a31f0c7c9960fd3d006d1f7d11d2b45",
            "/paper/All-answers-are-in-the-images%3A-A-review-of-deep-for-Chen-Zhou/2be74dd2433f98d6a3eb8172d84269c436645991",
            "/paper/A-Semantic-Segmentation-Method-with-Emphasis-on-the-Xu-Zhu/72df7f4496d2a46a6d3c69554961354b8d493d69",
            "/paper/CAAGP%3A-Rethinking-channel-attention-with-adaptive-Zhang-Lu/f58188a89ab0d96173fe7a3970f63465ca8bdbdd",
            "/paper/Vessel-CAPTCHA%3A-an-efficient-learning-framework-for-Dang-Giacomo/492904963d34db850cf6053d52bbb298eb0bebe7",
            "/paper/VesselNet%3A-A-deep-convolutional-neural-network-with-Kitrungrotsakul-Han/489ece232ec65477db0ed2ca01a43edc1bfc4318",
            "/paper/Learning-Fully-Connected-CRFs-for-Blood-Vessel-in-Orlando-Blaschko/09415598649f019f905c70b183417d83f06e9d49",
            "/paper/Retinal-vessel-segmentation-based-on-Fully-Neural-Oliveira-Pereira/e31e3e03b152756f2207195a0f023cc25e31e93e",
            "/paper/DeepVessel%3A-Retinal-Vessel-Segmentation-via-Deep-Fu-Xu/94b43a5a4224c8c1d62f5fa3ac567de37f0c44aa",
            "/paper/Retinal-Vessel-Segmentation-using-Deep-Neural-Melin%C5%A1%C4%8Dak-Prentasic/051672b323d171ffd2222e0c3221d3f2114e3fa3",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/Sub-cortical-brain-structure-segmentation-using-Shakeri-Tsogkas/62feffa9322f08934fadfa3f2dfc9a6183048d26",
            "/paper/Automatic-Detection-of-Cerebral-Microbleeds-From-MR-Dou-Chen/b1a507a7efb3ab49816b689d822352a9d14b4a25",
            "/paper/Efficient-multi%E2%80%90scale-3D-CNN-with-fully-connected-Kamnitsas-Ledig/7c2bcf6f32b05a04cd3444c030db743e5666af88",
            "/paper/A-Discriminatively-Trained-Fully-Connected-Random-Orlando-Prokofyeva/5fe24f2bb81d4695ae6dca46318dba6d52523d11"
        ]
    },
    {
        "id": "f1fdc50bbdb70a635ec30b6d6835060cd16dd15c",
        "title": "Long-term quality of life in patients with vestibular schwannoma managed with microsurgery.",
        "abstract": "Identifying and managing post-operative symptoms may improve quality of life in patients with vestibular schwannoma patients and can guide clinical decision making. OBJECTIVE\nLittle is known about the long term (greater than 10 years) quality of life in patients with vestibular schwannoma. This study aimed to evaluate long-term outcomes in patients with vestibular schwannoma.\n\n\nMETHOD\nA retrospective cohort study was performed across 2 academic institutions, with patients followed at least 10 years after vestibular schwannoma surgery (2000 to 2007). Telephone interviews were used to assess quality of life using the Glasgow Benefit Inventory and short form 12 item (version 2) health survey.\n\n\nRESULTS\nA total of 99 out of 110 patients were included. Increasing age and symptom burden were associated with poorer quality of life (p = 0.01 and 0.02, respectively). The presence of imbalance, headache and facial nerve dysfunction were all associated with poorer quality of life scores (p = 0.01, 0.04 and 0.02, respectively).\n\n\nCONCLUSION\nIdentifying and managing post-operative symptoms may improve quality of life in vestibular schwannoma patients and can guide clinical decision making.",
        "publication_year": "2019",
        "authors": [
            "C. Santa Maria",
            "P. S. Santa Maria",
            "V. Bulsara",
            "J. Jayawardena",
            "J. D. Caldow",
            "L. H. Png",
            "M. Atlas"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "8",
        "reference_count": "61",
        "references": [
            "/paper/Outcome-Measures-and-Quality-of-Life-in-Vestibular-Chartrand-Al-Tamami/4ff3a409def9dfe9bb88ee9808c1eb8ebfc2126d",
            "/paper/Outcomes-in-vestibular-schwannoma-treated-with-Landry-Yang/2419112b554c8e2c3d01474611d26bf966572b69",
            "/paper/Nomogram-for-Predicting-Facial-Nerve-Outcomes-After-Sun-Yang/eb856b00d26a8d4cdbc321e7eeb1ebf26c884e6c",
            "/paper/Factors-Influencing-Personalized-Management-of-A-Sergi-Settimi/27bf55fd4625103c40a58daf8acd9468c0ba113c",
            "/paper/Postoperative-headache-after-surgical-treatment-of-Pogoda-Nijdam/bc27eedb807996ee91a06e021c0e385f5a12095a",
            "/paper/Clinical-efficacy-of-robot-assisted-thoracoscopic-Li-Cong/75e479acd038d70f7f8d70ecf789746f4dfe3617",
            "/paper/Predictors-and-nomogram-models-for-postoperative-in-Wang-Huang/1316fb5b131cbd0b8deaa75e5882d4a08e07e4e6",
            "/paper/Reconstructive-Microsurgery-in-the-COVID-19-Shachar-Yaacobi/1676611ed06e3079168223281814b54ca21da064",
            "/paper/Comparison-of-Long-term-Quality-of-Life-Outcomes-in-Robinett-Walz/40698b032912d301afa310e05e5b7409a6dd3660",
            "/paper/The-Effect-of-Observation-versus-Microsurgical-on-A-Sandooram-Hornigold/f92e32c7df9eca8b10bbd1df7b3ab660b241cfb6",
            "/paper/Conservative-Treatment-of-Vestibular-Schwannoma%3A-A-Godefroy-Kaptein/94275749bd2c05f2080ba455f9ae728fc30453e1",
            "/paper/Systematic-review-of-quality-of-life-in-the-of-Gauden-Weir/ea2e2bd633917f823eba2f100acfe1df9b41edcd",
            "/paper/Prospective-comparison-of-quality-of-life-before-or-Maio-Akagami/81394e40bbb59ebcccae4a010e1332c1e2adc806",
            "/paper/Vestibular-Schwannomas%3A-Clinical-Results-and-of-or-Myrseth-M%C3%B8ller/608156e2bae124b16b12c13e4485e75db8c335dd",
            "/paper/Quality-of-Life-in-Patients-with-Vestibular-Gross-Link-Lund-Johansen/285a699650834c3d8e91126cd953c15e54dd404a",
            "/paper/Health-related-quality-of-life-in-patients-with-Kelleher-Fernandes/1ee7affd0a4a918ab153311d6d5c541c94ce43a9",
            "/paper/Patient-outcomes-after-vestibular-schwannoma-a-of-Pollock-Driscoll/1bbc5e671591c1d74a9deb165bf0a575104b2e0a",
            "/paper/Patient-assessed-outcomes-after-excision-of-and-of-Martin-Sethi/7d457bbc2bde775d6b4bf81723da814b045aa8ff"
        ]
    },
    {
        "id": "d44e3d1dc6bd08351a885a4ed3d6bb35931fffe0",
        "title": "Convolutional autoencoder joint boundary and mask adversarial learning for fundus image segmentation",
        "abstract": "A novel unsupervised domain-adaptive segmentation architecture called CAE-BMAL is proposed, which enhances the source domain with a convolutional autoencoder and introduces an adversarial learning-based boundary discrimination branch to reduce the impact of the complex environment during segmentation. The precise segmentation of the optic cup (OC) and the optic disc (OD) is important for glaucoma screening. In recent years, medical image segmentation based on convolutional neural networks (CNN) has achieved remarkable results. However, many traditional CNN methods do not consider the cross-domain problem, i.e., generalization on datasets of different domains. In this paper, we propose a novel unsupervised domain-adaptive segmentation architecture called CAE-BMAL. Firstly, we enhance the source domain with a convolutional autoencoder to improve the generalization ability of the model. Then, we introduce an adversarial learning-based boundary discrimination branch to reduce the impact of the complex environment during segmentation. Finally, we evaluate the proposed method on three datasets, Drishti-GS, RIM-ONE-r3, and REFUGE. The experimental evaluations outperform most state-of-the-art methods in accuracy and generalization. We further evaluate the cup-to-disk ratio performance in OD and OC segmentation, which indicates the effectiveness of glaucoma discrimination.",
        "publication_year": "2022",
        "authors": [
            "Xu Zhang",
            "Jiaqi Song",
            "Chengrui Wang",
            "Zhen Zhou"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "27",
        "references": [
            "/paper/Boundary-and-Entropy-driven-Adversarial-Learning-Wang-Yu/f2b3de7f036f8f35294d7c8008622f7d3ad2b4eb",
            "/paper/Patch-Based-Output-Space-Adversarial-Learning-for-Wang-Yu/ba62442fc88eb4da204e98899214c45960341fa5",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/CADA%3A-Multi-scale-Collaborative-Adversarial-Domain-Liu-Tran/28d84201425a08252af8ea8455afb04817fdff8d",
            "/paper/Unsupervised-Cross-Modality-Domain-Adaptation-of-Dou-Ouyang/1af573c96c2c0bc46a4ee01dfa303c43fcc11274",
            "/paper/DoFE%3A-Domain-Oriented-Feature-Embedding-for-Fundus-Wang-Yu/4a1eb41f1df29a76ddab80823f62b77bcdb13489",
            "/paper/CFEA%3A-Collaborative-Feature-Ensembling-Adaptation-Liu-Kong/da30ccbc77adec96354d974abf46b953eb0a5f53",
            "/paper/C2-GAN%3A-Content-consistent-generative-adversarial-Zhang-Li/888eedc8e95882e19a5e5e5cf537317ffe15b909",
            "/paper/Learning-to-Adapt-Structured-Output-Space-for-Tsai-Hung/193b518bc3025804c6d587c74cbc154d91478417",
            "/paper/REFUGE-Challenge%3A-A-Unified-Framework-for-Automated-Orlando-Fu/b60f795c6f512ff3ebf6ee09f487aec21edbfec0"
        ]
    },
    {
        "id": "97b03dbc329d1c18adea23a6c81558a5abeb3d12",
        "title": "Multi-scale Convolution Transformer for Human Activity Detection",
        "abstract": "A multi-scale convolution Transformer that is able to exploit local features of WiFi data more effectively using CNNs, while global features are captured with Transformer. Human activity recognition (HAR) plays an important role in many applications such as smart homes, healthcare services, and security monitoring. Recently, WiFi-based human activity recognition (HAR) is becoming increasingly popular due to its non-invasiveness. Most existing HAR works only use classification methods for activity recognition, without focusing on the start time and end time of actions. In this paper, we propose to use a detection method that predicts both the type of activity as well as its start and end times. For detection tasks, both global information and local information are essential for modeling and identifying various types of activities. Therefore, we propose a multi-scale convolution Transformer that is able to exploit local features of WiFi data more effectively using CNNs, while global features are captured with Transformer. In our experiments, the proposed model shows outstanding performance in indoor environment, with a weak micro F1 score of 98.37% and a strong micro F1 score of 92.81%.",
        "publication_year": "2022",
        "authors": [
            "Dejun Gao",
            "Lei Wang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "22",
        "references": [
            "/paper/Two-Stream-Convolution-Augmented-Transformer-for-Li-Cui/a3196e65467b80f4755968923b382e40c02ccb51",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/Using-GAN-to-Enhance-the-Accuracy-of-Indoor-Human-Moshiri-Navidan/5e956e96b93716589884be7a6efe45109b409bc8",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/Using-Wi-Fi-channel-state-information-(CSI)-for-and-Chowdhury/6415cbbdb171433e081f84b90897043e4c2a37dd",
            "/paper/Conformer%3A-Convolution-augmented-Transformer-for-Gulati-Qin/0170fc76e934ee643f869df18fb617d5357e8b4e",
            "/paper/Understanding-and-Modeling-of-WiFi-Signal-Based-Wang-Liu/539b28563ecd9fa14be7134bc17ec942958d00db",
            "/paper/Convolutional-Relational-Machine-for-Group-Activity-Azar-Atigh/c147261ad2a359865d5780607816c05dc4b48b56",
            "/paper/WiFiMap%2B%3A-High-Level-Indoor-Semantic-Inference-With-Zhang-Zhou/9d9d7ee2d4f34af92a6c5172f6c693e12eb7e0f1",
            "/paper/RT-Fall%3A-A-Real-Time-and-Contactless-Fall-Detection-Wang-Zhang/ca117d143e0e3f6a073ac6705b472072c8f676e5"
        ]
    },
    {
        "id": "d8663556aa1a875dcdc4f15ad1fd31933e724348",
        "title": "Video anomaly detection with multi-scale feature and temporal information fusion",
        "abstract": "Semantic Scholar extracted view of \"Video anomaly detection with multi-scale feature and temporal information fusion\" by Yiheng Cai et al.",
        "publication_year": "2021",
        "authors": [
            "Yiheng Cai",
            "Jiaqi Liu",
            "Yajun Guo",
            "Shaobin Hu",
            "S. Lang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "21",
        "reference_count": "11",
        "references": [
            "/paper/Abnormal-event-detection-in-surveillance-videos-on-Xia-Wei/1dc324681ac58abd2fad6b1da01c32997e06df50",
            "/paper/A-New-Unsupervised-Video-Anomaly-Detection-Using-Taghinezhad-Yazdi/6b1c013e1de3346c4cfe1da631be1a5f61f044c1",
            "/paper/Multi-memory-video-anomaly-detection-based-on-scene-Li-Chen/c5386effca34bdf0a99d97004d72dab8b71dc1b5",
            "/paper/3D-U-Net-for-Video-Anomaly-Detection-Yang-Cai/1496bf26c493fb9df581d9fc04bb974a41b38fb9",
            "/paper/Multi-scale-Siamese-prediction-network-for-video-Yang-Cai/edee93ddcfcfeb0674464080800623bf0ac0e71b",
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/A-cascade-reconstruction-model-with-generalization-Zhong-Chen/7fd052d40660d65c8497599794467812b78e1d0b",
            "/paper/Anomaly-detection-in-surveillance-videos%3A-a-of-deep-Chandrakala-Deepak/6192fff1c7e296ae0a98985c55246e150d02214b",
            "/paper/Transformer-Based-Self-Context-Aware-Prediction-for-Pillai-Verma/aadfea10bcc097ca786ffe566467fe7ecd933256",
            "/paper/Generalized-Video-Anomaly-Event-Detection%3A-Taxonomy-Liu-Yang/bb51ca71833d42fa58f9adccb2296bdf665cc158",
            "/paper/Video-Anomaly-Detection-With-Compact-Feature-Sets-Leyva-Sanchez/50e84132a1e405fd04ec59a72093ba30d9a74281",
            "/paper/Spatio-Temporal-Unity-Networking-for-Video-Anomaly-Li-Cai/1be10a34f619e203651036d2609fc0d9780525c5",
            "/paper/Anomaly-Detection-Based-on-Stacked-Sparse-Coding-Xu-Jiang/88ece7e67fbc19ac180867221e65cf096e70ffbb",
            "/paper/Video-anomaly-detection-and-localization-by-local-Wang-Zhu/b4cfbefc7cc3217c133c75d48ace1cddc078d870",
            "/paper/Fully-Convolutional-Neural-Network-for-Fast-Anomaly-Sabokrou-Fayyaz/8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6",
            "/paper/Video-anomaly-detection-and-localization-via-fully-Li-Chang/6c551fa9bdfb3c1e285bc9fa69e4c89a736af3e7",
            "/paper/Sparse-reconstruction-cost-for-abnormal-event-Cong-Yuan/ae37774ff871575b7799411bf87f42eb52634390",
            "/paper/Deep-Cascade%3A-Cascading-3D-Deep-Neural-Networks-for-Sabokrou-Fayyaz/6f68ce1e03c56c186256dac689a21f6405ae8d96",
            "/paper/Squirrel-Cage-Local-Binary-Pattern-and-Its-in-Video-Hu-Huang/1ac4e83971cb2d0114eb3101651239c27d1b5b2b",
            "/paper/Image-quality-assessment%3A-from-error-visibility-to-Wang-Bovik/eae2e0fa72e898c289365c0af16daf57a7a6cf40"
        ]
    },
    {
        "id": "06b002e1ba39fa5a3fb1642a79ee971e2d1e95af",
        "title": "Semantic Segmentation of Remote Sensing Imagery Based on Multiscale Deformable CNN and DenseCRF",
        "abstract": "A combination model of a modified multiscale deformable convolutional neural network and dense conditional random field based on the superpixel level and the pixel level is proposed, which can make full use of the context information of the image at different levels and further optimize the rough segmentation result of mmsDCNN. The semantic segmentation of remote sensing images is a significant research direction in digital image processing. The complex background environment, irregular size and shape of objects, and similar appearance of different categories of remote sensing images have brought great challenges to remote sensing image segmentation tasks. Traditional convolutional-neural-network-based models often ignore spatial information in the feature extraction stage and pay less attention to global context information. However, spatial context information is important in complex remote sensing images, which means that the segmentation effect of traditional models needs to be improved. In addition, neural networks with a superior segmentation performance often suffer from the problem of high computational resource consumption. To address the above issues, this paper proposes a combination model of a modified multiscale deformable convolutional neural network (mmsDCNN) and dense conditional random field (DenseCRF). Firstly, we designed a lightweight multiscale deformable convolutional network (mmsDCNN) with a large receptive field to generate a preliminary prediction probability map at each pixel. The output of the mmsDCNN model is a coarse segmentation result map, which has the same size as the input image. In addition, the preliminary segmentation result map contains rich multiscale features. Then, the multi-level DenseCRF model based on the superpixel level and the pixel level is proposed, which can make full use of the context information of the image at different levels and further optimize the rough segmentation result of mmsDCNN. To be specific, we converted the pixel-level preliminary probability map into a superpixel-level predicted probability map according to the simple linear iterative clustering (SILC) algorithm and defined the potential function of the DenseCRF model based on this. Furthermore, we added the pixel-level potential function constraint term to the superpixel-based Gaussian potential function to obtain a combined Gaussian potential function, which enabled our model to consider the features of various scales and prevent poor superpixel segmentation results from affecting the final result. To restore the contour of the object more clearly, we utilized the Sketch token edge detection algorithm to extract the edge contour features of the image and fused them into the potential function of the DenseCRF model. Finally, extensive experiments on the Potsdam and Vaihingen datasets demonstrated that the proposed model exhibited significant advantages compared to the current state-of-the-art models.",
        "publication_year": "2023",
        "authors": [
            "Xiang Cheng",
            "Hong Lei"
        ],
        "related_topics": [
            "Computer Science",
            "Environmental Science"
        ],
        "citation_count": 0,
        "reference_count": "39",
        "references": [
            "/paper/Semantic-Segmentation-of-Large-Size-VHR-Remote-a-Ding-Zhang/4c04ede41c2b77568f6b33c06cef6fbe425e6c95",
            "/paper/Multiattention-Network-for-Semantic-Segmentation-of-Li-Zheng/561f5bd4dd8db04e8b74c12b225757e0665b707a",
            "/paper/Multi-Scale-Context-Aggregation-for-Semantic-of-Zhang-Lin/fd0ff60d9cccd4ca2ad4a6aff2eb5b8eb39414de",
            "/paper/HRCNet%3A-High-Resolution-Context-Extraction-Network-Xu-Zhang/bb2280b4b45cdee70d2728f4939b50a2235c6cce",
            "/paper/ResUNet-a%3A-a-deep-learning-framework-for-semantic-Diakogiannis-Waldner/9c6eca31f311eae935e84efa6966c0165bc4e14a",
            "/paper/Accurate-cloud-detection-in-high-resolution-remote-Li-Wei/770a02f93febfeba2f5e6ceeb29b7e252930f919",
            "/paper/TSCNet%3A-Topological-Structure-Coupling-Network-for-Wang-Cheng/ffe9564e96ca9a92e0da3ecc6ef535c77bb4d125",
            "/paper/Remote-Sensing-Scene-Image-Classification-Based-on-Cheng-Lei/f0c588accc500902311eed678498824014b81671",
            "/paper/Image-Registration-Algorithm-for-Remote-Sensing-on-Zhang-Zhou/ad949e25e85d9469eed2c05097110a201586bdd9",
            "/paper/Deep-Learning-for-Remote-Sensing-Data%3A-A-Technical-Zhang-Zhang/b16408a97170785fb216c9e8b7920d64f478fbc8"
        ]
    },
    {
        "id": "85b063ab7990c2a54ab2f009988cd1af4b84df6d",
        "title": "Adversarial Machine Learning in Wireless Communications Using RF Data: A Review",
        "abstract": "An holistic survey of existing research on AML attacks for various wireless communication problems as well as the corresponding defense mechanisms in the wireless domain are presented. Machine learning (ML) provides effective means to learn from spectrum data and solve complex tasks involved in wireless communications. Supported by recent advances in computational resources and algorithmic designs, deep learning (DL) has found success in performing various wireless communication tasks such as signal recognition, spectrum sensing and waveform design. However, ML in general and DL in particular have been found vulnerable to manipulations thus giving rise to a field of study called adversarial machine learning (AML). Although AML has been extensively studied in other data domains such as computer vision and natural language processing, research for AML in the wireless communications domain is still in its early stage. This paper presents a comprehensive review of the latest research efforts focused on AML in wireless communications while accounting for the unique characteristics of wireless systems. First, the background of AML attacks on deep neural networks is discussed and a taxonomy of AML attack types is provided. Various methods of generating adversarial examples and attack mechanisms are also described. In addition, an holistic survey of existing research on AML attacks for various wireless communication problems as well as the corresponding defense mechanisms in the wireless domain are presented. Finally, as new attacks and defense techniques are developed, recent research trends and the overarching future outlook for AML in next-generation wireless communications are discussed.",
        "publication_year": "2020",
        "authors": [
            "D. Adesina",
            "C. Hsieh",
            "Y. Sagduyu",
            "Lijun Qian"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "35",
        "reference_count": "281",
        "references": [
            "/paper/Adversarial-Machine-Learning-for-5G-Communications-Sagduyu-Erpek/8fd0431186564148b8c0b8a30c363fe724ff320e",
            "/paper/Undermining-Deep-Learning-Based-Channel-Estimation-Hou-Wang/86fb22cc461f77b5c85b21227f74b9dfb90159ed",
            "/paper/Undermining-Deep-Learning-Based-Channel-Estimation-Hou/9077d34f9b719a7fd37f5794cad71d88a7c5cf89",
            "/paper/Membership-Inference-Attack-and-Defense-for-Signal-Shi-Sagduyu/7a925e5cb7bac0faa9293353652d52db6849cfa0",
            "/paper/A-Deep-Ensemble-based-Wireless-Receiver-for-in-Sahay-Brinton/46be52d8c389f749ab5f2b0dd07a0a16923a78a9",
            "/paper/Channel-Aware-Adversarial-Attacks-Against-Deep-Kim-Sagduyu/0497b410e841d42536cc48ba5869ee0258781b5c",
            "/paper/Adversarial-Attacks-against-Deep-Learning-Based-in-Kim-Shi/ce7781833a699d013c99ddf027aea852a2a8e940",
            "/paper/A-Deep-Ensemble-Based-Wireless-Receiver-for-Attacks-Sahay-Brinton/4bfaba5a04c6c88a1774c1acb9d6e8b7f8e5d409",
            "/paper/Adversarial-Machine-Learning-and-Defense-Game-for-Sagduyu/3ca7ad47068f96b0cd2f55cd19f41a1845611ebb",
            "/paper/Adversarial-Machine-Learning-for-NextG-Covert-Using-Kim-Sagduyu/bc3a460122bb7f27388e65258d8cb98c890636d5",
            "/paper/Evaluating-Adversarial-Evasion-Attacks-in-the-of-Flowers-Buehrer/a18bfcd9b3bdc8d9e1f771e5809f22d965ec4ceb",
            "/paper/Adversarial-Machine-Learning-for-5G-Communications-Sagduyu-Erpek/8fd0431186564148b8c0b8a30c363fe724ff320e",
            "/paper/On-the-Limitations-of-Targeted-Adversarial-Evasion-Bair-DelVecchio/f65ccb2cc8403a4879c5c74870c12792ea8f94a7",
            "/paper/Deep-Learning-for-Wireless-Communications-Erpek-O'Shea/c144420df0aec4f3d8f5771021cc1217ceca5184",
            "/paper/Generalized-wireless-adversarial-deep-learning-Restuccia-D%E2%80%99oro/dfdce1d5e31384a4edcab79499b8218bf115749e",
            "/paper/Robust-Adversarial-Attacks-Against-DNN-Based-Bahramali-Nasr/edd274b011440b1b02deee05a8e0c69d618c1273",
            "/paper/Adversarial-Attacks-on-Deep-Learning-Based-Power-in-Manoj-Sadeghi/920f85bda27df741984238a164e738e152028c1b",
            "/paper/Adversarial-Examples-in-RF-Deep-Learning%3A-Detection-Kokalj-Filipovic-Miller/203ccb9940a48a97aae702fedc7ed5f9ae41206f",
            "/paper/Spectrum-Data-Poisoning-with-Adversarial-Deep-Shi-Erpek/4531f346abb78892822825c56d33f2f1c7a6bead",
            "/paper/Hacking-the-Waveform%3A-Generalized-Wireless-Deep-Restuccia-D%E2%80%99oro/d52802ba603d81afcb9b6ded2f9f9d27340bc8d1"
        ]
    },
    {
        "id": "1fc134c0cc82632a7c28479a4ff430f3988f1da4",
        "title": "The Influence of Network Structural Preference on Node Classification and Link Prediction",
        "abstract": "This work introduces a new feature abstraction method, namely the Transition Probabilities Matrix (TPM), based on embedding anonymous random walks on feature vectors, which is superior to the state-of-the-art algorithms in terms of cross-networks generalization tasks. Recent advances in complex network analysis opened a wide range of possibilities for applications in diverse \ufb01elds. The power of the network analysis depends on the node features. The topology-based node features are realizations of local and global spatial relations and node connectivity structure. Hence, collecting correct information on the node characteristics and the connectivity structure of the neighboring nodes plays the most prominent role in node classi\ufb01cation and link prediction in complex network analysis. The present work introduces a new feature abstraction method, namely the Transition Probabilities Matrix (TPM), based on embedding anonymous random walks on feature vectors. The node feature vectors consist of transition probabilities obtained from sets of walks in a prede\ufb01ned radius. The transition probabilities are directly related to the local connectivity structure, hence correctly embedded onto feature vectors. The success of the proposed embedding method is tested on node identi\ufb01cation/classi\ufb01cation and link prediction on three commonly used real-world networks. In real-world networks, nodes with similar connectivity structures are common; Thus, obtaining information from similar networks for predictions on the new networks is the distinguishing characteristic that makes the proposed algorithm superior to the state-of-the-art algorithms in terms of cross-networks generalization tasks.",
        "publication_year": "2022",
        "authors": [
            "Sarmad N. Mohammed",
            "S. G\u00fcnd\u00fc\u00e7"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "47",
        "references": [
            "/paper/Link-prediction-in-dynamic-networks-based-on-the-Chi-Yin/f15456a69473643f565f4b1353638766ea796d2f",
            "/paper/A-Survey-of-Link-Prediction-in-Complex-Networks-Mart%C3%ADnez-Berzal/03b15e0ffa62d2626b8051e738ef7399447122d9",
            "/paper/LINE%3A-Large-scale-Information-Network-Embedding-Tang-Qu/0834e74304b547c9354b6d7da6fa78ef47a48fa8",
            "/paper/Community-structure-in-social-and-biological-Girvan-Newman/2a005868b79511cf8c924cd5990e2497527a0527",
            "/paper/The-Impact-of-Global-Structural-Information-in-Buffelli-Vandin/257a2e6730674c19be98780f4c58f8f7371baf4d",
            "/paper/Node-Classification-and-Link-Prediction-in-Social-Molokwu-Shuvo/8eef32d2f75604fc829a169d671b08fb48fff947",
            "/paper/Degree-Based-Random-Walk-Approach-for-Graph-Mohammed-G%C3%BCnd%C3%BC%C3%A7/096e5ce26a9d697fdf5b2804f00006df33869aef",
            "/paper/node2vec%3A-Scalable-Feature-Learning-for-Networks-Grover-Leskovec/36ee2c8bd605afd48035d15fdc6b8c8842363376",
            "/paper/Predicting-the-evolution-of-communities-in-social-Pavlopoulou-Tzortzis/d0aeff67a19f5c2be25ed6ffb601bcdb1da8f8e1",
            "/paper/On-community-structure-in-complex-networks%3A-and-Cherifi-Palla/ee292a61fc7469eff11d26b5a46c291019c8673e"
        ]
    },
    {
        "id": "e751128df94f367eea17933e9dbe218f3ef1f724",
        "title": "Bi-LSTM-Based Two-Stream Network for Machine Remaining Useful Life Prediction",
        "abstract": "A series of new handcrafted feature flows (HFFs) are proposed, which can suppress the raw signal noise and thus improve the encoded sequential information for the RUL prediction, and a novel bidirectional LSTM (Bi-LSTM)-based two-stream network is proposed. In industry, prognostics and health management (PHM) is used to improve the system reliability and efficiency. In PHM, remaining useful life (RUL) prediction plays a key role in preventing machine failure and reducing operation cost. Recently, with the development of deep learning technology, long short-term memory (LSTM) and convolutional neural networks (CNNs) are adopted into many RUL prediction approaches, which shows impressive performances. However, existing deep learning-based methods directly utilize raw signals. Since noise widely exists in raw signals, the quality of these approaches\u2019 feature representation is degraded, which degenerates their RUL prediction accuracy. To address this issue, we first propose a series of new handcrafted feature flows (HFFs), which can suppress the raw signal noise and thus improve the encoded sequential information for the RUL prediction. In addition, to effectively integrate our proposed HFFs with the raw input signals, a novel bidirectional LSTM (Bi-LSTM)-based two-stream network is proposed. In this novel two-stream network, three different fusion methods are designed to investigate how to combine both streams\u2019 feature representations in a reasonable way. To verify our proposed Bi-LSTM-based two-stream network, extensive experiments are carried out on the commercial modular aero propulsion system simulation (C-MAPSS) dataset, showing superior performances over state-of-the-art approaches.",
        "publication_year": "2022",
        "authors": [
            "Ruibing Jin",
            "Zhenghua Chen",
            "Keyu Wu",
            "Min Wu",
            "Xiaoli Li",
            "Ruqiang Yan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "14",
        "reference_count": "40",
        "references": [
            "/paper/Dual-Channel-Feature-Attention-Based-Approach-for-Gao-Li/f60e50df0674dc8446c507395ce4343495d2b5ff",
            "/paper/Investigating-and-predicting-the-dielectric-of-deep-Raj-Murugesan/54f0e4ef52ac767058c2e6a06793a6ae4c225b00",
            "/paper/Performance-degradation-prediction-model-of-rolling-Lan-Li/1119a2fc0e943d6014d81ea41e7f66a9cf2bfe32",
            "/paper/Sensing-Incipient-Faults-in-Power-Transformers-Long-Das-Paramane/c667a944fb0b37728a63e869293c2980b71ebd45",
            "/paper/Vehicle-Anomaly-Detection-by-Attention-Enhanced-He-Chen/9cd1e55d05a18677799abf87cbd68f5b5a703083",
            "/paper/Prediction-of-remaining-useful-life-of-rolling-on-Liu-Hao/da0f8276d2bd5d04c9419823b2023a67af08c0e9",
            "/paper/Scalability%2C-Explainability-and-Performance-of-in-A-Ramezani-Cummins/649cda08148d664e869751bcb9d9f488ca7c7773",
            "/paper/Multistate-Prediction-for-In-Service-Gas-Turbine-Yang-Zhao/04e1b37dbdbcb8e9b0f28da65c65e2be105d3f7e",
            "/paper/LSTM-ANN-Based-Price-Hike-Sentiment-Analysis-from-Chakraborty-Talukdar/5332063dd508e9695b723e14d3f33051a8981b31",
            "/paper/Interaction-models-for-remaining-useful-life-Zhevnenko-Kazantsev/f7a83c2d64d4fb6b48fc52c429475f80e9b990d8",
            "/paper/Multi-feature-Fused-Bidirectional-Long-Short-term-Jin-Chen/dbfc7ed6dacf99c861ca3b84f1cc85f4bc3afc8c",
            "/paper/Attention-Based-Bidirectional-LSTM-CNN-Model-for-Song-Park/c2f19932fcf6839a2df99863fecfd17333558a06",
            "/paper/Machine-Remaining-Useful-Life-Prediction-via-an-Chen-Wu/64aff4bac4dd205861488adade6c651085ce6b32",
            "/paper/A-Novel-Deep-Learning-Based-Encoder-Decoder-Model-Liu-Liu/1c6011a67e1a97f89dee9587523fdb3b1b0047e3",
            "/paper/Remaining-Useful-Life-Prediction-Based-on-a-Neural-Yang-Liu/60f317f7e5ddba6789535db49e309bc39b604135",
            "/paper/Learning-to-Monitor-Machine-Health-with-LSTM-Zhao-Yan/117fcfef38aa4641ae33e2605dc35013fc908719",
            "/paper/KDnet-RUL%3A-A-Knowledge-Distillation-Framework-to-Xu-Chen/a32ec5656d7cc05d770f401c78fbca759aa52b08",
            "/paper/A-BiGRU-Autoencoder-Remaining-Useful-Life-Scheme-Duan-Li/029bb71bc00c34870cd6cae950e41e507fe7ff45",
            "/paper/Remaining-useful-life-estimation-in-prognostics-Li-Ding/809003357de849d443a37b29996e2130c7bdb041",
            "/paper/Degradation-Aware-Remaining-Useful-Life-Prediction-Wu-Wu/ae65aaaaaadb1317e919c5b41a4ca3e0f071c973"
        ]
    },
    {
        "id": "9b09c3424456c587aa8239d108116d1e2afd4992",
        "title": "No Free Lunch: The Hazards of Over-Expressive Representations in Anomaly Detection",
        "abstract": "Evidence is provided for a no-free-lunch theorem in anomaly detection stating that increasing representation expressivity will eventually result in performance degradation, and guidance must be provided to focus the representation on the attributes relevant to the anomalies of interest. Anomaly detection methods, powered by deep learning, have recently been making significant progress, mostly due to improved representations. It is tempting to hypothesize that anomaly detection can improve indefinitely by increasing the scale of our networks, making their representations more expressive. In this paper, we provide theoretical and empirical evidence to the contrary. In fact, we empirically show cases where very expressive representations fail to detect even simple anomalies when evaluated beyond the well-studied object-centric datasets. To investigate this phenomenon, we begin by introducing a novel theoretical toy model for anomaly detection performance. The model uncovers a fundamental trade-off between representation sufficiency and over-expressivity. It provides evidence for a no-free-lunch theorem in anomaly detection stating that increasing representation expressivity will eventually result in performance degradation. Instead, guidance must be provided to focus the representation on the attributes relevant to the anomalies of interest. We conduct an extensive empirical investigation demonstrating that state-of-the-art representations often suffer from over-expressivity, failing to detect many types of anomalies. Our investigation demonstrates how this over-expressivity impairs image anomaly detection in practical settings. We conclude with future directions for mitigating this issue.",
        "publication_year": "2023",
        "authors": [
            "Tal Reiss",
            "Niv Cohen",
            "Yedid Hoshen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "50",
        "references": [
            "/paper/Deep-Visual-Analogy-Making-Reed-Zhang/a10d6877c90de39c42a143af60c0bf5e588be763",
            "/paper/Towards-Total-Recall-in-Industrial-Anomaly-Roth-Pemula/23ad8fc48530ce366f8192dfb48d0f7df1dba277",
            "/paper/Learning-and-Evaluating-Representations-for-Deep-Sohn-Li/498e003901f8287e89e5064477cd22dd47e49d61",
            "/paper/PANDA%3A-Adapting-Pretrained-Features-for-Anomaly-and-Reiss-Cohen/78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "/paper/CSI%3A-Novelty-Detection-via-Contrastive-Learning-on-Tack-Mo/e1bb329621de73d08c47beae9b5439a1c244eb1a",
            "/paper/SimpleNet%3A-A-Simple-Network-for-Image-Anomaly-and-Liu-Zhou/a23c0a89bd21bd2481fedcdd6d1ac891c6c06bdc",
            "/paper/WinCLIP%3A-Zero-Few-Shot-Anomaly-Classification-and-Jeong-Zou/aa207668318fec38d60b79f407fb64982e46fce9",
            "/paper/A-framework-for-benchmarking-detection-and-its-to-Galil-Dabbah/85e3375ff47be23ad3cee66f379284c416a57e2c",
            "/paper/Robustness-to-Spurious-Correlations-Improves-Zhang-Ranganath/2ae610a9233e7ef20aa2242410d40ffaf1387884",
            "/paper/Attribute-based-Representations-for-Accurate-and-Reiss-Hoshen/ecf1b50214ff13d2378e8f637c846c61ff2a0b43"
        ]
    },
    {
        "id": "6138553d7919172ac500d4ce24ec50b1a0ba812b",
        "title": "Robust integration of multiple single-cell RNA sequencing datasets using a single reference space",
        "abstract": "An algorithm that uses the gene eigenvectors from a reference dataset to establish a global frame for integration, called Reference Principal Component Integration (RPCI), consistently outperforms other methods by multiple metrics, with clear advantages in preserving genuine cross-sample gene expression differences in matching cell types. In many biological applications of single-cell RNA sequencing (scRNA-seq), an integrated analysis of data from multiple batches or studies is necessary. Current methods typically achieve integration using shared cell types or covariance correlation between datasets, which can distort biological signals. Here we introduce an algorithm that uses the gene eigenvectors from a reference dataset to establish a global frame for integration. Using simulated and real datasets, we demonstrate that this approach, called Reference Principal Component Integration (RPCI), consistently outperforms other methods by multiple metrics, with clear advantages in preserving genuine cross-sample gene expression differences in matching cell types, such as those present in cells at distinct developmental stages or in perturbated versus control studies. Moreover, RPCI maintains this robust performance when multiple datasets are integrated. Finally, we applied RPCI to scRNA-seq data for mouse gut endoderm development and revealed temporal emergence of genetic programs helping establish the anterior\u2013posterior axis in visceral endoderm. Integration of multiple single-cell RNA sequencing datasets is improved by creating a common reference space using a new algorithm.",
        "publication_year": "2021",
        "authors": [
            "Yang Liu",
            "Tao Wang",
            "B. Zhou",
            "D. Zheng"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "17",
        "reference_count": "74",
        "references": [
            "/paper/Benchmarking-integration-of-single-cell-expression-Nguyen-Baik/30c9e588b8d41fdf28b043417440a62875f80b49",
            "/paper/An-integrated-cell-barcoding-and-computational-for-Shen-Werner/ca1597d483d597b38ff8e0fe6785176067d2ba32",
            "/paper/Practical-bioinformatics-pipelines-for-single-cell-He-Lin/49d531e13840c46184e924354412511548788da5",
            "/paper/Domain-adaptation-for-supervised-integration-of-Sun-Qiu/626af7bfb4269b9e27b61cea949818e27d23bf7a",
            "/paper/Integrating-single-cell-genomics-pipelines-to-of-Shen-Sun/036e2d72ee31c19fd8b0cf81d8788552116d4532",
            "/paper/Single-cell-transcriptomics-uncovers-a-genetic-cell-Bono-Liu/7adbd763e8a2d4faa033b7912ab5389aedc51fd5",
            "/paper/Identifying-Gene-wise-Differences-in-Latent-Space-Baraban-Clark/17114bb128c38cc2750bbe39ea7944b3976106d2",
            "/paper/Learning-Cell-Annotation-under-Multiple-Reference-Liu-Yan/1f5f61e8bce64410a9b6f9410c3180acaddf426f",
            "/paper/Single-cell-multi-omic-analysis-identifies-a-primed-Nomaru-Liu/b74ffc64858940f29e99a6fe806e9a28cb5596b8",
            "/paper/Tbx2-and-Tbx3-regulate-cell-fate-progression-of-the-Song-Morrow/cd28e7ed2dc1ce521c8b00ec02993a067b4e7440",
            "/paper/Integrating-single-cell-transcriptomic-data-across-Butler-Hoffman/458c8ca3c2818b479d91dbdb83f2d10ded3708fa",
            "/paper/Comprehensive-Integration-of-Single-Cell-Data-Stuart-Butler/2287a3930a7568a956aae5f3f037efe8fed675e7",
            "/paper/Fast%2C-sensitive%2C-and-accurate-integration-of-single-Korsunsky-Fan/3ea71ab8877a3e96ce82daf24aacd3ccbcd19138",
            "/paper/Comprehensive-integration-of-single-cell-data-Stuart-Butler/d889f05b79dd1ac67743d2f15760d58a5cda3c14",
            "/paper/scMerge-leverages-factor-analysis%2C-stable-and-to-Lin-Ghazanfar/db45a1e03550df2a6d3dc1476c9415b80bf69e89",
            "/paper/Batch-effects-in-single-cell-RNA-sequencing-data-by-Haghverdi-Lun/56bf103a956b4a2ad11868c05db189d1e3f64ac1",
            "/paper/Systematic-comparison-of-single-cell-and-methods-Ding-Adiconis/9801c18d3ed0085d9cc3bd8007086682bcafc31e",
            "/paper/A-benchmark-of-batch-effect-correction-methods-for-Tran-Ang/d5baf1912d43d0af0e8f683eb5532f5f5445430e",
            "/paper/Multiplexed-droplet-single-cell-RNA-sequencing-Kang-Subramaniam/829fff0f1bab67a4bb98a0c77120ff80311d7da4",
            "/paper/Massively-parallel-digital-transcriptional-of-cells-Zheng-Terry/17422a9fcf3f05408f7f2f270b127aa812e9b2b3"
        ]
    },
    {
        "id": "ec230350b307cde84583a2b5d97da38cc009eae5",
        "title": "Delayless Block Individual-Weighting-Factors Sign Subband Adaptive Filters With an Improved Band-Dependent Variable Step-Size",
        "abstract": "A block implementation of the delayless IWF-SSAF algorithm designed for an active impulsive noise control (AINC) system and an improved BDVSS version (I-BDVSS) is proposed by using the multiple auxiliary past gradients, given for each band by the block-processing. Delayless individual-weighting-factors sign subband adaptive filter (IWF-SSAF) algorithms with a band-dependent variable step-size (BDVSS) were recently introduced to achieve a robust convergence performance against the impulsive interference and to avoid an undesirable signal path delay in subband systems. In this paper, we develop a block implementation of the delayless IWF-SSAF algorithm designed for an active impulsive noise control (AINC) system. With the block-processing approach, the proposed delayless block IWF-SSAF algorithm can be implemented more efficiently than the original delayless algorithm regardless of number of subbands, which is verified through the computational analysis. Furthermore, an improved BDVSS version (I-BDVSS) is also proposed by using the multiple auxiliary past gradients, which are given for each band by the block-processing. Finally, the simulation results illustrate that the proposed delayless block IWF-SSAF algorithm with the I-BDVSS, even requiring less computational burden, can achieve a better convergence performance than the original delayless algorithm with the BDVSS under severe impulsive noise control environment.",
        "publication_year": "2020",
        "authors": [
            "Jung-Hee Kim",
            "Jeonghwan Choi",
            "S. Nam",
            "Joon\u2010Hyuk Chang"
        ],
        "related_topics": [
            "Computer Science",
            "Engineering"
        ],
        "citation_count": "2",
        "reference_count": "28",
        "references": [
            "/paper/Improved-multiband-structured-subband-adaptive-with-Heydari-Abadi/0f1eb8d363609dc3c0f7a8f78e9b6b50529b45fd",
            "/paper/Stochastic-Behaviour-Analysis-of-Adaptive-Averaging-Wiangtong-Prongnuch/cbcbebb791af53979ac465e774249c09a2a9e3b1",
            "/paper/Delayless-Individual-Weighting-Factors-Sign-Subband-Kim-Kim/487d9b927b8b61504609ff2c5a2f8793dd5809f7",
            "/paper/Novel-sign-subband-adaptive-filter-algorithms-with-Yu-Zhao/f60191030674a718604f4b9051704337d9a57ef5",
            "/paper/Variable-step-size-sign-subband-adaptive-filter-Cho-Baek/7b61333d086b2c81fe091e62da0f94899411adbe",
            "/paper/Robust-variable-step-size-sign-subband-adaptive-Wen-Zhang/e87f942b9b37a4fcb1bd7799f7823def5bf7c37f",
            "/paper/A-band-dependent-variable-step-size-sign-subband-Yoo-Shin/8d387d2b68f31fb96f06ed9c243bffb150838dcf",
            "/paper/Variable-Step-Size-Sign-Subband-Adaptive-Filter-Shin-Yoo/3a4eb71e3cd6182d3f24852b662d9de01be72c10",
            "/paper/On-Delayless-Architecture-for-the-Normalized-Filter-Lee-Gan/0301fa9d3928638c37d183c5538f776a40b37dda",
            "/paper/Sign-subband-adaptive-filter-with-%E2%84%931-norm-variable-Kim-Chang/417bd43e223b77b8d622d2f729727f264c9d19ee",
            "/paper/Subband-Adaptive-Filtering%3A-Theory-and-Lee-Gan/254d87080d3c2a6d31a9a185552c8e9001fdcf0a",
            "/paper/Frequency-domain-and-multirate-adaptive-filtering-Shynk/2a3df97a9ee04536e8283361379d42b6834a40c9"
        ]
    },
    {
        "id": "cc0571b3f95f37c669f6e04fa145b7bfed10f037",
        "title": "Detecting Video Anomaly with a Stacked Convolutional LSTM Framework",
        "abstract": "An autoencoder architecture based on a stacked convolutional LSTM framework that highlights both spatial and temporal aspects in detecting anomalies of surveillance videos that rivals state-of-the-art methods with a faster detection speed is proposed. Automatic anomaly detection in real-world video surveillance is still challenging. In this paper, we propose an autoencoder architecture based on a stacked convolutional LSTM framework that highlights both spatial and temporal aspects in detecting anomalies of surveillance videos. The spatial component(i.e. spatial encoder/decoder) uses Convolutional Neural Network (CNN) and carries information about scenes and objects. The temporal component(i.e. temporal encoder/decoder) uses stacked convolutional LSTM and conveys object movement. Specifically, we integrate CNN and the stacked convolutional LSTM to learn normal patterns from the training data, which contains only normal events. With the integrated approach, our method can better model spatio-temporal information than many others. We train our models in an unsupervised manner, and labels are required only in the testing phase. Our method is evaluated on the datasets of Avenue, UCSD and ShanghaiTech Campus. The results show that the accuracy of our method rivals state-of-the-art methods with a faster detection speed.",
        "publication_year": "2019",
        "authors": [
            "Hao Wei",
            "Kai Li",
            "Haichang Li",
            "Yifan Lyu",
            "Xiaohui Hu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "32",
        "references": [
            "/paper/Attention-based-residual-autoencoder-for-video-Le-Kim/770c840fe25e4c09405529c639f1fcf0a1b245ea",
            "/paper/An-integration-of-Pseudo-Anomalies-and-Memory-for-Le-Nguyen/a283e48c27f5b0430536a4e8264aa1055de65cd6",
            "/paper/IBaggedFCNet%3A-An-Ensemble-Framework-for-Anomaly-in-Zahid-Tahir/8ee527b72f096a6e93e64a49978db7edb8d47fd5",
            "/paper/A-Self-Trained-Spatial-Graph-Convolutional-Network-Li-Chang/dbe1eb127c20920eaaa66d642098be26684930d4",
            "/paper/Human-related-anomalous-event-detection-via-network-Li-Chang/d8fb87ee41aa4189e64ff87c3919cc663fea217f",
            "/paper/Human-related-anomalous-event-detection-via-graph-Li-Chang/120d6d2b8869604ff59a1d6d12634db24b0715d8",
            "/paper/Anomaly-Detection-in-Real-Time-Surveillance-Videos-Cherian-Poovammal/91ac83a71b088247801aa3604b78eefd23e25339",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Abnormal-Event-Detection-in-Videos-using-Chong-Tay/527cc8cd2af06a9ac2e5cded806bab5c3faad9cf",
            "/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429",
            "/paper/Real-World-Anomaly-Detection-in-Surveillance-Videos-Sultani-Chen/598fe25743f9492c5c1ba30274ea446f65426d85",
            "/paper/A-Revisit-of-Sparse-Coding-Based-Anomaly-Detection-Luo-Liu/99dff291f260b3cc3ff190106b0c2e3e685223a4",
            "/paper/Real-time-anomaly-detection-and-localization-in-Sabokrou-Fathy/851ff5f13fbff7023717c3913f2df4a7551a374a",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Faster-R-CNN%3A-Towards-Real-Time-Object-Detection-Ren-He/424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Anomaly-detection-in-crowded-scenes-Mahadevan-Li/9d3f0d47449c7db37d1bae3b70db2928610a8db7"
        ]
    },
    {
        "id": "08064909d04c1a9a7529eb0b33c90141bdaa8948",
        "title": "Exercise therapy improves pain and mouth opening in temporomandibular disorders: A systematic review with meta-analysis",
        "abstract": "Therapeutic exercise is an effective therapy to reduce pain and increase pain pressure threshold and active and passive maximum mouth opening in patients with temporomandibular disorders. Objective To analyse the effectiveness of exercise therapy in improving pain and active or passive maximum mouth opening in patients with temporomandibular disorders. Data sources PubMed Medline, Web of Science, Scopus, CINAHL Complete and Physiotherapy Evidence Database, until April 2022, in accordance with Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Review methods We included randomized controlled trials evaluating the effect of exercise therapy on pain and on active and passive maximum mouth opening in patients with temporomandibular disorders. Effect size was calculated using Cohen's standardized mean difference (SMD) and their 95% confidence interval (95% CI) in a random-effects model. Results A total of 16 studies with 812 participants were included. Exercise therapy is effective in reducing pain (SMD: \u22120.58; 95% CI: \u22121.01 to \u22120.12) and increasing the pain pressure threshold (SMD: 0.45; 95% CI: 0.14\u20130.76), active and passive maximum mouth opening (SMD: 0.43; 95% CI: 0.14\u20130.71 and SMD: 0.4; 95% CI: 0.06\u20130.75, respectively). Subgroup analyses showed more effect of exercise therapy more splints versus splints on pain (SMD: \u22120.5; 95% CI: \u22120.73 to \u22120.26), active and passive maximum mouth opening (SMD: 1.14; 95% CI: 0.22\u20132.07 and SMD: 0.56; 95% CI: 0.06\u20131.06, respectively). On pain pressure threshold, exercise therapy was better than physiotherapy approach (manual therapy and electrotherapy) (SMD: 0.48; 95% CI: 0.09\u20130.87). Conclusions Therapeutic exercise is an effective therapy to reduce pain and increase pain pressure threshold and active and passive maximum mouth opening in patients with temporomandibular disorders.",
        "publication_year": "2022",
        "authors": [
            "Ana M Id\u00e1\u00f1ez-Robles",
            "Esteban Obrero-Gait\u00e1n",
            "R. Lomas-Vega",
            "M. C. Osuna-P\u00e9rez",
            "Irene Cort\u00e9s-P\u00e9rez",
            "N. Zagalaz-Anula"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "3",
        "reference_count": "66",
        "references": [
            "/paper/Are-exercises-with-or-without-occlusal-splints-more-Batista-Vila-Nova/cab837cb314a0523c1b8224f67bcde977f1b59be",
            "/paper/Effectiveness-of-Physiotherapy-in-the-Treatment-of-Cr%C4%83ciun-Geman/642aae205443fe0eeb12ee647a3b4aa78d5117d9",
            "/paper/Injectable-Platelet-Rich-Fibrin-(I-PRF)-to-Joint-A-Sielski-Ch%C4%99ci%C5%84ska/b82950c18ec83e63f458f64f58b794804d13d9d8",
            "/paper/The-effectiveness-of-exercise-therapy-for-a-review-Dickerson-Weaver/3fa34c272b27e895357f0f353fb75938b1caf84b",
            "/paper/Effectiveness-of-Manual-Therapy-and-Therapeutic-for-Armijo-Olivo-Pitance/970c02ad04a0ad795616f74333c6bbed0cf81d71",
            "/paper/Manual-therapy-and-exercise-in-temporomandibular-A-Touche-Boo-Mallo/b990d34339074ae720a13e0978ad1ce5b4665d0c",
            "/paper/Occlusal-stabilization-splint-for-patients-with-of-Pficer-Dodi%C4%87/a2b8cfa1b84e59e62bcc62d0a961b67f31f66510",
            "/paper/Mandibular-Range-of-Movement-and-Pain-Intensity-in-Alajbeg-Giki%C4%87/54a90a9f1cb2d5b8df8e0bfcbc7e88b540b5bb46",
            "/paper/Efficacy-of-different-combinations-of-physiotherapy-Tanhan-Ozer/a4a43a1edc32b64e7650a92082db6da3f5dab417",
            "/paper/Effectiveness-of-occlusal-splint-therapy-in-the-of-Al-Moraissi-Farea/d5805070831487b217fcc1e165e217639855ac3e",
            "/paper/The-Effect-of-Exercise-on-Range-of-Movement-and-Ba%C5%9F-Kazan/2cb0d8b44efdb570d26ed302e50d8aa0227fac7e",
            "/paper/The-Efficacy-of-Occlusal-Splints-in-the-Treatment-A-Hardy-Bonsor/87ba99c2fb719258e02fdf95f6a20d9c6aca5d51",
            "/paper/Short-term-efficacy-of-physical-therapy-compared-to-Ismail-Demling/9fc584a229d699e85d183ed8428a4e3808cd95c8"
        ]
    },
    {
        "id": "fe7efbe95e45dc15393d488ec7f8755ab8686a45",
        "title": "Delimiting CD34+ Stromal Cells/Telocytes Are Resident Mesenchymal Cells That Participate in Neovessel Formation in Skin Kaposi Sarcoma",
        "abstract": "Limiting CD34+SCs/TCs are mesenchymal/stromal cells that can transdifferentiate into KS ECs, participating in the formation of two types of neovessels, of histogenic, clinical and therapeutic interest. Kaposi sarcoma (KS) is an angioproliferative lesion in which two main KS cell sources are currently sustained: endothelial cells (ECs) and mesenchymal/stromal cells. Our objective is to establish the tissue location, characteristics and transdifferentiation steps to the KS cells of the latter. For this purpose, we studied specimens of 49 cases of cutaneous KS using immunochemistry and confocal and electron microscopy. The results showed that delimiting CD34+ stromal cells/Telocytes (CD34+SCs/TCs) in the external layer of the pre-existing blood vessels and around skin appendages form small convergent lumens, express markers for ECs of blood and lymphatic vessels, share ultrastructural characteristics with ECs and participate in the origin of two main types of neovessels, the evolution of which gives rise to lymphangiomatous or spindle-cell patterns\u2014the substrate of the main KS histopathological variants. Intraluminal folds and pillars (papillae) are formed in the neovessels, which suggests they increase by vessel splitting (intussusceptive angiogenesis and intussusceptive lymphangiogenesis). In conclusion, delimiting CD34+SCs/TCs are mesenchymal/stromal cells that can transdifferentiate into KS ECs, participating in the formation of two types of neovessels. The subsequent growth of the latter involves intussusceptive mechanisms, originating several KS variants. These findings are of histogenic, clinical and therapeutic interest.",
        "publication_year": "2023",
        "authors": [
            "L. D\u00edaz-Flores",
            "R. Guti\u00e9rrez",
            "M. Gonz\u00e1lez-G\u00f3mez",
            "M. Garc\u00eda",
            "Marta Palmas",
            "J. L. Carrasco",
            "J. Madrid",
            "L. D\u00edaz-Flores"
        ],
        "related_topics": [
            "Medicine",
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "77",
        "references": [
            "/paper/Human-resident-CD34%2B-stromal-cells-telocytes-have-a-D%C3%ADaz-Flores-Guti%C3%A9rrez/7f3ad99786e12be94fa64c9e80570094a0bfe77f",
            "/paper/Cd34%2B-Stromal-Cells-Telocytes-in-Normal-and-Skin-D%C3%ADaz-Flores-Guti%C3%A9rrez/23209c011cc17b83edb0ed239a7b81ec253ec009",
            "/paper/CD34%2B-stromal-cells-fibroblasts-fibrocytes-as-a-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/c387d88c70801cd94f51b05cf44dd0d9042a2ee4",
            "/paper/Uptake-and-intracytoplasmic-storage-of-pigmented-by-D%C3%ADaz-Flores-Guti%C3%A9rrez/e313e034e86f6261b8b49dc79dac7e4f52bc8a6d",
            "/paper/Behaviour-of-telocytes-during-physiopathological-D%C3%ADaz-Flores-Guti%C3%A9rrez/40fb968dfe2ffb25dfbe05cbacb9b343123a71bd",
            "/paper/Skin-telocytes-versus-fibroblasts%3A-two-distinct-Kang-Zhu/952df44a2d1d94c833228ea70a22bbd883f0d2e5",
            "/paper/Evidence-for-Kaposi-Sarcoma-Originating-from-Stem-Li-Zhong/d8377bcdbc8cc7657557613d0450bf59926ef92c",
            "/paper/Impairment-in-the-telocyte-CD34%2B-stromal-cell-in-Rosa-Faussone%E2%80%90Pellegrini/a33204154ea93df70229157435dfde8b8067dd86",
            "/paper/Kaposi%E2%80%99s-sarcoma-associated-herpesvirus-promotes-by-Ding-Chen/5dab9d7275a066f4541689dd8d273f6950783bef",
            "/paper/Evidence-for-progressive-reduction-and-loss-of-in-Manetti-Guiducci/3204fcc328c6ca66b66fa70440f3aa600a76ff0a"
        ]
    },
    {
        "id": "cb0c906a45dfbb92f7761b00dd637fa78091bc51",
        "title": "A Review on Prediction and Prognosis of the Prostate Cancer and Gleason Grading of Prostatic Carcinoma Using Deep Transfer Learning Based Approaches",
        "abstract": "Transfer learning is used to create resilient DL convolutional neural networks that can classify the aggressiveness of prostate cancer by automatically extracting characteristics from whole-slide images of prostate biopsies that have been annotated by skilled pathologists. Prostate cancer is a dangerous type of cancer that kills a lot of men because it is hard to diagnose. Images taken of people with carcinoma have complex and important parts that are hard to get out with traditional diagnostic methods. Deep learning (DL) can classify the aggressiveness of prostate cancer by automatically extracting characteristics from whole-slide images of prostate biopsies that have been annotated by skilled pathologists. This study uses transfer learning to create resilient DL convolutional neural networks. A technique of risk assessment for prostate cancer called Gleason grading is based on the pathologist who reports the results and is vulnerable to bias. Systems that use DL have the potential to improve the efficiency and objectivity of Gleason grading. Based on a sizable, high-quality training dataset, a cutting-edge convolutional network architecture, and an extensive training set, we developed DL-based models for identifying prostate cancer tissue in whole-slide images (MobileNet V2, InceptionResNet V2, DenseNet 169, ResNet101 V2, and NasNetMobile). Accuracy, loss, and RMSE measurements were used in a confusion matrix to evaluate performance. DenseNet 169 provided the best results, with validation accuracy of 89.76% (ISUP Grade 0), training accuracy of 95.63% (ISUP Grade 1), validation accuracy of 96.98% (ISUP Grade 2), validation accuracy of 91.98% (ISUP Grade 3), and training accuracy of 95.63% (ISUP Grade 5). InceptionResNet V2 has obtained the highest average accuracy (validation), 84.99%. The results demonstrate that InceptionResNet V2 performed better than other models.",
        "publication_year": "2023",
        "authors": [
            "G. P. Kanna",
            "S. J. K. J. Kumar",
            "P. Parthasarathi",
            "Y. Kumar"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "2",
        "reference_count": "48",
        "references": [
            "/paper/A-Comprehensive-Analysis-of-Deep-Learning-Based-for-Thakur-Kaur/9792bc635e7896642895d75aaf394f637ea29eac",
            "/paper/A-Review-of-Deep-Learning-Based-Approaches-for-and-Kumar-Kumar/0368dd7538b7245aca5133baff6bea4df228d152",
            "/paper/High-accuracy-prostate-cancer-pathology-using-deep-Tolkach-Dohmg%C3%B6rgen/d8bdf72c2ccfcce5ee3e6f6064b65ffe7a43cad9",
            "/paper/Artificial-intelligence-for-diagnosis-and-grading-a-Str%C3%B6m-Kartasalo/b75246ba25f10bc002a18ee03d78981d7b48f376",
            "/paper/Deep-Learning-Based-Gleason-Grading-of-Prostate-of-Karimi-Nir/95db99286b274352e7e1906ebf63e10ae9fce30c",
            "/paper/Automated-deep-learning-system-for-Gleason-grading-Bulten-Pinckaers/39a52867ea3d60ec4f28182e0e618b762d3d7909",
            "/paper/A-Multi-Channel-and-Multi-Spatial-Attention-Neural-Yang-Xiao/1a7125dd9c88a0174536479f5d5ee4c9ae96da11",
            "/paper/Prostate-cancer-classification-with-multiparametric-Yuan-Qin/cf2ae94f126635e4f736d840adc3dff3e3c994b9",
            "/paper/Development-and-Validation-of-a-Deep-Learning-for-Nagpal-Foote/17b6e6d7ce3ec7afcea1ce46c5a1d28d83b8e3cf",
            "/paper/Computerized-Classification-of-Prostate-Cancer-from-Xu-Park/30d0a269f8ffeb562808c9e4f4c675e641af4f6e",
            "/paper/A-Novel-Approach-to-Predict-Brain-Cancerous-Tumor-Khan-Omee/51df5094e18bc1ed239b3405033a73afb7f52c96",
            "/paper/A-transfer-learning-approach-for-classification-of-Chen-Xu/e17f23e736ef7a71f907623e752811e1f2616f76"
        ]
    },
    {
        "id": "97dd42c101a3d3b77924a58a6fea1968f905c029",
        "title": "N-Net: an UNet architecture with dual encoder for medical image segmentation",
        "abstract": "N-Net is proposed, a dual encoder model to deepen the network depth and enhance the ability of feature extraction that produces more coherent organ boundaries and finer details and demonstrates that N-Net outperforms the work of UNet, UNet\u2019s improved models, and UNet3\u2009+\u2009\u2009-and-\u2009and UNet4\u2009in these three datasets. In order to assist physicians in diagnosis and treatment planning, accurate and automatic methods of organ segmentation are needed in clinical practice. UNet and its improved models, such as UNet\u2009+\u2009\u2009+\u2009and UNt3\u2009+\u2009, have been powerful tools for medical image segmentation. In this paper, we focus on helping the encoder extract richer features and propose a N-Net for medical image segmentation. On the basis of UNet, we propose a dual encoder model to deepen the network depth and enhance the ability of feature extraction. In our implementation, the Squeeze-and-Excitation (SE) module is added to the dual encoder model to obtain channel-level global features. In addition, the introduction of full-scale skip connections promotes the integration of low-level details and high-level semantic information. The performance of our model is tested on the lung and liver datasets, and compared with UNet, UNet\u2009+\u2009\u2009+\u2009and UNet3\u2009+\u2009in terms of quantitative evaluation with the Dice, Recall, Precision and F1 score and qualitative evaluation. Our experiments demonstrate that N-Net outperforms the work of UNet, UNet\u2009+\u2009\u2009+\u2009and UNet3\u2009+\u2009in these three datasets. By visual comparison of the segmentation results, N-Net produces more coherent organ boundaries and finer details.",
        "publication_year": "2023",
        "authors": [
            "Bingtao Liang",
            "Chen Tang",
            "Wei Zhang",
            "Min Xu",
            "Tianbo Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "36",
        "references": [
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/UNet-3%2B%3A-A-Full-Scale-Connected-UNet-for-Medical-Huang-Lin/0b444f74dd9cc06c2833dd15f9258ef5e169e6ea",
            "/paper/CE-Net%3A-Context-Encoder-Network-for-2D-Medical-Gu-Cheng/a07aa5b834e5083624189a929be07c7ae2389229",
            "/paper/RA-UNet%3A-A-Hybrid-Deep-Attention-Aware-Network-to-Jin-Meng/5090fbfc9cf5db61ed060e5afdf01d2c08a8fcce",
            "/paper/H-DenseUNet%3A-Hybrid-Densely-Connected-UNet-for-and-Li-Chen/a86d7289c76d832e83c99539859b7b186e4ea6c8",
            "/paper/CHAOS-Challenge-Combined-(CT-MR)-Healthy-Abdominal-Kavur-Gezer/6d38bdd172cdbccb11745f5f031f848679117f25",
            "/paper/Pancreas-segmentation-using-a-dual-input-v-mesh-Wang-Gong/56e5586d90c4a3af2b99705d3e7abc7b5e41304d",
            "/paper/Deep-Learning-Techniques-for-Automatic-MRI-Cardiac-Bernard-Lalande/9406246f6972c03e5bfaac4df4676648dc4ac935",
            "/paper/Attention-U-Net%3A-Learning-Where-to-Look-for-the-Oktay-Schlemper/ae1c89817a3a239e5344293138bdd80293983460",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a"
        ]
    },
    {
        "id": "41396b28fb56f5699f24ac0a85902165b88c696f",
        "title": "SimViT: Exploring a Simple Vision Transformer with Sliding Windows",
        "abstract": "This paper introduces a simple vision Transformer named SimViT, to incorporate spatial structure and local information into the vision Transformers, and introduces Multi-head Central Self-Attention(MCSA) instead of conventional Multi- head Self-attention to capture highly local relations. Although vision Transformers have achieved excellent performance as backbone models in many vision tasks, most of them intend to capture global relations of all tokens in an image or a window, which disrupts the inherent spatial and local correlations between patches in 2D structure. In this paper, we introduce a simple vision Transformer named SimViT, to incorporate spatial structure and local information into the vision Transformers. Specifically, we introduce Multi-head Central Self-Attention(MCSA) instead of conventional Multi-head Self-Attention to capture highly local relations. The introduction of sliding windows facilitates the capture of spatial structure. Meanwhile, SimViT extracts multiscale hierarchical features from different layers for dense prediction tasks. Extensive experiments show the SimViT is effective and efficient as a general-purpose backbone model for various image processing tasks. Especially, our SimViT-Micro only needs 3.3M parameters to achieve 71.1% top-1 accuracy on ImageNet-1k dataset, which is the smallest size vision Transformer model by now.",
        "publication_year": "2021",
        "authors": [
            "Gang Li",
            "Di Xu",
            "Xingyi Cheng",
            "Lingyu Si",
            "Changwen Zheng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "21",
        "references": [
            "/paper/DilateFormer%3A-Multi-Scale-Dilated-Transformer-for-Jiao-Tang/0cd526723b87ae37981922992992d203448a2014",
            "/paper/LightViT%3A-Towards-Light-Weight-Convolution-Free-Huang-Huang/aa0b4b6ab37e75ba8407e0eddd69e778319e8fe0",
            "/paper/CAEVT%3A-Convolutional-Autoencoder-Meets-Lightweight-Zhang-Li/c1d79e63a4dfb68478fa5885c3951cbd67ce84ee",
            "/paper/Stepwise-Feature-Fusion%3A-Local-Guides-Global-Wang-Huang/dac5ad2509fe9886d25ad1dd75bf5b6c6c5e48ed",
            "/paper/An-Active-Multi-Object-Ultrafast-Tracking-System-Li-Hu/c8b126409c412667fad7176bb15f4049d19b1dde",
            "/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "/paper/Pyramid-Vision-Transformer%3A-A-Versatile-Backbone-Wang-Xie/3e398bad2d8636491a1034cc938a5e024c7aa881",
            "/paper/Transformer-in-Transformer-Han-Xiao/0ae67202f0584afccefa770865d14a46655d2975",
            "/paper/Stand-Alone-Self-Attention-in-Vision-Models-Ramachandran-Parmar/d6dccb5d71fbb6f5765f89633ba3a8e6809a720d",
            "/paper/PVT-v2%3A-Improved-baselines-with-Pyramid-Vision-Wang-Xie/67040b931c1a384426c44ae73f9553e97f08cf6a",
            "/paper/Panoptic-Feature-Pyramid-Networks-Kirillov-Girshick/a84906dbd4d6640f918d0b6ed2a7313dda0d55f1",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/Squeeze-and-Excitation-Networks-Hu-Shen/df67d46e78aae0d2fccfb6212d101a342259c01b",
            "/paper/Non-local-Neural-Networks-Wang-Girshick/8899094797e82c5c185a0893896320ef77f60e64",
            "/paper/Local-Relation-Networks-for-Image-Recognition-Hu-Zhang/061d6d5f3df0db70b12f9e90bec327e19b7259c1"
        ]
    },
    {
        "id": "5e502c618d559ce1e676eea02aff1e797ac3f1ef",
        "title": "Locality-Aware Transformer for Video-Based Sign Language Translation",
        "abstract": "A locality-aware transformer is proposed for sign language translation using a multi-stride position encoding scheme that assigns the same position index to adjacent frames with various strides to enhance the local dependency. Recently, the application of transformer makes significant progress in sign language translation. However, several characteristics of sign videos are neglected in existing transformer-based methods that hinder translation performance. Firstly, in sign videos, multiple consecutive frames represent a single sign gloss thus the local temporal relations are crucial. Secondly, the inconsistency between video and text demands the non-local and global context modeling ability of the model. To address these issues, a locality-aware transformer is proposed for sign language translation. Concretely, the multi-stride position encoding scheme assigns the same position index to adjacent frames with various strides to enhance the local dependency. Afterward, the adaptive temporal interaction module is utilized to capture non-local and flexible local frame correlation simultaneously. Moreover, a gloss counting task is designed to facilitate the holistic understanding of sign videos. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed framework.",
        "publication_year": "2023",
        "authors": [
            "Zihui Guo",
            "Yonghong Hou",
            "Chunping Hou",
            "Wenjie Yin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "31",
        "references": [
            "/paper/PiSLTRc%3A-Position-Informed-Sign-Language-With-Xie-Zhao/87e823d2cb58e741230c0fa3b83f3459c7e32241",
            "/paper/SimulSLT%3A-End-to-End-Simultaneous-Sign-Language-Yin-Zhao/d3d784b07fd4a444d11ac753e36964767214d667",
            "/paper/Explore-More-Guidance%3A-A-Task-aware-Instruction-for-Cao-Li/9b234fd1357b552f2a5eeca1bfb5f0cbe6db595d",
            "/paper/Hierarchical-Recurrent-Deep-Fusion-Using-Adaptive-Guo-Zhou/a97b13151ee3b3ddfc6f17c3cc04eaf827f00341",
            "/paper/Hierarchical-LSTM-for-Sign-Language-Translation-Guo-Zhou/d44c20c48e764a546d00b9155a56b171b0dc04bc",
            "/paper/TSPNet%3A-Hierarchical-Feature-Learning-via-Temporal-Li-Xu/16091f0821502b70294ef66671183dadd1afcdc0",
            "/paper/Neural-Sign-Language-Translation-by-Learning-Orbay-Akarun/4e39e59f41a480f68c934cc38eb874a25ceb5073",
            "/paper/Multi-channel-Transformers-for-Multi-articulatory-Camg%C3%B6z-Koller/4fe56f5f7a7196571e81ec243d86df376269695c",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2"
        ]
    },
    {
        "id": "51aafc680ccf6ba7d879e31fce49c55fd299f760",
        "title": "Spot the fake lungs: Generating Synthetic Medical Images using Neural Diffusion Models",
        "abstract": "Results demonstrate that images generated with the diffusion model can translate characteristics that are otherwise very specific to certain medical conditions in chest X-Ray or CT images. Generative models are becoming popular for the synthesis of medical images. Recently, neural diffusion models have demonstrated the potential to generate photo-realistic images of objects. However, their potential to generate medical images is not explored yet. In this work, we explore the possibilities of synthesis of medical images using neural diffusion models. First, we use a pre-trained DALLE2 model to generate lungs X-Ray and CT images from an input text prompt. Second, we train a stable diffusion model with 3165 X-Ray images and generate synthetic images. We evaluate the synthetic image data through a qualitative analysis where two independent radiologists label randomly chosen samples from the generated data as real, fake, or unsure. Results demonstrate that images generated with the diffusion model can translate characteristics that are otherwise very specific to certain medical conditions in chest X-Ray or CT images. Careful tuning of the model can be very promising. To the best of our knowledge, this is the first attempt to generate lungs X-Ray and CT images using neural diffusion models. This work aims to introduce a new dimension in artificial intelligence for medical imaging. Given that this is a new topic, the paper will serve as an introduction and motivation for the research community to explore the potential of diffusion models for medical image synthesis. We have released the synthetic images on https://www.kaggle.com/datasets/hazrat/awesomelungs.",
        "publication_year": "2022",
        "authors": [
            "Hazrat Ali",
            "Shafaq Murad",
            "Zubair Shah"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "10",
        "reference_count": "17",
        "references": [
            "/paper/Beware-of-diffusion-models-for-synthesizing-medical-Akbar-Wang/1987ee6b983fd2d082e0555e21909978c41d9c8f",
            "/paper/A-Survey-on-Training-Challenges-in-Generative-for-Saad-O'Reilly/73253320ba713ebc83d0794b78e40aa57bdbdc69",
            "/paper/Deep-Learning-Approaches-for-Data-Augmentation-in-A-Kebaili-Lapuyade-Lahorgue/13afd3c131dbb836bf9c6c65466ca8f5234bca11",
            "/paper/Diffusion-based-Data-Augmentation-for-Skin-Disease-Akrout-Gyepesi/a69a61b81b31e16339df59cd125027522b11a775",
            "/paper/Extracting-Training-Data-from-Diffusion-Models-Carlini-Hayes/2e965b5d97c2d6fb4af284307735be39283792ba",
            "/paper/Cascaded-Latent-Diffusion-Models-for-Chest-X-ray-Weber-Ingrisch/618911cda803267d03615d1a04db0bbfe584e28c",
            "/paper/A-Diffusion-Model-Predicts-3D-Shapes-from-2D-Images-Waibel-Rooell/616c95094f582623ae31926e7f95484b7788df4c",
            "/paper/Differentially-Private-Diffusion-Models-Generate-Ghalebikesabi-Berrada/510a068ba6ce4979202e309a0eafb82d6d89f243",
            "/paper/Aligning-Synthetic-Medical-Images-with-Clinical-Sun-Goldgof/993f0eb1cf576a50cba4fbc667e10f15d63b07f4",
            "/paper/Brain-Imaging-Generation-with-Latent-Diffusion-Pinaya-Tudosiu/e924a5cc4739f18fb225b7a8b506099042567ffa",
            "/paper/Segmentation-of-Lungs-in-Chest-X-Ray-Image-Using-Munawar-Azmat/da959782ef230a5653967585090ea31e67390ce1",
            "/paper/A-new-generative-adversarial-network-for-medical-Ahmad-Ali/c5427eab1a236e4529dc004307e921677fde304b",
            "/paper/Generative-Adversarial-Network-in-Medical-Imaging%3A-Yi-Walia/acbeebdfd9dd3456628604eefcd53f50f974b132",
            "/paper/COVID-19-CT-Image-Synthesis-With-a-Conditional-Jiang-Chen/b33d527aa5a1a17caea7a9cb3d8cb65bd9803929",
            "/paper/COVID-19-CT-Image-Synthesis-With-a-Conditional-Jiang-Chen/32095de948f289ba4bc40c730a5f2a90a5cb09b7",
            "/paper/The-role-of-generative-adversarial-networks-in-MRI%3A-Ali-Biswas/1f1c4153224370a8e3ee0d78c9948e163c273d65",
            "/paper/Diffusion-Models-Beat-GANs-on-Image-Synthesis-Dhariwal-Nichol/64ea8f180d0682e6c18d1eb688afdb2027c02794",
            "/paper/Deep-Feature-Learning-for-Medical-Image-Analysis-Chen-Shi/e72f626074252b7e17ebc48d9fd4a4cd9d231359",
            "/paper/Denoising-Diffusion-Probabilistic-Models-Ho-Jain/289db3be7bf77e06e75541ba93269de3d604ac72"
        ]
    },
    {
        "id": "2ef8be98d6f2028fc54cd354bb1fc22d97378125",
        "title": "SFA-Net: Scale and Feature Aggregate Network for Retinal Vessel Segmentation",
        "abstract": "A residual atrous spatial feature aggregate block (RASF) is embedded at the end of the encoder to learn multiscale information and an attentional feature module (AFF) is proposed to enhance the effective fusion between shallow and high-level features. A U-Net-based network has achieved competitive performance in retinal vessel segmentation. Previous work has focused on using multilevel high-level features to improve segmentation accuracy but has ignored the importance of shallow-level features. In addition, multiple upsampling and convolution operations may destroy the semantic feature information contained in the decoder layer. To address these problems, we propose a scale and feature aggregate network (SFA-Net), which can make full use of multiscale high-level feature information and shallow features. In this paper, a residual atrous spatial feature aggregate block (RASF) is embedded at the end of the encoder to learn multiscale information. Furthermore, an attentional feature module (AFF) is proposed to enhance the effective fusion between shallow and high-level features. In addition, we designed the multi-path feature fusion (MPF) block to fuse high-level features of different decoder layers, which aims to learn the relationship between the high-level features of different paths and alleviate the information loss. We apply the network to the three benchmark datasets (DRIVE, STARE, and CHASE_DB1) and compare them with the other current state-of-the-art methods. The experimental results demonstrated that the proposed SFA-Net performs effectively, indicating that the network is suitable for processing some complex medical images.",
        "publication_year": "2022",
        "authors": [
            "Jiajia Ni",
            "Jinhui Liu",
            "Xuefei Li",
            "Zhengming Chen"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "55",
        "references": [
            "/paper/A-feature-aggregation-and-feature-fusion-network-Ni-Sun/301f1c0d3ab3df8a886b2456e34239baf23d0242",
            "/paper/SCS-Net%3A-A-Scale-and-Context-Sensitive-Network-for-Wu-Wang/242a62aa1850bb1bcd146a8c6e14c41777574694",
            "/paper/Global-channel-attention-networks-for-intracranial-Ni-Wu/958aebc86388e7625fb8df4b0882bc3b764364a8",
            "/paper/DNL-Net%3A-deformed-non-local-neural-network-for-Ni-Wu/0f52f931e4493e810994a5a6dab71ee3ba89f77e",
            "/paper/Multi-level-deep-supervised-networks-for-retinal-Mo-Zhang/4edac46abeb9ce6535cede3755c662d4aabfd3bd",
            "/paper/IterNet%3A-Retinal-Image-Segmentation-Utilizing-in-Li-Verma/2576cae4e65d8b4853fd371289e2916417c74587",
            "/paper/DeepVessel%3A-Retinal-Vessel-Segmentation-via-Deep-Fu-Xu/94b43a5a4224c8c1d62f5fa3ac567de37f0c44aa",
            "/paper/SA-Net%3A-A-scale-attention-network-for-medical-image-Hu-Wang/9e74f1d682fb233a028d5607f64c5c49827baa74",
            "/paper/SSCA-Net%3A-Simultaneous-Self-and-Channel-Attention-Ni-Wu/cd5da7f4409655859ae08c0c3212eb3b0fd72ff4",
            "/paper/GC-Net%3A-Global-context-network-for-medical-image-Ni-Wu/e631fc7e9459386915b382fe74ce40de76251a1d",
            "/paper/Retinal-vessel-segmentation-based-on-Fully-Neural-Oliveira-Pereira/e31e3e03b152756f2207195a0f023cc25e31e93e"
        ]
    },
    {
        "id": "4ff3a409def9dfe9bb88ee9808c1eb8ebfc2126d",
        "title": "Outcome Measures and Quality of Life in Vestibular Schwannomas",
        "abstract": "Existing vestibular schwannoma (VS) disease-specific and non-disease-specific patient-reported outcome measure (PROM) tools for quality of life (QoL) and audio-vestibular symptoms are summarized, and the potential role of psychological variables in QoL and recovery after surgical resection of VS is discussed. This review summarizes existing vestibular schwannoma (VS) disease-specific and non-disease-specific patient-reported outcome measure (PROM) tools for quality of life (QoL) and audio-vestibular symptoms, compares QoL across treatment modalities, and discusses the potential role of psychological variables in QoL and recovery after surgical resection of VS. VS treatment success was previously assessed according to various factors such as the extent of tumor resection, facial nerve function, and hearing preservation. However, the literature demonstrates recent shifts away from using such physician-reported \u201cobjective\u201d outcomes as benchmarks for success towards more patient-perceived \u201csubjective\u201d measures. A number of PROM tools have been developed to assess QoL and other measures in patients with VS. This has allowed us to better understand and quantify the impact of the disease and of the treatments on our patient population. However, there are important considerations to be made when applying PROM in clinical settings such as understanding the concept of Minimal Clinically Important Difference (MCID). The use of disease-specific PROMs, such as the PANQOL, as a primary outcome in VS research is encouraged. When doing so, PROM scales should incorporate the concept of MCID to distinguish statistically significant from clinically significant findings and should further investigate the role of non-medical variables, such as psychological variables, on QoL and recovery trajectories in patients with VS. Actual literature does not seem to indicate a clinically significant difference in patient-reported outcomes among treatment modalities.",
        "publication_year": "2021",
        "authors": [
            "Benoit Chartrand",
            "Nasser Al-Tamami",
            "J. Carriere",
            "R. Moumdjian",
            "I. Saliba",
            "J. Saliba"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": 0,
        "reference_count": "55",
        "references": [
            "/paper/The-Impact-of-Primary-Treatment-Strategy-on-the-of-Foley-Maweni/7c5abd0cf656ed48db39c27f4f4cefc6d8801ef0",
            "/paper/Quality-of-Life-in-807-Patients-with-Vestibular-Soulier-Leeuwen/aa88fa15f92cdd413c481162b7cad303acd8dc4c",
            "/paper/Long-term-Quality-of-Life-Following-Vestibular-Via-Broomfield-Mandavia/57acd9b63daee439b292ad3ab3657554a3cc2d67",
            "/paper/Quality-of-Life-Within-the-First-6-Months-of-With-Carlson-Tombers/18cc616713bd3ad78dbf51ef158e37a39634ce63",
            "/paper/Long-term-quality-of-life-in-patients-with-managed-Maria-Maria/f1fdc50bbdb70a635ec30b6d6835060cd16dd15c",
            "/paper/Conservative-treatment-of-vestibular-schwannoma%3A-of-Oddon-Montava/a9c1f65c759b028f5651531255fd5cb901a50eaf",
            "/paper/Quality-of-Life-in-Vestibular-Schwannoma-Patients-Jufas-Flanagan/89be424e28fb7ed0e0e6c5a469904a182e26f593",
            "/paper/Quality-of-life-following-surgery-for-large-and-a-Turel-Thakar/796b1f4fc8a89b969c883990a15000538472fbd9",
            "/paper/Patient-versus-physician-reported-facial-disability-Tveiten-Carlson/5b69ac5d710af62a77899d09d128d225faa561be",
            "/paper/Quality-of-life-after-vestibular-schwannoma-does-a-Iyer-Gunn/2e54aa9d490352320bcb56ea86708442d9e19ccc"
        ]
    },
    {
        "id": "ba62442fc88eb4da204e98899214c45960341fa5",
        "title": "Patch-Based Output Space Adversarial Learning for Joint Optic Disc and Cup Segmentation",
        "abstract": "A novel patch-based output space adversarial learning framework to jointly and robustly segment the optic disc and OC from different fundus image datasets and achieves the first place in the OD and OC segmentation tasks in the MICCAI 2018 Retinal Fundus Glaucoma Challenge. Glaucoma is a leading cause of irreversible blindness. Accurate segmentation of the optic disc (OD) and optic cup (OC) from fundus images is beneficial to glaucoma screening and diagnosis. Recently, convolutional neural networks demonstrate promising progress in the joint OD and OC segmentation. However, affected by the domain shift among different datasets, deep networks are severely hindered in generalizing across different scanners and institutions. In this paper, we present a novel patch-based output space adversarial learning framework (<inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula>OSAL) to jointly and robustly segment the OD and OC from different fundus image datasets. We first devise a lightweight and efficient segmentation network as a backbone. Considering the specific morphology of OD and OC, a novel morphology-aware segmentation loss is proposed to guide the network to generate accurate and smooth segmentation. Our <inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula>OSAL framework then exploits unsupervised domain adaptation to address the domain shift challenge by encouraging the segmentation in the target domain to be similar to the source ones. Since the whole-segmentation-based adversarial loss is insufficient to drive the network to capture segmentation details, we further design the <inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula>OSAL in a patch-based fashion to enable fine-grained discrimination on local segmentation details. We extensively evaluate our <inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula>OSAL framework and demonstrate its effectiveness in improving the segmentation performance on three public retinal fundus image datasets, i.e., Drishti-GS, RIM-ONE-r3, and REFUGE. Furthermore, our <inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula>OSAL framework achieved the first place in the OD and OC segmentation tasks in the <italic>MICCAI 2018 Retinal Fundus Glaucoma Challenge</italic>.",
        "publication_year": "2019",
        "authors": [
            "Shujun Wang",
            "Lequan Yu",
            "Xin Yang",
            "Chi-Wing Fu",
            "P. Heng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "157",
        "reference_count": "51",
        "references": [
            "/paper/Joint-optic-disc-and-optic-cup-segmentation-based-Luo-Xue/52291fecbeb1af12bfcd0987487c50406edee5d0",
            "/paper/NENet%3A-Nested-EfficientNet-and-adversarial-learning-Pachade-Porwal/b2bfdad365f2032cc2bc046a992f2c64efbd1fd9",
            "/paper/Convolutional-autoencoder-joint-boundary-and-mask-Zhang-Song/d44e3d1dc6bd08351a885a4ed3d6bb35931fffe0",
            "/paper/Boundary-and-Entropy-driven-Adversarial-Learning-Wang-Yu/f2b3de7f036f8f35294d7c8008622f7d3ad2b4eb",
            "/paper/WGAN-domain-adaptation-for-the-joint-optic-in-Kadambi-Wang/2ec1b9e25cf08f412cac08149d8f7ab12222944e",
            "/paper/An-Efficient-Hierarchical-Optic-Disc-and-Cup-with-Wang-Yu/ef345a62e9a05263eb2a495af845d7f41e0774d0",
            "/paper/Joint-segmentation-of-optic-cup-and-optic-disc-deep-Yu/5c855f76c36d82ff70399fc8247bef346ba443a2",
            "/paper/MEAL%3A-Meta-enhanced-Entropy-driven-Adversarial-for-Ma-Yang/b934c6ea9a2f0bd719e120e0cef051672ce56ae8",
            "/paper/ECSD-Net%3A-A-joint-optic-disc-and-cup-segmentation-Liu-Pan/9c0e4e03d2c9a2f62ea6b58fc69d9dc03232eec2",
            "/paper/GDCSeg-Net%3A-general-optic-disc-and-cup-segmentation-Ianlong-Hu/17d1bfc59cff24c21da40913de0bda483530d8b9",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Using-Fully-Shankaranarayana-Ram/c8eec916ea6e6d2a57a0d9ca29c9b95525b53314",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/Towards-Accurate-Segmentation-of-Retinal-Vessels-in-Son-Park/817d5982c78b28411fb78569859c9d950998f5cf",
            "/paper/Automatic-Optic-Disk-and-Cup-Segmentation-of-Fundus-Edupuganti-Chawla/aead7bdd35a3780f1a1c169fae3f5f04dd946747",
            "/paper/Disc-Aware-Ensemble-Network-for-Glaucoma-Screening-Fu-Cheng/88b91fb2834432273b915a8fb63ccf017e1bc034",
            "/paper/Efficient-Optic-Cup-Detection-from-Intra-image-with-Xu-Liu/d43330d88a052fc9e38e57f7c8c0a59a68e8f9a2",
            "/paper/Automated-segmentation-of-optic-disc-and-optic-cup-Yin-Liu/2758b3a82fae061e2e4301da0f9c5f14714bcc4b",
            "/paper/Unsupervised-Cross-Modality-Domain-Adaptation-of-Dou-Ouyang/1af573c96c2c0bc46a4ee01dfa303c43fcc11274",
            "/paper/Level-set-based-automatic-cup-to-disc-ratio-using-Wong-Liu/9a0cf9c7f1af4ea6e1e5e80b8dc4a6d64f81fcd2",
            "/paper/Translating-and-Segmenting-Multimodal-Medical-with-Zhang-Yang/89fb34d44de8e63ec5bcaa736c2f52a363c90942"
        ]
    },
    {
        "id": "5e956e96b93716589884be7a6efe45109b409bc8",
        "title": "Using GAN to Enhance the Accuracy of Indoor Human Activity Recognition",
        "abstract": "This paper presents a semi-supervised learning method for CSI-based activity recognition systems in which long short-term memory (LSTM) is employed to learn features and recognize seven different actions, and aims to generate data by using 50% of raw data in conjunction with a generative adversarial network (GAN). Indoor human activity recognition (HAR) explores the correlation between human body movements and the reflected WiFi signals to classify different activities. By analyzing WiFi signal patterns, especially the dynamics of channel state information (CSI), different activities can be distinguished. Gathering CSI data is expensive both from the timing and equipment perspective. In this paper, we use synthetic data to reduce the need for real measured CSI. We present a semi-supervised learning method for CSI-based activity recognition systems in which long short-term memory (LSTM) is employed to learn features and recognize seven different actions. We apply principal component analysis (PCA) on CSI amplitude data, while short-time Fourier transform (STFT) extracts the features in the frequency domain. At first, we train the LSTM network with entirely raw CSI data, which takes much more processing time. To this end, we aim to generate data by using 50% of raw data in conjunction with a generative adversarial network (GAN). Our experimental results confirm that this model can increase classification accuracy by 3.4% and reduce the Log loss by almost 16% in the considered scenario.",
        "publication_year": "2020",
        "authors": [
            "P. Moshiri",
            "Hojjat Navidan",
            "Reza Shahbazian",
            "S. Ghorashi",
            "David Windridge"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "13",
        "reference_count": "16",
        "references": [
            "/paper/CSI-Based-Human-Activity-Recognition-using-Neural-Moshiri-Nabati/4406d6b8810965d31b721d59255305d5430b55ef",
            "/paper/Utilizing-deep-learning-models-in-CSI-based-human-Shalaby-Elshennawy/aa5069cd1675d513cf874038dc7457cf309e5583",
            "/paper/A-CSI-Based-Human-Activity-Recognition-Using-Deep-Moshiri-Shahbazian/97fd011e2b6f67f5e32575c3f81eb774ef1a6be3",
            "/paper/Human-Activity-Recognition-Using-Self-powered-Based-Su-Liao/38f09749b6863d43c23a68fb7655cae9d4a5b1bb",
            "/paper/Multi-scale-Convolution-Transformer-for-Human-Gao-Wang/97b03dbc329d1c18adea23a6c81558a5abeb3d12",
            "/paper/Guided-GAN%3A-Adversarial-Representation-Learning-for-Abedin-Rezatofighi/8d84feba4d65feb7b782fc5e62c148edf8721070",
            "/paper/Human-Sensing-by-Using-Radio-Frequency-Signals%3A-A-Shahbazian-Trubitsyna/4f0d940a12083d96d4e8ec1ab9f4afe237f22020",
            "/paper/A-Comprehensive-Survey-on-Human-Activity-Using-Wang/50ab6ec65e2582b9b88956468f0a713974814f2f",
            "/paper/Synthetic-Behavior-Sequence-Generation-Using-Akbari-Sartipi/e6885b232df4996a3f25fc5614351f15160959ed",
            "/paper/Generative-Adversarial-Networks-(GANs)-in-A-Survey-Navidan-Moshiri/8cd7faf524c0b6e3e7a986c6a315b6773793c7bb",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/WiAct%3A-A-Passive-WiFi-Based-Human-Activity-System-Yan-Zhang/fd8358e4c90a511496cc7fbdd981f7ec28d7ca98",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/On-Spatial-Diversity-in-WiFi-Based-Human-Activity-A-Wang-Gong/12d30796c1f4432ec287426841d3e357809eae52",
            "/paper/Device-free-human-micro-activity-recognition-method-Al-qaness/97dd0e4e5dac778e54fd93f04edf6faef07fd215",
            "/paper/CsiGAN%3A-Robust-Channel-State-Information-Based-With-Xiao-Han/e8425c4471794073c8c3dc3a77a9a16905e24b94",
            "/paper/Joint-Activity-Recognition-and-Indoor-Localization-Wang-Feng/75020f90bc2e65d069458dca79b4bfaa28ac1826",
            "/paper/A-Survey-on-CSI-Based-Human-Behavior-Recognition-in-Wang-Jiang/9a41f42dfd89bf5b5876e28a62f4d507e3d2792b",
            "/paper/A-Hybrid-Deep-Learning-Model-for-Human-Activity-Gumaei-Hassan/40c7e97580e8ab66778916608bbcf9c7f2452868",
            "/paper/DeepCount%3A-Crowd-Counting-with-WiFi-via-Deep-Liu-Zhao/86a315c282c4a443d48a66ddf48dadc098fe0eae"
        ]
    },
    {
        "id": "1dc324681ac58abd2fad6b1da01c32997e06df50",
        "title": "Abnormal event detection in surveillance videos based on multi-scale feature and channel-wise attention mechanism",
        "abstract": "A new multi-scale feature prediction framework for abnormal event detection is proposed that treats predicted features that differ from the actual features as abnormal features and experimental results demonstrate the superiority of the proposed framework over the state-of-the-art approaches. Abnormal event detection is a challenging task, due to object scale variation, impact of background and anomaly defined differently in different context. In this paper, we propose a new multi-scale feature prediction framework for abnormal event detection. Firstly, we construct a multi-scale alignment feature generator to fuse the characteristic of different receptive fields so that address the objects of different scales in video frame. Secondly, in order to weak the influence of background, a novel channel-wise attention mechanism is introduced to highlight those informative channels while suppressing the confusing ones. Finally, an autoencoder-based deep feature prediction module is applied to capture temporal information and contextual information to generate predicted features. Instead of giving a definition of anomaly, we treat predicted features that differ from the actual features as abnormal features. Experimental results on four benchmark datasets demonstrate the superiority of the proposed framework over the state-of-the-art approaches.",
        "publication_year": "2022",
        "authors": [
            "Li-min Xia",
            "C. Wei"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "42",
        "references": [
            "/paper/Video-anomaly-detection-with-multi-scale-feature-Cai-Liu/d8663556aa1a875dcdc4f15ad1fd31933e724348",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/A-new-method-of-abnormal-behavior-detection-using-Xia-Li/2a9c0595726cbdd42e973697d9781c27132e2500",
            "/paper/BMAN%3A-Bidirectional-Multi-Scale-Aggregation-for-Lee-Kim/3dab77815d36acfda913e48738ce1f63dde4b336",
            "/paper/Abnormal-event-detection-with-semi-supervised-topic-Wang-Xia/75b6c92326b4cabf5cf3cebb5c6b3de1e1da0e3c",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Anomalous-Behaviors-Detection-in-Moving-Crowds-on-a-Yang-Cao/0c369ecc6f818ea89cf57462771c8240fd2be370",
            "/paper/Two-stream-deep-spatial-temporal-auto-encoder-for-Li-Chen/e851978bb31848aba212e0d84c422742984cadff",
            "/paper/Detecting-Abnormal-Events-in-Video-Using-Narrowed-Ionescu-Smeureanu/ee1d50a0c6448253eaf8d1f7f6b00d893419589d"
        ]
    },
    {
        "id": "4c04ede41c2b77568f6b33c06cef6fbe425e6c95",
        "title": "Semantic Segmentation of Large-Size VHR Remote Sensing Images Using a Two-Stage Multiscale Training Architecture",
        "abstract": "A deep architecture with a two-stage multiscale training strategy that is tailored to the semantic segmentation of large-size VHR RSIs is proposed and experimental results show that it outperforms local-patch-based training models in terms of both accuracy and stability. Very-high resolution (VHR) remote sensing images (RSIs) have significantly larger spatial size compared to typical natural images used in computer vision applications. Therefore, it is computationally unaffordable to train and test classifiers on these images at a full-size scale. Commonly used methodologies for semantic segmentation of RSIs perform training and prediction on cropped image patches. Thus, they have the limitation of failing to incorporate enough context information. In order to better exploit the correlations between ground objects, we propose a deep architecture with a two-stage multiscale training strategy that is tailored to the semantic segmentation of large-size VHR RSIs. In the first stage of the training strategy, a semantic embedding network is designed to learn high-level features from downscaled images covering a large area. In the second training stage, a local feature extraction network is designed to introduce low-level information from cropped image patches. The resulting training strategy is able to fuse complementary information learned from multiple levels to make predictions. Experimental results on two data sets show that it outperforms local-patch-based training models in terms of both accuracy and stability.",
        "publication_year": "2020",
        "authors": [
            "L. Ding",
            "Jing Zhang",
            "L. Bruzzone"
        ],
        "related_topics": [
            "Environmental Science",
            "Computer Science"
        ],
        "citation_count": "59",
        "reference_count": "46",
        "references": [
            "/paper/Semantic-Segmentation-of-Remote-Sensing-Imagery-on-Cheng-Lei/06b002e1ba39fa5a3fb1642a79ee971e2d1e95af",
            "/paper/Segmentation-of-VHR-EO-Images-using-Unsupervised-Saha-Mou/66a22af50a42f1705533fa2845eb632313876c27",
            "/paper/SBSS%3A-Stacking-Based-Semantic-Segmentation-for-Very-Cai-Fan/3b9f96afbab12b70bf1545ed0201fb384fed0763",
            "/paper/Feature-Selection-High-Resolution-Network-With-for-Xu-Tang/567f187da24ea2003b3262af3f7264bcea98f08e",
            "/paper/Multi-Scale-Context-Aggregation-for-Semantic-of-Zhang-Lin/fd0ff60d9cccd4ca2ad4a6aff2eb5b8eb39414de",
            "/paper/HRNet-and-PSPNet-based-multiband-semantic-of-remote-Sun-Zheng/7c5fc996cf81c2452dfbf57322bafb6594b52fd7",
            "/paper/Remote-Sensing-Images-Semantic-Segmentation-with-a-Li-Li/542b9b7724fe728c62e1a32ebc5a6c0fd63b1e37",
            "/paper/Semantic-Segmentation-of-Remote-Sensing-Images-With-Li-Chen/72f44f41b0adae31f5edf3f0cca57af0e63ffb76",
            "/paper/Integrating-Spatial-Details-With-Long-Range-for-of-Long-Li/380dc3c8d39d1998cf22495019d648712b2c7935",
            "/paper/Full-Semantic-Constructed-Network-for-Urban-Use-Dong-Zhuang/f50d880d153a8c23654e622fa239b7d113cc09a1",
            "/paper/Efficient-Patch-Wise-Semantic-Segmentation-for-Liu-Ren/bb4b1a083eabddcad7da66a526ee46177bd8489f",
            "/paper/Semantic-Segmentation-for-High-Spatial-Resolution-Yu-Yang/649d0aa1be51cc545de52fc584640501efdcf68b",
            "/paper/Fully-Convolutional-Networks-for-Semantic-of-Very-Sun-Wang/6adfa744231b1ef4e194a1ab05d24c6d458ed676",
            "/paper/Dense-Semantic-Labeling-with-Atrous-Spatial-Pyramid-Wang-Liang/91c3eacf47c33192b11a99938359da1e7b4a9b42",
            "/paper/Learning-Aerial-Image-Segmentation-From-Online-Maps-Kaiser-Wegner/e0cd100dbf93befe1d224f5efe63d670595f59a0",
            "/paper/Feature-Fusion-Through-Multitask-CNN-for-Remote-Sun-Yang/f724f90d987360e7bb4db9a10069d5efeeba6c66",
            "/paper/Object-Based-Convolutional-Neural-Network-for-Zhao-Du/dd9a8643ef80fd3fb95060f9b02e0233759639aa",
            "/paper/An-object-based-supervised-classification-framework-Zhang-Wang/8411c85c27da21e763e326706a85bf183ef38844",
            "/paper/Hourglass-ShapeNetwork-Based-Semantic-Segmentation-Liu-Nguyen/e9b8f2ee742b32ae272c950cc6fa2d5a2d05f028",
            "/paper/Classification-With-an-Edge%3A-Improving-Semantic-Marmanis-Schindler/62b378f3d8d6d7803ba3a3339949aea9ecdc5749"
        ]
    },
    {
        "id": "8fd0431186564148b8c0b8a30c363fe724ff320e",
        "title": "Adversarial Machine Learning for 5G Communications Security",
        "abstract": "To sustain the 5G system operations in the presence of adversaries, a defense mechanism is presented to increase the uncertainty of the adversary in training the surrogate model used for launching its subsequent attacks. \u2014Machine learning provides automated means to capture complex dynamics of wireless spectrum and support better understanding of spectrum resources and their ef\ufb01cient utilization. As communication systems become smarter with cognitive radio capabilities empowered by machine learning to perform critical tasks such as spectrum awareness and spectrum sharing, they also become susceptible to new vulnerabilities due to the attacks that target the machine learning applications. This paper identi\ufb01es the emerging attack surface of adversarial machine learning and corresponding attacks launched against wireless communications in the context of 5G systems. The focus is on attacks against (i) spectrum sharing of 5G communications with incumbent users such as in the Citizens Broadband Radio Service (CBRS) band and (ii) physical layer authentication of 5G User Equipment (UE) to support network slicing. For the \ufb01rst attack, the adversary transmits during data transmission or spectrum sensing periods to manipulate the signal-level inputs to the deep learning classi\ufb01er that is deployed at the Environmental Sensing Capability (ESC) to support the 5G system. For the second attack, the adversary spoofs wireless signals with the generative adversarial network (GAN) to in\ufb01ltrate the physical layer authentication mechanism based on a deep learning classi\ufb01er that is deployed at the 5G base station. Results indicate major vulnerabilities of 5G systems to adversarial machine learning. To sustain the 5G system operations in the presence of adversaries, a defense mechanism is presented to increase the uncertainty of the adversary in training the surrogate model used for launching its subsequent attacks.",
        "publication_year": "2021",
        "authors": [
            "Y. Sagduyu",
            "T. Erpek",
            "Yi Shi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "31",
        "reference_count": "74",
        "references": [
            "/paper/Adversarial-Machine-Learning-in-Wireless-Using-RF-A-Adesina-Hsieh/85b063ab7990c2a54ab2f009988cd1af4b84df6d",
            "/paper/Adversarial-Machine-Learning-and-Defense-Game-for-Sagduyu/3ca7ad47068f96b0cd2f55cd19f41a1845611ebb",
            "/paper/On-Assessing-Vulnerabilities-of-the-5G-Networks-to-Zolotukhin-Miraghaei/3400cec603a0a67511afa7adc4099f567d11cbd7",
            "/paper/Black-box-Adversarial-Examples-against-Intelligent-Zolotukhin-Miraghaei/6ccf31afcf5dcf5ad2b8752f064995580544dc0d",
            "/paper/Adversarial-Attacks-against-Deep-Learning-Based-in-Kim-Shi/ce7781833a699d013c99ddf027aea852a2a8e940",
            "/paper/Sensing-Throughput-Tradeoffs-with-Generative-for-Shi-Sagduyu/2739efa693df35c9b9cd5f7e6002947a6cea756f",
            "/paper/Waveform-Defence-Against-Deep-Learning-Generative-Xu-Wei/83a345181f1db7b925c064290bc4bf2b36c84ba2",
            "/paper/Membership-Inference-Attack-and-Defense-for-Signal-Shi-Sagduyu/7a925e5cb7bac0faa9293353652d52db6849cfa0",
            "/paper/Attacks-against-Machine-Learning-Models-in-5G-Zolotukhin-Zhang/f0d6f459208e737a11c458e7caccacc6fbfd5a81",
            "/paper/Jamming-Attacks-on-Federated-Learning-in-Wireless-Shi-Sagduyu/b4acff631876436b330aaa150a0f7abfed404d3e",
            "/paper/IoT-Network-Security-from-the-Perspective-of-Deep-Sagduyu-Shi/7ff0063bcc074d04b89ef4bc3eede54521d7b654",
            "/paper/Adversarial-Deep-Learning-for-Cognitive-Radio-and-Shi-Sagduyu/25fb31c992edc8f4b913777c7a646cb0fe2f66ca",
            "/paper/Adversarial-Machine-Learning-in-Wireless-Using-RF-A-Adesina-Hsieh/85b063ab7990c2a54ab2f009988cd1af4b84df6d",
            "/paper/Evaluating-Adversarial-Evasion-Attacks-in-the-of-Flowers-Buehrer/a18bfcd9b3bdc8d9e1f771e5809f22d965ec4ceb",
            "/paper/Adversarial-Deep-Learning-for-Over-the-Air-Spectrum-Sagduyu-Shi/892d41979d1b76f9e2f789de8f27e31f12e65b96",
            "/paper/Deep-Learning-for-Launching-and-Mitigating-Wireless-Erpek-Sagduyu/b2ff78b76a302b005ab65ad0d404373a70f3d5ee",
            "/paper/Spectrum-Data-Poisoning-with-Adversarial-Deep-Shi-Erpek/4531f346abb78892822825c56d33f2f1c7a6bead",
            "/paper/When-Attackers-Meet-AI%3A-Learning-Empowered-Attacks-Luo-Zhao/6abc99d8a1e2ee6c4f1038cbd449ac52959a47b7",
            "/paper/Deep-Learning-for-Wireless-Communications-Erpek-O'Shea/c144420df0aec4f3d8f5771021cc1217ceca5184",
            "/paper/When-Wireless-Security-Meets-Machine-Learning%3A-and-Sagduyu-Shi/80a1f750e9654103aa30bd7290acef6806ff8efe"
        ]
    },
    {
        "id": "f15456a69473643f565f4b1353638766ea796d2f",
        "title": "Link prediction in dynamic networks based on the attraction force between nodes",
        "abstract": "Semantic Scholar extracted view of \"Link prediction in dynamic networks based on the attraction force between nodes\" by Kuo Chi et al.",
        "publication_year": "2019",
        "authors": [
            "Kuo Chi",
            "Guisheng Yin",
            "Yuxin Dong",
            "Hongbin Dong"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "27",
        "reference_count": "40",
        "references": [
            "/paper/Link-prediction-of-time-evolving-network-based-on-Wu-Wu/f0717bed735fb8a9f375947eb749611881f644f5",
            "/paper/Predicting-future-links-with-new-nodes-in-temporal-Ran-Liu/f73790ca569f9d1667502f13556080ea334c54ba",
            "/paper/The-Influence-of-Network-Structural-Preference-on-Mohammed-G%C3%BCnd%C3%BC%C3%A7/1fc134c0cc82632a7c28479a4ff430f3988f1da4",
            "/paper/The-Influence-of-Network-Structural-Preference-on-Wang-Wang/b62f64e5d54a59e5aac1efe04aff4773486039c3",
            "/paper/Evolutionary-Features-for-Dynamic-Link-Prediction-Choudhury-Uddin/562b21849a3fba7a000b10671eb3203750882dfe",
            "/paper/AN-INFLUENTIAL-NODE-METRICS-APPROACH-FOR-LINK-IN-Rohini/9d83da4743cbacd503dc5c6db41d3b551d487f4f",
            "/paper/Taxonomy-of-Link-Prediction-for-Social-Network-A-Yuliansyah-Othman/dad3c32d58c67fc02963572492a1e44bc0a09458",
            "/paper/An-edge-creation-history-retrieval-based-method-to-Florentino-Cavalcante/db60e94e2008f83851218a54a676cd278e90584c",
            "/paper/Supervised-shift-k%E2%80%90means-based-machine-learning-for-Bhanodia-Khamparia/61b65adb2240808f8253c38f1b7657f896915a02",
            "/paper/Supervised-link-prediction-in-multiplex-networks-Shan-Li/75a04f706484566594df8f4652e8677ad2f6e461",
            "/paper/Link-prediction-in-complex-networks-based-on-the-Yao-Zhang/9a6878b47486cd3f6bf44d976b3324e46eb97d58",
            "/paper/An-evolutionary-algorithm-approach-to-link-in-Bliss-Frank/92c8dbecdce4427f04a27b443de0d9fb0d2e2aa7",
            "/paper/Predicting-links-based-on-knowledge-dissemination-Zhou-Jia/f848c7aeacee204c319236506a02a2dec7181ee0",
            "/paper/Link-Prediction-Based-on-Common-Neighbors-for-Yao-Wang/264d2798abe444214d51033827fe3353f6db9add",
            "/paper/Predicting-top-L-missing-links-with-node-and-link-Wu-Lin/fcd2e4a26b90e1057e01e25ba56cefe66868d33e",
            "/paper/Proximity-measures-for-link-prediction-based-on-Soares-Prud%C3%AAncio/521b3375a6ec0b439c24e4706937aa97bcdd202d",
            "/paper/Combining-contextual%2C-temporal-and-topological-for-Muniz-Goldschmidt/23bc42eb6670d36d12749ca4565478f9a2dc57d5",
            "/paper/Supervised-random-walks%3A-predicting-and-links-in-Backstrom-Leskovec/29efbdf3f95cee97405accafdebd3bd374f1f003",
            "/paper/Improving-local-clustering-based-top-L-link-methods-Wu-Lin/c9e5ff32e13cbf0bffcb1a6477918edb6413583a",
            "/paper/Effective-and-Efficient-Similarity-Index-for-Link-Lv-Jin/78aaa500828380b8929d63c16336933f94ef26b9"
        ]
    },
    {
        "id": "f60e50df0674dc8446c507395ce4343495d2b5ff",
        "title": "Dual Channel Feature Attention-Based Approach for RUL Prediction Considering the Spatiotemporal Difference of Multisensor Data",
        "abstract": "A novel DL-based approach with dual channel feature attention (DCFA) modules used to automatically weigh the input on both time and spatial domain and shows that the proposed model outperforms other state-of-the-art approaches. The remaining useful life (RUL) prediction has always been the key technology to realize predictive maintenance. An accurate prediction can give decision-makers a reliable reference to develop maintenance schedules and adjust production planning. When dealing with the spatiotemporal data of multisensor system, recent deep learning (DL) methods, however, still remain unexplored to weigh the contributions from both spatial and temporal dimensions. In this article, we propose a novel DL-based approach with dual channel feature attention (DCFA) modules. First, the two-individual feature attention branches are used to automatically weigh the input on both time and spatial domain, which helps the model to focus more attention on the important elements. Then multilayer bidirectional long short-term memory (Bi-LSTM) and convolutional neural networks are used to extract the high-level features. Finally, a fusion network will combine the features to estimate the RUL. Evaluation experiments are conducted on the C-MAPSS dataset to verify the performance of the proposed model. The results show that the proposed model outperforms other state-of-the-art approaches.",
        "publication_year": "2023",
        "authors": [
            "Hui Gao",
            "Yibin Li",
            "Yingxiang Zhao",
            "Yan Song"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "38",
        "references": [
            "/paper/Distributed-Attention-Based-Temporal-Convolutional-Song-Gao/fc6a78d27a2268a2e0c9d4675018d1e92e7c67e5",
            "/paper/Remaining-Useful-Life-Prediction-Using-a-Novel-Liu-Liu/dc889d3f6d199ae67576a209c6ab0188abbd3e27",
            "/paper/Remaining-useful-life-prediction-using-multi-scale-Li-Zhao/bbb916e452fa9e5b0b8cf09cbdc27a93f9396e98",
            "/paper/A-Novel-Cap-LSTM-Model-for-Remaining-Useful-Life-Zhao-Huang/689b224a812ba4f9558a074d4dd2974267e4d10b",
            "/paper/Machine-Remaining-Useful-Life-Prediction-via-an-Chen-Wu/64aff4bac4dd205861488adade6c651085ce6b32",
            "/paper/Bi-LSTM-Based-Two-Stream-Network-for-Machine-Useful-Jin-Chen/e751128df94f367eea17933e9dbe218f3ef1f724",
            "/paper/Remaining-useful-life-estimation-via-transformer-by-Mo-Wu/cbb364f549debb914767c047104bb0c303e9f337",
            "/paper/A-BiGRU-Autoencoder-Remaining-Useful-Life-Scheme-Duan-Li/029bb71bc00c34870cd6cae950e41e507fe7ff45",
            "/paper/Joint-Learning-of-Degradation-Assessment-and-RUL-Miao-Li/cdaa75b42c4c232b73e2decabda9f5bd74286937",
            "/paper/Deep-Convolutional-Neural-Network-Based-Regression-Babu-Zhao/52b7cb1705f0815c3e66b785b3a4432b1af6d47a"
        ]
    },
    {
        "id": "a10d6877c90de39c42a143af60c0bf5e588be763",
        "title": "Deep Visual Analogy-Making",
        "abstract": "A novel deep network trained end-to-end to perform visual analogy making, which is the task of transforming a query image according to an example pair of related images, is developed. In addition to identifying the content within a single image, relating images and generating related images are critical tasks for image understanding. Recently, deep convolutional networks have yielded breakthroughs in predicting image labels, annotations and captions, but have only just begun to be used for generating high-quality images. In this paper we develop a novel deep network trained end-to-end to perform visual analogy making, which is the task of transforming a query image according to an example pair of related images. Solving this problem requires both accurately recognizing a visual relationship and generating a transformed query image accordingly. Inspired by recent advances in language modeling, we propose to solve visual analogies by learning to map images to a neural embedding in which analogical reasoning is simple, such as by vector subtraction and addition. In experiments, our model effectively models visual analogies on several datasets: 2D shapes, animated video game sprites, and 3D car models.",
        "publication_year": "2015",
        "authors": [
            "Scott E. Reed",
            "Yi Zhang",
            "Y. Zhang",
            "Honglak Lee"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "271",
        "reference_count": "30",
        "references": [
            "/paper/Visual-attribute-transfer-through-deep-image-Liao-Yao/4923c6bc3ab501651763f6814a8384745f3d9a4d",
            "/paper/Visual-Prompting-via-Image-Inpainting-Bar-Gandelsman/0a25c137edc7c9752aa6d99ae4084683c3fe6b56",
            "/paper/Learning-to-detect-visual-relations-Peyre/caffa07ead18aae78bf654bc57023eef58e74faf",
            "/paper/Semantic-Image-Analogy-with-a-Conditional-GAN-Li-Xiong/b5dd2ec1bbbf9732ea52a34d6e18e368f622479b",
            "/paper/Visual-Dynamics%3A-Probabilistic-Future-Frame-via-Xue-Wu/397e9b56e46d3cc34af1525493e597facb104570",
            "/paper/Neural-Photometry-Guided-Visual-Attribute-Transfer-Rodriguez-Pardo-Garces/f8de84ef31bb4b5fa467df234fab902e647d4726",
            "/paper/From-A-to-Z%3A-Supervised-Transfer-of-Style-and-Using-Upchurch-Snavely/6dd9da05e28e38976cc7aef8fa155455b211cf69",
            "/paper/Detecting-Unseen-Visual-Relations-Using-Analogies-Peyre-Sivic/b2dbe0d7f769410a26e2488b31b9fe6a34c5626a",
            "/paper/Leveraging-structure-in-Computer-Vision-tasks-for-Royer/5924bfeb91ff47e5f01d7307ccae3869834db79d",
            "/paper/VASR%3A-Visual-Analogies-of-Situation-Recognition-Bitton-Yosef/b48eb1a32dcc4dcd122a5234c0fc055b71752e98",
            "/paper/Analogy-preserving-Semantic-Embedding-for-Visual-Hwang-Grauman/aa425336f0fb396965d8abd757f87f80677c4034",
            "/paper/Deep-Convolutional-Inverse-Graphics-Network-Kulkarni-Whitney/687e80eb70c7bbad6001006d9269b202650a3354",
            "/paper/Learning-to-Represent-Spatial-Transformations-with-Memisevic-Hinton/0eb2e4a205a628ab059cab41d3b772f614ad29f2",
            "/paper/Weakly-supervised-Disentangling-with-Recurrent-for-Yang-Reed/3411535f7888a943853895e8eef2bb0b6d328c2a",
            "/paper/Image-analogies-Hertzmann-Jacobs/923562d216386a88947d40da310d94bbb1376a41",
            "/paper/%22Mental-Rotation%22-by-Optimizing-Transforming-Ding-Taylor/3203d306c230c584e29cdf0aab0bb1ac947f1c15",
            "/paper/Caffe%3A-Convolutional-Architecture-for-Fast-Feature-Jia-Shelhamer/6bdb186ec4726e00a8051119636d4df3b94043b5",
            "/paper/Modeling-the-joint-density-of-two-images-under-a-of-Susskind-Hinton/6c036729284a73075d4f9b2ce7b87cd05fe2bbba",
            "/paper/Transformation-Properties-of-Learned-Visual-Cohen-Welling/1420e02a8cf5d8c4ee0a966086aefa51a1c637c1",
            "/paper/Learning-to-generate-chairs-with-convolutional-Dosovitskiy-Springenberg/b437b5a0445f17b06b12791bc48aeb8110e95dc5"
        ]
    },
    {
        "id": "30c9e588b8d41fdf28b043417440a62875f80b49",
        "title": "Benchmarking integration of single-cell differential expression",
        "abstract": "It is found that for low depth data, single-cell techniques based on zero-inflation model deteriorate the performance, whereas the analysis of uncorrected data using limmatrend, Wilcoxon test and fixed effects model performs well. Integration of single-cell RNA sequencing data between different samples has been a major challenge for analyzing cell populations. Here the authors benchmark 46 workflows for differential expression analysis of single-cell data with multiple batches and suggest several high-performance methods under different conditions based on simulation and real data analyses. Integration of single-cell RNA sequencing data between different samples has been a major challenge for analyzing cell populations. However, strategies to integrate differential expression analysis of single-cell data remain underinvestigated. Here, we benchmark 46 workflows for differential expression analysis of single-cell data with multiple batches. We show that batch effects, sequencing depth and data sparsity substantially impact their performances. Notably, we find that the use of batch-corrected data rarely improves the analysis for sparse data, whereas batch covariate modeling improves the analysis for substantial batch effects. We show that for low depth data, single-cell techniques based on zero-inflation model deteriorate the performance, whereas the analysis of uncorrected data using limmatrend, Wilcoxon test and fixed effects model performs well. We suggest several high-performance methods under different conditions based on various simulation and real data analyses. Additionally, we demonstrate that differential expression analysis for a specific cell type outperforms that of large-scale bulk sample data in prioritizing disease-related genes.",
        "publication_year": "2023",
        "authors": [
            "Hai-Chau Nguyen",
            "Bukyung Baik",
            "Sora Yoon",
            "Taesung Park",
            "D. Nam"
        ],
        "related_topics": [
            "Biology",
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "60",
        "references": [
            "/paper/A-benchmark-of-batch-effect-correction-methods-for-Tran-Ang/d5baf1912d43d0af0e8f683eb5532f5f5445430e",
            "/paper/Benchmarking-atlas-level-data-integration-in-Luecken-B%C3%BCttner/2ae47c27b0d6bc2a52b69359f3f7810fb371ffa0",
            "/paper/Bias%2C-robustness-and-scalability-in-single-cell-Soneson-Robinson/ba0452a487f67e7c233967f4c5b56d1c786631b0",
            "/paper/Robust-integration-of-multiple-single-cell-RNA-a-Liu-Wang/6138553d7919172ac500d4ce24ec50b1a0ba812b",
            "/paper/Batch-effects-in-single-cell-RNA-sequencing-data-by-Haghverdi-Lun/56bf103a956b4a2ad11868c05db189d1e3f64ac1",
            "/paper/Data-exploration%2C-quality-control-and-testing-in-McDavid-Finak/9c2fc4e9eb3ed915dddb04e7d1dbdfca11b030e7",
            "/paper/Normalization-and-variance-stabilization-of-RNA-seq-Hafemeister-Satija/6ecf1dfa2688d949a309e2cc336ddd929a69b12b",
            "/paper/Comprehensive-Integration-of-Single-Cell-Data-Stuart-Butler/2287a3930a7568a956aae5f3f037efe8fed675e7",
            "/paper/Deep-Generative-Modeling-for-Single-cell-Lopez-Regier/ed5d6be2eb8fc1d42f9a0e3c50abaf5439bbd8dd",
            "/paper/Differential-expression-analysis-of-multifactor-to-McCarthy-Chen/571c3ea8cabd16ab0ae7a1a3495d3f3aca918e23"
        ]
    },
    {
        "id": "0f1eb8d363609dc3c0f7a8f78e9b6b50529b45fd",
        "title": "Improved multiband structured subband adaptive filter algorithm with L0-norm regularization for sparse system identification",
        "abstract": "Semantic Scholar extracted view of \"Improved multiband structured subband adaptive filter algorithm with L0-norm regularization for sparse system identification\" by Esmail Heydari et al.",
        "publication_year": "2021",
        "authors": [
            "Esmail Heydari",
            "M. Abadi",
            "Seyed Mahmoud Khademiyan"
        ],
        "related_topics": [
            "Engineering"
        ],
        "citation_count": "6",
        "reference_count": "25",
        "references": [
            "/paper/L0-norm-constraint-normalized-subband-adaptive-and-Liu-Zhao/9e31ceae5ada558541d1995e3f06d0166f79e37b",
            "/paper/Output-Layer-Structure-Optimization-for-Weighted-on-Yang-Wang/8e9e78bd9892c545f3e7a4a38fc24c67165f25da",
            "/paper/A-family-of-variable-step-size-sparsity-aware-SSAF-Liu-Zhao/db1c634a9b3eaf628cbfde78b70794dcc37178c3",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/50b98cc888fd59742d535f8c20f7975322dbe7d3",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/cf2395b281802968efce09a560ff52dd2007d913",
            "/paper/Study-of-L0-norm-constraint-normalized-subband-Liu-Zhao/7fff09b192d98b27e39a34aed9c6130c7c840da9",
            "/paper/Proximal-Normalized-Subband-Adaptive-Filtering-for-Guo-Yu/3a222306e77c7a4660b88df73f563123bcbe8ee0",
            "/paper/Sparsity-aware-SSAF-algorithm-with-individual-and-Yu-Yang/7b2ab099ec4b6e07ec330c352387337ec48af6e4",
            "/paper/Sparsity-aware-normalized-subband-adaptive-filters-Ji-Ni/aae369697b10bd7eb2e9c21a8c1911a4359707f0",
            "/paper/Diffusion-Improved-Multiband-Structured-Subband-of-Abadi-Ahmadi/e77720d72cff8e9613cc237221d506fd00ffd141",
            "/paper/Augmented-complex-valued-normalized-subband-filter%3A-Wen-Zhang/4bd43d99d7cbf26495a26f8797d842bb734df33a",
            "/paper/Weighted-Improved-Multiband-Structured-Sub-Band-Abadi-Ahmadi/e0de0bed782b1eb8cd061c947538d8472753d864",
            "/paper/Sparsity-aware-subband-adaptive-algorithms-with-Yu-Zhao/ebd0abdcae4d0580aa2ae4de7905e59349b9071a",
            "/paper/Two-improved-multiband-structured-subband-adaptive-Abadi-Hus%C3%B8y/cf064bc383a7a4030a4a2f3138205cccb0fc913d",
            "/paper/The-wavelet-transform-domain-LMS-adaptive-filter-of-Abadi-Mesgarani/a712a368b53c5a4b437e9fffd79a8f3deb832a35",
            "/paper/Sparse-normalized-subband-adaptive-filter-algorithm-Yu-Zhao/a8802905bf00aa79a578e9ebbffc7e4f162e93ef"
        ]
    },
    {
        "id": "770c840fe25e4c09405529c639f1fcf0a1b245ea",
        "title": "Attention-based residual autoencoder for video anomaly detection",
        "abstract": "The present system adopts a spatial branch and a temporal branch in a unified network that exploits both spatial and temporal information effectively, and suggests that the network outperforms the state-of-the-art methods. Automatic anomaly detection is a crucial task in video surveillance system intensively used for public safety and others. The present system adopts a spatial branch and a temporal branch in a unified network that exploits both spatial and temporal information effectively. The network has a residual autoencoder architecture, consisting of a deep convolutional neural network-based encoder and a multi-stage channel attention-based decoder, trained in an unsupervised manner. The temporal shift method is used for exploiting the temporal feature, whereas the contextual dependency is extracted by channel attention modules. System performance is evaluated using three standard benchmark datasets. Result suggests that our network outperforms the state-of-the-art methods, achieving 97.4% for UCSD Ped2, 86.7% for CUHK Avenue, and 73.6% for ShanghaiTech dataset in term of Area Under Curve, respectively.",
        "publication_year": "2022",
        "authors": [
            "Viet-Tuan Le",
            "Yong-Guk Kim"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "16",
        "reference_count": "39",
        "references": [
            "/paper/Dual-branch-network-with-memory-for-video-anomaly-Wang-Hu/01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
            "/paper/Video-anomaly-detection-with-memory-guided-Zhou-Yang/f3afe15c5975b38b3e9b7dd9c9333688fe24d055",
            "/paper/Improved-Video-Anomaly-Detection-with-Dual-and-Qi-Hu/409eecbca7febe13ab7dc77cdd7f86d66cf9181a",
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/Deep-Learning-Based-Anomaly-Detection-in-Video-A-Duong-Le/2d26033ada57a73f7c8135195bdaaef2573c6917",
            "/paper/Anomaly-Detection-by-Predicting-Future-Frames-using-Patrikar-Parate/a66b466fbea9cc11324b270395f79c7d817e4102",
            "/paper/An-Analysis-of-Artificial-Intelligence-Techniques-A-%C5%9Eeng%C3%B6n%C3%BCl-Samet/54a9bcf3edf88bbbb24159b09cfc5957cc7ae623",
            "/paper/Point-Cloud-Video-Anomaly-Detection-Based-on-Point-He-Wang/31b8ea745f2f6b2c8b2fe3d6e6377aa1318e48ff",
            "/paper/Generalized-Video-Anomaly-Event-Detection%3A-Taxonomy-Liu-Yang/bb51ca71833d42fa58f9adccb2296bdf665cc158",
            "/paper/Computer-Vision-Applications-in-Intelligent-A-Dilek-Dener/c988c6631df77482313dac577e3b02d8b696d85d",
            "/paper/Detecting-Video-Anomaly-with-a-Stacked-LSTM-Wei-Li/cc0571b3f95f37c669f6e04fa145b7bfed10f037",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/Residual-spatiotemporal-autoencoder-for-video-Deepak-Chandrakala/f750730710e0fd9632f86626ad554eb430fada77",
            "/paper/Spatio-Temporal-Unity-Networking-for-Video-Anomaly-Li-Cai/1be10a34f619e203651036d2609fc0d9780525c5",
            "/paper/Spatial-Temporal-Cascade-Autoencoder-for-Video-in-Li-Chang/a2812bce010a0548688cd344330fe39a2f4d7381",
            "/paper/Future-Frame-Prediction-Using-Convolutional-VRNN-Lu-MaheshKumar/16e1bdb834340b0fd7a5737dfb87abda373f72ca",
            "/paper/Video-anomaly-detection-and-localization-via-fully-Li-Chang/6c551fa9bdfb3c1e285bc9fa69e4c89a736af3e7",
            "/paper/Multi-Encoder-Towards-Effective-Anomaly-Detection-Fang-Zhou/b8b401cec9f6ea099e6d8705099c9400b9353545",
            "/paper/Spatiotemporal-Anomaly-Detection-Using-Deep-for-Nawaratne-Alahakoon/3a16085d520502077558e90c0d7228fb718c8488",
            "/paper/Video-Anomaly-Detection-and-Localization-via-Fully-Fan-Wen/d880d303ee0bfdbc80fc34df0978088cd15ce861"
        ]
    },
    {
        "id": "cab837cb314a0523c1b8224f67bcde977f1b59be",
        "title": "Are exercises with or without occlusal splints more effective in the reduction of pain in patients with temporomandibular disorders of myogenic origin? A systematic review",
        "abstract": "A systematic review of controlled trials to determine if exercises with or without occlusal splints are effective in reducing pain in patients with temporomandibular disorders (TMD) of myogenic origin showed no difference in the improvement of pain, quality of life, and mandibular movements between the groups that performed only exercises or the associated treatments. Abstract Temporomandibular disorders (TMD) is a term used to describe a set of clinical conditions that may compromise the temporomandibular joint (TMJ) and masticatory muscles and/or associated structures, considered the most frequent cause of orofacial pain of non-dental origin. In recent years, many forms of physical therapy have been used in the treatment of TMD to reduce pain and improve the range of mandibular movement present in this impairment. Among these resources are kinesiotherapy (exercise), electrothermal and manual therapy, acupuncture, training posture, mobilizations, and biofeedback. Objectives To determine if exercises with or without occlusal splints are effective in reducing pain in patients with temporomandibular disorders (TMD) of myogenic origin. Methodology This systematic review was registered in the International Prospective Register of Systematic Reviews (CRD 42019134244). Controlled trials published in PubMed, Scopus, and Cochrane Library following PRISMA guidelines up to April 2022 were randomized and included. The population above 18 years, which evaluated the effectiveness of exercise with or without occlusal splints in reducing pain in patients with TMD of myogenic origin, diagnosed through the Research Diagnostic Criteria for Temporomandibular Disorders, was also included. There was no restriction on the period of publication. Cochrane risk of bias analysis was performed. Results Of the five included articles, all showed a reduction of pain, but without significant differences between the interventions performed. Additionally, studies that evaluated the quality of life and mandibular movements showed a reduction in pain, but no significant differences between therapies. Conclusion The analyzed studies showed no difference in the improvement of pain, quality of life, and mandibular movements between the groups that performed only exercises or the associated treatments.",
        "publication_year": "2023",
        "authors": [
            "Jessica Fernanda de Oliveira Lima Batista",
            "T. Vila-Nova",
            "S. Moraes",
            "E. Pellizzer",
            "B. Vasconcelos",
            "J. M. L. Gomes",
            "C. Lemos",
            "M. Heimer"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": 0,
        "reference_count": "35",
        "references": [
            "/paper/Are-occlusal-splints-effective-in-reducing-pain-in-Deregibus-Ferrillo/248461bad5d66f4d202ecbeb3e5cf9443a3d3b32",
            "/paper/Evaluation-of-the-effects-of-occlusal-splint%2C-point-Bilici-Emes/68d66179b0e0d221524684c3307acd4b981efab8",
            "/paper/Behavioural-changes-and-occlusal-splints-are-in-the-Conti-Alencar/6da4b98fe4825111425fc8cd9528e61aa6e8087a",
            "/paper/Efficacy-of-Appliance-Therapy-on-Temporomandibular-Katyayan-Katyayan/84f9051933c480b0b7a53adc7271d368d3ff078c",
            "/paper/Towards-an-optimal-therapy-strategy-for-myogenous-Grootel-Buchner/0d6bff5689759d14a8b236a10df0b49be882989f",
            "/paper/Occlusal-appliance-therapy-in-a-short-term-in-with-Ekberg-Sabet/81de3d63846d359057b6f54575e62d5b6e30dcfd",
            "/paper/Effects-of-massage-therapy-and-occlusal-splint-on-a-Gomes-Politti/a360ba00c38b341320f7504ce64590d021f55634",
            "/paper/The-hierarchy-of-different-treatments-for-myogenous-Al-Moraissi-Conti/48109a656fc51824ebedadc175f7bc303d674540",
            "/paper/Evaluation-of-articular-disc-loading-in-the-joints-Pihut-Margielewicz/d3014fcc0fc1a4fc8021e1beec80cfce90148faf",
            "/paper/Comparison-of-the-Efficacies-of-Dry-Needling-and-in-K%C3%BCt%C3%BCk-%C3%96zkan/aaf737ce00c72af501e6dc117dc176dba4aee231"
        ]
    },
    {
        "id": "7f3ad99786e12be94fa64c9e80570094a0bfe77f",
        "title": "Human resident CD34+ stromal cells/telocytes have progenitor capacity and are a source of \u03b1SMA+ cells during repair.",
        "abstract": "Human resident CD34+ SC/TCs in the enteric wall have progenitor capacity and are activated with or without differentiation into \u03b1SMA+ stromal cells during inflammatory/repair processes. We studied the progenitor capacity of human resident CD34+ stromal cells/telocytes (SC/TCs) in the enteric wall affected by inflammatory/repair processes (appendicitis, diverticulitis of large bowel and Crohn's disease of the terminal ileum) at different stages of evolution (inflammatory, proliferative and remodelling). In these conditions, CD34+ SC/TCs are activated, showing changes, which include the following overlapping events: 1) separation from adjacent structures (e.g., from vascular walls) and location in oedematous spaces, 2) morphological modifications (in cell shape and size) with presence of transitional cell forms between quiescent and activated CD34+ SC/TCs, 3) rapid proliferation and 4) loss of CD34 expression and gain of \u03b1SMA expression. These events mainly occur in the inflammatory and proliferative stages. During the loss of CD34 expression, the following findings are observed: a) irregular cell labelling intensity for anti-CD34, b) co-localization of CD34 and actin, c) concurrent irregular labelling intensity for \u03b1SMA and d) \u03b1SMA expression in all stromal cells, with total loss of CD34 expression. While CD34 expression was conserved, a high proliferative capacity (Ki-67 expression) was observed and vice versa. In the segments of the ileum affected by Crohn's disease, the stromal cells around fissures were \u03b1SMA+ and, in the transitional zones with normal enteric wall, activated CD34+ SC/TCs were observed. In conclusion, human resident CD34+ SC/TCs in the enteric wall have progenitor capacity and are activated with or without differentiation into \u03b1SMA+ stromal cells during inflammatory/repair processes.",
        "publication_year": "2015",
        "authors": [
            "L. D\u00edaz-Flores",
            "R. Guti\u00e9rrez",
            "M. P. Garc\u00eda",
            "M. Gonzalez",
            "F. S\u00e1ez",
            "F. Aparicio",
            "L. D\u00edaz-Flores",
            "J. Madrid"
        ],
        "related_topics": [
            "Biology",
            "Medicine"
        ],
        "citation_count": "70",
        "reference_count": "71",
        "references": [
            "/paper/Telocyte-Behaviour-During-Inflammation%2C-Repair-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/319b52c4d3af7e6d19a6b646316655e279946491",
            "/paper/Presence-Absence-and-Specific-Location-of-Resident-D%C3%ADaz-Flores-Guti%C3%A9rrez/2dea372c9f048d5a5c4ca3fd7841e1b0ac0aa091",
            "/paper/Behaviour-of-telocytes-during-physiopathological-D%C3%ADaz-Flores-Guti%C3%A9rrez/40fb968dfe2ffb25dfbe05cbacb9b343123a71bd",
            "/paper/CD34%2B-Stromal-Cells-Telocytes-as-a-Source-of-(CAFs)-D%C3%ADaz-Flores-Guti%C3%A9rrez/e0ed3fd8f7e7b9d8697444f8a6402c4cf235f34d",
            "/paper/Impairment-in-the-telocyte-CD34%2B-stromal-cell-in-Rosa-Faussone%E2%80%90Pellegrini/a33204154ea93df70229157435dfde8b8067dd86",
            "/paper/Delimiting-CD34%2B-Stromal-Cells-Telocytes-Are-Cells-D%C3%ADaz-Flores-Guti%C3%A9rrez/fe7efbe95e45dc15393d488ec7f8755ab8686a45",
            "/paper/Changes-in-the-telocyte-CD34%2B-stromal-cell-and-cell-Marini-Ibba%E2%80%90Manneschi/ef48b245014922a2927c1da8546b50640d4b1b25",
            "/paper/Telocytes-of-the-mammary-gland-stroma.-Petre-Rusu/3d6ae8370d8cc3614e4592ba262392532b2e4717",
            "/paper/The-telopode-and-filopode-projecting-heterogeneous-Petrea-Cr%C4%83i%C5%A3oiu/0b7c01b1814949b7f6f7044bee3b4e84b29a4917",
            "/paper/Molecular-phenotypes-of-the-human-kidney%3A-Myoid-and-Rusu-Mogoant%C4%83/b7e342288904fb2fe6ae00bc74788e1872019d78",
            "/paper/Behavior-of-In-Situ-Human-Native-Adipose-Tissue-of-D%C3%ADaz-Flores-Guti%C3%A9rrez/fcde018a3c96d0b302eb7df9e000492243935a13",
            "/paper/Functional-implications-of-CD34-expression-in-human-Suga-Matsumoto/0f5e498cdc29a3845d6f23e58d1f8a430c399821",
            "/paper/CD34%2B-stromal-cells-fibroblasts-fibrocytes-as-a-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/c387d88c70801cd94f51b05cf44dd0d9042a2ee4",
            "/paper/Preadipocytes-in-the-human-subcutaneous-adipose-the-Sengen%C3%A8s-Lolm%C3%A8de/467e345f64049246843059f6a3867ceca2268b3f",
            "/paper/Telocytes-express-PDGFR%CE%B1-in-the-human-tract-Vannucchi-Traini/dfb53c1ac293ac3468fe151380f17125cacda31a",
            "/paper/Is-CD34-truly-a-negative-marker-for-mesenchymal-Lin-Ning/796ac799dccb041ffa6077ffbb062ba36b841b01",
            "/paper/CD34-positive-stromal-cells-in-gastric-Nakayama-Enzan/67acaf3aa6672a43ea3e7f5540f8e39264db3f7a",
            "/paper/Peripheral-Blood-Fibrocytes%3A-Differentiation-and-to-Abe-Donnelly/010c196a3cd1a3486eb5ce6ec2df2e4c7d4f649f",
            "/paper/Telocytes-in-Crohn%E2%80%99s-disease-Milia-Ruffo/ae107458587d9093e0951e9ef0795db15d481bae",
            "/paper/Concise-Review%3A-Evidence-for-CD34-as-a-Common-for-Sidney-Branch/6cb50d864135d20ea42f2306660e8f03c5285f09"
        ]
    },
    {
        "id": "9792bc635e7896642895d75aaf394f637ea29eac",
        "title": "A Comprehensive Analysis of Deep Learning-Based Approaches for Prediction and Prognosis of Infectious Diseases",
        "abstract": "The models have been evaluated on the basis of various parameters, and it has been discovered that during the testing phase, the InceptionResNetV2 model generated the highest accuracy of 88%, best loss value of 0.399, and root mean square error of 063. Artificial intelligence is the most powerful and promising tool for the present analytic technologies. It can provide real-time insights into disease spread and predict new pandemic epicenters by processing massive amount of data. The main aim of the paper is to detect and classify multiple infectious diseases using deep learning models. The work is conducted by using 29,252 images of COVID-19, Middle East Respiratory Syndrome Coronavirus, Pneumonia, normal, Severe Acute Respiratory Syndrome, tuberculosis, viral pneumonia, and lung opacity which has been collected from various disease datasets. These datasets are used to train the deep learning models such as EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, NASNetLarge, DenseNet169, ResNet152V2, and InceptionResNetV2. The images have been initially graphically represented using exploratory data analysis to study the pixel intensity and find anomalies by extracting the color channels in an RGB histogram. Later, the dataset has been pre-processed to remove noisy signals using image augmentation and contrast enhancement techniques. Further, feature extraction techniques such as morphological values of contour features and Otsu thresholding have been applied to extract the feature. The models have been evaluated on the basis of various parameters, and it has been discovered that during the testing phase, the InceptionResNetV2 model generated the highest accuracy of 88%, best loss value of 0.399, and root mean square error of 0.63.",
        "publication_year": "2023",
        "authors": [
            "K. Thakur",
            "M. Kaur",
            "Yogesh Kumar"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "54",
        "references": [
            "/paper/Deep-transfer-learning-techniques-with-hybrid-in-of-Bansal-Bathla/1fafff85108fc64f9fd3956ae2606992d81169de",
            "/paper/Transfer-Learning-to-Detect-COVID-19-Automatically-Taresh-Zhu/8efefb1f16bd01d6b41df74511c10117afe5258c",
            "/paper/Reliable-Tuberculosis-Detection-Using-Chest-X-Ray-Rahman-Khandakar/b00de2e18011659a26ffcc51c8e5f24d76efa8dd",
            "/paper/Deep-chest%3A-Multi-classification-deep-learning-for-Ibrahim-Elshennawy/13cfe1d5a4e89612f239568d75133717196d996d",
            "/paper/Cancer-Prognosis-Using-Artificial-Techniques-Gupta-Kumar/602fa606683b65ea3ddc5a992a62c6060e4aa9ff",
            "/paper/A-Systematic-Review-of-Artificial-Intelligence-in-Kumar-Gupta/248a51ea477d2635b5d87b1b25f46c91425821e1",
            "/paper/Image-Enhancement-for-Tuberculosis-Detection-Using-Munadi-Muchtar/5a1cce0bb153c54e13707ee613d885bbfbb2bcd5",
            "/paper/Deep-learning-Based-Approach-to-Identify-Covid-19-Feng-He/2be1006604c0ad08097821a38b050bab8e2dbae6",
            "/paper/A-Review-of-Deep-Learning-Based-Approaches-for-and-Kumar-Kumar/0368dd7538b7245aca5133baff6bea4df228d152",
            "/paper/An-Investigational-Approach-for-the-Prediction-of-A-Bhardwaj-Bhandari/5f9c44deffb3151ccdfc2eac1f99222fbb10abe9"
        ]
    },
    {
        "id": "0b444f74dd9cc06c2833dd15f9258ef5e169e6ea",
        "title": "UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation",
        "abstract": "A novel UNet 3+ is proposed, which takes advantage of full-scale skip connections and deep supervisions, and can reduce the network parameters to improve the computation efficiency. Recently, a growing interest has been seen in deep learning-based semantic segmentation. UNet, which is one of deep learning networks with an encoder-decoder architecture, is widely used in medical image segmentation. Combining multi-scale features is one of important factors for accurate segmentation. UNet++ was developed as a modified Unet by designing an architecture with nested and dense skip connections. However, it does not explore sufficient information from full scales and there is still a large room for improvement. In this paper, we propose a novel UNet 3+, which takes advantage of full-scale skip connections and deep supervisions. The full-scale skip connections incorporate low-level details with high-level semantics from feature maps in different scales; while the deep supervision learns hierarchical representations from the full-scale aggregated feature maps. The proposed method is especially benefiting for organs that appear at varying scales. In addition to accuracy improvements, the proposed UNet 3+ can reduce the network parameters to improve the computation efficiency. We further propose a hybrid loss function and devise a classification-guided module to enhance the organ boundary and reduce the over-segmentation in a non-organ image, yielding more accurate segmentation results. The effectiveness of the proposed method is demonstrated on two datasets. The code is available at: github.com/ZJUGiveLab/UNet-Version",
        "publication_year": "2020",
        "authors": [
            "Huimin Huang",
            "Lanfen Lin",
            "Ruofeng Tong",
            "Hongjie Hu",
            "Qiaowei Zhang",
            "Y. Iwamoto",
            "Xianhua Han",
            "Yenwei Chen",
            "Jian Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "606",
        "reference_count": "12",
        "references": [
            "/paper/MDA-Unet%3A-A-Multi-Scale-Dilated-Attention-U-Net-for-Amer-Lambrou/057159cbdca99b6ad047cd63f8c53904eb07e8ca",
            "/paper/TMD-Unet%3A-Triple-Unet-with-Multi-Scale-Input-and-Tran-Cheng/7f575a0661bf6396cdbb92db763ffcd566142d87",
            "/paper/N-Net%3A-an-UNet-architecture-with-dual-encoder-for-Liang-Tang/97dd42c101a3d3b77924a58a6fea1968f905c029",
            "/paper/UNet%23%3A-A-UNet-like-Redesigning-Skip-Connections-for-Qian-Zhou/86a25de9047a686099cb8e68c3b0abc8527baea8",
            "/paper/A-Medical-Image-Segmentation-Method-Based-on-UNet-Xu-Hou/67444a4a2f351cc92fb06af6bcc36078ae835ffe",
            "/paper/CA%E2%80%90Unet%2B%2B%3A-An-improved-structure-for-medical-CT-on-Li-Wu/f2a7803df0382897a91413f34ac17c4601bb1263",
            "/paper/UNeXt%3A-MLP-based-Rapid-Medical-Image-Segmentation-Valanarasu-Patel/ccb5a70f8a6f7b7fc923b9d4c18488b2837daa6f",
            "/paper/MSRD-Unet%3A-Multiscale-Residual-Dilated-U-Net-for-Khalaf-Dhannoon/89f3bf3de592a7a22673c23fb7cdac041846c75f",
            "/paper/Swin-Unet%3A-Unet-like-Pure-Transformer-for-Medical-Cao-Wang/ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "/paper/AFTer-UNet%3A-Axial-Fusion-Transformer-UNet-for-Image-Yan-Tang/7b4125cced6db9b14af663de1c593416f314e0da",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/DeepLab%3A-Semantic-Image-Segmentation-with-Deep-and-Chen-Papandreou/cab372bc3824780cce20d9dd1c22d4df39ed081a",
            "/paper/Attention-U-Net%3A-Learning-Where-to-Look-for-the-Oktay-Schlemper/ae1c89817a3a239e5344293138bdd80293983460",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/Rethinking-Atrous-Convolution-for-Semantic-Image-Chen-Papandreou/ee4a012a4b12d11d7ab8c0e79c61e807927a163c",
            "/paper/Focal-Loss-for-Dense-Object-Detection-Lin-Goyal/72564a69bf339ff1d16a639c86a764db2321caab",
            "/paper/DeepRoadMapper%3A-Extracting-Road-Topology-from-M%C3%A1ttyus-Luo/11d4bac69cf940cb13c2cac9a5b1e3af64960fce",
            "/paper/Pyramid-Scene-Parsing-Network-Zhao-Shi/1031a69923b80ad01cf3fbb703d10757a80e699b",
            "/paper/Multiscale-structural-similarity-for-image-quality-Wang-Simoncelli/554cb0e8a604701ca78f2d782f2a26119eadaa81"
        ]
    },
    {
        "id": "0cd526723b87ae37981922992992d203448a2014",
        "title": "DilateFormer: Multi-Scale Dilated Transformer for Visual Recognition",
        "abstract": "This work analyzes the patch interaction of global attention in ViTs and proposes Multi-Scale Dilated Attention (MSDA) to model local and sparse patch interaction within the sliding window, indicating the redundancy of global dependency modeling in shallow layers of ViTs. As a de facto solution, the vanilla Vision Transformers (ViTs) are encouraged to model long-range dependencies between arbitrary image patches while the global attended receptive field leads to quadratic computational cost. Another branch of Vision Transformers exploits local attention inspired by CNNs, which only models the interactions between patches in small neighborhoods. Although such a solution reduces the computational cost, it naturally suffers from small attended receptive fields, which may limit the performance. In this work, we explore effective Vision Transformers to pursue a preferable trade-off between the computational complexity and size of the attended receptive field. By analyzing the patch interaction of global attention in ViTs, we observe two key properties in the shallow layers, namely locality and sparsity, indicating the redundancy of global dependency modeling in shallow layers of ViTs. Accordingly, we propose Multi-Scale Dilated Attention (MSDA) to model local and sparse patch interaction within the sliding window. With a pyramid architecture, we construct a Multi-Scale Dilated Transformer (DilateFormer) by stacking MSDA blocks at low-level stages and global multi-head self-attention blocks at high-level stages. Our experiment results show that our DilateFormer achieves state-of-the-art performance on various vision tasks. On ImageNet-1K classification task, DilateFormer achieves comparable performance with 70% fewer FLOPs compared with existing state-of-the-art models. Our DilateFormer-Base achieves 85.6% top-1 accuracy on ImageNet-1K classification task, 53.5% box mAP/46.1% mask mAP on COCO object detection/instance segmentation task and 51.1% MS mIoU on ADE20K semantic segmentation task.",
        "publication_year": "2023",
        "authors": [
            "Jiayu Jiao",
            "Yuyao Tang",
            "Kun-Li Channing Lin",
            "Yipeng Gao",
            "Jinhua Ma",
            "Yaowei Wang",
            "Wei-Shi Zheng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "106",
        "references": [
            "/paper/Life-Regression-based-Patch-Slimming-for-Vision-Chen-Chen/6e22b09ce6a67377a2463c271f94295edf69f886",
            "/paper/EGformer%3A-Equirectangular-Geometry-biased-for-360-Yun-Shin/c0417c57bc38a031faaf2951e38e1127b4879291",
            "/paper/UniFormer%3A-Unifying-Convolution-and-Self-attention-Li-Wang/f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1",
            "/paper/CrossViT%3A-Cross-Attention-Multi-Scale-Vision-for-Chen-Fan/0eff37167876356da2163b2e396df2719adf7de9",
            "/paper/ViTAE%3A-Vision-Transformer-Advanced-by-Exploring-Xu-Zhang/576c462dbc1f3d732b919ef1daac37a817123e52",
            "/paper/Shunted-Self-Attention-via-Multi-Scale-Token-Ren-Zhou/e0e6ae2ef8ef9f02e0c65ada61eadd82b7ce8a9c",
            "/paper/MaxViT%3A-Multi-Axis-Vision-Transformer-Tu-Talebi/2ad12a7be5eaf339a98c4defd8669e11fe726acc",
            "/paper/CrossFormer%3A-A-Versatile-Vision-Transformer-Based-Wang-Yao/9f7f81b1c82828a45a52df8f0c6a92636af76c7e",
            "/paper/Dilated-Neighborhood-Attention-Transformer-Hassani-Shi/a883336e5c2e9f46f5012343227a6be4671c9ca0",
            "/paper/Focal-Self-attention-for-Local-Global-Interactions-Yang-Li/48418b285a92376a38daafa664a2dd07d42e3fe3",
            "/paper/MPViT%3A-Multi-Path-Vision-Transformer-for-Dense-Lee-Kim/15b0e710a9b8069d898ae6a0963d627e0fb86bd8",
            "/paper/Vision-Transformer-with-Progressive-Sampling-Yue-Sun/c945efdeefaacb8ca679298720f4b0b054dc84bd"
        ]
    },
    {
        "id": "d3d784b07fd4a444d11ac753e36964767214d667",
        "title": "SimulSLT: End-to-End Simultaneous Sign Language Translation",
        "abstract": "SimulSLT, the first end-to-end simultaneous sign language translation model, which can translate sign language videos into target text concurrently, is proposed, composed of a text decoder, a boundary predictor, and a masked encoder. Sign language translation as a kind of technology with profound social significance has attracted growing researchers' interest in recent years. However, the existing sign language translation methods need to read all the videos before starting the translation, which leads to a high inference latency and also limits their application in real-life scenarios. To solve this problem, we propose SimulSLT, the first end-to-end simultaneous sign language translation model, which can translate sign language videos into target text concurrently. SimulSLT is composed of a text decoder, a boundary predictor, and a masked encoder. We 1) use the wait-k strategy for simultaneous translation. 2) design a novel boundary predictor based on the integrate-and-fire module to output the gloss boundary, which is used to model the correspondence between the sign language video and the gloss. 3) propose an innovative re-encode method to help the model obtain more abundant contextual information, which allows the existing video features to interact fully. The experimental results conducted on the RWTH-PHOENIX-Weather 2014T dataset show that SimulSLT achieves BLEU scores that exceed the latest end-to-end non-simultaneous sign language translation model while maintaining low latency, which proves the effectiveness of our method.",
        "publication_year": "2021",
        "authors": [
            "Aoxiong Yin",
            "Zhou Zhao",
            "Jinglin Liu",
            "Weike Jin",
            "Meng Zhang",
            "Xingshan Zeng",
            "Xiaofei He"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "50",
        "references": [
            "/paper/Locality-Aware-Transformer-for-Video-Based-Sign-Guo-Hou/5e502c618d559ce1e676eea02aff1e797ac3f1ef",
            "/paper/MLSLT%3A-Towards-Multilingual-Sign-Language-Yin-Zhao/458e5d02c0612deae07e5fb241179b52429a81d4",
            "/paper/SignBERT%2B%3A-Hand-model-aware-Self-supervised-for-Hu-Zhao/0fcc797aeed56bcc127476d5b68836dc402021ea",
            "/paper/Machine-Translation-from-Signed-to-Spoken-State-of-Coster-Shterionov/7366fe7b4e7756dd13220d29077142ff802b41b3",
            "/paper/TranSpeech%3A-Speech-to-Speech-Translation-With-Huang-Zhao/08e8f6ad2c7f83ff04c6ef416fbb288976b1a890",
            "/paper/OpenSR%3A-Open-Modality-Speech-Recognition-via-Cheng-Jin/abac1f1f876d2cc332830bdf705ba5e8d7f92313",
            "/paper/A-Survey-of-Advancements-in-Real-Time-Sign-Language-Papatsimouli-Sarigiannidis/c8f5c6426ab2a3db12457756d941a14a09c6deb2",
            "/paper/Towards-Fast-and-High-Quality-Sign-Language-Huang-Pan/481f18278fc707dd7cf8254da1e68b96f6913326",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2",
            "/paper/Contrastive-Disentangled-Meta-Learning-for-Sign-Jin-Zhao/73a6b52896ff246f1278008f42858238e2814d2d",
            "/paper/Hierarchical-LSTM-for-Sign-Language-Translation-Guo-Zhou/d44c20c48e764a546d00b9155a56b171b0dc04bc",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/Neural-Sign-Language-Translation-by-Learning-Orbay-Akarun/4e39e59f41a480f68c934cc38eb874a25ceb5073",
            "/paper/SimulSpeech%3A-End-to-End-Simultaneous-Speech-to-Text-Ren-Liu/f0dfe7f0528eded4096a741a751aea4b1f707e82",
            "/paper/TSPNet%3A-Hierarchical-Feature-Learning-via-Temporal-Li-Xu/16091f0821502b70294ef66671183dadd1afcdc0",
            "/paper/Multi-channel-Transformers-for-Multi-articulatory-Camg%C3%B6z-Koller/4fe56f5f7a7196571e81ec243d86df376269695c"
        ]
    },
    {
        "id": "1987ee6b983fd2d082e0555e21909978c41d9c8f",
        "title": "Beware of diffusion models for synthesizing medical images - A comparison with GANs in terms of memorizing brain tumor images",
        "abstract": "Results show that diffusion models are much more likely to memorize the training images, especially for small datasets, and researchers should be careful when using diffusion models for medical imaging, if the final goal is to share the synthetic images. Diffusion models were initially developed for text-to-image generation and are now being utilized to generate high quality synthetic images. Preceded by GANs, diffusion models have shown impressive results using various evaluation metrics. However, commonly used metrics such as FID and IS are not suitable for determining whether diffusion models are simply reproducing the training images. Here we train StyleGAN and diffusion models, using BRATS20 and BRATS21 datasets, to synthesize brain tumor images, and measure the correlation between the synthetic images and all training images. Our results show that diffusion models are much more likely to memorize the training images, especially for small datasets. Researchers should be careful when using diffusion models for medical imaging, if the final goal is to share the synthetic images.",
        "publication_year": "2023",
        "authors": [
            "M. U. Akbar",
            "Wuhao Wang",
            "A. Eklund"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "29",
        "references": [
            "/paper/Brain-tumor-segmentation-using-synthetic-MR-images-Akbar-Larsson/57c61a12a9a152ca3641785234dc1477844e39b8",
            "/paper/Spot-the-fake-lungs%3A-Generating-Synthetic-Medical-Ali-Murad/51aafc680ccf6ba7d879e31fce49c55fd299f760",
            "/paper/Denoising-diffusion-probabilistic-models-for-3D-Khader-Mueller-Franzes/4616d468f2ec5b78206f2d00d0c6704b4bda19b4",
            "/paper/2D-medical-image-synthesis-using-transformer-based-Pan-Wang/1775333ad759bc827b8fde72c93ccbaca821c1e7",
            "/paper/A-Morphology-Focused-Diffusion-Probabilistic-Model-Moghadam-Dalen/804989a3687af0b13102569ffbb1c80f81eb454f",
            "/paper/Brain-Imaging-Generation-with-Latent-Diffusion-Pinaya-Tudosiu/e924a5cc4739f18fb225b7a8b506099042567ffa",
            "/paper/Does-an-ensemble-of-GANs-lead-to-better-performance-Larsson-Akbar/7d638720991f354497a9e50a1d6d61d4b1d53a2f",
            "/paper/Extracting-Training-Data-from-Diffusion-Models-Carlini-Hayes/2e965b5d97c2d6fb4af284307735be39283792ba",
            "/paper/Diffusion-Models-for-Medical-Image-Analysis%3A-A-Kazerouni-Aghdam/b57b8b6b8052bf2e7f6fe5c8e91cdcb385b75ab6",
            "/paper/Diffusion-Models-Beat-GANs-on-Image-Synthesis-Dhariwal-Nichol/64ea8f180d0682e6c18d1eb688afdb2027c02794",
            "/paper/The-Multimodal-Brain-Tumor-Image-Segmentation-Menze-Jakab/580062407427236ced45253a2ff7df2e147a81e2"
        ]
    },
    {
        "id": "301f1c0d3ab3df8a886b2456e34239baf23d0242",
        "title": "A feature aggregation and feature fusion network for retinal vessel segmentation",
        "abstract": "Semantic Scholar extracted view of \"A feature aggregation and feature fusion network for retinal vessel segmentation\" by Jiajia Ni et al.",
        "publication_year": "2023",
        "authors": [
            "Jiajia Ni",
            "Haihan Sun",
            "Jinxin Xu",
            "Jinhui Liu",
            "Zhengming Chen"
        ],
        "related_topics": "",
        "citation_count": 0,
        "reference_count": "33",
        "references": [
            "/paper/Retinal-Vascular-Image-Segmentation-Using-Improved-Huang-Yang/aae4ec3b514ad67e28a563d7801b98b4426a83a5",
            "/paper/SFA-Net%3A-Scale-and-Feature-Aggregate-Network-for-Ni-Liu/2ef8be98d6f2028fc54cd354bb1fc22d97378125",
            "/paper/DNL-Net%3A-deformed-non-local-neural-network-for-Ni-Wu/0f52f931e4493e810994a5a6dab71ee3ba89f77e",
            "/paper/MSAL-Net%3A-improve-accurate-segmentation-of-nuclei-Ali-Haq/0ede258f3007863ade1bb2c7316b4b57925485ac",
            "/paper/Edge-aware-U-net-with-gated-convolution-for-retinal-Zhang-Fang/44a7973b71ffb6005134d53dd0c78713bd7ed528",
            "/paper/EANet%3A-Iterative-edge-attention-network-for-medical-Wang-Zhang/46edfb243e871d2f274b6faacca2b94c4b3dd652",
            "/paper/U-Net-combined-with-multi-scale-attention-mechanism-Wu-Zhou/84826040cdf50b312f789b51df584f17cb56895f",
            "/paper/MF-Net%3A-Multi-Scale-Information-Fusion-Network-for-Meng-Wang/3eaeec814b5c5b77490cc4d79a972df099789e98",
            "/paper/Multi-path-cascaded-U-net-for-vessel-segmentation-Sun-Liu/56769ae06210d92bf976575eb562126b82c99179",
            "/paper/MD-Net%3A-A-multi-scale-dense-network-for-retinal-Shi-Wang/5adb465b3969ee3105da94b06f2166368b11f66a",
            "/paper/MFI-Net%3A-A-multi-resolution-fusion-input-network-Jiang-Wu/464cd13c6557c40e6c1113d6b8bb63908c102cc2"
        ]
    },
    {
        "id": "7c5abd0cf656ed48db39c27f4f4cefc6d8801ef0",
        "title": "The Impact of Primary Treatment Strategy on the Quality of Life in Patients with Vestibular Schwannoma.",
        "abstract": "Semantic Scholar extracted view of \"The Impact of Primary Treatment Strategy on the Quality of Life in Patients with Vestibular Schwannoma.\" by R. Foley et al.",
        "publication_year": "2017",
        "authors": [
            "R. Foley",
            "R. Maweni",
            "H. Jaafar",
            "R. McConn Walsh",
            "M. Javadpour",
            "D. Rawluk"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "11",
        "reference_count": "28",
        "references": [
            "/paper/Outcome-Measures-and-Quality-of-Life-in-Vestibular-Chartrand-Al-Tamami/4ff3a409def9dfe9bb88ee9808c1eb8ebfc2126d",
            "/paper/Prospective-Study-of-Disease-Specific-in-Sporadic-Carlson-Barnes/e9f42702f018cc45ae185e61cc47a6950f55ab0a",
            "/paper/Quality-of-life-reporting-in-the-management-of-A-Adegboyega-Jordan/33071a03d4793c8e2cf0fe47e3805d2ced3e1ab3",
            "/paper/Patient-preferred-outcomes-in-patients-with-a-of-on-Pruijn-Heemskerken/b89786e3bb4d1b4e52e943ab93d81b480b20a2fb",
            "/paper/Comparing-Patient-Satisfaction-After-Upfront-Versus-Nassiri-Lohse/5e91322f10a0a19d24221bbd27da3a820424405c",
            "/paper/Preservation-of-Hearing-and-Facial-Nerve-Function-Rajput-Ahmad/fa2dbba2c67f1b6e15d36e0cbff5feae4f12217a",
            "/paper/EANO-Guideline-on-the-Diagnosis-and-Treatment-of-Goldbrunner-Weller/59f2d96b85716e490b75ee575776184830e2e789",
            "/paper/Comparing-the-impact-of-upfront-radiosurgery-versus-Dhayalan-Tveiten/5cabe9d1f0226c1de3c4a8ca725dc2c7ae778138",
            "/paper/Hearing-aids-in-patients-with-vestibular-Interest-Reffet-Lescanne/2827df792f87ce1be6fc4e7b6658784909fe4803",
            "/paper/Leksell-Radiosurgery-for-Vestibular-Schwannomas.-Bowden-Niranjan/42be73d172cb9e78d05cb3b3ffc263501c2feac9",
            "/paper/Quality-of-Life-in-Vestibular-Schwannoma-Patients-Jufas-Flanagan/89be424e28fb7ed0e0e6c5a469904a182e26f593",
            "/paper/Quality-of-Life-in-Patients-With-Vestibular-to-Kim-Roh/7e0b9ebd83643d91e3997a5a83fa43acc5ae4bf2",
            "/paper/Systematic-review-of-quality-of-life-in-the-of-Gauden-Weir/ea2e2bd633917f823eba2f100acfe1df9b41edcd",
            "/paper/Prospective-comparison-of-quality-of-life-before-or-Maio-Akagami/81394e40bbb59ebcccae4a010e1332c1e2adc806",
            "/paper/The-Effect-of-Observation-versus-Microsurgical-on-A-Sandooram-Hornigold/f92e32c7df9eca8b10bbd1df7b3ab660b241cfb6",
            "/paper/Patient-assessed-outcomes-after-excision-of-and-of-Martin-Sethi/7d457bbc2bde775d6b4bf81723da814b045aa8ff",
            "/paper/Quality-of-Life-Among-Acoustic-Neuroma-Patients-by-Brooker-Fletcher/e5dddd3b88688d2a53397edb7e798af3389d053b",
            "/paper/Vestibular-Schwannomas%3A-Clinical-Results-and-of-or-Myrseth-M%C3%B8ller/608156e2bae124b16b12c13e4485e75db8c335dd",
            "/paper/Long-term-quality-of-life-in-patients-with-an-study-Carlson-Tveiten/d571627b938399be35a8268c6f743d03a9fe95ed",
            "/paper/Illness-Perceptions%2C-Coping%2C-and-Quality-of-Life-in-Vogel-Godefroy/aa9cf90cb675c75eade0584c1f5ebd36d85b5b66"
        ]
    },
    {
        "id": "52291fecbeb1af12bfcd0987487c50406edee5d0",
        "title": "Joint optic disc and optic cup segmentation based on boundary prior and adversarial learning",
        "abstract": "This work proposes a novel segmentation architecture, called BGA-Net, which introduces an auxiliary boundary branch and adversarial learning to jointly segment OD and OC in a multi-label manner and achieves superior OD and OD segmentation results. The most direct means of glaucoma screening is to use cup-to-disc ratio via colour fundus photography, the first step of which is the precise segmentation of the optic cup (OC) and optic disc (OD). In recent years, convolution neural networks (CNN) have shown outstanding performance in medical segmentation tasks. However, most CNN-based methods ignore the effect of boundary ambiguity on performance, which leads to low generalization. This paper is dedicated to solving this issue. In this paper, we propose a novel segmentation architecture, called BGA-Net, which introduces an auxiliary boundary branch and adversarial learning to jointly segment OD and OC in a multi-label manner. To generate more accurate results, the generative adversarial network is exploited to encourage boundary and mask predictions to be similar to the ground truth ones. Experimental results show that our BGA-Net system achieves state-of-the-art OC and OD segmentation performance on three publicly available datasets, i.e., the Dice scores for the optic disc/cup on the Drishti-GS, RIM-ONE-r3 and REFUGE datasets are 0.975/0.898, 0.967/0.872 and 0.951/0.866, respectively. In this work, we not only achieve superior OD and OC segmentation results, but also confirm that the values calculated through the geometric relationship between the former two are highly related to glaucoma.",
        "publication_year": "2021",
        "authors": [
            "Ling Luo",
            "Dingyu Xue",
            "Feng Pan",
            "Xinglong Feng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "31",
        "references": [
            "/paper/RSAP-Net%3A-joint-optic-disc-and-cup-segmentation-a-Jiang-Ma/0568673ea1e8b749cb7be7338f4ad7fbb756ca4b",
            "/paper/Polarformer%3A-Optic-Disc-and-Cup-Segmentation-Using-Feng-Li/88f132ce3d8b04f42aa51d81cd90be1d4c14b1e8",
            "/paper/An-End-to-End-Real-Time-Lightweight-Network-for-the-Liu-Chen/2a7b1424713a5895c4f3373f405feec5bea443e9",
            "/paper/Automatic-Pancreas-Segmentation-Using-Double-with-Li-Lian/4b1da51ff23dcc3fb21b109d0f1f58d8f0ca8e66",
            "/paper/Generative-adversarial-networks-in-medical-image-A-Xun-Li/1163e9b771bd1c43249fa959bf84a63d5dbfa08d",
            "/paper/Patch-Based-Output-Space-Adversarial-Learning-for-Wang-Yu/ba62442fc88eb4da204e98899214c45960341fa5",
            "/paper/Boundary-and-Entropy-driven-Adversarial-Learning-Wang-Yu/f2b3de7f036f8f35294d7c8008622f7d3ad2b4eb",
            "/paper/Towards-Accurate-Segmentation-of-Retinal-Vessels-in-Son-Park/817d5982c78b28411fb78569859c9d950998f5cf",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/Robust-optic-disc-and-cup-segmentation-with-deep-Yu-Xiao/a35cf646bed6628417a681d9b6688553adce0979",
            "/paper/Fully-Convolutional-Networks-for-Monocular-Retinal-Shankaranarayana-Ram/faf3f776a74dfbe18ac51cb424e9d1cbc1f514c5",
            "/paper/JointRCNN%3A-A-Region-Based-Convolutional-Neural-for-Jiang-Duan/928d7e118bba3518dc3d40b182481655fcad15df",
            "/paper/REFUGE-Challenge%3A-A-Unified-Framework-for-Automated-Orlando-Fu/b60f795c6f512ff3ebf6ee09f487aec21edbfec0",
            "/paper/A-spatial-aware-joint-optic-disc-and-cup-method-Liu-Hong/0b8dacf57a29343448c9ad564596ba91b1d23f1f",
            "/paper/Superpixel-Classification-Based-Optic-Disc-and-Cup-Cheng-Liu/2d054c85a51f101b51f0427d332e22eb5c502165"
        ]
    },
    {
        "id": "4406d6b8810965d31b721d59255305d5430b55ef",
        "title": "CSI-Based Human Activity Recognition using Convolutional Neural Networks",
        "abstract": "A new model is developed in which CSI data are converted to grayscale images and fed into a 2D-Convolutional Neural Network (CNN) for activity classification, taking advantage of CNN's high accuracy on image classification along with WiFi-based ubiquity. Human activity recognition (HAR) as an emerging technology can have undeniable impacts on several applications such as health monitoring, context-aware systems, transportation, robotics, and smart cities. Among the main research methods in HAR (sensor, image, and WiFi-based), the WiFi-based method has attracted considerable attention due to the ubiquity of WiFi devices. WiFi devices can be utilized to distinguish daily activities such as \"walk\", \"run\", and \"sleep\". These activities affect WiFi signal propagation and can be further used to recognize activities. This paper proposes a Deep Learning method for HAR tasks using channel state information (CSI). A new model is developed in which CSI data are converted to grayscale images. These images are then fed into a 2D-Convolutional Neural Network (CNN) for activity classification. We take advantage of CNN's high accuracy on image classification along with WiFi-based ubiquity. The experimental results demonstrate that our proposed approach achieves acceptable performance in HAR tasks.",
        "publication_year": "2021",
        "authors": [
            "P. Moshiri",
            "M. Nabati",
            "Reza Shahbazian",
            "S. Ghorashi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "27",
        "references": [
            "/paper/Deep-Learning-and-Its-Applications-to-WiFi-Human-A-Yang-Chen/7a9057c5e91e7fe3611b80df10f4911ba0e56b87",
            "/paper/SenseFi%3A-A-library-and-benchmark-on-WiFi-human-Yang-Chen/3aadb6c7e584e4f4a281f7d9053b8d4a369c23f8",
            "/paper/A-Survey-on-Behavior-Recognition-Using-WiFi-Channel-Yousefi-Narui/ab3a1407179e67f18f81497f915d1b010a552092",
            "/paper/Wireless-Sensing-for-Human-Activity%3A-A-Survey-Liu-Liu/b42590f5f9bf7802d453dbe89544f27cc3f1b058",
            "/paper/Joint-Coordinate-Optimization-in-Fingerprint-Based-Nabati-Ghorashi/31985bc14d312c310c1eb7838a42eca9641753e3",
            "/paper/WiFi-Based-Activity-Recognition-using-Activity-and-Shi-Zhang/261368d0bcd9df8706d344997b3139acc6c37e0f",
            "/paper/Using-GAN-to-Enhance-the-Accuracy-of-Indoor-Human-Moshiri-Navidan/5e956e96b93716589884be7a6efe45109b409bc8",
            "/paper/Using-Synthetic-Data-to-Enhance-the-Accuracy-of-A-Nabati-Navidan/573f0f7fbf980ab21c1c1c3c7d87acb6e31421e3",
            "/paper/WiAct%3A-A-Passive-WiFi-Based-Human-Activity-System-Yan-Zhang/fd8358e4c90a511496cc7fbdd981f7ec28d7ca98",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/A-Hybrid-Deep-Learning-Model-for-Human-Activity-Gumaei-Hassan/40c7e97580e8ab66778916608bbcf9c7f2452868",
            "/paper/Joint-Activity-Recognition-and-Indoor-Localization-Wang-Feng/75020f90bc2e65d069458dca79b4bfaa28ac1826"
        ]
    },
    {
        "id": "7c75203739f5f89e109b11144d170d4d3f2a6abc",
        "title": "Clustering Driven Deep Autoencoder for Video Anomaly Detection",
        "abstract": "A novel convolution autoencoder architecture to separately capture spatial and temporal informative representation and a deep k-means cluster to force the appearance and the motion encoder to extract common factors of variation within the dataset. Because of the ambiguous definition of anomaly and the complexity of real data, video anomaly detection is one of the most challenging problems in intelligent video surveillance. Since the abnormal events are usually different from normal events in appearance and/or in motion behavior, we address this issue by designing a novel convolution autoencoder architecture to separately capture spatial and temporal informative representation. The spatial part reconstructs the last individual frame (LIF), while the temporal part takes consecutive frames as input and RGB difference as output to simulate the generation of optical flow. The abnormal events which are irregular in appearance or in motion behavior lead to a large reconstruction error. Besides, we design a deep k-means cluster to force the appearance and the motion encoder to extract common factors of variation within the dataset. Experiments on some publicly available datasets demonstrate the effectiveness of our method with the state-of-the-art performance.",
        "publication_year": "2020",
        "authors": [
            "Y. Chang",
            "Zhigang Tu",
            "Wei Xie",
            "Junsong Yuan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "101",
        "reference_count": "44",
        "references": [
            "/paper/Video-anomaly-detection-with-spatio-temporal-Chang-Tu/2e6088d5f1081f2b46295d8783a5c2642ec35041",
            "/paper/Attention-based-residual-autoencoder-for-video-Le-Kim/770c840fe25e4c09405529c639f1fcf0a1b245ea",
            "/paper/EADN%3A-An-Efficient-Deep-Learning-Model-for-Anomaly-Amin-Ullah/de3d8f6a981ad21b3e28a242575b9b9c25e0c2ca",
            "/paper/Dual-branch-network-with-memory-for-video-anomaly-Wang-Hu/01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
            "/paper/Making-Reconstruction-based-Method-Great-Again-for-Wang-Qin/2f0bbb6cb441002909d1dc7c5a6d235d30c55c88",
            "/paper/Anomaly-Detection-with-Prototype-Guided-Latent-Lai-Han/0e168983a36d0c1246210ebca2d54ebd7190b4e6",
            "/paper/Video-Anomaly-Detection-via-Successive-Image-Frame-Wang-Zhang/e6e2c93ee6ef830bd8e3bf6ef8ff2f7cf834746e",
            "/paper/FastAno%3A-Fast-Anomaly-Detection-via-Spatio-temporal-Park-Cho/0de3d8697dd2ff82e78e49fab86ac03b912c0e66",
            "/paper/Abnormal-event-detection-in-surveillance-videos-on-Xia-Wei/1dc324681ac58abd2fad6b1da01c32997e06df50",
            "/paper/An-integration-of-Pseudo-Anomalies-and-Memory-for-Le-Nguyen/a283e48c27f5b0430536a4e8264aa1055de65cd6",
            "/paper/Learning-Spatiotemporal-Representation-Based-on-3D-Chang-Tu/84139f71ca68d35ec2ba4008ce39bdb910ee5373",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Detecting-anomalous-events-in-videos-by-learning-of-Xu-Yan/e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Detecting-spatiotemporal-irregularities-in-videos-a-Yan-Meng/2b47a0178521cbedcb1cfa791ae17ccaf29e51ba",
            "/paper/A-Revisit-of-Sparse-Coding-Based-Anomaly-Detection-Luo-Liu/99dff291f260b3cc3ff190106b0c2e3e685223a4"
        ]
    },
    {
        "id": "66a22af50a42f1705533fa2845eb632313876c27",
        "title": "Segmentation of VHR EO Images using Unsupervised Learning",
        "abstract": "An unsupervised semantic segmentation method that can be trained using just a single unlabeled scene and uses deep clustering and contrastive learning to refine the weights of a lightweight deep model composed of a series of the convolution layers along with an embedded channel attention. Semantic segmentation is a crucial step in many Earth observation tasks. Large quantity of pixel-level annotation is required to train deep networks for semantic segmentation. Earth observation techniques are applied to varieties of applications and since classes vary widely depending on the applications, therefore, domain knowledge is often required to label Earth observation images, impeding availability of labeled training data in many Earth observation applications. To tackle these challenges, in this paper we propose an unsupervised semantic segmentation method that can be trained using just a single unlabeled scene. Remote sensing scenes are generally large. The proposed method exploits this property to sample smaller patches from the larger scene and uses deep clustering and contrastive learning to refine the weights of a lightweight deep model composed of a series of the convolution layers along with an embedded channel attention. After unsupervised training on the target image/scene, the model automatically segregates the major classes present in the scene and produces the segmentation map. Experimental results on the Vaihingen dataset demonstrate the efficacy of the proposed method.",
        "publication_year": "2021",
        "authors": [
            "Sudipan Saha",
            "Lichao Mou",
            "M. Shahzad",
            "Xiao Xiang Zhu"
        ],
        "related_topics": [
            "Computer Science",
            "Environmental Science"
        ],
        "citation_count": 0,
        "reference_count": "25",
        "references": [
            "/paper/Unsupervised-Deep-Joint-Segmentation-of-Images-Saha-Mou/b72d0d2c024688202952f3007298a9cf68688eaf",
            "/paper/Semantic-Segmentation-of-Large-Size-VHR-Remote-a-Ding-Zhang/4c04ede41c2b77568f6b33c06cef6fbe425e6c95",
            "/paper/Semantic-Segmentation-of-Remote-Sensing-Images-With-Hua-Marcos/726d428dd8baf7721e6d06da395cb9f382bce05b",
            "/paper/Semantic-Guided-Deep-Unsupervised-Image-Saha-Sudhakaran/11fa0230f3802fbbc8dbae94d38c99b1025b1fe3",
            "/paper/Fully-Convolutional-Networks-for-Dense-Semantic-of-Sherrah/83ef7de2669bb2827208fd3a64ac910e276fbdb4",
            "/paper/Dense-Semantic-Labeling-of-Subdecimeter-Resolution-Volpi-Tuia/ef500cd3c401cd0632656c9fddccb1655c6659f9",
            "/paper/High-Resolution-Aerial-Image-Labeling-With-Neural-Maggiori-Tarabalka/63c5e590028a08210261b98fe995684d6870c68f",
            "/paper/Classification-With-an-Edge%3A-Improving-Semantic-Marmanis-Schindler/62b378f3d8d6d7803ba3a3339949aea9ecdc5749",
            "/paper/DeepLab%3A-Semantic-Image-Segmentation-with-Deep-and-Chen-Papandreou/cab372bc3824780cce20d9dd1c22d4df39ed081a",
            "/paper/Unsupervised-Representation-Learning-by-Predicting-Gidaris-Singh/aab368284210c1bb917ec2d31b84588e3d2d7eb4"
        ]
    },
    {
        "id": "3ca7ad47068f96b0cd2f55cd19f41a1845611ebb",
        "title": "Adversarial Machine Learning and Defense Game for NextG Signal Classification with Deep Learning",
        "abstract": "A game-theoretic framework to study the interactions of attack and defense for deep learning-based NextG signal classification, where the performance in Nash equilibrium is compared to the fixed attack anddefense cases, and the resilience of Next G signal classification against attacks is quantified. This paper presents a game-theoretic framework to study the interactions of attack and defense for deep learning-based NextG signal classification. NextG systems such as the one envisioned for a massive number of IoT devices can employ deep neural networks (DNNs) for various tasks such as user equipment identification, physical layer authentication, and detection of incumbent users (such as in the Citizens Broadband Radio Service (CBRS) band). By training another DNN as the surrogate model, an adversary can launch an inference (exploratory) attack to learn the behavior of the victim model, predict successful operation modes (e.g., channel access), and jam them. A defense mechanism can increase the adversary's uncertainty by introducing controlled errors in the victim model's decisions (i.e., poisoning the adversary's training data). This defense is effective against an attack but reduces the performance when there is no attack. The interactions between the defender and the adversary are formulated as a non-cooperative game, where the defender selects the probability of defending or the defense level itself (i.e., the ratio of falsified decisions) and the adversary selects the probability of attacking. The defender's objective is to maximize its reward (e.g., throughput or transmission success ratio), whereas the adversary's objective is to minimize this reward and its attack cost. The Nash equilibrium strategies are determined as operation modes such that no player can unilaterally improve its utility given the other's strategy is fixed. A fictitious play is formulated for each player to play the game repeatedly in response to the empirical frequency of the opponent's actions. The performance in Nash equilibrium is compared to the fixed attack and defense cases, and the resilience of NextG signal classification against attacks is quantified.",
        "publication_year": "2022",
        "authors": [
            "Y. Sagduyu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "29",
        "references": [
            "/paper/Adversarial-Deep-Learning-for-Cognitive-Radio-and-Shi-Sagduyu/25fb31c992edc8f4b913777c7a646cb0fe2f66ca",
            "/paper/Adversarial-Deep-Learning-for-Over-the-Air-Spectrum-Sagduyu-Shi/892d41979d1b76f9e2f789de8f27e31f12e65b96",
            "/paper/Adversarial-Machine-Learning-for-5G-Communications-Sagduyu-Erpek/8fd0431186564148b8c0b8a30c363fe724ff320e",
            "/paper/Deep-Learning-for-Launching-and-Mitigating-Wireless-Erpek-Sagduyu/b2ff78b76a302b005ab65ad0d404373a70f3d5ee",
            "/paper/IoT-Network-Security-from-the-Perspective-of-Deep-Sagduyu-Shi/7ff0063bcc074d04b89ef4bc3eede54521d7b654",
            "/paper/Threats-of-Adversarial-Attacks-in-DNN-Based-Lin-Zhao/db5ac25593250c62f848459b9e27a468f6fc3ad2",
            "/paper/Over-the-air-membership-inference-attacks-as-for-Shi-Davaslioglu/ff1946e76c7320f0a67d5a05490fd7334dbab7c1",
            "/paper/Trojan-Attacks-on-Wireless-Signal-Classification-Davaslioglu-Sagduyu/9bd74ce88249bee09e6c2e7fec74af7efd4db468",
            "/paper/Adversarial-Attacks-on-Deep-Learning-Based-Radio-Sadeghi-Larsson/f74fb6b38dd2d38a5f7a61a69958f5191e21d035",
            "/paper/When-Attackers-Meet-AI%3A-Learning-Empowered-Attacks-Luo-Zhao/6abc99d8a1e2ee6c4f1038cbd449ac52959a47b7"
        ]
    },
    {
        "id": "f0717bed735fb8a9f375947eb749611881f644f5",
        "title": "Link prediction of time-evolving network based on node ranking",
        "abstract": "Semantic Scholar extracted view of \"Link prediction of time-evolving network based on node ranking\" by Xiaomin Wu et al.",
        "publication_year": "2020",
        "authors": [
            "Xiaomin Wu",
            "Jianshe Wu",
            "Yafeng Li",
            "Qian Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "19",
        "reference_count": "62",
        "references": [
            "/paper/Integrating-node-centralities%2C-similarity-measures%2C-Anand-Rahul/95476a8b26b8e51c5f1bc7ebd245685a0feb489f",
            "/paper/TLP-CCC%3A-Temporal-Link-Prediction-Based-on-and-Zhu-Liu/ab3d19a8fc0076f07ad75d6fa94e3331f470adb4",
            "/paper/Adaptive-Similarity-Function-with-Structural-of-for-Zhang-Shang/fc6488e71546d79f74392c56c04d8af04d649bb6",
            "/paper/An-edge-creation-history-retrieval-based-method-to-Florentino-Cavalcante/db60e94e2008f83851218a54a676cd278e90584c",
            "/paper/Evolutionary-Features-for-Dynamic-Link-Prediction-Choudhury-Uddin/562b21849a3fba7a000b10671eb3203750882dfe",
            "/paper/A-Systematic-Analysis-of-Link-Prediction-in-Complex-Gul-Amin/20db0740a2c519e9e43f99983fb906127fcd9512",
            "/paper/A-Novel-Temporal-Network-Embedding-Algorithm-for-in-Abbas-Abbasi/a4dcd366db2f276da070b19c64d085d6b5565e1b",
            "/paper/A-variable-action-set-cellular-learning-algorithm-Manshad-Meybodi/c4616603b407a4757dcca72d702af1bf1eff1bb3",
            "/paper/Link-prediction-in-complex-networks-based-on-and-Peng-Xu/7598d6b7dfe363c50b53cda94dadfa394aa8f818",
            "/paper/GC-LSTM%3A-Graph-Convolution-Embedded-LSTM-for-Link-Chen-Xu/9e17dcfc7cf86e7db30363df37e7211c8e63d9eb",
            "/paper/Link-prediction-in-dynamic-networks-based-on-the-Chi-Yin/f15456a69473643f565f4b1353638766ea796d2f",
            "/paper/Time-Series-Based-Link-Prediction-Soares-Prud%C3%AAncio/e4ea943603fd90674c9fc665d4f9ea53faf65e16",
            "/paper/Link-Prediction-in-Evolving-Networks-Based-on-of-Wang-Zhou/518ae77a62a2b2f95d2830817a0b8b4ff8c2164c",
            "/paper/Evolving-networks%E2%80%94Using-past-structure-to-predict-Shang-Yan/02d4cde6bb29529293f313f331c098866214a187",
            "/paper/Towards-time-aware-link-prediction-in-evolving-Tylenda-Angelova/219d95a38e8e3f2e7f2c102cc5f31f9fdddb1742",
            "/paper/A-Supervised-Learning-Approach-to-Link-Prediction-Xu-Han/4acde4989e7d15a59334958a2c8eb58ece657bae",
            "/paper/Exploiting-Structural-and-Temporal-Evolution-in-Chen-Li/33841403bb8676b462a30707754fac09b312165f",
            "/paper/DyLink2Vec%3A-Effective-Feature-Representation-for-in-Rahman-Saha/3c5c43b7713b81293a94cc0bee622d5f35f6af14",
            "/paper/Evaluating-Link-Prediction-Accuracy-in-Dynamic-with-Junuthula-Xu/9cf365fbc0267762ad0365e57c8f247a2357ac0c",
            "/paper/Prediction-of-missing-links-based-on-community-and-Ding-Jiao/e1f99e48d09a972385118178aa6f8609feb712f3"
        ]
    },
    {
        "id": "fc6a78d27a2268a2e0c9d4675018d1e92e7c67e5",
        "title": "Distributed Attention-Based Temporal Convolutional Network for Remaining Useful Life Prediction",
        "abstract": "This work presents a deep learning-based RUL prediction method with an attention mechanism to weight sequence data representations based on the distributed attention mechanism that has high accuracy and is efficient in practical applications. Massive industrial data collected from the Industrial Internet-of-Things (IIoT) assets improve data-driven methods for prognostics and health management (PHM) systems. As an important role in PHM, remaining useful life (RUL) prediction is essential to maintain the reliability and safety of industrial manufacture. However, recent data-driven approaches for bearing RUL prediction do not weight the contributions of data from different sensors and time steps, which decreases the efficiency in the big data era. In this context, we present a deep learning-based RUL prediction method with an attention mechanism to weight sequence data representations. Specifically, the proposed method weights different industrial sensors and time steps, respectively, based on the distributed attention mechanism. Then, temporal convolution modules with the shared weights are used for feature extraction of time series. Finally, the performance of the proposed method is verified using a popular data set C-MAPSS. The experimental results reveal that the proposed method has high accuracy and is efficient in practical applications.",
        "publication_year": "2021",
        "authors": [
            "Yan Song",
            "Shengyao Gao",
            "Yibin Li",
            "Lei Jia",
            "Qiqiang Li",
            "Fuzhen Pang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "33",
        "reference_count": "34",
        "references": [
            "/paper/Non-parametric-Multi-Self-Attention-Temporal-for-Xiong-Tian/0a3532d23a94e5fbe69a5f184040b60160189d5f",
            "/paper/Remaining-Useful-Life-Prediction-Using-Temporal-for-Qin-Cai/e9828c471bc07f32769bd6f38a0f6fa7d7e87da1",
            "/paper/Hybrid-Multi-Scale-Convolutional-Long-Short-Term-Sharma-Sharma/07b0f35afcd9368968b6f5f125ea4a46eefa86c3",
            "/paper/Dual-Aspect-Self-Attention-Based-on-Transformer-for-Zhang-Song/5bcb50523a8ea315f4c16c8fb05f26a8220d70d6",
            "/paper/Dual-Channel-Feature-Attention-Based-Approach-for-Gao-Li/f60e50df0674dc8446c507395ce4343495d2b5ff",
            "/paper/Machine-remaining-life-prediction-based-on-and-Shang-Zhang/57da7d24de0b2c3b68e12d90e6fbea5a922af3c7",
            "/paper/Machine-remaining-life-prediction-based-on-and-Shang-Zhang/38ee21170e984f3b3e8d95c029a1afe0c4924d85",
            "/paper/Learning-representations-with-end-to-end-models-for-Chaoub-Voisin/30f89a8c2482f1d37fb851321d51659270acbdb9",
            "/paper/Deep-Learning-with-Spatial-Attention-Based-for-SOC-Tian-Chen/a0ab545031ebafb3d2ec87de631fb5632f744b95",
            "/paper/Rolling-Bearing-Health-Indicator-Extraction-and-RUL-Ye-Zhang/597617684e7156914563e9fed6969a592981fefe",
            "/paper/Prediction-of-Bearing-Remaining-Useful-Life-With-Ren-Sun/eea1d303b4e78c86a2675880fa20ff35cf1fe6cb",
            "/paper/A-novel-deep-learning-method-based-on-attention-for-Chen-Peng/447ca540fcde8630e60a98853dbddb57b5628c07",
            "/paper/Remaining-useful-life-estimation-in-prognostics-Li-Ding/809003357de849d443a37b29996e2130c7bdb041",
            "/paper/Remaining-Useful-Life-Estimation-in-Prognostics-Wang-Wen/ea88fd2474d3beb46f630808ce1e6dbc42d248d0",
            "/paper/Deep-Convolutional-Neural-Network-Based-Regression-Babu-Zhao/52b7cb1705f0815c3e66b785b3a4432b1af6d47a",
            "/paper/A-Directed-Acyclic-Graph-Network-Combined-With-CNN-Li-Li/f225641fa0e9fa2c34dd2c10a909b1f2639cd128",
            "/paper/Remaining-useful-life-predictions-for-turbofan-deep-Ellefsen-Bj%C3%B8rlykhaug/5177be422e9eadcc806551c78430173e5a4a3f42",
            "/paper/Long-Short-Term-Memory-Network-for-Remaining-Useful-Zheng-Ristovski/e66afb33d246dbe3199fd57bcfc1b611136d96c2",
            "/paper/Remaining-useful-life-prediction-of-aircraft-engine-Zhao-Liang/42576ab7fffb380d6746d458467e2468e0f973ba",
            "/paper/Understanding-Convolution-for-Semantic-Segmentation-Wang-Chen/84c1717345dd451e7a61fe89807b4c017754fc4e"
        ]
    },
    {
        "id": "4923c6bc3ab501651763f6814a8384745f3d9a4d",
        "title": "Visual attribute transfer through deep image analogy",
        "abstract": "The technique finds semantically-meaningful dense correspondences between two input images by adapting the notion of \"image analogy\" with features extracted from a Deep Convolutional Neutral Network for matching, and is called deep image analogy. We propose a new technique for visual attribute transfer across images that may have very different appearance but have perceptually similar semantic structure. By visual attribute transfer, we mean transfer of visual information (such as color, tone, texture, and style) from one image to another. For example, one image could be that of a painting or a sketch while the other is a photo of a real scene, and both depict the same type of scene. Our technique finds semantically-meaningful dense correspondences between two input images. To accomplish this, it adapts the notion of \"image analogy\" [Hertzmann et al. 2001] with features extracted from a Deep Convolutional Neutral Network for matching; we call our technique deep image analogy. A coarse-to-fine strategy is used to compute the nearest-neighbor field for generating the results. We validate the effectiveness of our proposed method in a variety of cases, including style/texture transfer, color/style swap, sketch/painting to photo, and time lapse.",
        "publication_year": "2017",
        "authors": [
            "Jing Liao",
            "Y. Yao",
            "Lu Yuan",
            "G. Hua",
            "S. B. Kang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "432",
        "reference_count": "76",
        "references": [
            "/paper/Deep-color-transfer-using-histogram-analogy-Lee-Son/1d30b941448645bc2dc304dcb1aacf9261070e0e",
            "/paper/Neural-Color-Transfer-between-Images-He-Liao/b9fea96a88d9a390d0a51d25022ca73b90f801b4",
            "/paper/Neural-Photometry-Guided-Visual-Attribute-Transfer-Rodriguez-Pardo-Garces/f8de84ef31bb4b5fa467df234fab902e647d4726",
            "/paper/Fast-Facial-Image-Analogy-with-Spatial-Guidance-Zheng-Xia/89ba88a4df711fcd1d1dd7de8f7d49985a38de00",
            "/paper/Semantic-Image-Analogy-with-a-Conditional-GAN-Li-Xiong/b5dd2ec1bbbf9732ea52a34d6e18e368f622479b",
            "/paper/Semantic-related-image-style-transfer-with-loss-Ma-Li/fce40f1b04c3e81d0a36d624a81ef5c76169afa5",
            "/paper/Structural-Analogy-from-a-Single-Image-Pair-Benaim-Mokady/abd5ae25308d3fe352e1c6a6182fe603220e78fa",
            "/paper/Automatic-semantic-style-transfer-using-deep-neural-Zhao-Rosin/e9b86473062151369341fa25608e3d24568677f5",
            "/paper/Cross-Domain-Correspondence-Learning-for-Image-Zhang-Zhang/62f1ba6f5a7ad125dd62261fb5fec1a125232c8c",
            "/paper/Fast-Universal-Style-Transfer-for-Artistic-and-An-Xiong/e0d5dd85d98e93c1eeab39ccc829c48cdb4b77b4",
            "/paper/Deep-Visual-Analogy-Making-Reed-Zhang/a10d6877c90de39c42a143af60c0bf5e588be763",
            "/paper/Data-driven-visual-similarity-for-cross-domain-Shrivastava-Malisiewicz/0c717f5c1361a3c064b269462e27bdc685f85444",
            "/paper/Deep-Photo-Style-Transfer-Luan-Paris/8b5253c8159ffa7cca12901af26a0a0897b45cda",
            "/paper/Style-Transfer-Via-Texture-Synthesis-Elad-Milanfar/05d7697cfbc0c2c7dd2aa5a4bc5fac1682d80220",
            "/paper/Perceptual-Losses-for-Real-Time-Style-Transfer-and-Johnson-Alahi/9fa3720371e78d04973ce9752781bc337480b68f",
            "/paper/A-Neural-Algorithm-of-Artistic-Style-Gatys-Ecker/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6",
            "/paper/SIFT-Flow%3A-Dense-Correspondence-across-Scenes-and-Liu-Yuen/af14da35d7fd12d182b10594027232489c6a8b51",
            "/paper/Fast-Texture-Transfer-Ashikhmin/ab1234274c0138e552080672647cba634d11edf5",
            "/paper/Non-rigid-dense-correspondence-with-applications-HaCohen-Shechtman/fec3714f5a2d7d4cd8c8e2e5ba83a162fbefcb38",
            "/paper/Texture-Networks%3A-Feed-forward-Synthesis-of-and-Ulyanov-Lebedev/ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1"
        ]
    },
    {
        "id": "d5baf1912d43d0af0e8f683eb5532f5f5445430e",
        "title": "A benchmark of batch-effect correction methods for single-cell RNA sequencing data",
        "abstract": "An in-depth benchmark study on available batch correction methods to determine the most suitable method for batch-effect removal and data integration and recommends Harmony, LIGER, and Seurat 3 as recommended methods for batch integration. Background Large-scale single-cell transcriptomic datasets generated using different technologies contain batch-specific systematic variations that present a challenge to batch-effect removal and data integration. With continued growth expected in scRNA-seq data, achieving effective batch integration with available computational resources is crucial. Here, we perform an in-depth benchmark study on available batch correction methods to determine the most suitable method for batch-effect removal. Results We compare 14 methods in terms of computational runtime, the ability to handle large datasets, and batch-effect correction efficacy while preserving cell type purity. Five scenarios are designed for the study: identical cell types with different technologies, non-identical cell types, multiple batches, big data, and simulated data. Performance is evaluated using four benchmarking metrics including kBET, LISI, ASW, and ARI. We also investigate the use of batch-corrected data to study differential gene expression. Conclusion Based on our results, Harmony, LIGER, and Seurat 3 are the recommended methods for batch integration. Due to its\u00a0significantly shorter runtime, Harmony is recommended as the first method to try, with the other methods as viable alternatives.",
        "publication_year": "2020",
        "authors": [
            "Hoa Tran",
            "Kok Siong Ang",
            "Marion Chevrier",
            "Xiaomeng Zhang",
            "N. Lee",
            "Michelle Goh",
            "Jinmiao Chen"
        ],
        "related_topics": [
            "Biology",
            "Computer Science"
        ],
        "citation_count": "468",
        "reference_count": "49",
        "references": [
            "/paper/Flexible-comparison-of-batch-correction-methods-for-Chazarra-Gil-Dongen/f48d75612695cc36c3a820ae175261329318ab4c",
            "/paper/SCIBER%3A-a-simple-method-for-removing-batch-effects-Gan-Li/2aa7fde76a1e362845a630246c47ddb82d7d1bec",
            "/paper/CellMixS%3A-quantifying-and-visualizing-batch-effects-L%C3%BCtge-Zyprych-Walczak/26bf74add0ee73ec8c80662508f39b41da1eca6d",
            "/paper/Batch-alignment-of-single-cell-transcriptomics-data-Yu-Xu/e2fde6d6f5ddb0cc14aca91203d195f65e769176",
            "/paper/SSBER%3A-removing-batch-effect-for-single-cell-RNA-Zhang-Wang/21e611d2225dd07a8665df64979a3286c46c7ea9",
            "/paper/scRAA%3A-the-development-of-a-robust-and-automatic-Yan-Sun/eed5b5059e529f4cae816938bcfe11129bd285ab",
            "/paper/A-multicenter-study-benchmarking-single-cell-RNA-Chen-Zhao/45b14f2573e26dd217c7e0cb041dc9632df37095",
            "/paper/Benchmarking-integration-of-single-cell-expression-Nguyen-Baik/30c9e588b8d41fdf28b043417440a62875f80b49",
            "/paper/Data-Matrix-Normalization-and-Merging-Strategies-in-Babcock-Kosters/adb164bfb92e28f51fdecebc3c38e049de4195d3",
            "/paper/Integration-of-Single-Cell-RNA-Seq-Datasets%3A-A-of-Ryu-Han/d9084620a15a94d0853c5f94ff29767362176185",
            "/paper/A-benchmark-of-batch-effect-correction-methods-for-Tran-Ang/2bf824eae3ce1e842124901c0fbf8bba0e3c074c",
            "/paper/Batch-effects-in-single-cell-RNA-sequencing-data-by-Haghverdi-Lun/56bf103a956b4a2ad11868c05db189d1e3f64ac1",
            "/paper/Integrating-single-cell-transcriptomic-data-across-Butler-Hoffman/458c8ca3c2818b479d91dbdb83f2d10ded3708fa",
            "/paper/A-step-by-step-workflow-for-low-level-analysis-of-Lun-McCarthy/74e86a3375ac2c2ffe89577fbf16456eb39ff581",
            "/paper/Fast%2C-sensitive%2C-and-accurate-integration-of-single-Korsunsky-Fan/3ea71ab8877a3e96ce82daf24aacd3ccbcd19138",
            "/paper/BBKNN%3A-fast-batch-alignment-of-single-cell-Pola%C5%84ski-Young/e6368f1cb43fb26b0f006ebd711984d5a8cd530f",
            "/paper/scMerge-leverages-factor-analysis%2C-stable-and-to-Lin-Ghazanfar/db45a1e03550df2a6d3dc1476c9415b80bf69e89",
            "/paper/Comprehensive-Integration-of-Single-Cell-Data-Stuart-Butler/2287a3930a7568a956aae5f3f037efe8fed675e7",
            "/paper/Massively-parallel-digital-transcriptional-of-cells-Zheng-Terry/17422a9fcf3f05408f7f2f270b127aa812e9b2b3",
            "/paper/Adjusting-batch-effects-in-microarray-expression-Johnson-Li/427eaafcd47b3abc620b953ff021f25925ff0e62"
        ]
    },
    {
        "id": "9e31ceae5ada558541d1995e3f06d0166f79e37b",
        "title": "L0-norm constraint normalized subband adaptive filtering algorithm: Performance development and AEC application",
        "abstract": "An effective variable step-size L0-norm constraint NSAF algorithms (VSS-L0-NSAFs) are proposed that achieve better performance in terms of estimation accurateness and tracking capability in comparison with existing related algorithms in sparse system identification and adaptive echo cancellation circumstances. Limited by fixed step-size and sparsity penalty factor, the conventional sparsity-aware normalized subband adaptive filtering (NSAF) type algorithms suffer from trade-off requirements of high filtering accurateness and quicker convergence behavior for sparse system identification. To deal with this problem, this paper proposes variable step-size L0-norm constraint NSAF algorithms (VSS-L0-NSAFs). We first analyze mean-square-deviation (MSD) statistics behavior of the L0-NSAF innovatively in according to novel weight recursion form and arrive at corresponding expressions for the cases that background noise variance is available and unavailable, where correlation degree of system input is indicated by scaling parameter r. Based on derivations, we develop an effective variable step-size scheme through minimizing the upper bounds of the MSD under some reasonable assumptions and lemma. Furthermore, an effective reset strategy is incorporated into presented algorithms to tackle with non-stationary situations. Finally, numerical simulations corroborate that the proposed algorithms achieve better performance in terms of estimation accurateness and tracking capability in comparison with existing related algorithms in sparse system identification and adaptive echo cancellation circumstances.",
        "publication_year": "2023",
        "authors": [
            "Dongxu Liu",
            "Haiquan Zhao",
            "Yang Zhou"
        ],
        "related_topics": [
            "Engineering",
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "57",
        "references": [
            "/paper/Sparsity-aware-subband-adaptive-algorithms-with-Yu-Zhao/ebd0abdcae4d0580aa2ae4de7905e59349b9071a",
            "/paper/A-Variable-Step-Size-Matrix-Normalized-Subband-Ni-Li/8f64798dffa4f901e6730ab2d92d3915e1fd70bb",
            "/paper/Sparsity-aware-normalized-subband-adaptive-filters-Ji-Ni/aae369697b10bd7eb2e9c21a8c1911a4359707f0",
            "/paper/Sparsity-Aware-Logarithmic-Hyperbolic-Cosine-Filter-Liu-Zhao/a48a98e6251407660ce1d80a17b4fcbc00b01861",
            "/paper/Sparse-normalized-subband-adaptive-filter-algorithm-Yu-Zhao/a8802905bf00aa79a578e9ebbffc7e4f162e93ef",
            "/paper/Subband-Adaptive-Filtering-with-Norm-Constraint-for-Choi/60a603f4e1486514c96380504e580ac7a2996e23",
            "/paper/Scheduled-Step-Size-Subband-Adaptive-Filter-With-Park-Lee/e09f45e59dcd455ab9105393703999110a488d4f",
            "/paper/Robust-Subband-Adaptive-Filter-Algorithms-Based-and-Zhao-Gao/3d8f2e8be2a2ce7ac2501b7d6f79d257515269e0",
            "/paper/Adaptive-Sparse-Channel-Estimation-under-Symmetric-Pelekanakis-Chitre/49c102ecdc3460995ee842fb414ecefcd34d333d",
            "/paper/General-Robust-Subband-Adaptive-Filtering%3A-and-Yu-He/cf2c460aee10886b6b8a8b6534d9e7a574aa718a"
        ]
    },
    {
        "id": "01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
        "title": "Dual-branch network with memory for video anomaly detection",
        "abstract": "A memory module is adopted to reduce the reconstruction error, which is capable of enhancing the robustness of the autoencoder as a prototype memory module, and the prediction of high-quality future frames can effectively prevent the reconstruction of abnormal frames, thus further elevating the performance of video anomaly detection. Anomaly event detection is a video surveillance technology automatically analyzing video sequences without manual intervention by employing machine learning and computer vision technology. In the existing approaches, most of them are utilized to reconstruct or predict the video frame based on an autoencoder (AE). However, impacted by the powerful characterization capabilities of Convolutional Neural Network (CNN), abnormal frames will be improperly reconstructed into normal frames. To solve the above issue, an autoencoder, based on a branch framework of reconstruction and prediction in training, is proposed. A memory module is adopted to reduce the reconstruction error, which is capable of enhancing the robustness of the autoencoder as a prototype memory module. The prediction of high-quality future frames can effectively prevent the reconstruction of abnormal frames, and the two branches can be supplemented with their respective loss functions, thus further elevating the performance of video anomaly detection. The framework for this study is trained from end to end. The methodology put forth in this article is extensively verified on three publicly available data sets, and its robustness to the uncertainty for the common occurrence as well as the efficiency to the sensitivity for the abnormalies are also confirmed.",
        "publication_year": "2022",
        "authors": [
            "Dicong Wang",
            "Qinghua Hu",
            "Kaijun Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "54",
        "references": [
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/A-Hybrid-Video-Anomaly-Detection-Framework-via-Flow-Liu-Nie/5cccc8bab11927e5527dd5b917ed4c306a2ccf49",
            "/paper/Attention-based-residual-autoencoder-for-video-Le-Kim/770c840fe25e4c09405529c639f1fcf0a1b245ea",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/Integrating-prediction-and-reconstruction-for-Tang-Zhao/fe09f7a379944444201552e952b910188c0aeaca",
            "/paper/Video-Anomaly-Detection-and-Localization-Based-on-Xu-Sun/32323526b61685d007f4d2a62b23b8669e602fa8",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Anomaly-Detection-with-Prototype-Guided-Latent-Lai-Han/0e168983a36d0c1246210ebca2d54ebd7190b4e6",
            "/paper/Improved-anomaly-detection-in-surveillance-videos-a-Khaleghi-Moin/1a5c917ec7763c2ff9619e6f19d02d2f254d236a"
        ]
    },
    {
        "id": "248461bad5d66f4d202ecbeb3e5cf9443a3d3b32",
        "title": "Are occlusal splints effective in reducing myofascial pain in patients with muscle-related temporomandibular disorders? A randomized-controlled trial",
        "abstract": "The study results suggest that OS, independently from being built on the upper or lower arch, seems to not have significant effects in reducing pain over a six-month period in TMD patients. Objectives This study aims to evaluate the effectiveness of upper Michigan occlusal splint (OS) compared to mandibular OS in terms of pain, range of motion (ROM), and muscle activity as assessed by surface electromyography (sEMG) in patients affected by muscle-related temporomandibular disorders (TMD). Patients and methods In this randomized-controlled trial, a total of 40 adult patients (13 males, 27 females; mean age: 47.2\u00b112.8 years; range, 22 to 56 years) with a diagnosis of myofascial pain, lasting from at least three months on at least one masseter muscle. The patients were randomly allocated into two groups: Group 1 (n=20) using upper Michigan OS and Group 2 (n=20) using mandibular OS. At baseline (T0), at one (T1), three (T2), and six months (T3), the following outcomes were assessed: myofascial pain by Visual Analog Scale (VAS) and ROM of mandible movements, activity of the main masticatory muscles through sEMG. Results There were no significant intra-group differences in the outcome measures assessed in both groups. However, Group 2 had a significantly higher right lateral mandibular ROM at T2 (7.1\u00b13.1 vs. 9.8\u00b12.3, respectively; p<0.05) and a significantly higher left lateral mandibular ROM at T3 (7.6\u00b13.5 vs. 10.5\u00b12.1, respectively; p<0.05). We found no significant difference in none of the sEMG parameters. Conclusion Our study results suggest that OS, independently from being built on the upper or lower arch, seems to not have significant effects in reducing pain over a six-month period in TMD patients.",
        "publication_year": "2021",
        "authors": [
            "A. Deregibus",
            "M. Ferrillo",
            "Maria Grazia Piancino",
            "Maria Chiara Domini",
            "Alessandro de Sire",
            "T. Castroflorio"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "28",
        "reference_count": "43",
        "references": [
            "/paper/Changes-in-Maximum-Mandibular-Mobility-Due-to-in-Wiechens-Paschereit/4d9aaa1cfd1d0fa6a18a88425d62442e8126e751",
            "/paper/Are-exercises-with-or-without-occlusal-splints-more-Batista-Vila-Nova/cab837cb314a0523c1b8224f67bcde977f1b59be",
            "/paper/Efficacy-of-Botulinum-Toxin-Type-A-I-in-the-of-and-Canales-Poluha/2bd87958108786f5e200bcfdaf191c6e31558c3d",
            "/paper/Efficacy-of-rehabilitation-on-reducing-pain-in-A-of-Ferrillo-Ammendolia/fdb7f6bc1154dc30f90592ed7237374f6187fe73",
            "/paper/Ef%EF%AC%81cacy-of-rehabilitation-on-reducing-pain-in-A-and-Ferrillo-Ammendolia/d6609c67edd0496448f9ef56a008da76157fa3fa",
            "/paper/Intramuscular-Injections-and-Dry-Needling-within-in-Nowak-Ch%C4%99ci%C5%84ski/b355734d31204827bc4ae70db808033a347a4321",
            "/paper/Effects-of-Radial-Extracorporeal-Shock-Wave-Therapy-Marotta-Ferrillo/2bbe7ea99fe71e42171ed0b77a5b777899b843a1",
            "/paper/Efficacy-of-conservative-approaches-on-pain-relief-Ferrillo-Nucci/269292470ccfa71ab9a5e7df3eb9e06ef9f46ac7",
            "/paper/Assessment-of-the-masseter-stiffness-in-patients-Olchowy-Seweryn/e35c8b90762a50a073b3a1815f03eb04bb7fbd02",
            "/paper/Effects-of-Occlusal-Splints-on-Spinal-Posture-in-A-Ferrillo-Marotta/4301b85900b9b662f382eec10be90eb9867c8bd7",
            "/paper/Effect-of-occlusal-splints-for-the-management-of-a-Zhang-Wang/67563f0cb12ceecad7702c48dbfe8786aea45187",
            "/paper/Occlusal-stabilization-splint-for-patients-with-of-Pficer-Dodi%C4%87/a2b8cfa1b84e59e62bcc62d0a961b67f31f66510",
            "/paper/Effectiveness-of-occlusal-splint-therapy-in-the-of-Al-Moraissi-Farea/d5805070831487b217fcc1e165e217639855ac3e",
            "/paper/Comparison-of-kinesio-taping-and-occlusal-splint-in-Keskinruzgar-Kucuk/092f4bdd6b004f9d3ebb7fcbe75f73f3b244ee64",
            "/paper/Comparison-of-the-efficacy-of-dry-needling-and-with-Aksu-Do%C4%9Fan/eb77bf5db008814f3ea78a59ac0de5fc3e8a83f0",
            "/paper/Immediate-effect-of-a-stabilization-splint-on-in-Ferrario-Sforza/93aa6f1747e1e54aa8212faf0a00ec25252d6aeb",
            "/paper/Ultrasound-evaluation-of-masseter-muscle-changes-in-Aldemir-%C3%9Cst%C3%BCner/30e1d123b7615ac64f7130a91f12b43c4a65a1a6",
            "/paper/Does-occlusal-splint-affect-posture-A-randomized-Giorgi-Castroflorio/72ac0055be21d75940c0569cf0759c5e647a9415",
            "/paper/Evaluation-the-effects-of-low-level-laser-therapy-Tunc%CC%A7/4cb8923b1e100f7601d2f487b865b5b1900486d8",
            "/paper/Immediate-effects-of-various-physical-therapeutic-Hou-Tsai/53d46bda432ba1a722418676688474a4e3659655"
        ]
    },
    {
        "id": "319b52c4d3af7e6d19a6b646316655e279946491",
        "title": "Telocyte Behaviour During Inflammation, Repair and Tumour Stroma Formation.",
        "abstract": "The role of human CD34+ stromal cells/telocytes (CD34+ SC/TCs) as progenitor cells during repair is outlined and their behaviour in vivo and in vitro and different behaviour depending on location, time, type of injury are considered. In this chapter, we outline the role of human CD34+ stromal cells/telocytes (CD34+ SC/TCs) as progenitor cells during repair. The in vivo activation phenomena of CD34+ SC/TCs in this process include increased size; separation from the neighbouring structures (mainly of the vascular walls); association with inflammatory cells, predominantly macrophages; development of the organelles of synthesis (rough endoplasmic reticulum and Golgi apparatus); cell proliferation with presence of mitosis and high proliferative index (transit-amplifying cells); and fibroblastic and myofibroblastic differentiation. A procedure to study these tissue-resident cells, comparison of their behaviour in vivo and in vitro and different behaviour depending on location, time, type of injury (including tumour stroma) and greater or lesser proximity to the injury are also considered.",
        "publication_year": "2016",
        "authors": [
            "L. D\u00edaz-Flores",
            "R. Guti\u00e9rrez",
            "M. Gonz\u00e1lez-G\u00f3mez",
            "L. D\u00edaz-Flores",
            "F. Valladares",
            "N. Rancel",
            "F. S\u00e1ez",
            "J. Madrid"
        ],
        "related_topics": [
            "Biology",
            "Medicine"
        ],
        "citation_count": "12",
        "reference_count": "67",
        "references": [
            "/paper/Behaviour-of-telocytes-during-physiopathological-D%C3%ADaz-Flores-Guti%C3%A9rrez/40fb968dfe2ffb25dfbe05cbacb9b343123a71bd",
            "/paper/The-telopode-and-filopode-projecting-heterogeneous-Petrea-Cr%C4%83i%C5%A3oiu/0b7c01b1814949b7f6f7044bee3b4e84b29a4917",
            "/paper/Identification-of-PDGFR%CE%B1%2B-cells-in-uterine-fibroids-Aleksandrovych-Bereza/07a546e20150faefe25c0c9f04216387c92ad3fb",
            "/paper/Comparison-of-the-Behavior-of-Perivascular-Cells-in-D%C3%ADaz-Flores-Guti%C3%A9rrez/3e40fe76e9ec98524c4a4679bc68245d552662ce",
            "/paper/The-molecular-phenotypes-of-ureteral-telocytes-are-Dobra-Vrapciu/e650c229d10be2f8efd26d331b9d61690b5fc6d2",
            "/paper/Molecular-phenotypes-of-the-human-kidney%3A-Myoid-and-Rusu-Mogoant%C4%83/b7e342288904fb2fe6ae00bc74788e1872019d78",
            "/paper/Morphological-and-histochemical-identification-of-Yang-Yuan/e0ef656d51374c60f1a53b86eaaaa1e40d7a505a",
            "/paper/PV-1-expression-could-distinguish-the-subset-of-are-Vrapciu-Rusu/e6c3421dec53cbd708e5e94a0d3b2af59f507dc4",
            "/paper/Altered-Mucus-Barrier-Integrity-and-Increased-to-in-Nicol%C3%A1s-Allaire/a1c1c96dfa942c3715f1dcad32ac8206eda4fa4b",
            "/paper/Adaptive-changes-of-telocytes-in-the-urinary-of-by-Traini-Fausssone%E2%80%90Pellegrini/2ca11a3e5a4002123fa36a3ef50178af084e1141",
            "/paper/Human-resident-CD34%2B-stromal-cells-telocytes-have-a-D%C3%ADaz-Flores-Guti%C3%A9rrez/7f3ad99786e12be94fa64c9e80570094a0bfe77f",
            "/paper/Telocytes-as-a-Source-of-Progenitor-Cells-in-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/61005948f1f6946411a7059ac344d51147b0fb98",
            "/paper/Telocytes-in-regenerative-medicine-Bei-Wang/ac40123de90d564e110473a9ecb4f3b3f6a92daf",
            "/paper/Telocytes-Contribute-as-Cell-Progenitors-and-in-Vannucchi-Bani/0bf44839521120b5226aabd96d04d69d4b77edc1",
            "/paper/Circulating-Fibrocytes-Define-a-New-Leukocyte-That-Bucala-Spiegel/b4035a200c091a3210615ad01d8094138ffb43f1",
            "/paper/Identification-of-telocytes-in-skeletal-muscle-for-Popescu-Manole/73bd1e8c8e9e9bf418e798c12180326411b43b21",
            "/paper/Telocytes-and-Stem-Cells-Popescu-Nicolescu/0c17feadd55e3e0577e727a4dee4eae71c311d4b",
            "/paper/Telocytes-in-liver-regeneration%3A-possible-roles-Wang-Song/74dfb0fc01b7988a1df21343b961c59444db0df0",
            "/paper/Fibrocytes%3A-emerging-effector-cells-in-chronic-Reilkoff-Bucala/90e1449668fa6d4c82baa36dac58e52f928d7bf7",
            "/paper/Recruitment-of-CD34(%2B)-fibroblasts-in-reactive-the-Martin-Barron/62aad400e79196516af347c2841919bb023630c3"
        ]
    },
    {
        "id": "1fafff85108fc64f9fd3956ae2606992d81169de",
        "title": "Deep transfer learning techniques with hybrid optimization in early prediction and diagnosis of different types of oral cancer",
        "abstract": "Deep transfer learning algorithms were applied to non-malignant and oral cancerous photographs acquired from histopathologic and real-time datasets in this study to obtain optimal results and accuracy, loss, RMSE, precision, and AUC were used to analyze the findings. Oral cancer is a frequent and challenging cancer that has a high fatality rate. It is the fifth most common cancer in India, with 130,000 deaths each year. There are various diagnostic techniques for oral cancer, but they are limited to accurately detecting cancer cells. As a result, deep transfer learning algorithms such as ResNet50, MobileNetV2, VGG19, VGG16, and DenseNet were applied to non-malignant and oral cancerous photographs acquired from histopathologic and real-time datasets in this study. The images were first preprocessed with techniques like Gaussian blur to eliminate noise signals. Then, features were extracted with morphological operations to produce extreme points on the images, subsequently cropped. The retrieved pictures were fed into deep transfer learning models along with optimization techniques as ADAM, SGD, and RMSprop optimizers to obtain optimal results. Accuracy, loss, RMSE, precision, and AUC were used to analyze the findings. During the validation phase, the hybrid optimization techniques using ADAM, RMSprop, and SGD on DenseNet produced effective results, with accuracy of 92.41%, loss of 0.70, and RMSE of 0.29 for the real-time dataset, accuracy of 95.41%, loss of 0.10, and RMSE of 0.03 for oral cancer images, and accuracy of 92.41%, loss of 0.30, and RMSE of 0.09 for non-cancerous images taken from the histopathologic dataset.",
        "publication_year": "2022",
        "authors": [
            "Khushboo Bansal",
            "R. Bathla",
            "Yogesh Kumar"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "7",
        "reference_count": "51",
        "references": [
            "/paper/A-Comprehensive-Analysis-of-Deep-Learning-Based-for-Thakur-Kaur/9792bc635e7896642895d75aaf394f637ea29eac",
            "/paper/Impact-of-Image-Preprocessing-Methods-and-Deep-for-Murcia-G%C3%B3mez-Rojas-Valenzuela/fb52c9004eb8f2bef2d58df6febdba2f60d70b4f",
            "/paper/A-Review-of-Deep-Learning-Based-Approaches-for-and-Kumar-Kumar/0368dd7538b7245aca5133baff6bea4df228d152",
            "/paper/A-Comprehensive-Analysis-of-Artificial-Intelligence-Chaplot-Pandey/3a9ba7c482b4ff4141b54aa084bca766c5dfe6f6",
            "/paper/Classification-of-Oral-Squamous-Carcinoma-images-Saraswathi-Bhaskaran/010a56b4b2fe30785f30807ea672c5826501b9b6",
            "/paper/A-Review-of-Deep-Transfer-Learning-Approaches-for-Sisodia-Ameta/d05d27c7b4f639b104498d15aea0a90d65cbebce",
            "/paper/Diagnosis-and-Detection-of-Congenital-Diseases-in-A-Kaur-Singh/458e554fe0e5219e27aa75a39d28bc025912dadf",
            "/paper/Automatic-classification-and-detection-of-oral-in-Warin-Limprasert/a932aa4621106478255a5b1defd17236ca2e6c35",
            "/paper/Histopathological-Image-Analysis-for-Oral-Squamous-Amin-Zamir/629c3a99f0f62a12f8aee93aea9934bc61509335",
            "/paper/Deep-learning-neural-network-for-texture-feature-in-Bhandari-Alsadoon/f2d66eede760722f5b19e815ee01bfbb79d13794",
            "/paper/Transfer-Learning-for-Oral-Cancer-Detection-using-Palaskar-Vyas/65d5aa2c5a277332a03d984703c0af2b919992d1",
            "/paper/Automated-detection-of-oral-pre-cancerous-tongue-of-Shamim-Syed/395cc086fa298cf161bcf51a4bf8be02a647bc3f",
            "/paper/Classification-of-imbalanced-oral-cancer-image-data-Song-Li/ffae8af43cfa956ad10f4ca280d0e36e9b154d6a",
            "/paper/Computer-assisted-medical-image-classification-for-Jeyaraj-Nadar/11ded8e630c3d52bf3563c30b72cc06f6e66af7f",
            "/paper/Automated-Detection-and-Classification-of-Oral-Deep-Welikala-Remagnino/230b8255925d56b72444df3f358f5851b3158b59",
            "/paper/DEEPORCD%3A-Detection-of-Oral-Cancer-using-Deep-Dharani-Revathy/b9cda12ff13b1b78ebed18f8de8e005c1e9472bb",
            "/paper/A-Novel-Lightweight-Deep-Convolutional-Neural-for-Jubair-Al-karadsheh/a6ee87dc926e1ada80673d702c7de278e53682c9"
        ]
    },
    {
        "id": "057159cbdca99b6ad047cd63f8c53904eb07e8ca",
        "title": "MDA-Unet: A Multi-Scale Dilated Attention U-Net for Medical Image Segmentation",
        "abstract": "A model named MDA-Unet is proposed, a novel multi-scale deep learning segmentation model that improves upon U-Net and enhances its performance in segmenting medical images with variability in the shape and size of the region of interest. The advanced development of deep learning methods has recently made significant improvements in medical image segmentation. Encoder\u2013decoder networks, such as U-Net, have addressed some of the challenges in medical image segmentation with an outstanding performance, which has promoted them to be the most dominating deep learning architecture in this domain. Despite their outstanding performance, we argue that they still lack some aspects. First, there is incompatibility in U-Net\u2019s skip connection between the encoder and decoder features due to the semantic gap between low-processed encoder features and highly processed decoder features, which adversely affects the final prediction. Second, it lacks capturing multi-scale context information and ignores the contribution of all semantic information through the segmentation process. Therefore, we propose a model named MDA-Unet, a novel multi-scale deep learning segmentation model. MDA-Unet improves upon U-Net and enhances its performance in segmenting medical images with variability in the shape and size of the region of interest. The model is integrated with a multi-scale spatial attention module, where spatial attention maps are derived from a hybrid hierarchical dilated convolution module that captures multi-scale context information. To ease the training process and reduce the gradient vanishing problem, residual blocks are deployed instead of the basic U-net blocks. Through a channel attention mechanism, the high-level decoder features are used to guide the low-level encoder features to promote the selection of meaningful context information, thus ensuring effective fusion. We evaluated our model on 2 different datasets: a lung dataset of 2628 axial CT images and an echocardiographic dataset of 2000 images, each with its own challenges. Our model has achieved a significant gain in performance with a slight increase in the number of trainable parameters in comparison with the basic U-Net model, providing a dice score of 98.3% on the lung dataset and 96.7% on the echocardiographic dataset, where the basic U-Net has achieved 94.2% on the lung dataset and 93.9% on the echocardiographic dataset.",
        "publication_year": "2022",
        "authors": [
            "Alyaa Amer",
            "T. Lambrou",
            "Xujiong Ye"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "49",
        "references": [
            "/paper/TiM-Net%3A-Transformer-in-M-Net-for-Retinal-Vessel-Zhang-Zhong/aed671e50e5d1ef8f8b05d8b0d04cb6e5aa2439e",
            "/paper/A-Review-on-Multiscale-Deep-Learning-Applications-Elizar-Zulkifley/01316758ddfd43096fb092268c56bcb4215d59e3",
            "/paper/Feature-fusion-and-optimization-integrated-refined-Dayana-Emmanuel/008212081ea839e0681f8d2ea16fd34237151a85",
            "/paper/MSCAUNet-3D%3A-Multiscale-Spatial-Channel-Attention-Poonkodi-Kanchana/08f4fd40a4f1c01f7fcbdabc754a2b1e4c696314",
            "/paper/A-hybrid-deep-learning-approach-for-detection-and-Maria-Jossy/4ee07fe9a00163993ac16829b0100d5c947ba132",
            "/paper/A-Survey-on-Attention-Mechanisms-for-Medical-are-we-Gon%C3%A7alves-Rio-Torto/41b6cc4acedea461646ea85426f4f750a753a33b",
            "/paper/Deep-Learning-Based-Auricular-Point-Localization-Sun-Dong/db85506a2c1cce507327fcf37fc5bd848894013b",
            "/paper/Do-you-need-sharpened-details-Asking-MMDC-Net%3A-for-Zhong-Zhang/870c5ca509f73bd7576195bc53b10732d868a63b",
            "/paper/UNet-3%2B%3A-A-Full-Scale-Connected-UNet-for-Medical-Huang-Lin/0b444f74dd9cc06c2833dd15f9258ef5e169e6ea",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/UNet%2B%2B%3A-Redesigning-Skip-Connections-to-Exploit-in-Zhou-Siddiquee/42b0a8f757e45462e627e57f9af7e9849dcdacdf",
            "/paper/SCAU-Net%3A-Spatial-Channel-Attention-U-Net-for-Gland-Zhao-Zhang/f3ec8c29a34d0cc1bb7c7892ba4cae86347914e8",
            "/paper/Residual-Dilated-U-net-For-The-Segmentation-Of-From-Amer-Ye/7f56fd54d19d37e23ea96f94e956bb5e9c06e952",
            "/paper/SA-UNet%3A-Spatial-Attention-U-Net-for-Retinal-Vessel-Guo-Szemenyei/557180b3ec281593cf4d7088c735316ab3405a8b",
            "/paper/Recurrent-Residual-Convolutional-Neural-Network-on-Alom-Hasan/27c761258329eddb90b64d52679ff190cb4527b5",
            "/paper/ASCU-Net%3A-Attention-Gate%2C-Spatial-and-Channel-U-Net-Tong-Wei/14764f61e66f0e78f2c9a47b45c77a09bb068755",
            "/paper/DA-Capnet%3A-Dual-Attention-Deep-Learning-Based-on-Hariyani-Eom/dc9c60de646b3ae8b3220089ec3a5d891633d3ae",
            "/paper/Deep-Learning-for-Segmentation-Using-an-Open-in-2D-Leclerc-Smistad/82b46dd7c67b17dfc34b10b4e7db6f8391cd4886"
        ]
    },
    {
        "id": "6e22b09ce6a67377a2463c271f94295edf69f886",
        "title": "Life Regression based Patch Slimming for Vision Transformers",
        "abstract": "This study tackles the patch slimming problem from a different perspective by proposing a life regression module that determines the lifespan of each image patch in one go to enhance inference speed while maintaining competitive performance. Vision transformers have achieved remarkable success in computer vision tasks by using multi-head self-attention modules to capture long-range dependencies within images. However, the high inference computation cost poses a new challenge. Several methods have been proposed to address this problem, mainly by slimming patches. In the inference stage, these methods classify patches into two classes, one to keep and the other to discard in multiple layers. This approach results in additional computation at every layer where patches are discarded, which hinders inference acceleration. In this study, we tackle the patch slimming problem from a different perspective by proposing a life regression module that determines the lifespan of each image patch in one go. During inference, the patch is discarded once the current layer index exceeds its life. Our proposed method avoids additional computation and parameters in multiple layers to enhance inference speed while maintaining competitive performance. Additionally, our approach requires fewer training epochs than other patch slimming methods.",
        "publication_year": "2023",
        "authors": [
            "Jiawei Chen",
            "Lin Chen",
            "Jianguo Yang",
            "Tianqi Shi",
            "Lechao Cheng",
            "Zunlei Feng",
            "Min-Gyoo Song"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "28",
        "references": [
            "/paper/IA-RED2%3A-Interpretability-Aware-Redundancy-for-Pan-Jiang/e2f2662f0734e2edc2b4b36a734de111c7f8d54d",
            "/paper/EAPT%3A-Efficient-Attention-Pyramid-Transformer-for-Lin-Sun/eb36750a31af99baf22ed01d0b8c24d9ff550b40",
            "/paper/DilateFormer%3A-Multi-Scale-Dilated-Transformer-for-Jiao-Tang/0cd526723b87ae37981922992992d203448a2014",
            "/paper/Width-%26-Depth-Pruning-for-Vision-Transformers-Yu-Huang/d451901a6a12c61179289cac7a4588a86c234112",
            "/paper/A-ViT%3A-Adaptive-Tokens-for-Efficient-Vision-Yin-Vahdat/c2a0c18e810535db52e5ebaf180c64ce70356748",
            "/paper/Bottleneck-Transformers-for-Visual-Recognition-Srinivas-Lin/16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78",
            "/paper/DynamicViT%3A-Efficient-Vision-Transformers-with-Rao-Zhao/dbdcabd0444ad50b68ee09e30f39b66e9068f5d2",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/Vision-Transformer-Pruning-Zhu-Tang/93efaf8c27940aaef145d8bcbca957be634d26e5",
            "/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7"
        ]
    },
    {
        "id": "458e5d02c0612deae07e5fb241179b52429a81d4",
        "title": "MLSLT: Towards Multilingual Sign Language Translation",
        "abstract": "MLLT is proposed, the first MSLT model, which contains two novel dy-namic routing mechanisms for controlling the degree ofpa-rameter sharing between different languages and shows that the average performance of ML-SLT outperforms the baseline MS LT model and the com-bination of multiple BSLT models in many cases. Most of the research to date focuses on bilingual sign language translation (BSLT). However, such models are in-efficient in building multilingual sign language translation systems. To solve this problem, we introduce the multilin-gual sign language translation (MSLT) task. It aims to use a single model to complete the translation between multiple sign languages and spoken languages. Then, we propose MLSLT, the first MSLT model, which contains two novel dy-namic routing mechanisms for controlling the degree ofpa-rameter sharing between different languages. Intra-layer language-specific routing controls the proportion of data flowing through shared parameters and language-specific parameters from the token level through a soft gate within the layer, and inter-layer language-specific routing controls and learns the data flow path of different languages at the language level through a soft gate between layers. In order to evaluate the performance of MLSLT, we collect the first publicly available multilingual sign language understanding dataset, Spreadthesign-Ten (SP-10), which contains up to 100 language pairs, e.g., CSL\u2192en, GSG\u2192zh. Experi-mental results show that the average performance of ML-SLT outperforms the baseline MSLT model and the com-bination of multiple BSLT models in many cases. In ad-dition, we also explore zero-shot translation in sign language and find that our model can achieve comparable performance to the supervised BSLT model on some language pairs. Dataset and more details are at https://mlslt.github.io/.",
        "publication_year": "2022",
        "authors": [
            "Aoxiong Yin",
            "Zhou Zhao",
            "Weike Jin",
            "Meng Zhang",
            "Xingshan Zeng",
            "Xiaofei He"
        ],
        "related_topics": [
            "Computer Science",
            "Linguistics"
        ],
        "citation_count": "5",
        "reference_count": "55",
        "references": [
            "/paper/Clean-Text-and-Full-Body-Transformer%3A-Microsoft%E2%80%99s-Dey-Pal/53e4247f7743767f39805573c71b820651335d89",
            "/paper/Natural-Language-Assisted-Sign-Language-Recognition-Zuo-Wei/6648bbbb7ad41397d315d1c83ac02a39ac875b19",
            "/paper/OpenSR%3A-Open-Modality-Speech-Recognition-via-Cheng-Jin/abac1f1f876d2cc332830bdf705ba5e8d7f92313",
            "/paper/TranSpeech%3A-Speech-to-Speech-Translation-With-Huang-Zhao/08e8f6ad2c7f83ff04c6ef416fbb288976b1a890",
            "/paper/DATE%3A-Domain-Adaptive-Product-Seeker-for-E-commerce-Li-Jiang/bc110959a69fad8e0db611bb5710193226fdd31e",
            "/paper/Improving-Sign-Language-Translation-with-Data-by-Zhou-Zhou/7811df11a75f58646d04b3132d35f0656e50a109",
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/SimulSLT%3A-End-to-End-Simultaneous-Sign-Language-Yin-Zhao/d3d784b07fd4a444d11ac753e36964767214d667",
            "/paper/Share-or-Not-Learning-to-Schedule-Language-Specific-Zhang-Bapna/940214c9afde6664127ba552de2ac8fa67997769",
            "/paper/Neural-Sign-Language-Translation-by-Learning-Orbay-Akarun/4e39e59f41a480f68c934cc38eb874a25ceb5073",
            "/paper/Sign-language-recognition-with-long-short-term-Liu-Zhou/5c32fa84747c4b9d0cf63ee038dddae644ac53e0",
            "/paper/On-Learning-Universal-Representations-Across-Wei-Hu/311909621177c397c6b7099beff32332124f7d46",
            "/paper/Google%E2%80%99s-Multilingual-Neural-Machine-Translation-Johnson-Schuster/a486e2839291111bb44fa1f07731ada123539f75"
        ]
    },
    {
        "id": "57c61a12a9a152ca3641785234dc1477844e39b8",
        "title": "Brain tumor segmentation using synthetic MR images - A comparison of GANs and diffusion models",
        "abstract": "This work comprehensively evaluates four GANs (progressive GAN, StyleGAN 1-3) and a diffusion model and shows that segmentation networks trained on synthetic images reach Dice scores that are 80\\% - 90\\% of Dice scores when training with real images, but that memorization of the training images can be a problem for diffusion models if the original dataset is too small. Large annotated datasets are required for training deep learning models, but in medical imaging data sharing is often complicated due to ethics, anonymization and data protection legislation (e.g. the general data protection regulation (GDPR)). Generative AI models, such as generative adversarial networks (GANs) and diffusion models, can today produce very realistic synthetic images, and can potentially facilitate data sharing as GDPR should not apply for medical images which do not belong to a specific person. However, in order to share synthetic images it must first be demonstrated that they can be used for training different networks with acceptable performance. Here, we therefore comprehensively evaluate four GANs (progressive GAN, StyleGAN 1-3) and a diffusion model for the task of brain tumor segmentation. Our results show that segmentation networks trained on synthetic images reach Dice scores that are 80\\% - 90\\% of Dice scores when training with real images, but that memorization of the training images can be a problem for diffusion models if the original dataset is too small. Furthermore, we demonstrate that common metrics for evaluating synthetic images, Fr\\'echet inception distance (FID) and inception score (IS), do not correlate well with the obtained performance when using the synthetic images for training segmentation networks.",
        "publication_year": "2023",
        "authors": [
            "M. U. Akbar",
            "Maans Larsson",
            "A. Eklund"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "45",
        "references": [
            "/paper/Medical-Image-Synthesis-for-Data-Augmentation-and-Shin-Tenenholtz/37a052144b510b8827634c38146b190d8b2c8d0b",
            "/paper/Can-Segmentation-Models-Be-Trained-with-Fully-Data-Fernandez-Pinaya/ce62ee331a43338ccaad0461faa0dfbe5db3d6a2",
            "/paper/SinGAN-Seg%3A-Synthetic-training-data-generation-for-Thambawita-Salehi/419100bc2f2035198e1ed55ffa632a535c16a2fa",
            "/paper/DiffuseExpand%3A-Expanding-dataset-for-2D-medical-Shao-Yuan/7fc23bc11fde815b7735b115ffe5c57ff0d6cc93",
            "/paper/GAN-based-Synthetic-Medical-Image-Augmentation-for-Frid-Adar-Diamant/0597aba86088282423e7c2d2deb6fca4075e7a91",
            "/paper/GAN-Augmentation%3A-Augmenting-Training-Data-using-Bowles-Chen/003ec88cbec156131058e53409115cd056057644",
            "/paper/Breast-cancer-detection-using-synthetic-mammograms-Guan-Loew/30f2d1fc88e3e1362ff4bda44d1f521841c6bea4",
            "/paper/Does-an-ensemble-of-GANs-lead-to-better-performance-Larsson-Akbar/7d638720991f354497a9e50a1d6d61d4b1d53a2f",
            "/paper/Ensembles-of-GANs-for-synthetic-training-data-Eilertsen-Tsirikoglou/ebfa2827fc65c69b9dbfcb8aed861785b7cbb69a",
            "/paper/Beware-of-diffusion-models-for-synthesizing-medical-Akbar-Wang/1987ee6b983fd2d082e0555e21909978c41d9c8f"
        ]
    },
    {
        "id": "aae4ec3b514ad67e28a563d7801b98b4426a83a5",
        "title": "Retinal Vascular Image Segmentation Using Improved UNet Based on Residual Module",
        "abstract": "This study proposes a machine learning architecture designed to segment images of retinal blood vessels based on an improved U-Net neural network model that incorporates a residual module to extract features more effectively, and includes a full-scale skip connection to combine low level details with high-level features at different scales. In recent years, deep learning technology for clinical diagnosis has progressed considerably, and the value of medical imaging continues to increase. In the past, clinicians evaluated medical images according to their individual expertise. In contrast, the application of artificial intelligence technology for automatic analysis and diagnostic assistance to support clinicians in evaluating medical information more efficiently has become an important trend. In this study, we propose a machine learning architecture designed to segment images of retinal blood vessels based on an improved U-Net neural network model. The proposed model incorporates a residual module to extract features more effectively, and includes a full-scale skip connection to combine low level details with high-level features at different scales. The results of an experimental evaluation show that the model was able to segment images of retinal vessels accurately. The proposed method also outperformed several existing models on the benchmark datasets DRIVE and ROSE, including U-Net, ResUNet, U-Net3+, ResUNet++, and CaraNet.",
        "publication_year": "2023",
        "authors": [
            "Ko-Wei Huang",
            "Yao Yang",
            "Ziwen Huang",
            "Yi-yang Liu",
            "Shih-Hsiung Lee"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "55",
        "references": [
            "/paper/CaraNet%3A-context-axial-reverse-attention-network-of-Lou-Guan/97326c0468e4e412630b4db7cea9d0f8ac4dc475",
            "/paper/Deep-ensemble-learning-for-accurate-retinal-vessel-Du-Liu/066891143bc4975efecfcc4263089df37346736e",
            "/paper/Retinal-disease-prediction-through-blood-vessel-and-Kumar-Singh/ec41dcec1f4ed3fd49686d850ebc93d91e683452",
            "/paper/UIU-Net%3A-U-Net-in-U-Net-for-Infrared-Small-Object-Wu-Hong/77ccb7485bcec1d3fc732b19717b69b3c779339d",
            "/paper/An-attention-residual-u-net-with-differential-and-Mu-Lyu/c2f5914412b6e10b6f2e847e27392d5c3435c407",
            "/paper/An-effective-CNN-and-Transformer-complementary-for-Yuan-Zhang/fa78a6ed2fa66688b1fe5eb18c635a4850fab20f",
            "/paper/Volumetric-memory-network-for-interactive-medical-Zhou-Li/f2c899599e11ec7c503e7d1a9f07930c8d1d7f96",
            "/paper/Edge-U-Net%3A-Brain-Tumor-Segmentation-using-MRI-on-Allah-Sarhan/318a7d2ce087462fbb0ad6378219f493a9c5bd58",
            "/paper/A-novel-framework-for-retinal-vessel-segmentation-Mahapatra-Agrawal/7e89b3f074e7928541ab6d3da5fe1d9802dc0119",
            "/paper/Retinal-vessel-image-segmentation-algorithm-based-Zhai-Feng/039259f77d4bfc148fa67b80179f5a45bbf96801"
        ]
    },
    {
        "id": "e9f42702f018cc45ae185e61cc47a6950f55ab0a",
        "title": "Prospective Study of Disease-Specific Quality-of-Life in Sporadic Vestibular Schwannoma Comparing Observation, Radiosurgery, and Microsurgery",
        "abstract": "Treatment did not modify quality of life outcomes among VS treatment groups using the disease-specific PANQOL instrument, and microsurgery may confer an advantage with regard to patient anxiety, presumably relating to the psychological benefit of \"cure\" from having the tumor removed. Background: Previous cross-sectional studies analyzing quality of life (QOL) outcomes in patients with sporadic vestibular schwannoma (VS) have shown surprisingly little difference among treatment modalities. To date, there is limited prospective QOL outcome data available comparing baseline to posttreatment scores. Study Design: Prospective longitudinal study using the disease-specific Penn Acoustic Neuroma Quality of Life (PANQOL) scale. Setting: Large academic skull base center. Patients: Patients diagnosed with unilateral VS who completed a baseline survey before treatment and at least one posttreatment survey. Main Outcome Measures: Change in PANQOL scores from baseline to most recent survey. Results: A total of 244 patients were studied, including 78 (32%) who elected observation, 118 (48%) microsurgery, and 48 (20%) stereotactic radiosurgery. Patients who underwent microsurgery were younger (p\u200a<\u200a0.001) and had larger tumors (p\u200a<\u200a0.001) than those who underwent observation or radiosurgery; there was no significant difference in duration of follow-up among management groups (mean 2.1 yrs; p\u200a=\u200a0.28). When comparing the total PANQOL score at baseline to the most recent survey, the net change was only \u20131.1, \u20130.1, and 0.3 points on a 100-point scale for observation, microsurgery, and radiosurgery, respectively (p\u200a=\u200a0.89). After multivariable adjustment for baseline features, there were no statistically significant changes when comparing baseline to most recent scores within each management group for facial function, general health, balance, hearing loss, energy, and pain domains or total score. However, the microsurgical group experienced a 10.8-point improvement (p\u200a=\u200a0.002) in anxiety following treatment, compared with 1.5 (p\u200a=\u200a0.73) and 5.3 (p\u200a=\u200a0.31) for observation and radiosurgery, respectively. Conclusions: In this prospective longitudinal study investigating differences in QOL outcomes among VS treatment groups using the disease-specific PANQOL instrument, treatment did not modify QOL in most domains. Microsurgery may confer an advantage with regard to patient anxiety, presumably relating to the psychological benefit of \u201ccure\u201d from having the tumor removed.",
        "publication_year": "2020",
        "authors": [
            "M. Carlson",
            "Jason H. Barnes",
            "A. Nassiri",
            "Neil S. Patel",
            "Nicole Tombers",
            "C. Lohse",
            "J. V. Van Gompel",
            "B. Neff",
            "C. Driscoll",
            "M. Link"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "17",
        "reference_count": "33",
        "references": [
            "/paper/Impact-of-Treatment-on-Vestibular-Symptoms%3A-A-Study-Barnes-Patel/8703994d245dff6d27a5992dfad23ee8ce4a8ead",
            "/paper/Comparing-Patient-Satisfaction-After-Upfront-Versus-Nassiri-Lohse/5e91322f10a0a19d24221bbd27da3a820424405c",
            "/paper/Development-and-validation-of-a-new-quality-of-life-Carlson-Lohse/41455cb3511505e8abadec3f21c8d3ea6b793222",
            "/paper/Vestibular-Complaints-Impact-on-the-Long-Term-of-of-Fuentealba-Bassaletti-Neve/16713ba75cf3e5f4e21aef525f5ff6f77093c52c",
            "/paper/Hearing-Preservation-in-Observed-Sporadic-A-Review-Khandalavala-Saba/68d83b6bbb5c1087d67f5556babeadbfe3901097",
            "/paper/Single-fraction-stereotactic-radiosurgery-versus-of-Jakubeit-Sturtz/0996ec7cbe04d1d3e1529623363acf7435ae69e2",
            "/paper/Outcomes-of-Initial-Observation-Versus-Upfront-for-Patro-Totten/af300b2cddf9978cd63097bb2e27f22a7ef202ce",
            "/paper/Association-of-extent-of-resection-on-survival-and-Wang-Machetanz/ef88cfadf2cf02dd7829c2736bf1585028632bf8",
            "/paper/A-Subset-of-Intracanalicular-Vestibular-Schwannomas-Wu-Knoll/f8878abc4f61fbc066ec0144f7a32de97c3c4d9f",
            "/paper/Lifetime-Cost-and-Quality-Adjusted-Life-Years-for-Macielak-Thao/f687510a7f8d3907acfd564b81fb326cd627769f",
            "/paper/Long-term-quality-of-life-in-patients-with-an-study-Carlson-Tveiten/d571627b938399be35a8268c6f743d03a9fe95ed",
            "/paper/Quality-of-Life-in-Vestibular-Schwannoma-Patients%3A-Miller-Brant/b2e58514f52bf0e5705c362c24a02e131ef2a7f4",
            "/paper/Prospective-comparison-of-quality-of-life-before-or-Maio-Akagami/81394e40bbb59ebcccae4a010e1332c1e2adc806",
            "/paper/Comparison-of-Long-term-Quality-of-Life-Outcomes-in-Robinett-Walz/40698b032912d301afa310e05e5b7409a6dd3660",
            "/paper/Quality-of-Life-in-807-Patients-with-Vestibular-Soulier-Leeuwen/aa88fa15f92cdd413c481162b7cad303acd8dc4c",
            "/paper/The-Impact-of-Primary-Treatment-Strategy-on-the-of-Foley-Maweni/7c5abd0cf656ed48db39c27f4f4cefc6d8801ef0",
            "/paper/Quality-of-Life-in-Patients-With-Vestibular-to-Kim-Roh/7e0b9ebd83643d91e3997a5a83fa43acc5ae4bf2",
            "/paper/Systematic-review-of-quality-of-life-in-the-of-Gauden-Weir/ea2e2bd633917f823eba2f100acfe1df9b41edcd",
            "/paper/Patient-outcomes-after-vestibular-schwannoma-a-of-Pollock-Driscoll/1bbc5e671591c1d74a9deb165bf0a575104b2e0a",
            "/paper/The-Effect-of-Observation-versus-Microsurgical-on-A-Sandooram-Hornigold/f92e32c7df9eca8b10bbd1df7b3ab660b241cfb6"
        ]
    },
    {
        "id": "0568673ea1e8b749cb7be7338f4ad7fbb756ca4b",
        "title": "RSAP-Net: joint optic disc and cup segmentation with a residual spatial attention path module and MSRCR-PT pre-processing algorithm",
        "abstract": "A new encoder\u2013decoder segmentation structure, called RSAP-Net, for joint segmentation of OD and OC, which incorporates a multi-scale Retinex colour recovery algorithm and a polar coordinate transformation to produce more refined boundaries of the optic disc and the optic cup. Background Glaucoma can cause irreversible blindness to people\u2019s eyesight. Since there are no symptoms in its early stage, it is particularly important to accurately segment the optic disc (OD) and optic cup (OC) from fundus medical images for the screening and prevention of glaucoma. In recent years, the mainstream method of OD and OC segmentation is convolution neural network (CNN). However, most existing CNN methods segment OD and OC separately and ignore the a priori information that OC is always contained inside the OD region, which makes the segmentation accuracy of most methods not high enough. Methods This paper proposes a new encoder\u2013decoder segmentation structure, called RSAP-Net, for joint segmentation of OD and OC. We first designed an efficient U-shaped segmentation network as the backbone. Considering the spatial overlap relationship between OD and OC, a new Residual spatial attention path is proposed to connect the encoder\u2013decoder to retain more characteristic information. In order to further improve the segmentation performance, a pre-processing method called MSRCR-PT (Multi-Scale Retinex Colour Recovery and Polar Transformation) has been devised. It incorporates a multi-scale Retinex colour recovery algorithm and a polar coordinate transformation, which can help RSAP-Net to produce more refined boundaries of the optic disc and the optic cup. Results The experimental results show that our method achieves excellent segmentation performance on the Drishti-GS1 standard dataset. In the OD and OC segmentation effects, the F1 scores are 0.9752 and 0.9012, respectively. The BLE are 6.33 pixels and 11.97 pixels, respectively. Conclusions This paper presents a new framework for the joint segmentation of optic discs and optic cups, called RSAP-Net. The framework mainly consists of a U-shaped segmentation skeleton and a residual space attention path module. The design of a pre-processing method called MSRCR-PT for the OD/OC segmentation task can improve segmentation performance. The method was evaluated on the publicly available Drishti-GS1 standard dataset and proved to be effective.",
        "publication_year": "2022",
        "authors": [
            "Yun Jiang",
            "Zeqi Ma",
            "Chao Wu",
            "Zequn Zhang",
            "Wei Yan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "52",
        "references": [
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/An-Efficient-Hierarchical-Optic-Disc-and-Cup-with-Wang-Yu/ef345a62e9a05263eb2a495af845d7f41e0774d0",
            "/paper/Patch-Based-Output-Space-Adversarial-Learning-for-Wang-Yu/ba62442fc88eb4da204e98899214c45960341fa5",
            "/paper/Joint-optic-disc-and-optic-cup-segmentation-based-Luo-Xue/52291fecbeb1af12bfcd0987487c50406edee5d0",
            "/paper/Joint-segmentation-of-optic-cup-and-optic-disc-deep-Yu/5c855f76c36d82ff70399fc8247bef346ba443a2",
            "/paper/Ellipse-Detection-of-Optic-Disc-and-Cup-Boundary-in-Wang-Dong/19f5bba735f71831bfbe83e1ee385e3c0d8db902",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Using-Fully-Shankaranarayana-Ram/c8eec916ea6e6d2a57a0d9ca29c9b95525b53314",
            "/paper/High-Performance-Optic-Disc-Segmentation-Using-Mohan-Kumar/0f1ea968782fec91658677139c7905dfa866f2d9",
            "/paper/JointRCNN%3A-A-Region-Based-Convolutional-Neural-for-Jiang-Duan/928d7e118bba3518dc3d40b182481655fcad15df",
            "/paper/Dynamic-Region-Proposal-Networks-For-Semantic-In-Shah-Kasukurthi/5dad30cb489818245f05c9691af25981de00aa6b"
        ]
    },
    {
        "id": "7a9057c5e91e7fe3611b80df10f4911ba0e56b87",
        "title": "Deep Learning and Its Applications to WiFi Human Sensing: A Benchmark and A Tutorial",
        "abstract": "A benchmark, SenseFi, is proposed to study the effectiveness of various deep learning models for WiFi sensing, and is believed to be the first benchmark with an open-source library for deep learning in WiFi sensing research. \u2014WiFi sensing has been evolving rapidly in recent years. Empowered by propagation models and deep learning methods, many challenging applications are realized such as WiFi-based human activity recognition and gesture recognition. However, in contrast to deep learning for visual recognition and natural language processing, no suf\ufb01ciently comprehensive public benchmark exists. In this paper, we review the recent progress on deep learning enabled WiFi sensing, and then propose a benchmark, SenseFi, to study the effectiveness of various deep learning models for WiFi sensing. These advanced models are compared in terms of distinct sensing tasks, WiFi platforms, recognition accuracy, model size, computational complexity, feature transferability, and adaptability of unsupervised learning. It is also regarded as a tutorial for deep learning based WiFi sensing, starting from CSI hardware platform to sensing algorithms. The extensive experiments provide us with experiences in deep model design, learning strategy skills and training techniques for real- world applications. To the best of our knowledge, this is the \ufb01rst benchmark with an open-source library for deep learning in WiFi sensing research. The benchmark codes are available at https://github.com/xyanchen/WiFi-CSI-Sensing-Benchmark.",
        "publication_year": "2022",
        "authors": [
            "Jianfei Yang",
            "Xinyan Chen",
            "Dazhuo Wang",
            "Han Zou",
            "Chris Xiaoxuan Lu",
            "Sumei Sun",
            "Lihua Xie"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "8",
        "reference_count": "114",
        "references": [
            "/paper/AirFi%3A-Empowering-WiFi-based-Passive-Human-Gesture-Wang-Yang/e939719b2a66bbaddd74ed139970e5a7e0b5f3cd",
            "/paper/GaitFi%3A-Robust-Device-Free-Human-Identification-via-Deng-Yang/8d626c5a879501b29b50cd60f17ba8d0d5f64bab",
            "/paper/WiTransformer%3A-A-Novel-Robust-Gesture-Recognition-Yang-Zhu/97f287a817355ec4f3f864edb18070dd5a5379ae",
            "/paper/Passive-Sensing-for-Class-Incremental-Human-Ding-Zhong/9536bbdabda55e299e0583fb48d41d2605483e94",
            "/paper/VariFi%3A-Variational-Inference-for-Indoor-Pedestrian-Huang-Yang/b12c7c4125d442fc9fc7c6f7509ff8ce6fd274af",
            "/paper/MM-Fi%3A-Multi-Modal-Non-Intrusive-4D-Human-Dataset-Yang-Huang/3dc7fb0dc1310c4766967be14bb53fc23abda932",
            "/paper/SecureSense%3A-Defending-Adversarial-Attack-for-Human-Yang-Zou/b5c2b952e0bd42086644cdf12d1f6910720a76dd",
            "/paper/SiMWiSense%3A-Simultaneous-Multi-Subject-Activity-Haque-Zhang/ee3432bc0586b19b8c576292b0d5b0c5e45a395f",
            "/paper/WiFi-and-Vision-Multimodal-Learning-for-Accurate-Zou-Yang/e9e01af30f1507555008f4b0a1b83ea2debe6f19",
            "/paper/AutoFi%3A-Towards-Automatic-WiFi-Human-Sensing-via-Yang-Chen/2a1ea90a71131275685d815daa9c5c40208f9c9f",
            "/paper/TransferSense%3A-towards-environment-independent-and-Bu-Ming/00ac1ffc1f0bfd1a4598d143064c323c577df67a",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/On-Spatial-Diversity-in-WiFi-Based-Human-Activity-A-Wang-Gong/12d30796c1f4432ec287426841d3e357809eae52",
            "/paper/Learning-Gestures-From-WiFi%3A-A-Siamese-Recurrent-Yang-Zou/a6d087332d4cadd9a90c8c4aa2c122413033cd9d",
            "/paper/EfficientFi%3A-Toward-Large-Scale-Lightweight-WiFi-Yang-Chen/7fba53b652d920b3bcb71893814d336150335c66",
            "/paper/WiFi-CSI-Based-Human-Activity-Recognition-Using-Ding-Wang/8024433b38c8051c25b811bcf9b543e1c73f3a29",
            "/paper/CSI-Based-Human-Activity-Recognition-using-Neural-Moshiri-Nabati/4406d6b8810965d31b721d59255305d5430b55ef",
            "/paper/Leveraging-Transfer-Learning-in-Multiple-Human-WiFi-Arshad-Feng/8c2f2972518f5dafcd2ca1bcbcbb9ccdf31d918a"
        ]
    },
    {
        "id": "2e6088d5f1081f2b46295d8783a5c2642ec35041",
        "title": "Video anomaly detection with spatio-temporal dissociation",
        "abstract": "Semantic Scholar extracted view of \"Video anomaly detection with spatio-temporal dissociation\" by Y. Chang et al.",
        "publication_year": "2022",
        "authors": [
            "Y. Chang",
            "Zhigang Tu",
            "Wei Xie",
            "B. Luo",
            "Shifu Zhang",
            "H. Sui",
            "Junsong Yuan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "45",
        "reference_count": "63",
        "references": [
            "/paper/Exploiting-Spatial-temporal-Correlations-for-Video-Zhao-Liu/0548c96de57f8fad3053be706e094320e14c10ec",
            "/paper/Bidirectional-Spatio-Temporal-Feature-Learning-With-Zhong-Chen/9e875a417b411bc2923db87cc1b80df4b705bc1c",
            "/paper/Learning-Graph-Enhanced-Spatial-Temporal-Coherence-Cheng-Liu/e6dec25eead54db490aa80a7f2ee36d0139c98b5",
            "/paper/A-New-Unsupervised-Video-Anomaly-Detection-Using-Taghinezhad-Yazdi/6b1c013e1de3346c4cfe1da631be1a5f61f044c1",
            "/paper/Unsupervised-video-anomaly-detection-via-flows-with-Cho-Kim/e4b4349d19124be609622b75585d158055c1a0b3",
            "/paper/Configurable-Spatial-Temporal-Hierarchical-Analysis-Cheng-Zeng/8acf1ec907ad22d57c1dbba18d9d4ab2b1d1543e",
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/OSIN%3A-Object-Centric-Scene-Inference-Network-for-Liu-Guo/e4e6f0afca17f79dc7a1ab671ab5ad448e97ae7d",
            "/paper/Attention-based-residual-autoencoder-for-video-Le-Kim/770c840fe25e4c09405529c639f1fcf0a1b245ea",
            "/paper/Bi-directional-Frame-Interpolation-for-Unsupervised-Deng-Zhang/d7de9df4dd7c579651c4b4189cfda6810d2cf032",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/Detecting-anomalous-events-in-videos-by-learning-of-Xu-Yan/e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Learning-Regularity-in-Skeleton-Trajectories-for-in-Morais-Le/db20d81d40243d66ff90f11b5c6f058d43d3701f",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/Learning-Temporal-Regularity-in-Video-Sequences-Hasan-Choi/97e7c94a78ae17cfb90848c1cfca8c431082a7b2",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Anomaly-detection-in-crowded-scenes-Mahadevan-Li/9d3f0d47449c7db37d1bae3b70db2928610a8db7"
        ]
    },
    {
        "id": "b72d0d2c024688202952f3007298a9cf68688eaf",
        "title": "Unsupervised Deep Joint Segmentation of Multitemporal High-Resolution Images",
        "abstract": "This article proposes a novel method that processes multitemporal images by separately feeding to a deep network comprising of trainable convolutional layers and extended the proposed joint segmentation method for change detection (CD) and tested on a VHR multisensor data set from Trento. High/very-high-resolution (HR/VHR) multitemporal images are important in remote sensing to monitor the dynamics of the Earth\u2019s surface. Unsupervised object-based image analysis provides an effective solution to analyze such images. Image semantic segmentation assigns pixel labels from meaningful object groups and has been extensively studied in the context of single-image analysis, however not explored for multitemporal one. In this article, we propose to extend supervised semantic segmentation to the unsupervised joint semantic segmentation of multitemporal images. We propose a novel method that processes multitemporal images by separately feeding to a deep network comprising of trainable convolutional layers. The training process does not involve any external label, and segmentation labels are obtained from the argmax classification of the final layer. A novel loss function is used to detect object segments from individual images as well as establish a correspondence between distinct multitemporal segments. Multitemporal semantic labels and weights of the trainable layers are jointly optimized in iterations. We tested the method on three different HR/VHR data sets from Munich, Paris, and Trento, which shows the method to be effective. We further extended the proposed joint segmentation method for change detection (CD) and tested on a VHR multisensor data set from Trento.",
        "publication_year": "2020",
        "authors": [
            "Sudipan Saha",
            "Lichao Mou",
            "C. Qiu",
            "Xiaoxiang Zhu",
            "F. Bovolo",
            "L. Bruzzone"
        ],
        "related_topics": [
            "Environmental Science",
            "Computer Science"
        ],
        "citation_count": "36",
        "reference_count": "48",
        "references": [
            "/paper/Segmentation-of-VHR-EO-Images-using-Unsupervised-Saha-Mou/66a22af50a42f1705533fa2845eb632313876c27",
            "/paper/A-Novel-Multitemporal-Deep-Fusion-Network-(MDFN)-HR-Zheng-Liu/158506c9db9ec99ef23675bb6b289673009b38fc",
            "/paper/DEEP-NO-LEARNING-APPROACH-FOR-UNSUPERVISED-CHANGE-Saha-Kondmann/57dfb9302e930d8bf6f7c26b87e5b82431bf79dc",
            "/paper/Change-detection-for-multispectral-images-using-Su-Xie/03e425482988a0a2fceb245c6c373a2e3c841ac0",
            "/paper/Unsupervised-Single-Scene-Semantic-Segmentation-for-Saha-Shahzad/5986dbda3e05745595670a9f8e64944b10e9cb8f",
            "/paper/Progressive-Unsupervised-Deep-Transfer-Learning-for-Ahmed-Saha/33e24619010c833beb08d2df38cf28bafa650f8d",
            "/paper/ClassHyPer%3A-ClassMix-Based-Hybrid-Perturbations-for-He-Wang/2b85527d066dd4475724d190943196c053495c5d",
            "/paper/Improving-Spatial-Resolution-of-Satellite-Imagery-Karwowska-Wierzbicki/6870c750ac03576a82e23f238227015aa596434a",
            "/paper/Multitemporal-Intrinsic-Image-Decomposition-With-Gao-Liu/18f123410c49dd3b8cf162d527c868e4e40e2564",
            "/paper/Mitigating-Spatial-and-Spectral-Differences-for-and-Prexl-Saha/074e0ae7b19af435c9486392d68855dc6132d619",
            "/paper/Semantic-Guided-Deep-Unsupervised-Image-Saha-Sudhakaran/11fa0230f3802fbbc8dbae94d38c99b1025b1fe3",
            "/paper/Unsupervised-Deep-Change-Vector-Analysis-for-in-VHR-Saha-Bovolo/58139ebda484a3b857db2d08f94ad7e8f7cc7686",
            "/paper/Unsupervised-Multiple-Change-Detection-in-VHR-Via-Saha-Bovolo/5c07c93ef0c16be9368c3c712e69b239271360ea",
            "/paper/W-Net%3A-A-Deep-Model-for-Fully-Unsupervised-Image-Xia-Kulis/f8a727877dd258f80eec6d075a3d440c2ac98d36",
            "/paper/Unsupervised-Image-Segmentation-by-Backpropagation-Kanezaki/f440566df837b5be18be456eef47ed8f6206b66f",
            "/paper/Dense-Semantic-Labeling-of-Subdecimeter-Resolution-Volpi-Tuia/ef500cd3c401cd0632656c9fddccb1655c6659f9",
            "/paper/Unsupervised-Multiple-Change-Detection-in-VHR-Using-Saha-Bovolo/bf18ece0f8f962474ffd34297f0fcb49f4e55c57",
            "/paper/DeepLab%3A-Semantic-Image-Segmentation-with-Deep-and-Chen-Papandreou/cab372bc3824780cce20d9dd1c22d4df39ed081a",
            "/paper/Change-detection-based-on-deep-feature-and-mapping-Zhang-Gong/b396083d07de0c45c7f1a3d2b98017801d15dad0",
            "/paper/High-Resolution-Aerial-Image-Labeling-With-Neural-Maggiori-Tarabalka/63c5e590028a08210261b98fe995684d6870c68f"
        ]
    },
    {
        "id": "25fb31c992edc8f4b913777c7a646cb0fe2f66ca",
        "title": "Adversarial Deep Learning for Cognitive Radio Security: Jamming Attack and Defense Strategies",
        "abstract": "A defense scheme is developed against adversarial deep learning by exploiting the sensitivity of deep learning to training errors and allows the transmitter to sustain its performance against intelligent jamming attacks. This paper presents an adversarial machine learning approach to launch jamming attacks on wireless communications and introduces a defense strategy. In a cognitive radio network, a transmitter senses channels, identifies spectrum opportunities, and transmits data to its receiver in idle channels. On the other hand, an attacker may also sense channels, identify busy channels and aim to jam transmissions of legitimate users. In a dynamic system with complex channel, traffic and interference characteristics, the transmitter applies some pre-trained machine learning algorithm to classify a channel as idle or busy. This classifier is unknown to the attacker that senses a channel, captures the transmitter's decisions by tracking the acknowledgments and applies deep learning (in form of an exploratory attack, i.e., inference attack) to build a classifier that is functionally equivalent to the one at the transmitter. This approach is shown to support the attacker to reliably predict successful transmissions based on the sensing results and effectively jam these transmissions. Then, a defense scheme is developed against adversarial deep learning by exploiting the sensitivity of deep learning to training errors. The transmitter deliberately takes a small number of wrong actions (in form of a causative attack, i.e., poisoning attack, launched against the attacker) when it accesses the spectrum. The objective is to prevent the attacker from building a reliable classifier. For that purpose, the attacker systematically selects when to take wrong actions to balance the conflicting effects of deceiving the attacker and making correct transmission decisions. This defense scheme successfully fools the attacker into making prediction errors and allows the transmitter to sustain its performance against intelligent jamming attacks.",
        "publication_year": "2018",
        "authors": [
            "Yi Shi",
            "Y. Sagduyu",
            "T. Erpek",
            "Kemal Davaslioglu",
            "Zhuo Lu",
            "Jason H. Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "74",
        "reference_count": "17",
        "references": [
            "/paper/Deep-Learning-for-Launching-and-Mitigating-Wireless-Erpek-Sagduyu/b2ff78b76a302b005ab65ad0d404373a70f3d5ee",
            "/paper/Adversarial-Deep-Learning-for-Over-the-Air-Spectrum-Sagduyu-Shi/892d41979d1b76f9e2f789de8f27e31f12e65b96",
            "/paper/Channel-Aware-Adversarial-Attacks-Against-Deep-Kim-Sagduyu/0497b410e841d42536cc48ba5869ee0258781b5c",
            "/paper/Adversarial-Machine-Learning-and-Defense-Game-for-Sagduyu/3ca7ad47068f96b0cd2f55cd19f41a1845611ebb",
            "/paper/Spectrum-Data-Poisoning-with-Adversarial-Deep-Shi-Erpek/4531f346abb78892822825c56d33f2f1c7a6bead",
            "/paper/Adversarial-Machine-Learning-for-5G-Communications-Sagduyu-Erpek/8fd0431186564148b8c0b8a30c363fe724ff320e",
            "/paper/Channel-Effects-on-Surrogate-Models-of-Adversarial-Kim-Sagduyu/300cac3d7b8ff14a4ee1aaf2345e55b7d79f1790",
            "/paper/Generative-Adversarial-Network-in-the-Air%3A-Deep-for-Shi-Davaslioglu/86eb5ad210695c51b521604d94320ad2e0d39799",
            "/paper/Adversarial-Machine-Learning-for-NextG-Covert-Using-Kim-Sagduyu/bc3a460122bb7f27388e65258d8cb98c890636d5",
            "/paper/Adversarial-Attacks-against-Deep-Learning-Based-in-Kim-Shi/ce7781833a699d013c99ddf027aea852a2a8e940",
            "/paper/Generative-Adversarial-Learning-for-Spectrum-Davaslioglu-Sagduyu/5e2d9d7e94b4587c452df573b9b8ed05fa9ac828",
            "/paper/Evasion-and-causative-attacks-with-adversarial-deep-Shi-Sagduyu/78b7bed9176cc1eab592041c95faff8fd157e1c8",
            "/paper/Adversarial-examples-in-the-physical-world-Kurakin-Goodfellow/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b",
            "/paper/Evasion-Attacks-against-Machine-Learning-at-Test-Biggio-Corona/033c08ca48aaed2d5ab0a17d668d410538678ed8",
            "/paper/How-to-steal-a-machine-learning-classifier-with-Shi-Sagduyu/2ac11a0b84580e88bb8c6e5edb38c92fe1456864",
            "/paper/The-Limitations-of-Deep-Learning-in-Adversarial-Papernot-Mcdaniel/819167ace2f0caae7745d2f25a803979be5fbfae",
            "/paper/Model-Inversion-Attacks-that-Exploit-Confidence-and-Fredrikson-Jha/d1b9a3b11e6c9571a1553556f82b605b2b4baec3",
            "/paper/Jamming-games-in-wireless-networks-with-incomplete-Sagduyu-Berry/52c6814a3d323c6226ba7df16d6d40137428d4d4",
            "/paper/Deep-Sensing%3A-Cooperative-Spectrum-Sensing-Based-on-Lee-Kim/af4f116aee6d01670b76f90a9a349e4b15446087",
            "/paper/Machine-Learning-Techniques-for-Cooperative-Sensing-Thilina-Choi/fc3fb8de45d2376df82e8d43d2f4119942609d7d"
        ]
    },
    {
        "id": "95476a8b26b8e51c5f1bc7ebd245685a0feb489f",
        "title": "Integrating node centralities, similarity measures, and machine learning classifiers for link prediction",
        "abstract": "This paper proposes a generic and improved method of link prediction named as NSMLLP by integrating Node centralities, Similarity measures, and Machine Learning classifiers and demonstrates that the proposed technique outperforms many existing popular methods of link predication based on several evaluation criteria. Link prediction is a widely studied topic in graph data analytics and finds numerous applications like friend recommendations in social networks and product recommendations in e-commerce. It refers to predicting new connections or edges that may arise in the near future amongst the nodes of the network. There exist various methods of link prediction generally based on either local, semi-local, or global features of networks and usually suffers from the problems of consistency in their performances over different and large size networks. In this paper, we intend to propose a generic and improved method of link prediction named as NSMLLP by integrating Node centralities, Similarity measures, and Machine Learning classifiers. We calculate popularity measures for every node and evaluate similarity measures for every pair of nodes in the network. The combined popularity and similarity measures form the features for every node pair in the network. The combined features of the nodes at the end of the edges, along with the positive or negative edge label, form a well-defined dataset for the task of link prediction. This dataset is then fed into machine learning classifiers like Random Forest classifier, AdaBoost classifier, and an ANN based classifier. The results obtained from these classifiers are then combined to make the final link prediction. We provide an information gain study aiming to quantify the improvement brought on by our proposed method. A feature importance study is also provided to comprehend better the relative importance of the various popularity and similarity measures used by us. The experimental results obtained on multiple real-life networks demonstrate that the proposed technique outperforms many existing popular methods of link predication based on several evaluation criteria.",
        "publication_year": "2022",
        "authors": [
            "Sameer Anand",
            "Rahul",
            "Abhishek Mallik",
            "Sanjay Kumar"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "68",
        "references": [
            "/paper/Line-Graph-Contrastive-Learning-for-Link-Prediction-Zhang-Sun/03f64803afaf312a3b299fe1c2bc26c329d43747",
            "/paper/Opinion-Leader-Detection-in-Asian-Social-Networks-Kumar-Kumar/fb64dcee40eda740389d0385455c368a305bf8dc",
            "/paper/Application-of-an-Improved-Link-Prediction-Based-on-Ma-Zhao/7189914c398836d234bf4e1d7a581f795ffbb90d",
            "/paper/Recoloring-Grayscale-Images-using-GAN-Mathur-Dabas/10557902eacd64c443493c8291ed16b1fc676442",
            "/paper/Word2Vec-and-LSTM-based-deep-learning-technique-for-Mallik-Kumar/9534939ce648bfc23000ec3e6a8d114e6224b7f5",
            "/paper/General-link-prediction-with-influential-node-Wu-Shen/d9e92ee8d60d9d9fb4d6c31eea8d12dd4ac21c13",
            "/paper/Review-on-Graph-Feature-Learning-and-Feature-for-Mutlu-Oghaz/6b724755aaf9b5afb526e9f8ba3df73fd44d26a1",
            "/paper/Link-prediction-of-time-evolving-network-based-on-Wu-Wu/f0717bed735fb8a9f375947eb749611881f644f5",
            "/paper/Follower-Link-Prediction-Using-the-XGBoost-Model-Behera-Das/bdd3025b6753dc9364170c467374d9ad42e2a475",
            "/paper/A-modified-DeepWalk-method-for-link-prediction-in-Berahmand-Nasiri/22ce86429439dd963f5d67175497b94c7ca505ea",
            "/paper/A-hybrid-method-of-link-prediction-in-directed-Ghorbanzadeh-Sheikhahmadi/89d7f8991a8e3deae5adafaf55252c6064c05f28",
            "/paper/Hybrid-Approach-for-Predicting-and-Recommending-in-Tripathi-Yadav/792e527d2d95bcec985770b88680e2964a30600f",
            "/paper/A-Preference-Random-Walk-Algorithm-for-Link-through-Berahmand-Nasiri/e5ec5959a77a80514c30af6c8618db8375da0c7c",
            "/paper/Ranking-nodes-in-complex-networks-based-on-local-Salavati-Abdollahpouri/0dbf44863c156ab4fafedc3d017ebc4287f16317",
            "/paper/Link-prediction-using-node-information-on-local-Aziz-Gul/e273d90f87e42558d60035f88b200d379cde832e"
        ]
    },
    {
        "id": "0a3532d23a94e5fbe69a5f184040b60160189d5f",
        "title": "Non-parametric Multi Self-Attention Temporal Convolutional Network for Probabilistic Remaining Useful Life Prediction",
        "abstract": "A deep learning-based probabilistic RUL prediction framework with multi self-attention mechanisms that can adaptively extract useful information from both time dimension and feature dimension by weighting measurements from multiple in-suit sensors. Massive condition monitoring (CM) data from industrial systems has increased the usability of data-driven methods in prognostics. Remaining useful life (RUL) prediction plays a vital role in helping to improve system reliability and to reduce system risks. However, most of existing data-driven methods for RUL prediction only support point estimation and cannot adaptively extract information from different system features and time periods, but it is important to provide probabilistic RUL prediction results in practice. In this context, we propose a deep learning-based probabilistic RUL prediction framework with multi self-attention mechanisms. It is able to weight CM data in two dimensions and predict the probability density of the target RUL. Specifically, based on the multi self-attention mechanisms, the proposed framework can adaptively extract useful information from both time dimension and feature dimension by weighting measurements from multiple in-suit sensors. Then, a temporal convolution network with the shared weights is applied to feature extraction of the CM data. A non-parametric method is used to obtain a confidence interval (CI) of the target RUL with aleatoric uncertainty. The performance of the proposed framework is evaluated via a public turbofan CM dataset. The results show that the proposed framework can output high-accuracy CI for RUL prediction.",
        "publication_year": "2022",
        "authors": [
            "Jiawei Xiong",
            "Jiaqi Tian",
            "Jian Zhou",
            "Yizhong Ma"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "36",
        "references": [
            "/paper/Controlled-physics-informed-data-generation-for-Xiong-Fink/97af4edcd2978b535c4efd1df45243eac8ff8d37",
            "/paper/Distributed-Attention-Based-Temporal-Convolutional-Song-Gao/fc6a78d27a2268a2e0c9d4675018d1e92e7c67e5",
            "/paper/A-novel-temporal-convolutional-network-with-for-of-Cao-Ding/f4e207955d89f7d962cdd98e9443fe27dbab5baf",
            "/paper/Remaining-Useful-Life-Prediction-Using-a-Novel-Liu-Liu/dc889d3f6d199ae67576a209c6ab0188abbd3e27",
            "/paper/Remaining-useful-life-estimation-in-prognostics-Li-Ding/809003357de849d443a37b29996e2130c7bdb041",
            "/paper/Remaining-useful-life-predictions-for-turbofan-deep-Ellefsen-Bj%C3%B8rlykhaug/5177be422e9eadcc806551c78430173e5a4a3f42",
            "/paper/Remaining-Useful-Life-Prediction-Based-on-a-Neural-Yang-Liu/60f317f7e5ddba6789535db49e309bc39b604135",
            "/paper/Estimation-of-Bearing-Remaining-Useful-Life-Based-Zhu-Chen/9c38986568db937527c3a6c8d847c317136eac74",
            "/paper/Joint-Learning-of-Degradation-Assessment-and-RUL-Miao-Li/cdaa75b42c4c232b73e2decabda9f5bd74286937",
            "/paper/Using-Deep-Learning-Based-Approach-to-Predict-Life-Deutsch-He/811551ca0c9e74fb673ff5698a5c34380394eaa1",
            "/paper/A-Bidirectional-LSTM-Prognostics-Method-Under-Huang-Huang/f224f57fa20ee6e7526a7f0e88ce90ca30d6969d"
        ]
    },
    {
        "id": "1d30b941448645bc2dc304dcb1aacf9261070e0e",
        "title": "Deep color transfer using histogram analogy",
        "abstract": "A deep neural network is proposed that leverages color histogram analogy for color transfer, and this network utilizes the analogy between the source and reference histograms to modulate the color of the source image with abstract color features of the reference image. We propose a novel approach to transferring the color of a reference image to a given source image. Although there can be diverse pairs of source and reference images in terms of content and composition similarity, previous methods are not capable of covering the whole diversity. To resolve this limitation, we propose a deep neural network that leverages color histogram analogy for color transfer. A histogram contains essential color information of an image, and our network utilizes the analogy between the source and reference histograms to modulate the color of the source image with abstract color features of the reference image. In our approach, histogram analogy is exploited basically among the whole images, but it can also be applied to semantically corresponding regions in the case that the source and reference images have similar contents with different compositions. Experimental results show that our approach effectively transfers the reference colors to the source images in a variety of settings. We also demonstrate a few applications of our approach, such as palette-based recolorization, color enhancement, and color editing.",
        "publication_year": "2020",
        "authors": [
            "Junyong Lee",
            "Hyeongseok Son",
            "Gun-Hee Lee",
            "Jonghyeop Lee",
            "Sunghyun Cho",
            "Seungyong Lee"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "12",
        "reference_count": "36",
        "references": [
            "/paper/Example-based-color-transfer-with-Gaussian-mixture-Gu-Lu/fec702c4fef109faccd98fb3f0502c7258970d80",
            "/paper/Color-Transfer-Algorithm-between-Images-Based-on-a-Xu-Ding/85410d1078a5816ad6419da27ee17e97661435f4",
            "/paper/Non-local-Matching-of-Superpixel-based-Deep-for-Carrillo-Cl%C3%A9ment/c24f3b54286c987a2abec4fc63b569af27c31471",
            "/paper/Palette-Based-Recoloring-of-Natural-Images-Under-Liu-Zhu/5e0e3955dc70fc7dba67fa6a332bf55d67e87b95",
            "/paper/Detecting-Recolored-Image-by-Spatial-Correlation-Zhang-Chen/dca59c4536d9045ef7e6c514f5315e19da5695a6",
            "/paper/Controlled-and-Conditional-Text-to-Image-Generation-Aggarwal-Ravi/6d0100a6d8e3be6f51f80e1668870acb00f6fa32",
            "/paper/Feature-spatial-pyramid-network-for-low-light-image-Song-Huang/566df4f3189155a84e10fb4c48adb370c34068d1",
            "/paper/Towards-natural-object-based-image-recoloring-Cui-Zhu/11fb274bf7d843045704e221a1cdc5af80e11579",
            "/paper/Towards-natural-object-based-image-recoloring-Cui-Zhu/df512f9bdaa045196140c253961a6cb377a2b907",
            "/paper/Modernizing-Old-Photos-Using-Multiple-References-Gunawan-Kim/946ce4354c990bf37f3393b19fd896e525240377",
            "/paper/Visual-attribute-transfer-through-deep-image-Liao-Yao/4923c6bc3ab501651763f6814a8384745f3d9a4d",
            "/paper/Style-aware-robust-color-transfer-Hristova-Meur/d2d443cd8f26340d1daf2d4cda45bb450a3098f6",
            "/paper/Local-texture-based-color-transfer-and-colorization-Arbelot-Vergne/5e698ed0a4e2a3d8a2ddb3a1682ed569d1066f1e",
            "/paper/Universal-Style-Transfer-via-Feature-Transforms-Li-Fang/83083c5760bd1b58e5f827e57415e5ed676ef3bc",
            "/paper/Deep-Photo-Style-Transfer-Luan-Paris/8b5253c8159ffa7cca12901af26a0a0897b45cda",
            "/paper/Progressive-Color-Transfer-With-Dense-Semantic-He-Liao/95069a2d3bbfb885580c2ee08b5dd00c8bfa3539",
            "/paper/Learning-Linear-Transformations-for-Fast-Image-and-Li-Liu/836a143a4bf5b78f883934e3d5de611ca747aa38",
            "/paper/PaletteNet%3A-Image-Recolorization-with-Given-Color-Cho-Yun/e9d0b27eca503547f56b9e042f61441ab12d9e5f",
            "/paper/Learning-Linear-Transformations-for-Fast-Arbitrary-Li-Liu/91bd017c1b19c36e430a22929d8de3af0795dfa4",
            "/paper/Photorealistic-Style-Transfer-via-Wavelet-Yoo-Uh/d42c6d60e984880ca5528159f465f4b4ca2a03b5"
        ]
    },
    {
        "id": "f48d75612695cc36c3a820ae175261329318ab4c",
        "title": "Flexible comparison of batch correction methods for single-cell RNA-seq using BatchBench",
        "abstract": "BatchBench is presented, a modular and flexible pipeline for comparing batch correction methods for single-cell RNA-seq data and a systematic comparison guides users in the choice of batch correction tool. As the cost of single-cell RNA-seq experiments has decreased, an increasing number of datasets are now available. Combining newly generated and publicly accessible datasets is challenging due to non-biological signals, commonly known as batch effects. Although there are several computational methods available that can remove batch effects, evaluating which method performs best is not straightforward. Here we present BatchBench (https://github.com/cellgeni/batchbench), a modular and flexible pipeline for comparing batch correction methods for single-cell RNA-seq data. We apply BatchBench to eight methods, highlighting their methodological differences and assess their performance and computational requirements through a compendium of well-studied datasets. This systematic comparison guides users in the choice of batch correction tool, and the pipeline makes it easy to evaluate other datasets.",
        "publication_year": "2020",
        "authors": [
            "Ruben Chazarra-Gil",
            "S. van Dongen",
            "V. Kiselev",
            "M. Hemberg"
        ],
        "related_topics": [
            "Biology",
            "Computer Science"
        ],
        "citation_count": "37",
        "reference_count": "49",
        "references": [
            "/paper/CellMixS%3A-quantifying-and-visualizing-batch-effects-L%C3%BCtge-Zyprych-Walczak/26bf74add0ee73ec8c80662508f39b41da1eca6d",
            "/paper/Batch-alignment-of-single-cell-transcriptomics-data-Yu-Xu/e2fde6d6f5ddb0cc14aca91203d195f65e769176",
            "/paper/The-shaky-foundations-of-simulating-single-cell-RNA-Crowell-Leonardo/614784ef42a5200cd5cfae7b2ea5a3d2cc763bca",
            "/paper/CBA%3A-Cluster-Guided-Batch-Alignment-for-Single-Cell-Yu-Mahfouz/c341dcd2162a11976f20131421ac7e65167d52f5",
            "/paper/Built-on-sand%3A-the-shaky-foundations-of-simulating-Crowell-Leonardo/1b4ccadcc489a354bf74ec89960bcf8824daef65",
            "/paper/Benchmarking-atlas-level-data-integration-in-Luecken-B%C3%BCttner/d88158745b69f5732397175389101e2d98799c00",
            "/paper/Benchmarking-atlas-level-data-integration-in-Luecken-B%C3%BCttner/2ae47c27b0d6bc2a52b69359f3f7810fb371ffa0",
            "/paper/Influence-of-single-cell-RNA-sequencing-data-on-the-Kujawa-Marczyk/c4c1c40b63707a5936ff20e9220a596d37d1a1fa",
            "/paper/deepMNN%3A-Deep-Learning-Based-Single-Cell-RNA-Data-Zou-Zhang/426f2616b7531c18fa6ecee1abc75baf0ccfdd2a",
            "/paper/An-integrated-single-cell-transcriptomic-dataset-Prazanowska-Lim/2e68442733604d3ff3f9fe5e62201ffc4f1ea951",
            "/paper/A-benchmark-of-batch-effect-correction-methods-for-Tran-Ang/d5baf1912d43d0af0e8f683eb5532f5f5445430e",
            "/paper/Batch-effects-in-single-cell-RNA-sequencing-data-by-Haghverdi-Lun/56bf103a956b4a2ad11868c05db189d1e3f64ac1",
            "/paper/BBKNN%3A-fast-batch-alignment-of-single-cell-Pola%C5%84ski-Young/e6368f1cb43fb26b0f006ebd711984d5a8cd530f",
            "/paper/Single-Cell-RNA-Seq-Technologies-and-Related-Data-Chen-Ning/bf3447b4c5fd98b236f408ff86d1f8acfd467676",
            "/paper/scmap%3A-projection-of-single-cell-RNA-seq-data-data-Kiselev-Yiu/ecb81c5d18e38b29316da77f69c8a36d5b98f196",
            "/paper/Fast%2C-sensitive%2C-and-accurate-integration-of-single-Korsunsky-Fan/3ea71ab8877a3e96ce82daf24aacd3ccbcd19138",
            "/paper/Current-best-practices-in-single%E2%80%90cell-RNA%E2%80%90seq-a-Luecken-Theis/d197473a348efadb23a6bb52de3476fdfdfe7dec",
            "/paper/Comprehensive-Integration-of-Single-Cell-Data-Stuart-Butler/2287a3930a7568a956aae5f3f037efe8fed675e7",
            "/paper/Single-cell-RNA-sequencing-technologies-and-Hwang-Lee/219bee9fde1303f423fac52ff373f19552c60d53",
            "/paper/Robust-detection-of-alternative-splicing-in-a-of-Welch-Hu/f8177af5f696b2feb9de679ba35de8420433fcd2"
        ]
    },
    {
        "id": "ebd0abdcae4d0580aa2ae4de7905e59349b9071a",
        "title": "Sparsity-aware subband adaptive algorithms with adjustable penalties",
        "abstract": "Semantic Scholar extracted view of \"Sparsity-aware subband adaptive algorithms with adjustable penalties\" by Yi Yu et al.",
        "publication_year": "2019",
        "authors": [
            "Yi Yu",
            "Haiquan Zhao",
            "R. D. Lamare",
            "Lu Lu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "27",
        "reference_count": "45",
        "references": [
            "/paper/L0-norm-constraint-normalized-subband-adaptive-and-Liu-Zhao/9e31ceae5ada558541d1995e3f06d0166f79e37b",
            "/paper/Sparsity-aware-normalized-subband-adaptive-filters-Ji-Ni/aae369697b10bd7eb2e9c21a8c1911a4359707f0",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/50b98cc888fd59742d535f8c20f7975322dbe7d3",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/cf2395b281802968efce09a560ff52dd2007d913",
            "/paper/Sparsity-Aware-SSAF-Algorithm-with-Individual-for-Yu-Yang/2760c75dde76cdcfb45c78facc9d880c2bd03cf3",
            "/paper/Sparsity-aware-SSAF-algorithm-with-individual-and-Yu-Yang/7b2ab099ec4b6e07ec330c352387337ec48af6e4",
            "/paper/A-Delayless-Sub-band-PNLMS-Adaptive-Filter-for-Bekrani-Khong/1ccde1415cdcb7815a6bc2c975555d288809861f",
            "/paper/Study-of-Proximal-Normalized-Subband-Adaptive-for-Guo-Yu/4e853c29996684ebfb6d59348f508a9258de03d5",
            "/paper/Mean-Square-Performance-Analysis-of-Noise-Robust-Yu-Zhao/69bc7c9029af92827549e14d96de8ae015678b11",
            "/paper/Convergence-analysis-of-the-mixed-norm-LMS-and-two-Eleyan-Salman/e968d46a904c88cc15276d99ee7884469e30106f",
            "/paper/Subband-Adaptive-Filtering-with-Norm-Constraint-for-Choi/60a603f4e1486514c96380504e580ac7a2996e23",
            "/paper/Sparsity-Aware-Data-Selective-Adaptive-Filters-Lima-Ferreira/c427b07b94abb0c3a73850948246a21099970022",
            "/paper/A-Variable-Step-Size-Matrix-Normalized-Subband-Ni-Li/8f64798dffa4f901e6730ab2d92d3915e1fd70bb",
            "/paper/Stochastic-Analysis-of-the-Normalized-Subband-Yin-Mehr/a9d45da99245c6fd72e288b8d476db47cb57892f",
            "/paper/Improving-convergence-of-the-NLMS-algorithm-using-Lee-Gan/48905b7b0149d88ba221afa0f1ef2fb9426a3c12",
            "/paper/Optimal-Sparsity-Tradeoff-in-%24%5Cell-_0%24-NLMS-Al-Shabili-Weruaga/d44b267f7cb250da1a5218a4d52860317c81088b",
            "/paper/Performance-Analysis-of-%24l_0%24-Norm-Constraint-Least-Su-Jin/4dbf4359da59e7091983fc1be7dae091a502c59e",
            "/paper/Mean-Square-Deviation-Analysis-of-Subband-Adaptive-Jeong-Kim/786c626f7127743d3a42ffe8c1fdc717957fc37f",
            "/paper/An-Improved-Multiband-Structured-Subband-Adaptive-Yang-Wu/ad8c2bf71aa9f8f95bc450ea03b0cbd033da2d76",
            "/paper/Sparsity-Aware-Adaptive-Algorithms-Based-on-and-Lamare-Neto/e1b9d11efa3362ed6968c324ed3afd616a4241bd"
        ]
    },
    {
        "id": "5cccc8bab11927e5527dd5b917ed4c306a2ccf49",
        "title": "A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction",
        "abstract": "HF2-VAD is proposed, a Hybrid framework that integrates Flow reconstruction and Frame prediction seamlessly to handle Video Anomaly Detection, and designs the network of ML-MemAE-SC to memorize normal patterns for optical flow reconstruction so that abnormal events can be sensitively identified with larger flow reconstruction errors. In this paper, we propose HF2-VAD, a Hybrid framework that integrates Flow reconstruction and Frame prediction seamlessly to handle Video Anomaly Detection. Firstly, we design the network of ML-MemAE-SC (Multi-Level Memory modules in an Autoencoder with Skip Connections) to memorize normal patterns for optical flow reconstruction so that abnormal events can be sensitively identified with larger flow reconstruction errors. More importantly, conditioned on the reconstructed flows, we then employ a Conditional Variational Autoencoder (CVAE), which captures the high correlation between video frame and optical flow, to predict the next frame given several previous frames. By CVAE, the quality of flow reconstruction essentially influences that of frame prediction. Therefore, poorly reconstructed optical flows of abnormal events further deteriorate the quality of the final predicted future frame, making the anomalies more detectable. Experimental results demonstrate the effectiveness of the proposed method. Code is available at https://github.com/LiUzHiAn/hf2vad.",
        "publication_year": "2021",
        "authors": [
            "Zhian Liu",
            "Yongwei Nie",
            "Chengjiang Long",
            "Qing Zhang",
            "Guiqing Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "67",
        "reference_count": "53",
        "references": [
            "/paper/A-Novel-Unsupervised-Video-Anomaly-Detection-Based-Huang-Zhao/228273c1beb2f54a56dd19a650e73c10780044c5",
            "/paper/Multi-level-Memory-augmented-Appearance-Motion-for-Huang-Zhao/2ed0438c7136463c7d742c99b525299268fe854a",
            "/paper/Dual-branch-network-with-memory-for-video-anomaly-Wang-Hu/01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
            "/paper/Anomaly-Detection-in-Surveillance-Videos-via-Frame-Yang-Li/74863ff04ca4654d5c2861f5d8d85dc488eb65cc",
            "/paper/Multi-Contextual-Predictions-with-Vision-for-Video-Lee-Nam/1c1c590ffd5d5f4e9ce455bbdbc15d0e781ac540",
            "/paper/Real-time-anomaly-detection-on-surveillance-video-Liu-Cao/6d7e7d102559743cbae81ea0b4ec1f040f17a68f",
            "/paper/An-integration-of-Pseudo-Anomalies-and-Memory-for-Le-Nguyen/a283e48c27f5b0430536a4e8264aa1055de65cd6",
            "/paper/Context-Recovery-and-Knowledge-Retrieval%3A-A-Novel-Cao-Lu/274fe6d15b7d13d9514976fad2cfc8f744bb8c4b",
            "/paper/Regularity-Learning-via-Explicit-Distribution-for-Yu-Zhao/b08e6cb814868eae2d0941372efd1e23bd39dee1",
            "/paper/Bi-directional-Frame-Interpolation-for-Unsupervised-Deng-Zhang/d7de9df4dd7c579651c4b4189cfda6810d2cf032",
            "/paper/Cloze-Test-Helps%3A-Effective-Video-Anomaly-Detection-Yu-Wang/96d7a07237e146c28173767dfc6290a337696c04",
            "/paper/Future-Frame-Prediction-Using-Convolutional-VRNN-Lu-MaheshKumar/16e1bdb834340b0fd7a5737dfb87abda373f72ca",
            "/paper/AnoPCN%3A-Video-Anomaly-Detection-via-Deep-Predictive-Ye-Peng/3c439ef038419f9db396628ed9766af568625f31",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Video-Anomaly-Detection-and-Localization-via-Fully-Fan-Wen/d880d303ee0bfdbc80fc34df0978088cd15ce861",
            "/paper/Detecting-anomalous-events-in-videos-by-learning-of-Xu-Yan/e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "/paper/A-Revisit-of-Sparse-Coding-Based-Anomaly-Detection-Luo-Liu/99dff291f260b3cc3ff190106b0c2e3e685223a4"
        ]
    },
    {
        "id": "4d9aaa1cfd1d0fa6a18a88425d62442e8126e751",
        "title": "Changes in Maximum Mandibular Mobility Due to Splint Therapy in Patients with Temporomandibular Disorders",
        "abstract": "Investigation of which qualifiable and quantifiable effects of splint therapy are detectable found that 24 of 29 patients diagnosed with myofascial pain experienced an improvement in pain symptoms, 17 of whom experienced complete remission. Splint therapy is widely used in the treatment of myofascial pain, but valid studies on the efficacy of this therapy are rare. The purpose of the present study was to investigate which qualifiable and quantifiable effects of splint therapy are detectable. For this purpose, 29 patients (21 women, mean age 44.6 \u00b1 16 years) diagnosed with myofascial pain (RDC/TMD) were investigated in this prospective clinical trial (10/6/14An). Patients were treated with Michigan splints applied overnight for three months. Before (T1) and after three months of treatment (T2), patients were registered with an electronic ultrasound device with qualitative and quantitative evaluation of the registrations and a qualitative assessment of pain symptoms using a verbal analog scale. Significant differences were found between maximum mouth opening (MMP) (p < 0.001) and right condylar movement (CM) at MMP (p = 0.045). Qualitative assessment revealed that 24 of 29 patients experienced an improvement in pain symptoms, 17 of whom experienced complete remission. The results of the qualitative and quantitative analysis provide indications of the effectiveness of the splint therapy. In addition to quantitative measurements, the ultrasound facebow technique was also able to provide qualitative information.",
        "publication_year": "2022",
        "authors": [
            "B. Wiechens",
            "Svea Paschereit",
            "Tristan Hampe",
            "T. Wassmann",
            "N. Gersdorff",
            "R. B\u00fcrgers"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": "2",
        "reference_count": "41",
        "references": [
            "/paper/Accurate-Diagnosis-and-Treatment-of-Painful-A-by-Garstka-Kozowska/40257e46141b0f0533ab8ac93c3c0dcbd632f105",
            "/paper/Intra-Articular-Injections-into-the-Inferior-versus-Ch%C4%99ci%C5%84ski-Ch%C4%99ci%C5%84ska/7126c8faba2c2ba9bda04c0a2a0c7ce51572d98c",
            "/paper/Are-occlusal-splints-effective-in-reducing-pain-in-Deregibus-Ferrillo/248461bad5d66f4d202ecbeb3e5cf9443a3d3b32",
            "/paper/Effect-of-occlusal-splints-for-the-management-of-a-Zhang-Wang/67563f0cb12ceecad7702c48dbfe8786aea45187",
            "/paper/Correlation-of-splint-therapy-outcome-with-the-of-Daif/67c8a6b745d9df926532189cb46f84975050d7f2",
            "/paper/Occlusal-stabilization-splint-for-patients-with-of-Pficer-Dodi%C4%87/a2b8cfa1b84e59e62bcc62d0a961b67f31f66510",
            "/paper/Comparison-of-device%E2%80%90supported-sensorimotor-and-for-Giannakopoulos-Rauer/3d73c7eb861bf3e8df881127a4267bf813d35c9d",
            "/paper/Effectiveness-of-occlusal-splint-therapy-in-the-of-Al-Moraissi-Farea/d5805070831487b217fcc1e165e217639855ac3e",
            "/paper/Comparison-of-the-efficacy-of-dry-needling-and-with-Aksu-Do%C4%9Fan/eb77bf5db008814f3ea78a59ac0de5fc3e8a83f0",
            "/paper/Ultrasound-evaluation-of-masseter-muscle-changes-in-Aldemir-%C3%9Cst%C3%BCner/30e1d123b7615ac64f7130a91f12b43c4a65a1a6",
            "/paper/Efficacy-of-rehabilitation-on-reducing-pain-in-A-of-Ferrillo-Ammendolia/fdb7f6bc1154dc30f90592ed7237374f6187fe73",
            "/paper/Surface-electromyographic-patterns-of-masticatory%2C-Tecco-Tete%CC%80/b36587ac104b5f2bd9cfd0bcf1d99e2b0954ec8e"
        ]
    },
    {
        "id": "40fb968dfe2ffb25dfbe05cbacb9b343123a71bd",
        "title": "Behaviour of telocytes during physiopathological activation.",
        "abstract": "Semantic Scholar extracted view of \"Behaviour of telocytes during physiopathological activation.\" by L. D\u00edaz-Flores et al.",
        "publication_year": "2016",
        "authors": [
            "L. D\u00edaz-Flores",
            "R. Guti\u00e9rrez",
            "L. D\u00edaz-Flores",
            "Miriam Gonz\u00e1lez Gom\u00e9z",
            "F. S\u00e1ez",
            "J. Madrid"
        ],
        "related_topics": [
            "Medicine",
            "Biology"
        ],
        "citation_count": "61",
        "reference_count": "130",
        "references": [
            "/paper/Telocytes-%7C-Encyclopedia-D%C3%ADaz-Flores/c200ac3ae8083fba1f3a7027525265ee0e68932a",
            "/paper/Telocytes-(Tcs)-%7C-Encyclopedia-D%C3%ADaz-Flores/14ae68a383e1cc35d8c02e5f858491216e740480",
            "/paper/Identification-of-PDGFR%CE%B1%2B-cells-in-uterine-fibroids-Aleksandrovych-Bereza/07a546e20150faefe25c0c9f04216387c92ad3fb",
            "/paper/Immunophenotypic-characterization-of-telocyte-like-Maxia-Murtas/d1552ac6cca0cb868472a1459bf75a2dfaca8059",
            "/paper/Telocytes-in-the-Normal-and-Pathological-Peripheral-D%C3%ADaz-Flores-Guti%C3%A9rrez/a3650764669059b7e6dd81608405435222d43d6f",
            "/paper/Changes-in-the-telocyte-CD34%2B-stromal-cell-and-cell-Marini-Ibba%E2%80%90Manneschi/ef48b245014922a2927c1da8546b50640d4b1b25",
            "/paper/Telocytes%3A-An-Emerging-Component-of-Stem-Cell-Niche-Rosa-Marini/4ac60f2a8d82e1f55fa74bf5e8e2529c198fe660",
            "/paper/Telocytes-in-Fibrosis-Diseases%3A-From-Current-to-Wei-Chen/a63a1a6219106269bb91b6c6e5c82e34cd16b4c7",
            "/paper/The-telopode-and-filopode-projecting-heterogeneous-Petrea-Cr%C4%83i%C5%A3oiu/0b7c01b1814949b7f6f7044bee3b4e84b29a4917",
            "/paper/Delimiting-CD34%2B-Stromal-Cells-Telocytes-Are-Cells-D%C3%ADaz-Flores-Guti%C3%A9rrez/fe7efbe95e45dc15393d488ec7f8755ab8686a45",
            "/paper/Human-resident-CD34%2B-stromal-cells-telocytes-have-a-D%C3%ADaz-Flores-Guti%C3%A9rrez/7f3ad99786e12be94fa64c9e80570094a0bfe77f",
            "/paper/Telocyte-Behaviour-During-Inflammation%2C-Repair-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/319b52c4d3af7e6d19a6b646316655e279946491",
            "/paper/Telocytes-as-a-Source-of-Progenitor-Cells-in-and-D%C3%ADaz-Flores-Guti%C3%A9rrez/61005948f1f6946411a7059ac344d51147b0fb98",
            "/paper/Telocytes-in-regenerative-medicine-Bei-Wang/ac40123de90d564e110473a9ecb4f3b3f6a92daf",
            "/paper/Telocytes-in-human-oesophagus-Chen-Zheng/3a9ac634399c8565a2cfa2ccdf88aa8e3726e4ed",
            "/paper/Telocytes-in-neuromuscular-spindles-D%C3%ADaz-Flores-Guti%C3%A9rrez/e2c4112109be2a2c3abc1878dcbbb9c078bbfc1b",
            "/paper/CD34%E2%80%90positive-dendritic-cells-disappear-from-scars-Erdag-Qureshi/2c0c8f77275c38fe485214d254e06823c9433695",
            "/paper/Telocytes-in-Crohn%E2%80%99s-disease-Milia-Ruffo/ae107458587d9093e0951e9ef0795db15d481bae",
            "/paper/Telocytes-in-human-skin-%E2%80%93-are-they-involved-in-skin-Ceafalan-Gherghiceanu/22bda2439a0f1b2929dbc069c5205896a48491ba",
            "/paper/Telocytes-Contribute-as-Cell-Progenitors-and-in-Vannucchi-Bani/0bf44839521120b5226aabd96d04d69d4b77edc1"
        ]
    },
    {
        "id": "fb52c9004eb8f2bef2d58df6febdba2f60d70b4f",
        "title": "Impact of Image Preprocessing Methods and Deep Learning Models for Classifying Histopathological Breast Cancer Images",
        "abstract": "A comparative study of different preprocessing methods and deep learning models for a set of breast cancer images is presented and it is found that the filter used for the preprocessing of the image, has no statistical significance for the behavior of the system. Early diagnosis of cancer is very important as it significantly increases the chances of appropriate treatment and survival. To this end, Deep Learning models are increasingly used in the classification and segmentation of histopathological images, as they obtain high accuracy index and can help specialists. In most cases, images need to be preprocessed for these models to work correctly. In this paper, a comparative study of different preprocessing methods and deep learning models for a set of breast cancer images is presented. For this purpose, the statistical test ANOVA with data obtained from the performance of five different deep learning models is analyzed. An important conclusion from this test can be obtained; from the point of view of the accuracy of the system, the main repercussion is the deep learning models used, however, the filter used for the preprocessing of the image, has no statistical significance for the behavior of the system.",
        "publication_year": "2022",
        "authors": [
            "David Murcia-G\u00f3mez",
            "Ignacio Rojas-Valenzuela",
            "Olga Valenzuela"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "81",
        "references": [
            "/paper/Deep-learning-model-enhanced-skin-cancer-detection-Kolachina-Agada/0852ca8b92a957a016e88b380bf4445f88ae849b",
            "/paper/Concrete-3D-Printing%3A-Process-Parameters-for-and-in-Quah-Tay/594e4c6cd44a4c505fd3b0f225b2add616b49e44",
            "/paper/Breast-Cancer-Classification-From-Histopathological-Hirra-Ahmad/64cde7d04c3fe506286eb4f6d4f65cf9bb9968f9",
            "/paper/Breast-Cancer-Histopathology-Image-Classification-Hameed-Zahia/a5c6968aabc95eece01d61484f7e24e279897d8c",
            "/paper/Classification-of-Breast-Tumours-Based-on-Images-of-Abbasniya-Sheikholeslamzadeh/38a3511f5ace7871aa6b0a51e8a3ea62dbc24e14",
            "/paper/Multiclass-classification-of-breast-cancer-images-Hameed-Garcia-Zapirain/6e5c1be5d62f534114c70170a53c787a9e118cbb",
            "/paper/Classification-of-breast-cancer-histology-images-Ara%C3%BAjo-Aresta/61244d24d769fb6c9626becd58204e766c059513",
            "/paper/Histopathological-image-recognition-of-breast-based-Zhang-Bai/e0b0b46107ee943ff3739146b17cc7523bfb90dd",
            "/paper/Deep-transfer-learning-based-model-for-colorectal-A-Kassani-Kassani/dea5aa0d76331724ff3e7f301719c536cd8e0587",
            "/paper/Automated-classification-of-histopathology-images-Talo/becc21aed36681804997ecb5df564c0a77ac333a",
            "/paper/Intelligent-Hybrid-Deep-Learning-Model-for-Breast-Wang-Ahmad/7f28b0048d2828e6a31f7508004a031685dd4919",
            "/paper/An-experimental-study-on-classification-of-thyroid-Buddhavarapu-Jothi/69dca46739f802219e4ae2f68782bbf0d833ef0f"
        ]
    },
    {
        "id": "aed671e50e5d1ef8f8b05d8b0d04cb6e5aa2439e",
        "title": "TiM-Net: Transformer in M-Net for Retinal Vessel Segmentation",
        "abstract": "A novel model called Transformer in M-Net (TiM-Net) based on M- net, diverse attention mechanisms, and weighted side output layers to efficaciously perform retinal vessel segmentation is proposed. retinal image is a crucial window for the clinical observation of cardiovascular, cerebrovascular, or other correlated diseases. Retinal vessel segmentation is of great benefit to the clinical diagnosis. Recently, the convolutional neural network (CNN) has become a dominant method in the retinal vessel segmentation field, especially the U-shaped CNN models. However, the conventional encoder in CNN is vulnerable to noisy interference, and the long-rang relationship in fundus images has not been fully utilized. In this paper, we propose a novel model called Transformer in M-Net (TiM-Net) based on M-Net, diverse attention mechanisms, and weighted side output layers to efficaciously perform retinal vessel segmentation. First, to alleviate the effects of noise, a dual-attention mechanism based on channel and spatial is designed. Then the self-attention mechanism in Transformer is introduced into skip connection to re-encode features and model the long-range relationship explicitly. Finally, a weighted SideOut layer is proposed for better utilization of the features from each side layer. Extensive experiments are conducted on three public data sets to show the effectiveness and robustness of our TiM-Net compared with the state-of-the-art baselines. Both quantitative and qualitative results prove its clinical practicality. Moreover, variants of TiM-Net also achieve competitive performance, demonstrating its scalability and generalization ability. The code of our model is available at https://github.com/ZX-ECJTU/TiM-Net.",
        "publication_year": "2022",
        "authors": [
            "Hongbin Zhang",
            "Xiang Zhong",
            "Zhijie Li",
            "Yanan Chen",
            "Zhiliang Zhu",
            "Jingqin Lv",
            "Chuanxiu Li",
            "Ying Zhou",
            "Guangli Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "61",
        "references": [
            "/paper/Neuron-tracing-from-light-microscopy-images%3A-deep-Liu-Wang/6050d3b64eadae2ab87eaf9030cadf5ff871c929",
            "/paper/Dual-Encoding-U-Net-for-Retinal-Vessel-Segmentation-Wang-Qiu/a441052a8c01ffbe6f95e29ce44d47c8e2b6ef79",
            "/paper/Multiscale-U-Net-with-Spatial-Positional-Attention-Liu-Gu/3b0c85d6195b28277e0e847a2ca496936f750145",
            "/paper/Pyramid-U-Net-for-Retinal-Vessel-Segmentation-Zhang-Zhang/674e20e42c8bf6285989e2e3880170e3c5a78834",
            "/paper/Vessel-Net%3A-Retinal-Vessel-Segmentation-Under-Wu-Xia/27ebbe7a8fba498ed918f33bd2b5188d2b83144c",
            "/paper/SAT-Net%3A-a-side-attention-network-for-retinal-image-Tong-Fang/8a5b513d7bdc4bbb15cec34a1963ba8a34bb917e",
            "/paper/PCAT-UNet%3A-UNet-like-network-fused-convolution-and-Chen-Yang/ef33b66c0f95700e20ab4df8f96b7e43c67f98bd",
            "/paper/Residual-Connection-Based-Encoder-Decoder-Network-Khan-Alhussein/aa2b30f8efa6733feec9ab32e2c8b70a5c65c2b8",
            "/paper/DUNet%3A-A-deformable-network-for-retinal-vessel-Jin-Meng/6fadd5b08391b0fd0b9bf9f6c18b2dc3194907b9",
            "/paper/Hard-Attention-Net-for-Automatic-Retinal-Vessel-Wang-Haytham/679a66e4a87f9ec1f8ac84bddfe27d16c671b5a6",
            "/paper/Multi-task-Neural-Networks-with-Spatial-Activation-Ma-Yu/f5ed4167776fe75cb69a6c3d1af7185e66d151f1"
        ]
    },
    {
        "id": "e2f2662f0734e2edc2b4b36a734de111c7f8d54d",
        "title": "IA-RED2: Interpretability-Aware Redundancy Reduction for Vision Transformers",
        "abstract": "It is demonstrated that the interpretability that naturally emerged in the I-RED framework can outperform the raw attention learned by the original visual transformer, as well as those generated by off-the-shelf interpretation methods, with both qualitative and quantitative results. The self-attention-based model, transformer, is recently becoming the leading backbone in the field of computer vision. In spite of the impressive success made by transformers in a variety of vision tasks, it still suffers from heavy computation and intensive memory costs. To address this limitation, this paper presents an Interpretability-Aware REDundancy REDuction framework (IA-RED$^2$). We start by observing a large amount of redundant computation, mainly spent on uncorrelated input patches, and then introduce an interpretable module to dynamically and gracefully drop these redundant patches. This novel framework is then extended to a hierarchical structure, where uncorrelated tokens at different stages are gradually removed, resulting in a considerable shrinkage of computational cost. We include extensive experiments on both image and video tasks, where our method could deliver up to 1.4x speed-up for state-of-the-art models like DeiT and TimeSformer, by only sacrificing less than 0.7% accuracy. More importantly, contrary to other acceleration approaches, our method is inherently interpretable with substantial visual evidence, making vision transformer closer to a more human-understandable architecture while being lighter. We demonstrate that the interpretability that naturally emerged in our framework can outperform the raw attention learned by the original visual transformer, as well as those generated by off-the-shelf interpretation methods, with both qualitative and quantitative results. Project Page: http://people.csail.mit.edu/bpan/ia-red/.",
        "publication_year": "2021",
        "authors": [
            "Bowen Pan",
            "Yifan Jiang",
            "R. Panda",
            "Zhangyang Wang",
            "R. Feris",
            "A. Oliva"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "65",
        "reference_count": "67",
        "references": [
            "/paper/X-Pruner%3A-eXplainable-Pruning-for-Vision-Yu-Xiang/e60b6836b45ad0ae02a5fa663c8c31119f0c0a94",
            "/paper/AdaViT%3A-Adaptive-Vision-Transformers-for-Efficient-Meng-Li/38212997a6e8c55141574c329bb58d2eadcb0db5",
            "/paper/Peeling-the-Onion%3A-Hierarchical-Reduction-of-Data-Kong-Ma/a92d2c468835571f3302ce9299fdf37b36c2e367",
            "/paper/CF-ViT%3A-A-General-Coarse-to-Fine-Method-for-Vision-Chen-Lin/ed00842931ebb0db2c634330a77c8dee6f77e547",
            "/paper/Coarse-to-Fine-Vision-Transformer-Chen-Lin/d79d8ecda2cbb3712a021d14c50278ae4c3c1cd9",
            "/paper/Multi-Dimensional-Model-Compression-of-Vision-Hou-Kung/b3ccbba3b77728cffc323d8d4bc3ada615e8e273",
            "/paper/Pruning-Self-attentions-into-Convolutional-Layers-He-Liu/5b5f5ece7e73317ff1d66a6a79372c66ea960a2e",
            "/paper/Multi-Dimensional-Vision-Transformer-Compression-Hou-Kung/6f4093a7ad5378e8cd3b73a52fbec80b784c107d",
            "/paper/Super-Vision-Transformer-Lin-Chen/3093854172b2912db6ba8da7021ccf373c796639",
            "/paper/Life-Regression-based-Patch-Slimming-for-Vision-Chen-Chen/6e22b09ce6a67377a2463c271f94295edf69f886",
            "/paper/DynamicViT%3A-Efficient-Vision-Transformers-with-Rao-Zhao/dbdcabd0444ad50b68ee09e30f39b66e9068f5d2",
            "/paper/Transformer-Interpretability-Beyond-Attention-Chefer-Gur/0acd7ff5817d29839b40197f7a4b600b7fba24e4",
            "/paper/Chasing-Sparsity-in-Vision-Transformers%3A-An-Chen-Cheng/efbe9f591090018f78b42c84613c8afda9292fdb",
            "/paper/CvT%3A-Introducing-Convolutions-to-Vision-Wu-Xiao/e775e649d815a02373eac840cf5e33a04ff85c95",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/ConTNet%3A-Why-not-use-convolution-and-transformer-at-Yan-Li/2c9fdba6bf846e0986cbbf30d56b467d9e334333",
            "/paper/Emerging-Properties-in-Self-Supervised-Vision-Caron-Touvron/ad4a0938c48e61b7827869e4ac3baffd0aefab35",
            "/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "/paper/Glance-and-Focus%3A-a-Dynamic-Approach-to-Reducing-in-Wang-Lv/9fa283d4f9c2ed991383c0434ef6043bee0dc8e2",
            "/paper/Generative-Adversarial-Transformers-Hudson-Zitnick/4f5a194ee365b074dcb0434e9c2eb976f6f32298"
        ]
    },
    {
        "id": "53e4247f7743767f39805573c71b820651335d89",
        "title": "Clean Text and Full-Body Transformer: Microsoft\u2019s Submission to the WMT22 Shared Task on Sign Language Translation",
        "abstract": "This paper describes Microsoft\u2019s submission to the first shared task on sign language translation at WMT 2022, a public competition tackling sign language to spoken language translation for Swiss German sign language. The task is very challenging due to data scarcity and an unprecedented vocabulary size of more than 20k words on the target side. Moreover, the data is taken from real broadcast news, includes native signing and covers scenarios of long videos. Motivated by recent advances in action recognition, we incorporate full body information by extracting features from a pre-trained I3D model and applying a standard transformer network. The accuracy of the system is furtherimproved by applying careful data cleaning on the target text. We obtain BLEU scores of 0.6 and 0.78 on the test and dev set respectively, which is the best score among the participants of the shared task. Also in the human evaluation the submission reaches the first place. The BLEU score is further improved to 1.08 on the dev set by applying features extracted from a lip reading model.",
        "publication_year": "2022",
        "authors": [
            "S. Dey",
            "Abhilash Pal",
            "Cyrine Chaabani",
            "Oscar Koller"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "29",
        "references": [
            "/paper/Findings-of-the-First-WMT-Shared-Task-on-Sign-M%C3%BCller-Ebling/6140abf6acd1a3594a69c24edf1cbe448489e6ef",
            "/paper/Sign-Language-Translation-from-Instructional-Videos-Tarr'es-G%C3%A1llego/06c8cdd8c517e45adcbb519d77c897aaa6766282",
            "/paper/Audio-Visual-Speech-and-Gesture-Recognition-by-of-Ryumin-Ivanko/7b10ff58096da3881cd5b9f82d4559bd78f2e637",
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2",
            "/paper/Open-Domain-Sign-Language-Translation-Learned-from-Shi-Brentari/9f9bec2b0b27fa6995940fe493418e400ebc7420",
            "/paper/Sign-Language-Translation-with-Transformers-Yin/bb7fb4ab8c09937d7389f06839361be625dc062b",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/Neural-Sign-Language-Translation-by-Learning-Orbay-Akarun/4e39e59f41a480f68c934cc38eb874a25ceb5073",
            "/paper/Neural-Sign-Language-Translation-based-on-Human-Ko-Kim/74669631d3f1fcc06d0e5e5daa7e4bfd5b6f6b59",
            "/paper/Read-and-Attend%3A-Temporal-Localisation-in-Sign-Varol-Momeni/95c466170f60cc5a652b51ec23814320666a4f73",
            "/paper/MLSLT%3A-Towards-Multilingual-Sign-Language-Yin-Zhao/458e5d02c0612deae07e5fb241179b52429a81d4",
            "/paper/BSL-1K%3A-Scaling-up-co-articulated-sign-language-Albanie-Varol/0b2538f9c22273db62b205402864062bf222b68c"
        ]
    },
    {
        "id": "37a052144b510b8827634c38146b190d8b2c8d0b",
        "title": "Medical Image Synthesis for Data Augmentation and Anonymization using Generative Adversarial Networks",
        "abstract": "This work proposes a method to generate synthetic abnormal MRI images with brain tumors by training a generative adversarial network using two publicly available data sets of brain MRI, and demonstrates the value of generative models as an anonymization tool. Data diversity is critical to success when training deep learning models. Medical imaging data sets are often imbalanced as pathologic findings are generally rare, which introduces significant challenges when training deep learning models. In this work, we propose a method to generate synthetic abnormal MRI images with brain tumors by training a generative adversarial network using two publicly available data sets of brain MRI. We demonstrate two unique benefits that the synthetic images provide. First, we illustrate improved performance on tumor segmentation by leveraging the synthetic images as a form of data augmentation. Second, we demonstrate the value of generative models as an anonymization tool, achieving comparable tumor segmentation results when trained on the synthetic data versus when trained on real subject data. Together, these results offer a potential solution to two of the largest challenges facing machine learning in medical imaging, namely the small incidence of pathological findings, and the restrictions around sharing of patient data.",
        "publication_year": "2018",
        "authors": [
            "Hoo-Chang Shin",
            "Neil A. Tenenholtz",
            "Jameson K. Rogers",
            "C. Schwarz",
            "M. Senjem",
            "J. Gunter",
            "K. Andriole",
            "Mark H. Michalski"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "418",
        "reference_count": "22",
        "references": [
            "/paper/Synthetic-medical-image-generator-for-data-and-on-Kamli-Saouli/bb431f8dd5df4868eac2028c926eb0f010d30eed",
            "/paper/Generation-of-3D-Brain-MRI-Using-Auto-Encoding-Kwon-Han/40bf9de59df11ee2713b29c36a050a3ee31fe0ef",
            "/paper/Evolutionary-GAN%E2%80%93Based-Data-Augmentation-for-Image-Fu-Gong/9b223b9e9e136680d8f6934ea24b52ce3cf3ed43",
            "/paper/Deep-Learning-Approaches-for-Data-Augmentation-in-A-Kebaili-Lapuyade-Lahorgue/13afd3c131dbb836bf9c6c65466ca8f5234bca11",
            "/paper/Adversarial-Data-Augmentation-on-Breast-MRI-Teixeira-Dias/3c75099ce09df4a364782a3248a1f76c8da603a6",
            "/paper/Overcoming-barriers-to-data-sharing-with-medical-a-Sch%C3%BCtte-Hetzel/9a41af609f3514dafddbc2a2d31b972e17475221",
            "/paper/Brain-tumor-segmentation-using-synthetic-MR-images-Akbar-Larsson/57c61a12a9a152ca3641785234dc1477844e39b8",
            "/paper/MM-GAN%3A-3D-MRI-Data-Augmentation-for-Medical-Image-Sun-Yuan/3deb69a3153c3a011c4bb1e8d9f9553548577033",
            "/paper/Ensembles-of-GANs-for-synthetic-training-data-Eilertsen-Tsirikoglou/ebfa2827fc65c69b9dbfcb8aed861785b7cbb69a",
            "/paper/Medical-Image-Synthetic-Data-Augmentation-Using-GAN-Zhang-Huang/bf0674362e418e10a76ba3509348e18f2b14a0c5",
            "/paper/Synthetic-data-augmentation-using-GAN-for-improved-Frid-Adar-Klang/90ebfcda74a92a9111f330951e2e5bfd871ff952",
            "/paper/Medical-Image-Synthesis-with-Context-Aware-Networks-Nie-Trullo/ef6abdcbd0871cb356e8669b6cdb31ed8b013cc2",
            "/paper/End-to-End-Adversarial-Retinal-Image-Synthesis-Costa-Galdran/dc421786d8883d99f3709da2b68ee1f3a3643894",
            "/paper/Image-Synthesis-in-Multi-Contrast-MRI-With-Networks-Dar-Yurt/757993ad8c3574857a01906d2b46a5909882a4fa",
            "/paper/Deep-Adversarial-Networks-for-Biomedical-Image-Zhang-Yang/b2662b3dd67415f75722e128a62a527c6ceae396",
            "/paper/Intraoperative-Organ-Motion-Models-with-an-Ensemble-Hu-Gibson/b363baf921caf973a966b5498443a548fc559378",
            "/paper/V-Net%3A-Fully-Convolutional-Neural-Networks-for-Milletar%C3%AC-Navab/50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "/paper/Automatic-Liver-Segmentation-Using-an-Adversarial-Yang-Xu/8b6b0c1139a3ab405e6df58aaa79305867f453ef",
            "/paper/Image-to-Image-Translation-with-Conditional-Isola-Zhu/8acbe90d5b852dadea7810345451a99608ee54c7",
            "/paper/Image-Super-Resolution-Using-Generative-Adversarial-Mahapatra-Bozorgtabar/ce52577e4f7fe983467f4983d42a7f3473193aee"
        ]
    },
    {
        "id": "97326c0468e4e412630b4db7cea9d0f8ac4dc475",
        "title": "CaraNet: context axial reverse attention network for segmentation of small medical objects",
        "abstract": "A Context Axial Reserve Attention Network (CaraNet) is proposed to improve the segmentation performance on small objects compared with several recent state-of-the-art models and achieves the top-rank mean Dice segmentation accuracy. Segmenting medical images accurately and reliably is important for disease diagnosis and treatment. It is a challenging task because of the wide variety of objects\u2019 sizes, shapes, and scanning modalities. Recently, many convolutional neural networks (CNN) have been designed for segmentation tasks and achieved great success. Few studies, however, have fully considered the sizes of objects, and thus most demonstrate poor performance for small objects segmentation. This can have a significant impact on the early detection of diseases. This paper proposes a Context Axial Reserve Attention Network (CaraNet) to improve the segmentation performance on small objects compared with several recent state-of-the-art models. We test our CaraNet on brain tumor (BraTS 2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300, and ETIS-LaribPolypDB) segmentation datasets. Our CaraNet achieves the top-rank mean Dice segmentation accuracy, and results show a distinct advantage of CaraNet in the segmentation of small medical objects. Codes available: https://github.com/AngeLouCN/CaraNet",
        "publication_year": "2021",
        "authors": [
            "Ange Lou",
            "Shuyue Guan",
            "Murray H. Loew"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "45",
        "reference_count": "49",
        "references": [
            "/paper/TAE-ResU-Net%3AA-trinomial-attention-based-U-shaped-Yu-Wang/5d317135562c408aceceb11adfac0ccdc8ff68c5",
            "/paper/Counterfactual-Explainable-Gastrointestinal-and-Singh-Somani/66f536f7e2ef072f021207af9e39d813a96e0ebf",
            "/paper/DSNet%3A-a-simple-yet-efficient-network-with-for-Liu/72a09f4e482a405ac3e0691400338e989b77b5f2",
            "/paper/ESFPNet%3A-efficient-deep-learning-architecture-for-Chang-Ahmad/807e198558c26d4be621eb6fffacab08ebf0eb26",
            "/paper/CLD-Net%3A-Complement-Local-Detail-For-Medical-Chen-Wang/d95def7c56453df7a2c2b53dbe7bebc52a9dbec8",
            "/paper/JudgeNet%3A-Inverse-Attention-and-Multiscale-Fusion-Wang-Xu/ac41d7785f10208e66bca8b722e9992ed2ee0477",
            "/paper/FCN-Transformer-Feature-Fusion-for-Polyp-Sanderson-Matuszewski/8d732f0ecb290c022de6ad9061bebe377b00b5d9",
            "/paper/Incremental-Boundary-Refinement-using-Self-Axial-Viet-Duy/064c076d37748844e6bafa1bfc55513d42ba1b29",
            "/paper/Rema-Net%3A-An-efficient-multi-attention-neural-for-Yang-Fan/e34f9063ce56948f919c4458ef5d954d61676d97",
            "/paper/GCA-Net%3A-Geometrical-Constraints-based-Advanced-for-Nguyen-Tran/be6d2a227049c50e64f857469185751b301d1500",
            "/paper/TransUNet%3A-Transformers-Make-Strong-Encoders-for-Chen-Lu/24b8a0b02bcb7934967757fc59d273a71ba67e30",
            "/paper/CFPNet-M%3A-A-Light-Weight-Encoder-Decoder-Based-for-Lou-Guan/302e73be5a6f47e81abdd562605e5700b55c16f6",
            "/paper/Multi-Task-Learning-for-Small-Brain-Tumor-from-MRI-Ngo-Tran/389250f71549858554eae9c5d6778b1624cd8c1f",
            "/paper/CoTr%3A-Efficiently-Bridging-CNN-and-Transformer-for-Xie-Zhang/8356d155d730e374f4db6dfd03d19a7b66c348a8",
            "/paper/ResUNet%2B%2B%3A-An-Advanced-Architecture-for-Medical-Jha-Smedsrud/80f4c7c360d1150ba58c3bacf5c35718ebdd0c10",
            "/paper/Medical-Transformer%3A-Gated-Axial-Attention-for-Valanarasu-Oza/1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/The-KiTS19-Challenge-Data%3A-300-Kidney-Tumor-Cases-Heller-Sathianathen/2bc472478247173b25aaf5e12f2604a74a8d2063",
            "/paper/Kvasir-SEG%3A-A-Segmented-Polyp-Dataset-Jha-Smedsrud/349461d60b4d3d34dc97147e4b9ec2b9bd611be8",
            "/paper/PraNet%3A-Parallel-Reverse-Attention-Network-for-Fan-Ji/89c6badea0d7bf834d4c069517116dd99c4cc0fd"
        ]
    },
    {
        "id": "8703994d245dff6d27a5992dfad23ee8ce4a8ead",
        "title": "Impact of Treatment on Vestibular Schwannoma\u2013Associated Symptoms: A Prospective Study Comparing Treatment Modalities",
        "abstract": "It is suggested that tinnitus, dizziness or imbalance, and headaches are unlikely to be significantly modified by treatment modality and generally should not be used to direct treatment choice. Objective The degree to which various treatment modalities modify vestibular schwannoma (VS)\u2013associated symptoms has received limited attention. The purpose of this study was to determine how different treatment modalities affect subjective symptoms in those presenting with VS. Study Design Prospective survey. Setting Tertiary neurotology referral center. Methods Patients with sporadic VS who received treatment at our institution were prospectively surveyed with a VS symptom questionnaire. Those who completed a baseline survey prior to treatment and at least 1 posttreatment survey were included. The prospective survey evaluated the severity of self-reported symptoms (Likert scale, 1-10), including tinnitus, dizziness or imbalance, headaches, and hearing loss. Results A total of 244 patients were included (mean age, 57 years). The mean duration of follow-up was 2.1 years, and the median number of surveys completed was 2 (interquartile range, 1-3). Seventy-eight (32%) cases were managed with observation, 118 (48%) with microsurgery, and 48 (20%) with radiosurgery. Multivariable analyses revealed no statistically significant difference in the change in tinnitus (P = .15), dizziness or imbalance (P = 0.66), or headaches (P = .24) among treatment groups. Evaluation of clinically important differences demonstrated that microsurgery leads to significant bidirectional changes in headaches. Conclusions Limited prospective data exist regarding the progression or resolution of subjective symptoms in those presenting with VS. This study suggests that tinnitus, dizziness or imbalance, and headaches are unlikely to be significantly modified by treatment modality and generally should not be used to direct treatment choice.",
        "publication_year": "2021",
        "authors": [
            "Jason H. Barnes",
            "Neil S. Patel",
            "C. Lohse",
            "Nicole Tombers",
            "M. Link",
            "M. Carlson"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "5",
        "reference_count": "21",
        "references": [
            "/paper/Outcomes-of-Initial-Observation-Versus-Upfront-for-Patro-Totten/af300b2cddf9978cd63097bb2e27f22a7ef202ce",
            "/paper/Single-fraction-stereotactic-radiosurgery-versus-of-Jakubeit-Sturtz/0996ec7cbe04d1d3e1529623363acf7435ae69e2",
            "/paper/Radiation-for-Sporadic-Vestibular-Schwannoma%3A-An-on-Woodson/21db66a912d65b66f5c9e9a2fcfd52b3aa170e72",
            "/paper/Introducing-an-Evidence-Based-Approach-to-of-Size-Marinelli-Lohse/cd94cd76627c1a9be3fd91acfbb8323a77baa061",
            "/paper/Skull-Base-Registries%3A-A-Roadmap-Parikh-Motiwala/385ad46d69b49e422583178cc5c8814d520e383f",
            "/paper/Risk-factors-and-analysis-of-long-term-headache-in-Carlson-Tveiten/c2bd19673fa22b01a516ffeb1e8af6cca882567e",
            "/paper/Sex-and-Age-Associations-With-Vestibular-Schwannoma-Harun-Agrawal/af257199d04543437b57781afe9f3f0e1d43d430",
            "/paper/Prospective-Study-of-Disease-Specific-in-Sporadic-Carlson-Barnes/e9f42702f018cc45ae185e61cc47a6950f55ab0a",
            "/paper/Efficacy-of-microsurgical-tumor-removal-for-of-with-Samii-Metwali/dc8d88a23684f344ee1564634066cb3c485a197e",
            "/paper/Long-term-Dizziness-Handicap-in-Patients-with-A-Carlson-Tveiten/9a20bcac2213253b054e990ce00774c26f67ae63",
            "/paper/Long-term-quality-of-life-in-patients-with-an-study-Carlson-Tveiten/d571627b938399be35a8268c6f743d03a9fe95ed",
            "/paper/Does-where-you-live-influence-how-your-vestibular-Carlson-Glasgow/70b71aed928bcf39acfe0ac58ce4443f6fba1b54",
            "/paper/Hearing-preservation-after-stereotactic-for-A-Yang-Aranda/630f70bffa9a3ab30aca3ee620c763c0517b8203",
            "/paper/Durability-of-Hearing-Preservation-Following-of-Dowling-Patel/5dc0831b7d1fdf9cacc7689e92967c5d0a3b9c22",
            "/paper/Hearing-Preservation-for-Vestibular-Schwannomas-or-Udawatta-Kwan/25bc69c6343c711f90b7aed62f11e0393671d023"
        ]
    },
    {
        "id": "83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
        "title": "Joint Optic Disc and Cup Segmentation Based on Multi-Label Deep Network and Polar Transformation",
        "abstract": "A deep learning architecture, named M-Net, is proposed, which solves the OD and OC segmentation jointly in a one-stage multi-label system and introduces the polar transformation, which provides the representation of the original image in the polar coordinate system. Glaucoma is a chronic eye disease that leads to irreversible vision loss. The cup to disc ratio (CDR) plays an important role in the screening and diagnosis of glaucoma. Thus, the accurate and automatic segmentation of optic disc (OD) and optic cup (OC) from fundus images is a fundamental task. Most existing methods segment them separately, and rely on hand-crafted visual feature from fundus images. In this paper, we propose a deep learning architecture, named M-Net, which solves the OD and OC segmentation jointly in a one-stage multi-label system. The proposed M-Net mainly consists of multi-scale input layer, U-shape convolutional network, side-output layer, and multi-label loss function. The multi-scale input layer constructs an image pyramid to achieve multiple level receptive field sizes. The U-shape convolutional network is employed as the main body network structure to learn the rich hierarchical representation, while the side-output layer acts as an early classifier that produces a companion local prediction map for different scale layers. Finally, a multi-label loss function is proposed to generate the final segmentation map. For improving the segmentation performance further, we also introduce the polar transformation, which provides the representation of the original image in the polar coordinate system. The experiments show that our M-Net system achieves state-of-the-art OD and OC segmentation result on ORIGA data set. Simultaneously, the proposed method also obtains the satisfactory glaucoma screening performances with calculated CDR value on both ORIGA and SCES datasets.",
        "publication_year": "2018",
        "authors": [
            "H. Fu",
            "Jun Cheng",
            "Yanwu Xu",
            "D. Wong",
            "Jiang Liu",
            "Xiaochun Cao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "539",
        "reference_count": "45",
        "references": [
            "/paper/A-multi-scale-convolutional-neural-network-with-for-Yuan-Zhou/e3a8b8b9300e05321ffa92439d5c49bd02d99e50",
            "/paper/Joint-optic-disc-and-cup-segmentation-based-on-deep-Liu-Pan/f451015017417fb4d45bb084cee73ba3318967f7",
            "/paper/A-Simplified-Deep-Network-Architecture-on-Optic-Cup-Huang-Hsiang/12350ad25eddab793bdfc64af9c0fba46d03366f",
            "/paper/UT-Net%3A-Combining-U-Net-and-Transformer-for-Joint-Hussain-Basak/76c03bc14aa3ee387d8ebf4dc3b78276bf9103a8",
            "/paper/Mixed-Maximum-Loss-Design-for-Optic-Disc-and-Optic-Xu-Lu/2c3880954cd76ed2d5b86dd4faf151f8b0bd7ec8",
            "/paper/Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Qin-Wang/e3998e916c7f944745b4599b963c736135a304b4",
            "/paper/Glaucoma-Detection-Based-on-Deep-Learning-Network-Fu-Cheng/f8f3134cdbd3159f15144cd630ee24343bedcd6b",
            "/paper/GDCSeg-Net%3A-general-optic-disc-and-cup-segmentation-Ianlong-Hu/17d1bfc59cff24c21da40913de0bda483530d8b9",
            "/paper/Automatic-Measurement-of-Cup-to-Disc-Ratio-for-Zhao-Guo/3581e7fee260cbb92ba7356ae6569fe8659227b4",
            "/paper/Joint-optic-disc-and-cup-segmentation-using-feature-Guo-Li/d8239a910afd9a6400d03dba7c50414c5f2d68ca",
            "/paper/Efficient-Optic-Cup-Detection-from-Intra-image-with-Xu-Liu/d43330d88a052fc9e38e57f7c8c0a59a68e8f9a2",
            "/paper/Automatic-Feature-Learning-for-Glaucoma-Detection-Chen-Xu/4593068aeb2b2fc9d961b14e656d1b1afaf8a872",
            "/paper/Superpixel-Classification-Based-Optic-Disc-and-Cup-Cheng-Liu/2d054c85a51f101b51f0427d332e22eb5c502165",
            "/paper/Level-set-based-automatic-cup-to-disc-ratio-using-Wong-Liu/9a0cf9c7f1af4ea6e1e5e80b8dc4a6d64f81fcd2",
            "/paper/Optic-Disc-and-Optic-Cup-Segmentation-Methodologies-Almazroa-Burman/ae32cc948e196ab3dd9f8e01a5cd0cb128d92e72",
            "/paper/ORIGA-light%3A-An-online-retinal-fundus-image-for-and-Zhang-Yin/47ec115fb91adcd00716467fa038b0507ad6ac41",
            "/paper/Optic-Disk-and-Cup-Segmentation-From-Monocular-for-Joshi-Sivaswamy/f020b386f5a2be002e09b17cd348c388cc1199fc",
            "/paper/Automated-segmentation-of-optic-disc-in-SD-OCT-and-Wu-Leng/ad3830183f3620c475b9d7d1304823dcd1dc7dc2",
            "/paper/Segmentation-of-the-Optic-Disc-in-3-D-OCT-Scans-of-Lee-Niemeijer/96660e0f1664a44dcfa5659006c2696fe2543d07",
            "/paper/Sliding-Window-and-Regression-Based-Cup-Detection-Xu-Xu/97008b8fb65fea3e10d4d4c1b5315f39682e5f3d"
        ]
    },
    {
        "id": "e939719b2a66bbaddd74ed139970e5a7e0b5f3cd",
        "title": "AirFi: Empowering WiFi-based Passive Human Gesture Recognition to Unseen Environment via Domain Generalization",
        "abstract": "The AirFi is a novel domain generalization framework that learns the critical part of CSI regardless of different environments and generalizes the model to unseen scenarios, which does not require collecting any data for adaptation to the new environment. WiFi-based smart human sensing technology enabled by Channel State Information (CSI) has received great attention in recent years. However, CSI-based sensing systems suffer from performance degradation when deployed in different environments. Existing works solve this problem by domain adaptation using massive unlabeled high-quality data from the new environment, which is usually unavailable in practice. In this paper, we propose a novel augmented environment-invariant robust WiFi gesture recognition system named AirFi that deals with the issue of environment dependency from a new perspective. The AirFi is a novel domain generalization framework that learns the critical part of CSI regardless of different environments and generalizes the model to unseen scenarios, which does not require collecting any data for adaptation to the new environment. AirFi extracts the common features from several training environment settings and minimizes the distribution differences among them. The feature is further augmented to be more robust to environments. Moreover, the system can be further improved by few-shot learning techniques. Compared to state-of-the-art methods, AirFi is able to work in different environment settings without acquiring any CSI data from the new environment. The experimental results demonstrate that our system remains robust in the new environment and outperforms the compared systems.",
        "publication_year": "2022",
        "authors": [
            "Dazhuo Wang",
            "Jianfei Yang",
            "Wei Cui",
            "Lihua Xie",
            "S. Sun"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "87",
        "references": [
            "/paper/SenseFi%3A-A-library-and-benchmark-on-WiFi-human-Yang-Chen/3aadb6c7e584e4f4a281f7d9053b8d4a369c23f8",
            "/paper/AutoFi%3A-Towards-Automatic-WiFi-Human-Sensing-via-Yang-Chen/2a1ea90a71131275685d815daa9c5c40208f9c9f",
            "/paper/WiFi-Based-Cross-Domain-Gesture-Recognition-via-Zhang-Tang/e9852705307b09b6b067c91973e836a182e68503",
            "/paper/WiFi-CSI-Based-Passive-Human-Activity-Recognition-Chen-Zhang/0017ece1f39a0ed3a054697e87bc4d92c52a3658",
            "/paper/Robust-CSI-based-Human-Activity-Recognition-using-Wang-Yang/f227c76e3fb7924abcc54911ce2e18070e236dca",
            "/paper/Multimodal-CSI-Based-Human-Activity-Recognition-Wang-Yang/db5796032ac7fec7abd457dfa6531131b3ebe70f",
            "/paper/Joint-Adversarial-Domain-Adaptation-for-Resilient-Zou-Yang/8fde5f2e4b9950e708aeaf3a0c6f47037cc5d6a1",
            "/paper/WiFi-and-Vision-Multimodal-Learning-for-Accurate-Zou-Yang/e9e01af30f1507555008f4b0a1b83ea2debe6f19",
            "/paper/WiGrus%3A-A-Wifi-Based-Gesture-Recognition-System-Zhang-Song/dfd4fe7fb38f148ce0fcf6d5b6771245ba26be9a",
            "/paper/Learning-Gestures-From-WiFi%3A-A-Siamese-Recurrent-Yang-Zou/a6d087332d4cadd9a90c8c4aa2c122413033cd9d",
            "/paper/A-Ubiquitous-WiFi-Based-Fine-Grained-Gesture-System-Abdelnasser-Harras/64f5dad3c616a1c34c788c166e7df3d3be7a6fb3"
        ]
    },
    {
        "id": "0548c96de57f8fad3053be706e094320e14c10ec",
        "title": "Exploiting Spatial-temporal Correlations for Video Anomaly Detection",
        "abstract": "This paper addresses unsupervised VAD by learning the evolution regularity of appearance and motion in the long and short-term and exploit the spatial-temporal correlations among consecutive frames in normal videos more adequately and introduces a discriminator to perform adversarial learning with the ST-LSTM to enhance the learning capability. Video anomaly detection (VAD) remains a challenging task in the pattern recognition community due to the ambiguity and diversity of abnormal events. Existing deep learning-based VAD methods usually leverage proxy tasks to learn the normal patterns and discriminate the instances that deviate from such patterns as abnormal. However, most of them do not take full advantage of spatial-temporal correlations among video frames, which is critical for understanding normal patterns. In this paper, we address unsupervised VAD by learning the evolution regularity of appearance and motion in the long and short-term and exploit the spatial-temporal correlations among consecutive frames in normal videos more adequately. Specifically, we proposed to utilize the spatiotemporal long short-term memory (ST-LSTM) to extract and memorize spatial appearances and temporal variations in a unified memory cell. In addition, inspired by the generative adversarial network, we introduce a discriminator to perform adversarial learning with the ST-LSTM to enhance the learning capability. Experimental results on standard benchmarks demonstrate the effectiveness of spatial-temporal correlations for unsupervised VAD. Our method achieves competitive performance compared to the state-of-the-art methods with AUCs of 96.7%, 87.8%, and 73.1% on the UCSD Ped2, CUHK Avenue, and ShanghaiTech, respectively.",
        "publication_year": "2022",
        "authors": [
            "Mengyang Zhao",
            "Yang Liu",
            "Jing Li",
            "Xinhua Zeng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "32",
        "references": [
            "/paper/LGN-Net%3A-Local-Global-Normality-Network-for-Video-Zhao-Liu/83665e3366c67aade3e771825b2d886fb77e6b02",
            "/paper/Configurable-Spatial-Temporal-Hierarchical-Analysis-Cheng-Zeng/8acf1ec907ad22d57c1dbba18d9d4ab2b1d1543e",
            "/paper/Generalized-Video-Anomaly-Event-Detection%3A-Taxonomy-Liu-Yang/bb51ca71833d42fa58f9adccb2296bdf665cc158",
            "/paper/OSIN%3A-Object-Centric-Scene-Inference-Network-for-Liu-Guo/e4e6f0afca17f79dc7a1ab671ab5ad448e97ae7d",
            "/paper/Multi-scale-Spatial-temporal-Interaction-Network-Ning-Li/8ac566e14bf837f3525cd002aabfbdc299b0ec3b",
            "/paper/Convolutional-Transformer-based-Dual-Discriminator-Feng-Song/014ad6b5c003ecf7566570266d43154ac8683758",
            "/paper/Video-anomaly-detection-with-spatio-temporal-Chang-Tu/2e6088d5f1081f2b46295d8783a5c2642ec35041",
            "/paper/Appearance-Motion-United-Auto-Encoder-Framework-for-Liu-Liu/a420ed5d7a8f8fd1a1ccf4c819b19d14749b7488",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/NM-GAN%3A-Noise-modulated-generative-adversarial-for-Chen-Yue/91336c65cddd8546745f67a1b860c2595904ac15",
            "/paper/Learning-Task-Specific-Representation-for-Video-Liu-Liu/2ac0ad0afcbc73a2063f4f003592d0d216e61e54",
            "/paper/Clustering-Driven-Deep-Autoencoder-for-Video-Chang-Tu/7c75203739f5f89e109b11144d170d4d3f2a6abc",
            "/paper/Collaborative-Normality-Learning-Framework-for-Liu-Liu/f9870bfdcec0de7b3aebce75768e0ee75952cd71",
            "/paper/Appearance-Motion-Memory-Consistency-Network-for-Cai-Zhang/08c4fa2132dda85c5f02a88fddfb7f17973f3978",
            "/paper/Stan%3A-Spatio-Temporal-Adversarial-Networks-for-Lee-Kim/1df6db34c477aa43218f2efc4ec5458eaf734849"
        ]
    },
    {
        "id": "158506c9db9ec99ef23675bb6b289673009b38fc",
        "title": "A Novel Multitemporal Deep Fusion Network (MDFN) for Short-Term Multitemporal HR Images Classification",
        "abstract": "Experimental results carried on two real multitem temporal HR remote sensing datasets demonstrate that the proposed MDFN provides better classification performance over the state-of-the-art methods, and it also shows the potentiality to use short-term multitemporal HR images for more accurate land use/land cover mapping. High-resolution (HR) satellite images, due to the technical constraints on spectral and spatial resolutions, usually contain only several broad spectral bands but with a very high spatial resolution. This provides rich spatial details of the objects on the Earth surface, while their spectral discrimination is relatively low. Recently, the increase of the satellite revisit times made it possible to acquire more frequent data coverage for finer classification. In this article, we proposed a novel multitemporal deep fusion network (MDFN) for short-term multitemporal HR images classification. Specifically, a two-branch structure of MDFN is designed, which includes a long short-term memory (LSTM) and a convolutional neural network (CNN). The LSTM branch is mainly used to learn the joint expression of different temporal-spectral features. For the CNN branch, the three-dimensional (3-D) convolution is firstly applied along the temporal and spectral dimensions to jointly learn the temporal-spatial and spectral-spatial information, respectively, and then the 2-D convolution is performed along the spatial dimension to further extract the spatial context information. Finally, features generated from the two different branches are fused to obtain the discriminative high-level semantic information for classification. Experimental results carried on two real multitemporal HR remote sensing datasets demonstrate that the proposed MDFN provides better classification performance over the state-of-the-art methods, and it also shows the potentiality to use short-term multitemporal HR images for more accurate land use/land cover mapping.",
        "publication_year": "2021",
        "authors": [
            "Yongjie Zheng",
            "Sicong Liu",
            "Q. Du",
            "Hui Zhao",
            "X. Tong",
            "M. Dalponte"
        ],
        "related_topics": [
            "Environmental Science",
            "Mathematics"
        ],
        "citation_count": "11",
        "reference_count": "39",
        "references": [
            "/paper/GCFnet%3A-Global-Collaborative-Fusion-Network-for-and-Zhao-Liu/ee80947b8d7a87009a2d2c9f3646aa0d725796b6",
            "/paper/Novel-Cross-Resolution-Feature-Level-Fusion-for-of-Liu-Zhao/3fcb3826469046a078fc510d66e8d0c29631b742",
            "/paper/A-Shallow-to-Deep-Feature-Fusion-Network-for-VHR-Liu-Zheng/008e123a6b7df2bd8b4e50377bf663d6094460d8",
            "/paper/FCAU-Net-for-the-Semantic-Segmentation-of-Remotely-Niu-Zeng/92775aca1142fcd274e208608de9c12f00602685",
            "/paper/Multi-Task-Learning-for-Building-Extraction-and-Hong-Qiu/4d4fd9b57abf1355180c9c2d5bad583c9f235357",
            "/paper/A-Temporal-Spectral-Generative-Adversarial-Fusion-Ren-Sun/48796cdfcc79768576ebc2162dfe292deddbeb37",
            "/paper/Location-aware-Adaptive-Denormalization%3A-A-Deep-For-Eddin-Roscher/2898571ec05cfacf61e24822e1e6e45a9619d376",
            "/paper/Feature-Alignment-FPN-for-Oriented-Object-Detection-Li-Li/98b4d9f0a08f0234d1881d7ca109ba712e849d70",
            "/paper/Extracting-Wetland-Type-Information-with-a-Deep-Guan-Wang/6d655be24eab30c37084b3f3eb4e0393af21c2a9",
            "/paper/Non-IID-federated-learning-via-random-exchange-of-Peng-Chi/1b064b6b9999958060f762809be695b777324943",
            "/paper/Spatial%E2%80%93Spectral-Feature-Extraction-via-Deep-Neural-Hu-Li/e0c9e793e046d58af98a789592d81ea168e47345",
            "/paper/Attention-Multibranch-Convolutional-Neural-Network-Feng-Wu/f44d4fdc3eaf3546ff3c99ce306681b82dea1f95",
            "/paper/Temporal-Attention-Networks-for-Multitemporal-Crop-Li-Chen/68c82ad323d85a51b38a362c74c5db44e8e5d75a",
            "/paper/Unsupervised-Deep-Joint-Segmentation-of-Images-Saha-Mou/b72d0d2c024688202952f3007298a9cf68688eaf",
            "/paper/Spectral%E2%80%93Spatial-Residual-Network-for-Hyperspectral-Zhong-Li/18056fcac6fc744b940a8d10ff36d42269006f3c",
            "/paper/Deep-Feature-Extraction-and-Classification-of-Based-Chen-Jiang/10fb16414324a5db44f5d830adcb4810af59eed0",
            "/paper/Graph-Convolutional-Networks-for-Hyperspectral-Hong-Gao/56ac2cac5c9f4996de3cc0c344d12ec3b8e7e8e6",
            "/paper/A-Simplified-2D-3D-CNN-Architecture-for-Image-Based-Yu-Han/ad4e5f7ffceba9dc9a8de461d0bb1c7a57bbc501",
            "/paper/More-Diverse-Means-Better%3A-Multimodal-Deep-Learning-Hong-Gao/3e496094ccd932c8e1b24189710d819b016ff4c1",
            "/paper/Spectral%E2%80%93Spatial-Unified-Networks-for-Hyperspectral-Xu-Zhang/33b2ad104a71644444ffa10563c2792614a4d7ec"
        ]
    },
    {
        "id": "b2ff78b76a302b005ab65ad0d404373a70f3d5ee",
        "title": "Deep Learning for Launching and Mitigating Wireless Jamming Attacks",
        "abstract": "An adversarial machine learning approach is introduced to launch jamming attacks on wireless communications and a defense strategy is presented, where the transmitter systematically selects when to take wrong actions and adapts the level of defense to mislead the jammer into making prediction errors and consequently increase its throughput. An adversarial machine learning approach is introduced to launch jamming attacks on wireless communications and a defense strategy is presented. A cognitive transmitter uses a pre-trained classifier to predict the current channel status based on recent sensing results and decides whether to transmit or not, whereas a jammer collects channel status and ACKs to build a deep learning classifier that reliably predicts the next successful transmissions and effectively jams them. This jamming approach is shown to reduce the transmitter\u2019s performance much more severely compared with random or sensing-based jamming. The deep learning classification scores are used by the jammer for power control subject to an average power constraint. Next, a generative adversarial network is developed for the jammer to reduce the time to collect the training dataset by augmenting it with synthetic samples. As a defense scheme, the transmitter deliberately takes a small number of wrong actions in spectrum access (in form of a causative attack against the jammer) and therefore prevents the jammer from building a reliable classifier. The transmitter systematically selects when to take wrong actions and adapts the level of defense to mislead the jammer into making prediction errors and consequently increase its throughput.",
        "publication_year": "2018",
        "authors": [
            "T. Erpek",
            "Y. Sagduyu",
            "Yi Shi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "147",
        "reference_count": "41",
        "references": [
            "/paper/Adversarial-Deep-Learning-for-Over-the-Air-Spectrum-Sagduyu-Shi/892d41979d1b76f9e2f789de8f27e31f12e65b96",
            "/paper/Efficient-Power-Adaptation-against-Deep-Learning-Ciftcioglu-Ricos/1b9171593aeedca2314e539031c7c28b6de9d718",
            "/paper/Channel-Aware-Adversarial-Attacks-Against-Deep-Kim-Sagduyu/0497b410e841d42536cc48ba5869ee0258781b5c",
            "/paper/Trojan-Attacks-on-Wireless-Signal-Classification-Davaslioglu-Sagduyu/9bd74ce88249bee09e6c2e7fec74af7efd4db468",
            "/paper/Adversarial-Machine-Learning-and-Defense-Game-for-Sagduyu/3ca7ad47068f96b0cd2f55cd19f41a1845611ebb",
            "/paper/Over-the-Air-Adversarial-Attacks-on-Deep-Learning-Kim-Sagduyu/930015ee9b741c723fc3e6504f3cb67b3fba0e53",
            "/paper/Adversarial-jamming-attacks-and-defense-strategies-Wang-Zhong/5d38bc57cbd2dc2da316d51ab124bbee3cd08ee6",
            "/paper/Undermining-Deep-Learning-Based-Channel-Estimation-Hou-Wang/86fb22cc461f77b5c85b21227f74b9dfb90159ed",
            "/paper/Adversarial-Machine-Learning-for-5G-Communications-Sagduyu-Erpek/8fd0431186564148b8c0b8a30c363fe724ff320e",
            "/paper/Analysis-on-Deep-Learning-Based-5G-Wireless-Jamming-Tyagi/366f54591cc3257bbc1d7704c683b95d71faecc8",
            "/paper/Adversarial-Deep-Learning-for-Cognitive-Radio-and-Shi-Sagduyu/25fb31c992edc8f4b913777c7a646cb0fe2f66ca",
            "/paper/Spectrum-Data-Poisoning-with-Adversarial-Deep-Shi-Erpek/4531f346abb78892822825c56d33f2f1c7a6bead",
            "/paper/The-feasibility-of-launching-and-detecting-jamming-Xu-Trappe/2b7a0cb7ff419faaaec2a5c228c18ea1bd269dd6",
            "/paper/Generative-Adversarial-Learning-for-Spectrum-Davaslioglu-Sagduyu/5e2d9d7e94b4587c452df573b9b8ed05fa9ac828",
            "/paper/Two-dimensional-anti-jamming-communication-based-on-Han-Xiao/0b8be881b5c4611087713e7b5d823119742bce26",
            "/paper/Evasion-and-causative-attacks-with-adversarial-deep-Shi-Sagduyu/78b7bed9176cc1eab592041c95faff8fd157e1c8",
            "/paper/Vulnerability-Detection-and-Analysis-in-Adversarial-Shi-Sagduyu/5354140931564832e98db08556311fe91185a1c4",
            "/paper/Generative-Adversarial-Networks-for-Black-Box-API-Shi-Sagduyu/096302a0294ff007787fe58d1476598c9675b870",
            "/paper/How-to-steal-a-machine-learning-classifier-with-Shi-Sagduyu/2ac11a0b84580e88bb8c6e5edb38c92fe1456864",
            "/paper/Adversarial-examples-in-the-physical-world-Kurakin-Goodfellow/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b"
        ]
    },
    {
        "id": "03f64803afaf312a3b299fe1c2bc26c329d43747",
        "title": "Line Graph Contrastive Learning for Link Prediction",
        "abstract": "A novel cross-scale contrastive learning framework on the line graph and the subgraph to maximize the mutual information of them, so that fuses the structure and feature information. Link prediction tasks focus on predicting possible future connections. Most existing researches measure the likelihood of links by different similarity scores on node pairs and predict links between nodes. However, the similarity-based approaches have some challenges in information loss on nodes and generalization ability on similarity indexes. To address the above issues, we propose a Line Graph Contrastive Learning(LGCL) method to obtain rich information with multiple perspectives. LGCL obtains a subgraph view by h-hop subgraph sampling with target node pairs. After transforming the sampled subgraph into a line graph, the link prediction task is converted into a node classification task, which graph convolution progress can learn edge embeddings from graphs more effectively. Then we design a novel cross-scale contrastive learning framework on the line graph and the subgraph to maximize the mutual information of them, so that fuses the structure and feature information. The experimental results demonstrate that the proposed LGCL outperforms the state-of-the-art methods and has better performance on generalization and robustness.",
        "publication_year": "2022",
        "authors": [
            "Zehua Zhang",
            "Shilin Sun",
            "Guixiang Ma",
            "Caiming Zhong"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "58",
        "references": [
            "/paper/Line-Graph-Neural-Networks-for-Link-Prediction-Cai-Li/ad720ec891fd143090de390a2e800eb8e9e6eb4d",
            "/paper/Link-Prediction-Based-on-Graph-Neural-Networks-Zhang-Chen/e4715a13f6364b1c81e64f247651c3d9e80b6808",
            "/paper/Cross-Network-Skip-Gram-Embedding-for-Joint-Network-Du-Yan/3608eced135f5f405f0f45635ed7f44d26cd3baf",
            "/paper/Integrating-node-centralities%2C-similarity-measures%2C-Anand-Rahul/95476a8b26b8e51c5f1bc7ebd245685a0feb489f",
            "/paper/GraphAIR%3A-Graph-Representation-Learning-with-and-Hu-Zhu/4c92208c7062ae5f9daf8df8b06ac5378233bc02",
            "/paper/Deep-Graph-Contrastive-Representation-Learning-Zhu-Xu/4bf76588122827157c43a59e656dccc6b6a22e90",
            "/paper/Neural-graph-embeddings-as-explicit-low-rank-matrix-Agibetov/72e48f3c71fc749f0b589e02a1ce7a4f0afba07e",
            "/paper/node2vec%3A-Scalable-Feature-Learning-for-Networks-Grover-Leskovec/36ee2c8bd605afd48035d15fdc6b8c8842363376",
            "/paper/Graph-Contrastive-Learning-with-Adaptive-Zhu-Xu/0d67d3ddca1c4e370eaf1e99ec674f612c39c66c",
            "/paper/Learning-graph-structure-via-graph-convolutional-Zhang-Chang/2c65aeb1ddb6edcf636e4548a7dcd76aac3dc48b"
        ]
    },
    {
        "id": "97af4edcd2978b535c4efd1df45243eac8ff8d37",
        "title": "Controlled physics-informed data generation for deep learning-based remaining useful life prediction under unseen operation conditions",
        "abstract": "Semantic Scholar extracted view of \"Controlled physics-informed data generation for deep learning-based remaining useful life prediction under unseen operation conditions\" by Jiawei Xiong et al.",
        "publication_year": "2023",
        "authors": [
            "Jiawei Xiong",
            "Olga Fink",
            "Jian Zhou",
            "Yizhong Ma"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "56",
        "references": [
            "/paper/Fusing-Physics-based-and-Deep-Learning-Models-for-Chao-Kulkarni/28ec028c2bd8a535fa665e20a1317a6c8835af52",
            "/paper/Remaining-Useful-Lifetime-Prediction-via-Deep-Costa-Ak%C3%A7ay/ed2cb425300837f99af4cc188dbbfafc3391c71a",
            "/paper/Remaining-useful-life-predictions-for-turbofan-deep-Ellefsen-Bj%C3%B8rlykhaug/5177be422e9eadcc806551c78430173e5a4a3f42",
            "/paper/TimeVAE%3A-A-Variational-Auto-Encoder-for-Time-Series-Desai-Freeman/b8b43e4a2b476743cbaa05451e1c72b309083e42",
            "/paper/Physics-Infused-Fuzzy-Generative-Adversarial-for-Nguyen-Singh/fb9e348fe06882e517db6d5c5548c749324783f7",
            "/paper/TTS-CGAN%3A-A-Transformer-Time-Series-Conditional-GAN-Li-Ngu/441dd647943c4f807672a61d6b4928f9bf335a69",
            "/paper/Real-valued-(Medical)-Time-Series-Generation-with-Esteban-Hyland/d01f5f3d1971e7906d58dcc8baf9efb406c47fd2",
            "/paper/Non-parametric-Multi-Self-Attention-Temporal-for-Xiong-Tian/0a3532d23a94e5fbe69a5f184040b60160189d5f",
            "/paper/Time-series-Generative-Adversarial-Networks-Yoon-Jarrett/08d350a25720d865a52c00f3af6cb80e7af52d58",
            "/paper/A-Bayesian-deep-learning-framework-for-interval-of-Kim-Liu/7ddf5423b45aa8f68f07e83f2aa43b286aac92d4"
        ]
    },
    {
        "id": "fec702c4fef109faccd98fb3f0502c7258970d80",
        "title": "Example-based color transfer with Gaussian mixture modeling",
        "abstract": "Semantic Scholar extracted view of \"Example-based color transfer with Gaussian mixture modeling\" by Chunzhi Gu et al.",
        "publication_year": "2020",
        "authors": [
            "Chunzhi Gu",
            "Xuequan Lu",
            "Chao Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "68",
        "references": [
            "/paper/A-Lightness-aware-Nearest-Neighbor-Search-Method-Gu-Zhang/f58502f06ce5f964f65f7960edbbab9bb8531233",
            "/paper/Style-aware-robust-color-transfer-Hristova-Meur/d2d443cd8f26340d1daf2d4cda45bb450a3098f6",
            "/paper/Local-color-transfer-via-probabilistic-segmentation-Tai-Jia/6f1d7d584b39b423151488832b98880c6c7391cd",
            "/paper/Corruptive-Artifacts-Suppression-for-Example-Based-Su-Zeng/702a6d1168a6601086817c72e6fb0f2bf2f2bbba",
            "/paper/Optimal-Transportation-for-Example-Guided-Color-Frigo-Sabater/2611e2502864ace363f6decbaec591a25c8e4544",
            "/paper/Soft-Color-Segmentation-and-Its-Applications-Tai-Jia/7c2517f714a9015cf1673f9f7d2e024cb2be7230",
            "/paper/Deep-color-transfer-using-histogram-analogy-Lee-Son/1d30b941448645bc2dc304dcb1aacf9261070e0e",
            "/paper/Color-Transfer-Using-Probabilistic-Moving-Least-Hwang-Lee/54e8f504c3fc6b8e8e27c9a9cd7285698272c81d",
            "/paper/Filter-Style-Transfer-between-Photos-Yim-Yoo/b9802c0ed57fa2027e1365272bfbf1d3170f1b0e",
            "/paper/Robust-Image-to-Image-Color-Transfer-Using-Optimal-Oskarsson/53c8bc7cf08bed28493237e5004dd202077fc59f",
            "/paper/Recoding-Color-Transfer-as-A-Color-Homography-Gong-Finlayson/60a70eec9d6e49620655e334b61ecc469214678d"
        ]
    },
    {
        "id": "26bf74add0ee73ec8c80662508f39b41da1eca6d",
        "title": "CellMixS: quantifying and visualizing batch effects in single-cell RNA-seq data",
        "abstract": "A cell-specific mixing score (cms) is developed that quantifies mixing of cells from multiple batches and is able to detect local batch bias as well as differentiate between unbalanced batches and systematic differences between cells of the same cell type. A systematic comparison of batch effect metrics for single cell data is performed. The new cell-specific mixing score from the R/Bioconductor CellMixS package performs well across various tasks. A key challenge in single-cell RNA-sequencing (scRNA-seq) data analysis is batch effects that can obscure the biological signal of interest. Although there are various tools and methods to correct for batch effects, their performance can vary. Therefore, it is important to understand how batch effects manifest to adjust for them. Here, we systematically explore batch effects across various scRNA-seq datasets according to magnitude, cell type specificity, and complexity. We developed a cell-specific mixing score (cms) that quantifies mixing of cells from multiple batches. By considering distance distributions, the score is able to detect local batch bias as well as differentiate between unbalanced batches and systematic differences between cells of the same cell type. We compare metrics in scRNA-seq data using real and synthetic datasets and whereas these metrics target the same question and are used interchangeably, we find differences in scalability, sensitivity, and ability to handle differentially abundant cell types. We find that cell-specific metrics outperform cell type\u2013specific and global metrics and recommend them for both method benchmarks and batch exploration.",
        "publication_year": "2020",
        "authors": [
            "A. L\u00fctge",
            "J. Zyprych-Walczak",
            "Urszula Brykczynska Kunzmann",
            "Helena L. Crowell",
            "D. Calini",
            "D. Malhotra",
            "C. Soneson",
            "M. Robinson"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "15",
        "reference_count": "66",
        "references": [
            "/paper/A-comparison-of-data-integration-methods-for-RNA-of-Richards-Riverin/3ade37352a8d63048528d67badff5e4090ee019a",
            "/paper/The-shaky-foundations-of-simulating-single-cell-RNA-Crowell-Leonardo/614784ef42a5200cd5cfae7b2ea5a3d2cc763bca",
            "/paper/Built-on-sand%3A-the-shaky-foundations-of-simulating-Crowell-Leonardo/1b4ccadcc489a354bf74ec89960bcf8824daef65",
            "/paper/Dissecting-tumor-cell-programs-through-group-in-Johri-Bi/8e74bfbd533a7c5d9a3d2351961ecd8bab640e20",
            "/paper/distinct%3A-a-novel-approach-to-differential-analyses-Tiberi-Crowell/7fc07ff3169a8201036df815856d371388465572",
            "/paper/Meta-analysis-of-(single-cell-method)-benchmarks-Sonrel-Luetge/41ae69550ffc4e58c7810c630ef5230c6b3ee515",
            "/paper/Doublet-identification-in-single-cell-sequencing-Germain-Lun/cd5ce83ca2237072ebd36e492faf98d4086adabe",
            "/paper/A-structured-evaluation-of-cryopreservation-in-cell-Touil-Roostaei/e2f5cf0f51616e63f52d05e873da0cce49293452",
            "/paper/Single-cell-transcriptional-regulation-and-genetic-Wang-Wang/24a943ce641020cf16f1f23968d3b7ae31e6ea57",
            "/paper/Single-cell-eQTL-analysis-of-activated-T-cell-and-Schmiedel-Gonz%C3%A1lez-Col%C3%ADn/72d125f8bdfc38b4ddfcb2e5bae13563875479ae",
            "/paper/A-benchmark-of-batch-effect-correction-methods-for-Tran-Ang/d5baf1912d43d0af0e8f683eb5532f5f5445430e",
            "/paper/Flexible-comparison-of-batch-correction-methods-for-Chazarra-Gil-Dongen/f48d75612695cc36c3a820ae175261329318ab4c",
            "/paper/Batch-effects-in-single-cell-RNA-sequencing-data-by-Haghverdi-Lun/56bf103a956b4a2ad11868c05db189d1e3f64ac1",
            "/paper/Benchmarking-single-cell-RNA-sequencing-protocols-Mereu-Lafzi/ea90f772d80b0532dc3e7736a25f6551d1920cf2",
            "/paper/Benchmarking-single-cell-RNA-sequencing-protocols-Mereu-Lafzi/16427167f541cf06f9200dfc81ab78f168695559",
            "/paper/Bias%2C-robustness-and-scalability-in-differential-of-Soneson-Robinson/b2e4afcea95a65cf4769472654dfdb0d418bf4de",
            "/paper/A-step-by-step-workflow-for-low-level-analysis-of-Lun-McCarthy/74e86a3375ac2c2ffe89577fbf16456eb39ff581",
            "/paper/Bias%2C-robustness-and-scalability-in-single-cell-Soneson-Robinson/ba0452a487f67e7c233967f4c5b56d1c786631b0",
            "/paper/Comprehensive-Integration-of-Single-Cell-Data-Stuart-Butler/2287a3930a7568a956aae5f3f037efe8fed675e7",
            "/paper/Benchmarking-atlas-level-data-integration-in-Luecken-B%C3%BCttner/d88158745b69f5732397175389101e2d98799c00"
        ]
    },
    {
        "id": "aae369697b10bd7eb2e9c21a8c1911a4359707f0",
        "title": "Sparsity-aware normalized subband adaptive filters with jointly optimized parameters",
        "abstract": "Semantic Scholar extracted view of \"Sparsity-aware normalized subband adaptive filters with jointly optimized parameters\" by Lipeng Ji et al.",
        "publication_year": "2020",
        "authors": [
            "Lipeng Ji",
            "J. Ni"
        ],
        "related_topics": [
            "Computer Science",
            "Engineering"
        ],
        "citation_count": "13",
        "reference_count": "38",
        "references": [
            "/paper/L0-norm-constraint-normalized-subband-adaptive-and-Liu-Zhao/9e31ceae5ada558541d1995e3f06d0166f79e37b",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/50b98cc888fd59742d535f8c20f7975322dbe7d3",
            "/paper/Sparsity-Aware-Robust-Normalized-Subband-Adaptive-Yu-Huang/cf2395b281802968efce09a560ff52dd2007d913",
            "/paper/A-novel-normalized-subband-adaptive-filter-based-on-Shin-Park/bd3fd27d2a7f6b8e58db3ae07f3a772fbf90c4c4",
            "/paper/Sparsity-Aware-Logarithmic-Hyperbolic-Cosine-Filter-Liu-Zhao/a48a98e6251407660ce1d80a17b4fcbc00b01861",
            "/paper/Sparsity-Promoting-Affine-Projection-Algorithm-With-Ni-Zhang/a7bd11d13570562177c25418ff752368fa5297c5",
            "/paper/Improved-Performance-in-Distributed-Estimation-by-Pouradabi-Rastegarnia/368f245ecac5ed1a2adc3a5c4d7c830910a6a96c",
            "/paper/Study-of-L0-norm-constraint-normalized-subband-Liu-Zhao/7fff09b192d98b27e39a34aed9c6130c7c840da9",
            "/paper/A-New-Affine-Projection-Algorithm-with-Adaptive-l-0-Boopalan-Alagala/02fa59af1e966d2c22c57c7ebd009032d7d35218",
            "/paper/Variable-Step-Size-%24%5Cell-_%7B0%7D%24-Norm-Constraint-NLMS-Lee-Park/f66476bb4dd3bb45d60be9165201f70f8a546027",
            "/paper/Sparsity-aware-subband-adaptive-algorithms-with-Yu-Zhao/ebd0abdcae4d0580aa2ae4de7905e59349b9071a",
            "/paper/A-Variable-Step-Size-Matrix-Normalized-Subband-Ni-Li/8f64798dffa4f901e6730ab2d92d3915e1fd70bb",
            "/paper/Sparse-normalized-subband-adaptive-filter-algorithm-Yu-Zhao/a8802905bf00aa79a578e9ebbffc7e4f162e93ef",
            "/paper/A-shrinkage-variable-step-size-for-normalized-Xia-Zhu/18e1d803ddde843de679ae08d0e39e503cceb388",
            "/paper/A-Variable-Regularization-Matrix-Normalized-Subband-Ni-Li/dcca6794546d7ec7c3349cea7e74639bc2b9e8c6",
            "/paper/Subband-Adaptive-Filtering-with-Norm-Constraint-for-Choi/60a603f4e1486514c96380504e580ac7a2996e23",
            "/paper/Improving-convergence-of-the-NLMS-algorithm-using-Lee-Gan/48905b7b0149d88ba221afa0f1ef2fb9426a3c12",
            "/paper/An-Improved-Multiband-Structured-Subband-Adaptive-Yang-Wu/ad8c2bf71aa9f8f95bc450ea03b0cbd033da2d76",
            "/paper/Influence-of-input-noises-on-the-mean-square-of-the-Zheng-Liu/c04858d173a19ac9dc24bf9e2f101c5a7db91eb9",
            "/paper/Improved-affine-projection-subband-adaptive-filter-Zhao-Zheng/7832bb9f8f2685adeb207d688c007a0cc640514b"
        ]
    },
    {
        "id": "228273c1beb2f54a56dd19a650e73c10780044c5",
        "title": "A Novel Unsupervised Video Anomaly Detection Framework Based on Optical Flow Reconstruction and Erased Frame Prediction",
        "abstract": "The idea of a training model based on the \u201cCloze Test\u201d strategy in natural language processing (NLP) is exploited and a novel unsupervised learning framework is introduced to encode both motion and appearance information at an object level to improve the performance of VAD. Reconstruction-based and prediction-based approaches are widely used for video anomaly detection (VAD) in smart city surveillance applications. However, neither of these approaches can effectively utilize the rich contextual information that exists in videos, which makes it difficult to accurately perceive anomalous activities. In this paper, we exploit the idea of a training model based on the \u201cCloze Test\u201d strategy in natural language processing (NLP) and introduce a novel unsupervised learning framework to encode both motion and appearance information at an object level. Specifically, to store the normal modes of video activity reconstructions, we first design an optical stream memory network with skip connections. Secondly, we build a space\u2013time cube (STC) for use as the basic processing unit of the model and erase a patch in the STC to form the frame to be reconstructed. This enables a so-called \u201dincomplete event (IE)\u201d to be completed. On this basis, a conditional autoencoder is utilized to capture the high correspondence between optical flow and STC. The model predicts erased patches in IEs based on the context of the front and back frames. Finally, we employ a generating adversarial network (GAN)-based training method to improve the performance of VAD. By distinguishing the predicted erased optical flow and erased video frame, the anomaly detection results are shown to be more reliable with our proposed method which can help reconstruct the original video in IE. Comparative experiments conducted on the benchmark UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets demonstrate AUROC scores reaching 97.7%, 89.7%, and 75.8%, respectively.",
        "publication_year": "2023",
        "authors": [
            "Heqing Huang",
            "Bing Zhao",
            "F. Gao",
            "Penghui Chen",
            "J. Wang",
            "A. Hussain"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "77",
        "references": [
            "/paper/A-Hybrid-Video-Anomaly-Detection-Framework-via-Flow-Liu-Nie/5cccc8bab11927e5527dd5b917ed4c306a2ccf49",
            "/paper/Cloze-Test-Helps%3A-Effective-Video-Anomaly-Detection-Yu-Wang/96d7a07237e146c28173767dfc6290a337696c04",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Anomaly-Detection-in-Video-Sequence-With-Nguyen-Meunier/53599f3748b73f5d3bbddab646905b5b8e7d3210",
            "/paper/Attention-Driven-Loss-for-Anomaly-Detection-in-Zhou-Zhang/945b53ede48dae40af9870030fc4985a119cd1b8",
            "/paper/Integrating-prediction-and-reconstruction-for-Tang-Zhao/fe09f7a379944444201552e952b910188c0aeaca",
            "/paper/Video-Anomaly-Detection-With-Compact-Feature-Sets-Leyva-Sanchez/50e84132a1e405fd04ec59a72093ba30d9a74281",
            "/paper/Video-Anomaly-Detection-and-Localization-via-Fully-Fan-Wen/d880d303ee0bfdbc80fc34df0978088cd15ce861",
            "/paper/Any-Shot-Sequential-Anomaly-Detection-in-Videos-Doshi-Yilmaz/5472fc060d6d22ed3b055732013ac767eb522fa4"
        ]
    },
    {
        "id": "40257e46141b0f0533ab8ac93c3c0dcbd632f105",
        "title": "Accurate Diagnosis and Treatment of Painful Temporomandibular Disorders: A Literature Review Supplemented by Own Clinical Experience",
        "abstract": "There is no single ideal form of pain therapy for TMD, and appropriate diagnostic tools are needed, as well as therapeutic regimens to alleviate and/or eliminate the pain experienced by patients. Introduction Temporomandibular disorders (TMD) is a multifactorial group of musculoskeletal disorders often with combined etiologies that demand different treatment plans. While pain is the most common reason why patients decide to seek help, TMD is not always painful. Pain is often described by patients as a headache, prompting patients to seek the help of neurologists, surgeons, and ultimately dentists. Due to the unique characteristics of this anatomical area, appropriate diagnostic tools are needed, as well as therapeutic regimens to alleviate and/or eliminate the pain experienced by patients. Aim of the Study. The aim of this study is to collect and organize information on the diagnosis and treatment of pain in TMD, through a review of the literature supplemented by our own clinical experience. Material and Methods. The study was conducted by searching scientific databases PubMed, Scopus, and Google Scholar for documents published from 2002\u20132022. The following keywords were used to build the full list of references: TMD, pain, temporomandibular joint (TMJ), TMJ disorders, occlusal splint, relaxing splints, physiotherapy TMD, pharmacology TMD, natural therapy TMD, diagnostic criteria for TMD, and DC/TMD. The literature review included 168 selected manuscripts, the content of which was important for pain diagnosis and clinical treatment of TMD. Results An accurate diagnosis of TMD is the foundation of appropriate treatment. The most commonly described treatments include physiotherapy, occlusal splints therapy, and pharmacological treatment tailored to the type of TMD. Conclusions Based on the literature review and their own experience, the authors concluded that there is no single ideal form of pain therapy for TMD. Treatment of TMD should be based on a thorough diagnostic process, including the DC/TMD examination protocol, psychological evaluation, and cone beam computer tomography (CBCT) imaging. Following the diagnostic process, once a diagnosis is established, a treatment plan can be constructed to address the patient's complaints.",
        "publication_year": "2023",
        "authors": [
            "A. Garstka",
            "Lidia Kozowska",
            "Konrad Kijak",
            "Monika Brz\u00f3zka",
            "Helena Gronwald",
            "P. Skomro",
            "Danuta Lietz-Kijak"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "169",
        "references": [
            "/paper/Temporomandibular-Disorder-Treated-With-Therapy-Chu-Lee/5e5f58be34c5d893ee49762dc664770a9dad97f2",
            "/paper/Reported-concepts-for-the-treatment-modalities-and-Wi%C4%99ckiewicz-Boening/b62568b84529efa73576e0984cc456bb37c61baf",
            "/paper/Diagnosis-and-treatment-of-temporomandibular-Gauer-Semidey/0c6977c45884ec3e152d278202de5cc9c36292c6",
            "/paper/The-neuro-pathophysiology-of-temporomandibular-a-of-Yin-He/7dae22288bd091a2ab8d9ed8b00afe79076bbca7",
            "/paper/Temporomandibular-Disorders%3A-Current-Concepts-and-Li-Leung/b2c9335b9dc9d0e6888b7f4d7cf70867b1358cb4",
            "/paper/Efficacy-of-splint-therapy-for-the-management-of-a-Zhang-Wu/0bee1de4d11fb7959d792822b533e0d04c466b92",
            "/paper/Temporomandibular-disorders.-Part-1%3A-anatomy-and-Shaffer-Brism%C3%A9e/bc6865198bc359c8b38a286c4612f2663f36507c",
            "/paper/Conservative-management-of-temporomandibular-A-with-Butts-Dunning/3a0c040b409c77c7cd97a8b33384d5f94259e758",
            "/paper/Temporomandibular-disorders-and-dental-occlusion.-A-Manfredini-Lombardo/8273de8ca463db89c54c06018033af0c7883cd6e",
            "/paper/Management-of-pain-in-patients-with-disorder-(TMD)%3A-Gil-Mart%C3%ADnez-Paris%E2%80%90Alemany/496585f00f7f4dc066dfbcef433ae3192c1c9c69",
            "/paper/Clinical-TMD%2C-pain-related-disability-and-status-of-Yap-Chua/d441591a56ee858e64d07239afd308af84669142"
        ]
    },
    {
        "id": "c200ac3ae8083fba1f3a7027525265ee0e68932a",
        "title": "Telocytes | Encyclopedia",
        "abstract": "Telocytes (TCs), located in the interstitium of many tissues, have mesenchymal stromal cell properties, which play an important role during repair and tumour stroma formation. Telocytes (TCs), located in the interstitium of many tissues, were described by Popescu and Faussone-Pellegrini in 2010 . These authors identified a stromal cell type, which shows a triangular or ovoid somatic body and several (two to five) long, slender, moniliform cytoplasmic processes (telopodes) with thin segments (podomeres) and dilated portions (podoms) . TCs are a heterogenous population and express CD34 and PDGFRa, among other markers. Several roles have been hypothesized for TCs in tissue homeostasis, morphogenesis, regeneration and repair, including intercellular communication with the integration of tissue components by cell-to-cell-signalling or extracellular shedding vesicles and paracrine molecules , the control and organisation of the extracellular matrix , the creation of microenvironments within the tissues , structural support , endocytosis with the internalization of small particles , the control and regulation of other cell types , guidance to cell migration during development and the contribution of scaffolds , immunomodulation and immunosurveillance , the inhibition of apoptosis (inhibition of oxidative stress and prevention of cellular ageing) , neurotransmission (e.g., contribution of slow waves generated by interstitial cells of Cajal) and the modulation of stem cells (control of their growth and differentiation) . In addition, TCs have mesenchymal stromal cell properties, which play an important role during repair and tumour stroma formation .",
        "publication_year": "2020",
        "authors": [
            "L. D\u00edaz-Flores"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "89",
        "references": [
            "/paper/Behaviour-of-telocytes-during-physiopathological-D%C3%ADaz-Flores-Guti%C3%A9rrez/40fb968dfe2ffb25dfbe05cbacb9b343123a71bd",
            "/paper/Telocytes-revisited-Cre%C8%9Boiu-Popescu/f559a5a09de67821d9c77b3613fdacc32d672664",
            "/paper/Telocytes-and-Stem-Cells-Popescu-Nicolescu/0c17feadd55e3e0577e727a4dee4eae71c311d4b",
            "/paper/Telocytes-in-neuromuscular-spindles-D%C3%ADaz-Flores-Guti%C3%A9rrez/e2c4112109be2a2c3abc1878dcbbb9c078bbfc1b",
            "/paper/Telocytes-heterogeneity%3A-From-cellular-morphology-Cre%C8%9Boiu-Radu/16805cfd017a40d8eb597d7c3e48c4cdece561ed",
            "/paper/ex-The-Tandem%3A-Telocytes-Stem-Cells-Popescu/650862a460b1a175c4855557e8ee537ffde8671a",
            "/paper/TELOCYTES-%E2%80%93-A-Novel-Type-of-Interstitial-Cells-Popescu/8d218f4d1b21ed31c51ab289a9f0f305f8010e6c",
            "/paper/Telocytes%2C-a-distinct-type-of-cell-among-the-cells-Cre%C8%9Boiu-Cre%C8%9Boiu/1c818ec06ce4bca12dd1571099d2433e1718e58d",
            "/paper/Telocytes-Contribute-as-Cell-Progenitors-and-in-Vannucchi-Bani/0bf44839521120b5226aabd96d04d69d4b77edc1",
            "/paper/Genetic-comparison-of-mouse-lung-telocytes-with-and-Zheng-Zhang/7525f81423bfbeaedf23b9f179a7447afbbce848"
        ]
    },
    {
        "id": "0852ca8b92a957a016e88b380bf4445f88ae849b",
        "title": "Deep learning model enhanced skin cancer detection",
        "abstract": "This paper has compared several deep learning neural network architectures and classifiers such as DNN, RNN, SVM and KNN in terms of accuracy rate and computation complexity and presented an ensembled deep learning model for early skin cancer detection. According to the American Academy of Dermatology Association, identifying the types of skin cancer depends on the origin of a cell mutation resulting in the rapid growth of these abnormal cells in the epidermis. These mutations lead the skin cells to multiply rapidly and form malignant tumors. Skin cancer is ranked as the 17th most common form of cancer worldwide according to the World Cancer Research Fund. Skin cancer treatments cost the United States more than $8 billion (about $25 per person in the US) each year, making skin cancer the fifth most costly cancer for Medicare. Furthermore, skin cancer is an under recognized problem for diverse populations, including young women and minorities. Researchers have been exploring different technologies to detect skin care at its early stage to avoid high mortality rate and expensive medical treatment. This paper presents a novel ensembled deep learning model for the early detection of skin cancer. Our research is based on The HAM10000 dataset, a diverse collection of multi-sourced dermatoscopic images of common pigmented skin lesions which consists of 10015 dermatoscopic images. We have compared several deep learning neural network architectures and classifiers such as DNN, RNN, SVM and KNN in terms of accuracy rate and computation complexity and presented an ensembled deep learning model for early skin cancer detection. The main contribution of this paper is the productions of a comparative study of several skin cancer detection techniques using powerful computer vision techniques and deep learning models and a novel ensembled deep learning model for skin cancer detection.",
        "publication_year": "2023",
        "authors": [
            "S. Kolachina",
            "Ruth Agada",
            "Wenting Li",
            "Jie Yan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "49",
        "references": [
            "/paper/Skin-Cancer-Detection%3A-A-Review-Using-Deep-Learning-Dildar-Akram/faec7030c99bf2fa29d341bc09d351b7edfa05bc",
            "/paper/Skin-Cancer-Classification-With-Deep-Learning%3A-A-Wu-Chen/a94d7711320f83a5f39742f7985b17c3e7ced9e3",
            "/paper/Skin-Cancer-Detection-using-Ensemble-Learning-and-Guergueb-Akhloufi/df69e8c28c7f125939a1e294fea5d705038521dc",
            "/paper/Machine-Learning-Approaches-for-Skin-Cancer-from-A-Grignaffini-Barbuto/6d99522ac8c6dda2d93f0f2fbaaba4297047a532",
            "/paper/Skin-lesion-detection-using-an-ensemble-of-deep-Shahsavari-Khatibi/6a3adc7c77e2e1e24b575a4e97a0a42c59fced18",
            "/paper/Multi-Scale-Deep-Ensemble-Learning-for-Melanoma-Guergueb-Akhloufi/83b8410211e849c29d66245f4d9c1d081a647c2a",
            "/paper/WonDerM%3A-Skin-Lesion-Classification-with-Fine-tuned-Lee-Jung/90e9d8e87ff6895937f280a8c1038a1de2cc2d81",
            "/paper/Dermatologist-level-classification-of-skin-cancer-Esteva-Kuprel/e1ec11a1cb3d9745fb18d3bf74247f95a6663d08",
            "/paper/Transfer-Learning-with-Ensembles-of-Deep-Neural-for-Qureshi-Roos/1cbfcc1a0d4fcec1a3e329b80461f6088dc08172",
            "/paper/Machine-Learning-and-Its-Application-in-Skin-Cancer-Das-Cockerell/4a980355c6e926b31a6c255f13f623b84792c0f8"
        ]
    },
    {
        "id": "6050d3b64eadae2ab87eaf9030cadf5ff871c929",
        "title": "Neuron tracing from light microscopy images: automation, deep learning and bench testing",
        "abstract": "A review of neuron tracing in various scenarios with the goal of helping the community understand and navigate tools and resources and highlighting the semi-automatic methods for single neuron tracing of mammalian whole brains. Abstract Motivation Large-scale neuronal morphologies are essential to neuronal typing, connectivity characterization and brain modeling. It is widely accepted that automation is critical to the production of neuronal morphology. Despite previous survey papers about neuron tracing from light microscopy data in the last decade, thanks to the rapid development of the field, there is a need to update recent progress in a review focusing on new methods and remarkable applications. Results This review outlines neuron tracing in various scenarios with the goal to help the community understand and navigate tools and resources. We describe the status, examples and accessibility of automatic neuron tracing. We survey recent advances of the increasingly popular deep-learning enhanced methods. We highlight the semi-automatic methods for single neuron tracing of mammalian whole brains as well as the resulting datasets, each containing thousands of full neuron morphologies. Finally, we exemplify the commonly used datasets and metrics for neuron tracing bench testing.",
        "publication_year": "2022",
        "authors": [
            "Yufeng Liu",
            "Gaoyu Wang",
            "G. Ascoli",
            "Jiangning Zhou",
            "Lijuan Liu"
        ],
        "related_topics": [
            "Computer Science",
            "Biology"
        ],
        "citation_count": "3",
        "reference_count": "158",
        "references": [
            "/paper/Combinatorial-quantification-of-distinct-neural-Venkadesh-Santarelli/c9863b102aecde03454f050ed27b233c136c14de",
            "/paper/Improved-Workflow-for-Analysis-of-Vascular-Myocyte-Boskind-Nelapudi/a22ca11f90516ef6e98a45848ef867acee5a1fb0",
            "/paper/NRRS%3A-a-re-tracing-strategy-to-refine-neuron-Li-Jiang/193afa6d0bde27c6fcc005174feb7003f026096e",
            "/paper/Neuron-reconstruction-from-fluorescence-microscopy-Radojevi%C4%87-Meijering/12e4e2819964d184081454051b4b85c3fe747f80",
            "/paper/Progressive-Learning-for-Neuronal-Population-from-Zhao-Chen/47de226ca26abd0517b97c77ac3518d70c69e26b",
            "/paper/Automated-neuron-tracing-using-probability-density-Radojevi%C4%87-Meijering/a96a1b0c8fae6947b6882423a59336fe0f0e7d30",
            "/paper/The-DIADEM-Data-Sets%3A-Representative-Light-Images-Brown-Barrionuevo/88f9a4a16362238a8ec7f8b88b647e1e20d771da",
            "/paper/Deep-Learning-Segmentation-of-Optical-Microscopy-Li-Zeng/7cf541ec0692b55c24dc81e111ba693b74e7beaa",
            "/paper/Automatic-3D-Single-Neuron-Reconstruction-with-Tang-Zhang/70f4ff56aedf755c88cb52faf4cf17069ee5dd28",
            "/paper/Segmentation-and-Tracing-of-Single-Neurons-from-3D-Basu-Condron/c8ea6615e85e0df16cc52486bfdf725cc578ff59",
            "/paper/Neuronal-Population-Reconstruction-From-Ultra-Scale-Zhao-Chen/c49d0a7285161cab3fcf9bd953b03949a29c08dd",
            "/paper/Active-learning-of-neuron-morphology-for-accurate-Gala-Chapeton/c374df35ea0a85328871b24895c8af8b6438c01f",
            "/paper/Weakly-Supervised-Learning-of-3D-Deep-Network-for-Huang-Chen/589e66d5a2a67892512de83ca64319521223f079"
        ]
    },
    {
        "id": "e60b6836b45ad0ae02a5fa663c8c31119f0c0a94",
        "title": "X-Pruner: eXplainable Pruning for Vision Transformers",
        "abstract": "A novel explainable pruning framework dubbed X-Pruner is designed by considering the explainability of the pruning criterion, which outperforms the state-of-the-art black-box methods with significantly reduced computational costs and slight performance degradation. Recently vision transformer models have become prominent models for a range of tasks. These models, however, usually suffer from intensive computational costs and heavy memory requirements, making them impractical for deployment on edge platforms. Recent studies have proposed to prune transformers in an unexplainable manner, which overlook the relationship between internal units of the model and the target class, thereby leading to inferior performance. To alleviate this problem, we propose a novel explainable pruning framework dubbed X-Pruner, which is designed by considering the explainability of the pruning criterion. Specifically, to measure each prunable unit's contribution to predicting each target class, a novel explainability-aware mask is proposed and learned in an end-to-end manner. Then, to preserve the most informative units and learn the layer-wise pruning rate, we adaptively search the layer-wise threshold that differentiates between unpruned and pruned units based on their explainability-aware mask values. To verify and evaluate our method, we apply the X-Pruner on representative transformer models including the DeiT and Swin Transformer. Comprehensive simulation results demonstrate that the proposed X-Pruner outperforms the state-of-the-art black-box methods with significantly reduced computational costs and slight performance degradation.",
        "publication_year": "2023",
        "authors": [
            "Lu Yu",
            "Wei Xiang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "35",
        "references": [
            "/paper/IA-RED2%3A-Interpretability-Aware-Redundancy-for-Pan-Jiang/e2f2662f0734e2edc2b4b36a734de111c7f8d54d",
            "/paper/Width-%26-Depth-Pruning-for-Vision-Transformers-Yu-Huang/d451901a6a12c61179289cac7a4588a86c234112",
            "/paper/MiniViT%3A-Compressing-Vision-Transformers-with-Zhang-Peng/58c486ad4020177f5ed3d9f2883f3fc327b55770",
            "/paper/Chasing-Sparsity-in-Vision-Transformers%3A-An-Chen-Cheng/efbe9f591090018f78b42c84613c8afda9292fdb",
            "/paper/Unified-Visual-Transformer-Compression-Yu-Chen/4c69fdca6e8a1f10871ab9dc47f62c81ba7ead4a",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/PLATON%3A-Pruning-Large-Transformer-Models-with-Upper-Zhang-Zuo/76d40153acfbb35a7eb8272a4215854cafa10e78",
            "/paper/Vision-Transformer-Pruning-Zhu-Tang/93efaf8c27940aaef145d8bcbca957be634d26e5",
            "/paper/Transformer-Interpretability-Beyond-Attention-Chefer-Gur/0acd7ff5817d29839b40197f7a4b600b7fba24e4",
            "/paper/Scalable-Vision-Transformers-with-Hierarchical-Pan-Zhuang/ac591dbf261777e05d89c27f9a7bcb06f88aab5a"
        ]
    },
    {
        "id": "6140abf6acd1a3594a69c24edf1cbe448489e6ef",
        "title": "Findings of the First WMT Shared Task on Sign Language Translation (WMT-SLT22)",
        "abstract": "The task featured two tracks, translating from Swiss German Sign Language (DSGS) to German and vice versa, and resulted in the first publicly available set of system outputs and human evaluation scores for sign language translation. This paper presents the results of the First WMT Shared Task on Sign Language Translation (WMT-SLT22).This shared task is concerned with automatic translation between signed and spoken languages. The task is novel in the sense that it requires processing visual information (such as video frames or human pose estimation) beyond the well-known paradigm of text-to-text machine translation (MT).The task featured two tracks, translating from Swiss German Sign Language (DSGS) to German and vice versa. Seven teams participated in this first edition of the task, all submitting to the DSGS-to-German track.Besides a system ranking and system papers describing state-of-the-art techniques, this shared task makes the following scientific contributions: novel corpora, reproducible baseline systems and new protocols and software for human evaluation. Finally, the task also resulted in the first publicly available set of system outputs and human evaluation scores for sign language translation.",
        "publication_year": "2022",
        "authors": [
            "Mathias M\u00fcller",
            "Sarah Ebling",
            "Eleftherios Avramidis",
            "A. Battisti",
            "Mich\u00e8le Berger",
            "R. Bowden",
            "Annelies Braffort",
            "Necati Cihan Camg\u00f6z",
            "C. Espa\u00f1a-Bonet",
            "Roman Grundkiewicz",
            "Zifan Jiang",
            "Oscar Koller",
            "Amit Moryossef",
            "Regula Perrollaz",
            "Sabine Reinhard",
            "Annette Rios Gonzales",
            "D. Shterionov",
            "Sandra Sidler-Miserez",
            "Katja Tissi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "89",
        "references": [
            "/paper/Sign-Language-Translation-from-Instructional-Videos-Tarr'es-G%C3%A1llego/06c8cdd8c517e45adcbb519d77c897aaa6766282",
            "/paper/On-the-Importance-of-Signer-Overlap-for-Sign-Pal-Huber/837c0eabe65900f6c8d5636514eb0d755e1880a0",
            "/paper/Spatio-temporal-Sign-Language-Representation-and-Hamidullah-Genabith/09800c86308450ff102f9d36df171c3d8d2518d1",
            "/paper/Clean-Text-and-Full-Body-Transformer%3A-Microsoft%E2%80%99s-Dey-Pal/53e4247f7743767f39805573c71b820651335d89",
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/Machine-Translation-from-Signed-to-Spoken-State-of-Coster-Shterionov/7366fe7b4e7756dd13220d29077142ff802b41b3",
            "/paper/Changing-the-Representation%3A-Examining-Language-for-Walsh-Saunders/a4b404872f075c10c0c07114e7805907508fdf49",
            "/paper/TTIC%E2%80%99s-WMT-SLT-22-Sign-Language-Translation-System-Shi-Brentari/a0cf790c3a650d8cf4d201e17a12ec84812bee60",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/Extensions-of-the-Sign-Language-Recognition-and-Forster-Schmidt/109156b008f569fd279bddc48ae0d462b82ca635",
            "/paper/Findings-of-the-IWSLT-2022-Evaluation-Campaign-Anastasopoulos-Barrault/d78b3af53e690f094747b72d42dbc84b45f571a9"
        ]
    },
    {
        "id": "bb431f8dd5df4868eac2028c926eb0f010d30eed",
        "title": "Synthetic medical image generator for data augmentation and anonymisation based on generative adversarial network for glioblastoma tumors growth prediction",
        "abstract": "A synthetic medical image generator (SMIG) with the purpose of generating synthetic data based on the generative adversarial network in order to provide anonymised data and a tumour growth predictor based on end to end convolution neural network architecture are proposed. Prediction methods of glioblastoma tumours growth constitute a hard task due to the lack of medical data, which is mostly related to the patients' privacy, the cost of collecting a large medical data set, and the availability of related notations by experts.In this study, the authors propose a synthetic medical image generator (SMIG) with the purpose of generating synthetic data based on the generative adversarial network in order to provide anonymised data. In addition, to predict the glioblastoma multiform tumour growth the authors developed a tumour growth predictor based on end to end convolution neural network architecture that allows training on a public data set from the cancer imaging archive (TCIA), combined with the generated synthetic data. The authors also highlighted the impact of implicating a synthetic data generated using SMIG as a data augmentation tool. Despite small data size provided by TCIA data set, the obtained results demonstrate valuable tumour growth prediction accuracy.",
        "publication_year": "2020",
        "authors": [
            "Adel Kamli",
            "R. Saouli",
            "H. Batatia",
            "Mostefa Bennaceur",
            "Imane Youkana"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "45",
        "references": [
            "/paper/Applications-of-generative-adversarial-networks-in-Wang-Bashyam/4abeaf00b66459938306545c3441af9c3a2563eb",
            "/paper/Static-Dynamic-coordinated-Transformer-for-Tumor-Wang-Xiao/21a1baaee1956f0d9edb921bb2a4c0d7f7884c98",
            "/paper/RS-FFGAN%3AGenerative-adversarial-network-based-on-Guo-Zheng/1471eb64b1a0ed8180329188d6cf35c93e8d8a74",
            "/paper/Medical-Image-Synthesis-for-Data-Augmentation-and-Shin-Tenenholtz/37a052144b510b8827634c38146b190d8b2c8d0b",
            "/paper/GAN-Augmentation%3A-Augmenting-Training-Data-using-Bowles-Chen/003ec88cbec156131058e53409115cd056057644",
            "/paper/GAN-based-Synthetic-Medical-Image-Augmentation-for-Frid-Adar-Diamant/0597aba86088282423e7c2d2deb6fca4075e7a91",
            "/paper/Generative-Adversarial-Network-for-Medical-Images-Iqbal-Ali/5443e8aca3deb9dae313e7796435023727102130",
            "/paper/Generative-Adversarial-Network-in-Medical-Imaging%3A-Yi-Walia/acbeebdfd9dd3456628604eefcd53f50f974b132",
            "/paper/GAN-based-synthetic-brain-MR-image-generation-Han-Hayashi/3f95b6ff3fda46db7fae313f5412759b86da0341",
            "/paper/MisGAN%3A-Learning-from-Incomplete-Data-with-Networks-Li-Jiang/0a869336c65185f078ba473d7ca5b86a371ab929",
            "/paper/Multi-class-Generative-Adversarial-Networks-with-L2-Mao-Li/d47f8587ad5080c831548cb3f36d7745b545882c",
            "/paper/Generative-Image-Modeling-Using-Style-and-Structure-Wang-Gupta/9c763df6843aba88d7fb3ab3c55a5937a5f39276",
            "/paper/Learning-a-Classification-based-Glioma-Growth-Model-Morris-Greiner/9145a80e62613acd0771d558dd35a007ed832a33"
        ]
    },
    {
        "id": "5d317135562c408aceceb11adfac0ccdc8ff68c5",
        "title": "TAE-ResU-Net:A trinomial attention-based channel-interactive U-shaped residual network",
        "abstract": "A trinomial attention-based channel interaction residual U-shaped network to improve segmentation accuracy while reducing the number of model parameters as much as possible to achieve a balance between the numberof model parameters and segmentsation accuracy is proposed. Brain MRI images are characterized by complex data and large data volume, and accurate and reliable segmentation of brain MRI tumor images is a challenge due to the variability of lesion size, shape, and location. In recent years, many researchers have used deep learning-based convolutional neural networks for image segmentation of medical MRI, CT, etc., and have made great progress and achievements in the field of segmentation. However, the convolutional neural network-based model is limited by the local Receptive field, which cannot capture the relevant information at a long distance, and cannot achieve fine segmentation of brain lesion object boundaries, and the performance of small object segmentation is poor. For this reason, some researchers have proposed a self-attention-based segmentation method, which improves the accuracy but has a huge number of parameters, long running time, and cannot be used on small devices, which has far-reaching effects on patient medical images. To this end, to address the above problems, this paper proposes a trinomial attention-based channel interaction residual U-shaped network to improve segmentation accuracy while reducing the number of model parameters as much as possible to achieve a balance between the number of model parameters and segmentation accuracy. We use the datasets of BraTS2018 and BraTS2019 for experiments, and the experimental results show that our model outperforms other more advanced models in most indicators such as DISC, Hausdorff distance, etc., and has certain advantages in tumor segmentation.",
        "publication_year": "2022",
        "authors": [
            "Chen Yu",
            "Ruifeng Wang",
            "Tian-yi Gao",
            "Shuo Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "9",
        "references": [
            "/paper/CaraNet%3A-context-axial-reverse-attention-network-of-Lou-Guan/97326c0468e4e412630b4db7cea9d0f8ac4dc475",
            "/paper/TransUNet-with-Attention-Mechanism-for-Brain-Tumor-Wang-Hu/c3c41318e114b7605151ba15f99ef4454ec43250",
            "/paper/RA-UNet%3A-A-Hybrid-Deep-Attention-Aware-Network-to-Jin-Meng/5090fbfc9cf5db61ed060e5afdf01d2c08a8fcce",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/UNet%2B%2B%3A-Redesigning-Skip-Connections-to-Exploit-in-Zhou-Siddiquee/42b0a8f757e45462e627e57f9af7e9849dcdacdf",
            "/paper/Weighted-Res-UNet-for-High-Quality-Retina-Vessel-Xiao-Lian/ff8b823d6f04a78bdb568a09139ef6d02111764e",
            "/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/317aee7fc081f2b137a85c4f20129007fd8e717e",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/2018-9th-International-Conference-on-Information-in/b3a419ca8fa3afaeab61fe7f087b2b9a731f8c56"
        ]
    },
    {
        "id": "be6d2a227049c50e64f857469185751b301d1500",
        "title": "GCA-Net: Geometrical Constraints-based Advanced Network for Polyp Segmentation",
        "abstract": "This work proposes GCA-Net for polyp segmentation and develops a novel loss function based on the region-based strength of Dice loss and the geometrical constraints-based advantages of Active Contour with Elastica (ACE) loss. Colonoscopy is a common procedure for detecting and screening colorectal polyps, however, it poses a number of challenges because of the properties of images and the features of polyps inside, which can vary in shape, color, condition, and clear non-distinction with the surrounding context. Deep learning-based approaches have recently emerged, which considerably boost polyp segmentation procedures and gradually convert and replace out-of-date methods. Nevertheless, determining an effective measure remains a significant difficulty, which motivates us to propose GCA-Net for polyp segmentation. We first employ EfficientNetV2 as the backbone to extract improved salient features, then pass them via two modules, SE-PASPP and SE-RFB, to capture more contexture before feeding them into a dual-asymmetrical partial decoder to build a final resolution map. Finally, we develop a novel loss function based on the region-based strength of Dice loss and the geometrical constraints-based advantages of Active Contour with Elastica (ACE) loss. The suggested method's preeminence is demonstrated by comparing results to over state-of-the-art approaches in both learning and generalization assessment.",
        "publication_year": "2022",
        "authors": [
            "Q. Nguyen",
            "Thi-Thao Tran",
            "Van-Truong Pham"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "48",
        "references": [
            "/paper/PraNet%3A-Parallel-Reverse-Attention-Network-for-Fan-Ji/89c6badea0d7bf834d4c069517116dd99c4cc0fd",
            "/paper/Automatic-Polyp-Segmentation-via-Multi-scale-Zhao-Zhang/f36ff155a741f4c404fcac9de1d47e53aa99e71b",
            "/paper/Selective-Feature-Aggregation-Network-with-for-Fang-Chen/8cd4364347f647f2d2165953988c8895524dd8cc",
            "/paper/AG-CUResNeSt%3A-A-Novel-Method-for-Colon-Polyp-Sang-Chung/8c69762e9f3db1de58e6cfece22690f9b00e59bb",
            "/paper/ResUNet%2B%2B%3A-An-Advanced-Architecture-for-Medical-Jha-Smedsrud/80f4c7c360d1150ba58c3bacf5c35718ebdd0c10",
            "/paper/CaraNet%3A-context-axial-reverse-attention-network-of-Lou-Guan/97326c0468e4e412630b4db7cea9d0f8ac4dc475",
            "/paper/Fully-convolutional-neural-networks-for-polyp-in-Brandao-Mazomenos/05413ea5c16302f286dabe0d0cacf404dba3ecbf",
            "/paper/WM-DOVA-maps-for-accurate-polyp-highlighting-in-vs.-Bernal-S%C3%A1nchez/cb9b38e3b6e2a90657b8a3285986761b598b7bdc",
            "/paper/Automatic-polyp-detection-in-colonoscopy-videos-an-Tajbakhsh-Gurudu/606be505e35c1f4275b4a2f08a049032119e3a1d",
            "/paper/Polyp-Segmentation-in-Colonoscopy-Images-Using-Akbari-Mohrekesh/d0b7d8d43ee4593e7eeef6f36e731f90cacdefda"
        ]
    },
    {
        "id": "9a20bcac2213253b054e990ce00774c26f67ae63",
        "title": "Long-term Dizziness Handicap in Patients with Vestibular Schwannoma: A Multicenter Cross-Sectional Study",
        "abstract": "Data suggest that migraine may play a major role in long-term dizziness in patients with vestibular schwannoma, and factors including history of dizziness predating treatment and preexisting diagnosis of migraine most significantly influence dizziness handicap among subjects with VS. Objectives: Previous studies have demonstrated that ongoing dizziness is a powerful predictor of reduced quality of life for patients with vestibular schwannoma (VS). The purpose of the current study is: (1) to characterize long-term dizziness following observation, microsurgery, and stereotactic radiosurgery (SRS) for small to medium sized VS using a validated self-assessment inventory and (2) to identify clinical variables associated with long-term dizziness handicap. Methods: All patients with sporadic <3 cm VS who underwent primary microsurgery, SRS, or observation between 1998 and 2008 were identified. Subjects were surveyed via postal questionnaire using the Dizziness Handicap Inventory (DHI) and a VS symptom questionnaire. Results: A total of 642 respondents (mean age 56.2 years, 56.9% female) were analyzed and the average time interval between treatment and survey was 7.7 years. Female sex, older age, preexisting diagnosis of migraine, and symptoms of severe dizziness predating treatment were highly statistically significantly associated with a worse DHI score (P < .001) while type of dizziness (vertiginous vs non vertiginous), tumor size, and treatment strategy were not (P > .05). The 2 variables that were associated with the greatest deterioration in DHI scores were pre-existing migraine (24.5 vs 15.9 points) and history of severe dizziness prior to treatment (31.1 vs 14.0 points). Conclusions: These data suggest that migraine may play a major role in long-term dizziness in patients with VS. Factors including history of dizziness predating treatment and preexisting diagnosis of migraine most significantly influence dizziness handicap among subjects with VS, while management strategy is not associated with long-term DHI outcome.",
        "publication_year": "2014",
        "authors": [
            "M. Carlson",
            "\u00d8. Tveiten",
            "C. Driscoll",
            "B. Neff",
            "Nicole Tombers",
            "M. Lund-Johansen",
            "M. Link"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "12",
        "reference_count": 0,
        "references": [
            "/paper/Impact-of-Treatment-on-Vestibular-Symptoms%3A-A-Study-Barnes-Patel/8703994d245dff6d27a5992dfad23ee8ce4a8ead",
            "/paper/Vestibular-dose-correlates-with-dizziness-after-for-Ermi%C5%9F-Anschuetz/c67332e7c0e83f77909b77c02263f8a5409c8ecd",
            "/paper/Vestibular-Migraine-Following-Radiosurgery-for-Chae-McDermott/d464098140c03cb9fde85abaa63232fe8e7c418a",
            "/paper/Long-Term-Hearing-Outcome-After-Radiosurgery-for-A-Balossier-Tuleasca/1a59f3c7f830d279961cb75b71119675d0770387",
            "/paper/10%C2%A0years-of-Vertigo-Clinic-at-National-Hospital-we-Olusesi-Abubakar/ead328aacbbe66d2638eec734c6bf460c0efdee3",
            "/paper/Peripheral-Vestibular-System-Disease-in-Vestibular-M%C3%B8ller-Hansen/728fdbf57dac01d50b6a59d03a7ab602e89c794f",
            "/paper/Does-Stereotactic-Radiosurgery-Worsen-Vestibular-In-Teh-Lalwani/bbb972d8e671084a9da69a16d1be47bda4920e0d",
            "/paper/Diagnostics-and-therapy-of-vestibular-schwannomas-%E2%80%93-Rosahl-Bohr/f334211bd04f2b0e511513620a1bb732a865a175",
            "/paper/%E2%80%9CWait-and-scan%E2%80%9D-management-of-patients-with-and-the-Zou-Hirvonen/d449f5a2c6d2a3fd0be8e7745e10065f5ff42dc6",
            "/paper/Geographic-distribution-of-vestibular-schwannomas-Caulley-Sawada/9be9709bc5acd3bbacad3b941bd3b4d9a632a466"
        ]
    },
    {
        "id": "d8239a910afd9a6400d03dba7c50414c5f2d68ca",
        "title": "Joint optic disc and cup segmentation using feature fusion and attention",
        "abstract": "Semantic Scholar extracted view of \"Joint optic disc and cup segmentation using feature fusion and attention\" by Xiaoxin Guo et al.",
        "publication_year": "2022",
        "authors": [
            "Xiaoxin Guo",
            "Jiahui Li",
            "Qifeng Lin",
            "Zhenchuan Tu",
            "Xiaoying Hu",
            "Songtian Che"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "41",
        "references": [
            "/paper/Joint-optic-disc-and-cup-segmentation-based-on-and-Zhao-Su/4942ef23503b2808982aa91db4fc96678e6ce46f",
            "/paper/Measuring-distance-from-lowest-boundary-of-rectal-Shen-Lu/d313dc9a1bc32dbd70de943dedc91ec249062c74",
            "/paper/Multiple-graph-reasoning-network-for-joint-optic-Zhang-Guo/1d6129e3ada322fa5d086c513ab20f94d5a3d689",
            "/paper/Robust-optic-disc-and-cup-segmentation-with-deep-Yu-Xiao/a35cf646bed6628417a681d9b6688553adce0979",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/CDED-Net%3A-Joint-Segmentation-of-Optic-Disc-and-Cup-Tabassum-Khan/ba2e4e0c5ca1b7b62e9827fb6b39af6c4b99bf5e",
            "/paper/Mixed-Maximum-Loss-Design-for-Optic-Disc-and-Optic-Xu-Lu/2c3880954cd76ed2d5b86dd4faf151f8b0bd7ec8",
            "/paper/Joint-optic-disc-and-cup-segmentation-using-GANs-Liu-Hong/3d3b525fb08e23c02ee71ec913ed7a188b7500a7",
            "/paper/Survey-on-segmentation-and-classification-of-optic-Thakur-Juneja/5d264bebd0894fcb387712eb67e036073850517a",
            "/paper/Disc-Aware-Ensemble-Network-for-Glaucoma-Screening-Fu-Cheng/88b91fb2834432273b915a8fb63ccf017e1bc034",
            "/paper/Patch-Based-Output-Space-Adversarial-Learning-for-Wang-Yu/ba62442fc88eb4da204e98899214c45960341fa5",
            "/paper/NENet%3A-Nested-EfficientNet-and-adversarial-learning-Pachade-Porwal/b2bfdad365f2032cc2bc046a992f2c64efbd1fd9",
            "/paper/Level-set-based-automatic-cup-to-disc-ratio-using-Wong-Liu/9a0cf9c7f1af4ea6e1e5e80b8dc4a6d64f81fcd2"
        ]
    },
    {
        "id": "a6d087332d4cadd9a90c8c4aa2c122413033cd9d",
        "title": "Learning Gestures From WiFi: A Siamese Recurrent Convolutional Architecture",
        "abstract": "A novel deep Siamese representation learning architecture for one-shot gesture recognition that outperforms state-of-the-art solutions for temporal\u2013spatial representation learning and achieves satisfactory results under one- shot conditions is proposed. We propose a gesture recognition system that leverages existing WiFi infrastructures and learns gestures from channel state information (CSI) measurements. Having developed an innovative OpenWrt-based platform for commercial WiFi devices to extract CSI data, we propose a novel deep Siamese representation learning architecture for one-shot gesture recognition. Technically, our model extends the capacity of spatio-temporal patterns learning for the standard Siamese structure by incorporating convolutional and bidirectional recurrent neural networks. More importantly, the representation learning is ameliorated by our Siamese framework and transferable pairwise loss which helps to remove structured noise, such as individual heterogeneity and various measurement conditions during domain-different training. Meanwhile, our Siamese model also enables one-shot learning for higher availability in reality. We prototype our system on commercial WiFi routers. The experiments demonstrate that our model outperforms state-of-the-art solutions for temporal\u2013spatial representation learning and achieves satisfactory results under one-shot conditions.",
        "publication_year": "2019",
        "authors": [
            "Jianfei Yang",
            "Han Zou",
            "Yuxun Zhou",
            "Lihua Xie"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "60",
        "reference_count": "57",
        "references": [
            "/paper/Deep-Learning-and-Its-Applications-to-WiFi-Human-A-Yang-Chen/7a9057c5e91e7fe3611b80df10f4911ba0e56b87",
            "/paper/WiTransformer%3A-A-Novel-Robust-Gesture-Recognition-Yang-Zhu/97f287a817355ec4f3f864edb18070dd5a5379ae",
            "/paper/Insights-on-Mini-Batch-Alignment-for-WiFi-CSI-Data-Berlo-Ozcelebi/f1fcf425e5b8f413856a49d8a8863f79bc600fd8",
            "/paper/AirFi%3A-Empowering-WiFi-based-Passive-Human-Gesture-Wang-Yang/e939719b2a66bbaddd74ed139970e5a7e0b5f3cd",
            "/paper/SenseFi%3A-A-library-and-benchmark-on-WiFi-human-Yang-Chen/3aadb6c7e584e4f4a281f7d9053b8d4a369c23f8",
            "/paper/MobileDA%3A-Toward-Edge-Domain-Adaptation-Yang-Zou/6d5578f1ac452e45106c2364bf7abdd2721b9270",
            "/paper/A-Domain-Independent-Generative-Adversarial-Network-Zinys-Berlo/857b3ca9307fbd22e52cb3c264c45a5a2e52d8de",
            "/paper/Attention-Based-Gesture-Recognition-Using-Commodity-Gu-Yan/acbff0dea9c5db2ef256a18d4dc7fe277bc666aa",
            "/paper/DeepSeg%3A-Deep-Learning-Based-Activity-Segmentation-Xiao-Lei/fd15d0caac9d4e96927adb1225d53e36a35b231e",
            "/paper/Fine-grained-Finger-Gesture-Recognition-Using-WiFi-Tan-Yang/cb796787c7587f27b815575b4a7a433568cc93e7",
            "/paper/Robust-WiFi-Enabled-Device-Free-Gesture-Recognition-Zou-Yang/fdd2d6dcac8e16ef79e7afa5a951af264c19002f",
            "/paper/Beyond-Temporal-Pooling%3A-Recurrence-and-Temporal-in-Pigou-Oord/eae099ca54c9ee12a5763f6347b91f77df2c7bf4",
            "/paper/DeepSense%3A-Device-Free-Human-Activity-Recognition-Zou-Zhou/d032d7b4a232a736258aafb8c1926512cf37d0c3",
            "/paper/WiFi-and-Vision-Multimodal-Learning-for-Accurate-Zou-Yang/e9e01af30f1507555008f4b0a1b83ea2debe6f19",
            "/paper/WiFi-Based-Human-Identification-via-Convex-Tensor-Zou-Zhou/81ee79638113a225e01929def2a74374a64ddfdf",
            "/paper/Siamese-Neural-Networks-for-One-Shot-Image-Koch/f216444d4f2959b4520c61d20003fa30a199670a",
            "/paper/On-Spatial-Diversity-in-WiFi-Based-Human-Activity-A-Wang-Gong/12d30796c1f4432ec287426841d3e357809eae52",
            "/paper/Multiple-Kernel-Semi-Representation-Learning-With-Zou-Zhou/77695dfee8042ed09af5cf935d436cfebcac430b",
            "/paper/Learning-Transferable-Features-with-Deep-Adaptation-Long-Cao/7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7",
            "/paper/Deep-Recurrent-Multi-instance-Learning-with-for-Yang-Wang/cf8e2b3a9bceb5c80a2b5df454e69f5c76bc6da7"
        ]
    },
    {
        "id": "91336c65cddd8546745f67a1b860c2595904ac15",
        "title": "NM-GAN: Noise-modulated generative adversarial network for video anomaly detection",
        "abstract": "Semantic Scholar extracted view of \"NM-GAN: Noise-modulated generative adversarial network for video anomaly detection\" by Dongyue Chen et al.",
        "publication_year": "2021",
        "authors": [
            "Dongyue Chen",
            "Lingyi Yue",
            "Xingya Chang",
            "Ming Xu",
            "Tong Jia"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "24",
        "reference_count": "38",
        "references": [
            "/paper/Exploiting-Spatial-temporal-Correlations-for-Video-Zhao-Liu/0548c96de57f8fad3053be706e094320e14c10ec",
            "/paper/A-Deep-Generative-Adversarial-Network-(GAN)-enabled-Song-Qian/af2bb4fa5fd18aa854cf5987c421fb9a1113d901",
            "/paper/LGN-Net%3A-Local-Global-Normality-Network-for-Video-Zhao-Liu/83665e3366c67aade3e771825b2d886fb77e6b02",
            "/paper/Future-frame-prediction-based-on-generative-network-Li-Li/32c82fa3e438521d010e7c7b95a7c01d61f2ceff",
            "/paper/Clear-Memory-Augmented-Auto-Encoder-for-Surface-Luo-Niu/2db7509dbbe4a05336f1f3cb6ff7fb02de37308f",
            "/paper/A-New-Comprehensive-Benchmark-for-Semi-supervised-Cao-Lu/314076656c9e684c3f79e040b92f32c0afaa6d7d",
            "/paper/Multi-Prior-Twin-Least-Square-Network-for-Anomaly-Zhong-Li/b81258b74d3b701433964ff3de257c27a469faf0",
            "/paper/Hierarchical-Scene-Normality-Binding-Modeling-for-Bao-Liu/0c9add302abbc4efc853fd6766fdf0bb40c91e2b",
            "/paper/Generalized-Video-Anomaly-Event-Detection%3A-Taxonomy-Liu-Yang/bb51ca71833d42fa58f9adccb2296bdf665cc158",
            "/paper/Video-anomaly-detection-based-on-scene-Li-Shen/493a72a6af9e6eaada8e6a0c8c584cd1252b63c5",
            "/paper/Dual-Discriminator-Generative-Adversarial-Network-Dong-Zhang/e37daeaa20bc8cd68db07641201faf1db3b8c31d",
            "/paper/Learning-Normal-Patterns-via-Adversarial-for-Event-Song-Sun/3d9f880418a19067a6bcd04a1d81af098f8a3b8a",
            "/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "/paper/Training-Adversarial-Discriminators-for-Abnormal-in-Ravanbakhsh-Sangineto/e399a626ba21fafb19b3661603ec9724058e951b",
            "/paper/AVID%3A-Adversarial-Visual-Irregularity-Detection-Sabokrou-PourReza/c2b733a79db700b971327a58ef42699fe8a416aa",
            "/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d",
            "/paper/Learning-Memory-Guided-Normality-for-Anomaly-Park-Noh/18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "/paper/A-study-of-deep-convolutional-auto-encoders-for-in-Ribeiro-Lazzaretti/e0f73e991514450bb0f14f799878d84adc8601f9",
            "/paper/Spatio-Temporal-AutoEncoder-for-Video-Anomaly-Zhao-Deng/fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "/paper/An-Efficient-Anomaly-Detection-System-for-Crowded-Xu-Yu/3a50bff2b3e06e3af1e419af112f657ea5e73993"
        ]
    },
    {
        "id": "1b064b6b9999958060f762809be695b777324943",
        "title": "Non-IID federated learning via random exchange of local feature maps for textile IIoT secure computing",
        "abstract": "A novel federated framework is proposed for secure textile fiber identification (FedTFI) via cross-domain texture representation based on high-definition fabric images to obtain better detection accuracies than benchmarks in four Non-IID scenarios by keeping data privacy for secure computing in fabric IIoT. With the fast development of artificial intelligence (AI) and industrial Internet of Things (IIoT) technologies, it is challenging to deal with the problems of data privacy protection and secure computing. In recent years, federated learning (FL) is proposed to attack the challenges of learning shared models collaboratively while protecting security based on the data from cross-domain clients. However, data in the real environment is usually not independent and identically distributed (Non-IID) due to the differences in business, working environments, and data acquisition, and thus classic federated methods suffer from significant performance degradation. In this paper, a novel federated framework is proposed for secure textile fiber identification (FedTFI) via cross-domain texture representation based on high-definition fabric images. In addition to sharing the gradient of FedTFI, the local patch of feature maps between cross-domain clients is randomly exchanged to build a richer image texture feature distribution while protecting data security simultaneously for secure computing. Furthermore, a texture embedding layer is designed to provide a joint representation through similarity measure between triplet samples in low-dimensional space. To verify the effectiveness of the proposed framework, two textile image datasets, i.e., one public and the other we collected, are utilized to construct four Non-IID scenarios, including label skew, feature skew, and two combined skew scenarios. The experimental results confirm the effectiveness of our model to obtain better detection accuracies than benchmarks in four Non-IID scenarios by keeping data privacy for secure computing in fabric IIoT.",
        "publication_year": "2022",
        "authors": [
            "Bo Peng",
            "M. Chi",
            "Chao Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "3",
        "reference_count": "43",
        "references": [
            "/paper/Image-Signal-Correlation-Network-for-Textile-Fiber-Peng-He/379d69eaa96d31e8add3a37477dcd1cfd153a3f5",
            "/paper/A-Multi-Signal-Perception-Network-for-Textile-Peng-He/f73d5edb86895698007538887e90fff001b2a9e8",
            "/paper/Sequential-POI-Recommend-Based-on-Personalized-Dong-Liu/b5d33a3501214b7121cdfef4bc15f007da0008d3",
            "/paper/Federated-Learning-with-Non-IID-Data-Zhao-Li/5cfc112c932e38df95a0ba35009688735d1a386b",
            "/paper/Robust-Federated-Learning%3A-The-Case-of-Affine-Reisizadeh-Farnia/48aced1b11e6a3e16dd1f1ed9d0823e8eae48729",
            "/paper/Federated-Learning-on-Non-IID-Data-Silos%3A-An-Study-Li-Diao/dd30a98f5274541f018a762fba46a0730519606a",
            "/paper/Astraea%3A-Self-Balancing-Federated-Learning-for-of-Duan/1aa245db626691d092f263210be486cb6d8023a5",
            "/paper/FFD%3A-A-Federated-Learning-Based-Method-for-Credit-Yang-Zhang/6df4738784f2018ec2b8b7092016543832313719",
            "/paper/FedDG%3A-Federated-Domain-Generalization-on-Medical-Liu-Chen/d6a6d8f56c5db24bfae7c614f21195dc0e89f4a8",
            "/paper/CU-Net%3A-Component-Unmixing-Network-for-Textile-Feng-Liang/8d3e71da2cb665118b6f6c4b4555781d43cd4f4e",
            "/paper/Communication-Efficient-Learning-of-Deep-Networks-McMahan-Moore/d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "/paper/Collaborative-deep-learning-across-multiple-data-Xu-Mi/00ae3f736b28e2050e23acc65fcac1a516635425",
            "/paper/Federated-Latent-Dirichlet-Allocation%3A-A-Local-Wang-Tong/ad43db57322ecfc02ef09be9bc7ad84162a855ba"
        ]
    },
    {
        "id": "366f54591cc3257bbc1d7704c683b95d71faecc8",
        "title": "Analysis on Deep Learning Based 5G Wireless Multi-Stage Jamming Attacks",
        "abstract": "A multi-stage machine learning-based intrusion sensing (ML-IDS) in the 5G CRAN that detects and classifies 4 types of jamming attack and improves the safety of C-RAN architectures by minimizing false negative effects. Jamming is a clear danger to the wireless environment and becomes a key issue in raising the number of applications that are important for protection. Implementation of a jamming detector system is important for current networks in order to combat intelligent jamming attacks, which result in a significant loss of performance in wireless networks by the attacker at various intervals. Current detective mechanisms usually use the nodes in the network to obtain network information, which requires overhead costs and node communications. We compare the effectiveness of several model machines for the detection of jamming signals in this paper. We analyze the signal types that define jamming signals and use the same parameters to produce a broad dataset. This dataset was used for training, evaluation and testing of algorithms for machine learning. A random forest, neural system and vector are the algorithms. The results for these algorithms were evaluated and the likelihood of identification, fake warning, error and precision were compared. Machine learning techniques also gain importance on identification and detection algorithms. DCNN has been studied in particular in the area of communication problems, which involve rapid reaction in real-time applications. Deep neural network convolution (DCNNs). The results of the simulation show that jammers can be detected with high precision, high sensory probability and low probability of false alarm by jamming algorithms. The main purpose of this study is to deploy a multi-stage machine learning-based intrusion sensing (ML-IDS) in the 5G CRAN that detects and classifies 4 types of jamming attack. This deployment improves the safety of C-RAN architectures by minimizing false negative effects.",
        "publication_year": "2021",
        "authors": [
            "Aakanksha Tyagi"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "26",
        "references": [
            "/paper/Deep-Learning-for-Launching-and-Mitigating-Wireless-Erpek-Sagduyu/b2ff78b76a302b005ab65ad0d404373a70f3d5ee",
            "/paper/Machine-learning-based-jamming-detection-for-IEEE-Pu%C3%B1al-Aktas/dbb6c098c7adf0ecd8392ac4e9b70f8b2fa3502b",
            "/paper/Detection-of-jamming-style-DoS-attack-in-Wireless-Manju-Kumar/12220a63d1f4d2a2c00a06f18d753755255d6038",
            "/paper/The-feasibility-of-launching-and-detecting-jamming-Xu-Trappe/2b7a0cb7ff419faaaec2a5c228c18ea1bd269dd6",
            "/paper/Deep-Learning-in-Intrusion-Detection-System%3A-An-Aminanto-Kim/c0fa578c1fae002e02834806a576d811002cb4a4",
            "/paper/Detection-of-reactive-jamming-in-sensor-networks-Strasser-Danev/1cda3472ac6af5b8b0647a4f1f769ed17cceca85",
            "/paper/Deep-Learning-Approach-for-Intelligent-Intrusion-Vinayakumar-Alazab/d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "/paper/Network-Intrusion-Detection-through-Stacking-Yu-Long/10b0d53c0a8b3a85bb108e1eb436e7d5783085fc",
            "/paper/Evaluating-effectiveness-of-shallow-and-deep-to-Vinayakumar-Soman/a4564c2dabb7888ff7a6e32d0d730809a98b7eeb",
            "/paper/Jamming-attacks-on-wireless-networks%3A-A-taxonomic-Vadlamani-Eksioglu/9703fbf0cfcfc063351ae20153b2757dec63e452"
        ]
    },
    {
        "id": "2c65aeb1ddb6edcf636e4548a7dcd76aac3dc48b",
        "title": "Learning graph structure via graph convolutional networks",
        "abstract": "Semantic Scholar extracted view of \"Learning graph structure via graph convolutional networks\" by Qi Zhang et al.",
        "publication_year": "2019",
        "authors": [
            "Qi Zhang",
            "Jianlong Chang",
            "Gaofeng Meng",
            "Shibiao Xu",
            "Shiming Xiang",
            "Chunhong Pan"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "27",
        "reference_count": "35",
        "references": [
            "/paper/Dynamic-Filters-in-Graph-Convolutional-Neural-Apicella-Isgr%C3%B2/a350f701176355fcdc1eeb7c65648092aa1567f4",
            "/paper/Poisson-Kernel-Avoiding-Self-Smoothing-in-Graph-Yang-Han/fc60fd59ae7459a05bd6c47f1de6a2c8c069845e",
            "/paper/Adaptive-Filters-in-Graph-Convolutional-Neural-Apicella-Isgr%C3%B2/6c2b055238717bb37145b140511c0c595dd27854",
            "/paper/Line-Graph-Contrastive-Learning-for-Link-Prediction-Zhang-Sun/03f64803afaf312a3b299fe1c2bc26c329d43747",
            "/paper/HopGAT%3A-Hop-aware-Supervision-Graph-Attention-for-Ji-Wang/d95c7683cdc908e53af496eb5d3ce6bd6c8f5053",
            "/paper/Image-super-resolution-via-channel-attention-and-Yang-Qi/fdc35a9e0158579500309fba3e3fc37598a3b93f",
            "/paper/Weakly-supervised-image-classification-and-with-Liu-Chen/fcc3a62a587adfbb46adeb4b042f4c9beeb545f6",
            "/paper/Neural-graph-embeddings-as-explicit-low-rank-matrix-Agibetov/72e48f3c71fc749f0b589e02a1ce7a4f0afba07e",
            "/paper/A-novel-graph-convolutional-feature-based-neural-Chen-Jiang/028b3bd3f4a16d04059bd5756f9024c224d91128",
            "/paper/Attention-driven-tree-structured-convolutional-LSTM-Kong-Wang/9f35b0577ed27d0b61871df1bd357b0e3445a5aa",
            "/paper/Learning-Graph-While-Training%3A-An-Evolving-Graph-Li-Huang/236ec533889beee103df2e5b44a6250484362bc7",
            "/paper/Dynamic-Edge-Conditioned-Filters-in-Convolutional-Simonovsky-Komodakis/1a39bb2caa151d15efd6718f3a80d9f4bff95af2",
            "/paper/A-Generalization-of-Convolutional-Neural-Networks-Hechtlinger-Chakravarti/7040c149b797506426177d23d5ab52d402fa0fd7",
            "/paper/Learning-Convolutional-Neural-Networks-for-Graphs-Niepert-Ahmed/7c6de5a9e02a779e24504619050c6118f4eac181",
            "/paper/Deep-Convolutional-Networks-on-Graph-Structured-Henaff-Bruna/e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "/paper/Semi-Supervised-Classification-with-Graph-Networks-Kipf-Welling/36eff562f65125511b5dfab68ce7f7a943c27478",
            "/paper/Convolutional-Neural-Networks-on-Graphs-with-Fast-Defferrard-Bresson/c41eb895616e453dcba1a70c9b942c5063cc656c",
            "/paper/Geometric-Deep-Learning-on-Graphs-and-Manifolds-Monti-Boscaini/f09f7888aa5aeaf88a2a44aea768d9a8747e97d2",
            "/paper/Spectral-Networks-and-Locally-Connected-Networks-on-Bruna-Zaremba/5e925a9f1e20df61d1e860a7aa71894b35a1c186",
            "/paper/Diffusion-Convolutional-Neural-Networks-Atwood-Towsley/18b47b83a373f33d6b902a3615f42c10f7600d72"
        ]
    },
    {
        "id": "7ddf5423b45aa8f68f07e83f2aa43b286aac92d4",
        "title": "A Bayesian deep learning framework for interval estimation of remaining useful life in complex systems by incorporating general degradation characteristics",
        "abstract": "A novel Bayesian deep learning framework is proposed that incorporates general characteristics of degradation processes and provides the interval estimations of remaining useful life and demonstrates great prognostic performance and wide applicability to complex systems that may involve multiple sensor signals, multiple failure modes, and multiple operational conditions. Abstract Deep learning has emerged as a powerful tool to model complicated relationships between inputs and outputs in various fields including degradation modeling and prognostics. Existing deep learning-based prognostic approaches are often used in a black-box manner and provide only point estimations of remaining useful life. However, accurate interval estimations of the remaining useful life are crucial to understand the stochastic nature of degradation processes and perform reliable risk analysis and maintenance decision making. This study proposes a novel Bayesian deep learning framework that incorporates general characteristics of degradation processes and provides the interval estimations of remaining useful life. The proposed method enjoys several unique advantages: (i) providing a general approach by not assuming any particular type of degradation processes nor the availability of domain-specific prior knowledge such as a failure threshold; (ii) offering the interval estimations of the remaining useful life; (iii) systematically modeling two types of uncertainties embedded in prognostics; and (iv) exhibiting great prognostic performance and wide applicability to complex systems that may involve multiple sensor signals, multiple failure modes, and multiple operational conditions. Numerical studies demonstrate improved prognostic performance and practicality of the proposed method over benchmark approaches. Additional numerical results including the analysis of sensitivity and computational costs are given in the online supplemental materials.",
        "publication_year": "2020",
        "authors": [
            "Minhee Kim",
            "Kaibo Liu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "31",
        "reference_count": "38",
        "references": [
            "/paper/End-to-End-Pipeline-for-Uncertainty-Quantification-Kefalas-Stein/34f0909c213546ca92c0dda262e0b98ae36564e5",
            "/paper/Probabilistic-Remaining-Useful-Life-Prediction-on-Zhao-Wu/3c281d64543749581b44b1f194dee10d437bd48b",
            "/paper/Non-parametric-Multi-Self-Attention-Temporal-for-Xiong-Tian/0a3532d23a94e5fbe69a5f184040b60160189d5f",
            "/paper/A-Hybrid-Prognostics-Deep-Learning-Model-for-Useful-Xie-Du/4f478438f12a9e35800618ffe1664f49b619153e",
            "/paper/An-Uncertainty-Informed-Framework-for-Trustworthy-Zhou-Droguett/15d398cf7dc6b1f4df880e3d255d492176002305",
            "/paper/Controlled-physics-informed-data-generation-for-Xiong-Fink/97af4edcd2978b535c4efd1df45243eac8ff8d37",
            "/paper/An-adaptive-sensor-selection-framework-for-Kim-Cheng/4c13d7dde418c33086a8f6e37ab184dc5139d16e",
            "/paper/Building-Local-Models-for-Flexible-Degradation-and-Song-Zheng/31f0185f5fc42a38f5b4a5069d081d549ae5fb17",
            "/paper/Rotating-Machinery-Remaining-Useful-Life-Prediction-Zhang-Liang/cf1cec338d68bb3894a73292204c661fc7539d5d",
            "/paper/Multi-sensor-information-fusion-based-prediction-of-Wu-Zeng/49f9cc900c7a5b51c3ffaddd98b2dcfd095011a5",
            "/paper/Multiobjective-Deep-Belief-Networks-Ensemble-for-in-Zhang-Lim/f0959b291381e15ecc31502af6bad4f22cdd41f5",
            "/paper/Remaining-useful-life-estimation-in-prognostics-Li-Ding/809003357de849d443a37b29996e2130c7bdb041",
            "/paper/Bayesian-Deep-Learning-Based-Health-Prognostics-Peng-Ye/414a0e226aea2a77a2514e4c87f67853b5f642fa",
            "/paper/An-Enhanced-Deep-Learning-Based-Fusion-Prognostic-Huang-Yin/d24518ec24026d4969b982b18f0a6b295cb72b60",
            "/paper/Sensory-Based-Failure-Threshold-Estimation-for-Life-Chehade-Bonk/bd408036145a4383aaa671c1d093c9b811a842cc",
            "/paper/Deep-Convolutional-Neural-Network-Based-Regression-Babu-Zhao/52b7cb1705f0815c3e66b785b3a4432b1af6d47a",
            "/paper/Sensory-Updated-Residual-Life-Distributions-for-Gebraeel/67c545412446d97e2b8f031c87d4a27df0a7a237",
            "/paper/A-Neural-Network-Degradation-Model-for-Computing-Gebraeel-Lawley/5c28f1f8b5e512eee06fb46844a33ddd51fcdd87",
            "/paper/Prognostic-Degradation-Models-for-Computing-and-in-Gebraeel-Pan/ed5e7400047aa94ef42b5c3acec542bdc8b757c5",
            "/paper/Statistical-degradation-modeling-and-prognostics-of-Song-Liu/6915ca1af5ba2de9828fcba48b3ac0cd454aa044"
        ]
    },
    {
        "id": "53c8bc7cf08bed28493237e5004dd202077fc59f",
        "title": "Robust Image-to-Image Color Transfer Using Optimal Inlier Maximization",
        "abstract": "This paper presents a feature-based method, that robustly fits color transforms to data containing gross outliers, based on an optimal inlier maximization algorithm that maximizes the number of inliers in polynomial time. In this paper we target the color transfer estimation problem, when we have pixel-to-pixel correspondences. We present a feature-based method, that robustly fits color transforms to data containing gross outliers. Our solution is based on an optimal inlier maximization algorithm that maximizes the number of inliers in polynomial time. We introduce a simple feature detector and descriptor based on the structure tensor that gives the means for reliable matching of the color distributions in two images. Using combinatorial methods from optimization theory and a number of new minimal solvers, we can enumerate all possible stationary points to the inlier maximization problem. In order for our method to be tractable we use a decoupling of the intensity and color direction for a given RGB-vector. This enables the intensity transformation and the color direction transformation to be handled separately. Our method gives results comparable to state-of-the-art methods in the presence of little outliers, and large improvement for moderate or large amounts of outliers in the data. The proposed method has been tested in a number of imaging applications.",
        "publication_year": "2021",
        "authors": [
            "Magnus Oskarsson"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "2",
        "reference_count": "52",
        "references": [
            "/paper/Example-based-color-transfer-with-Gaussian-mixture-Gu-Lu/fec702c4fef109faccd98fb3f0502c7258970d80",
            "/paper/A-unified-probabilistic-framework-of-robust-and-for-Li-Yin/be6a7d3f90c6a9d2575bf42745a3e27fe17884ce",
            "/paper/Efficient-and-Robust-Color-Consistency-for-Photo-Park-Tai/8aef04d7118798dc83b66ee75d790ae8429f81c9",
            "/paper/Fast-and-Stable-Color-Balancing-for-Images-and-Oskam-Sorkine-Hornung/b61d31ff4fe4383e7511b8b261971e39a357b48d",
            "/paper/Non-rigid-dense-correspondence-with-applications-HaCohen-Shechtman/fec3714f5a2d7d4cd8c8e2e5ba83a162fbefcb38",
            "/paper/Color-Transfer-Using-Probabilistic-Moving-Least-Hwang-Lee/54e8f504c3fc6b8e8e27c9a9cd7285698272c81d",
            "/paper/A-Robust-Algorithm-for-Color-Correction-between-Two-Wang-Sun/1dd3bf7b02bb60c789fc442d14fa0be3c785a0c0",
            "/paper/Colour-and-illumination-in-computer-vision-Finlayson/31e4705c75f872eae78db20e82151f27801bdce4",
            "/paper/Optimal-Transportation-for-Example-Guided-Color-Frigo-Sabater/2611e2502864ace363f6decbaec591a25c8e4544",
            "/paper/As-projective-as-possible-bias-correction-for-Afifi-Punnappurath/ff095e2ff082fdb7e098e624bcd950f56b52d96d",
            "/paper/Color-Homography%3A-Theory-and-Applications-Finlayson-Gong/87903eb5b22a4545b774253921ee7fcd8119b15f",
            "/paper/Temporally-Consistent-Tone-Mapping-of-Images-and-Oskarsson/d5ae5b3d97b52db12c62ffe3c4db2910f720851a"
        ]
    },
    {
        "id": "72d125f8bdfc38b4ddfcb2e5bae13563875479ae",
        "title": "Single-cell eQTL analysis of activated T cell subsets reveals activation and cell type\u2013dependent effects of disease-risk variants",
        "abstract": "This DICE (Database of Immune Cell Expression, eQTLs, and Epigenomics) subproject highlights the power of sc-eQTL studies for simultaneously exploring the activation and cell type\u2013dependent effects of common genetic variants on gene expression. The impact of genetic variants on cells challenged in biologically relevant contexts has not been fully explored. Here, we activated CD4+ T cells from 89 healthy donors and performed a single-cell RNA sequencing assay with >1 million cells to examine cell type\u2013specific and activation-dependent effects of genetic variants. Single-cell expression quantitative trait loci (sc-eQTL) analysis of 19 distinct CD4+ T cell subsets showed that the expression of over 4000 genes is significantly associated with common genetic polymorphisms and that most of these genes show their most prominent effects in specific cell types. These genes included many that encode for molecules important for activation, differentiation, and effector functions of T cells. We also found new gene associations for disease-risk variants identified from genome-wide association studies and highlighted the cell types in which their effects are most prominent. We found that biological sex has a major influence on activation-dependent gene expression in CD4+ T cell subsets. Sex-biased transcripts were significantly enriched in several pathways that are essential for the initiation and execution of effector functions by CD4+ T cells like TCR signaling, cytokines, cytokine receptors, costimulatory, apoptosis, and cell-cell adhesion pathways. Overall, this DICE (Database of Immune Cell Expression, eQTLs, and Epigenomics) subproject highlights the power of sc-eQTL studies for simultaneously exploring the activation and cell type\u2013dependent effects of common genetic variants on gene expression (https://dice-database.org). Description Genetic variants associated with disease risk manifest activation and cell type\u2013dependent effects on gene expression in immune cells. Genetic cues influencing T cell activation Natural genetic variation influences immune cell function and responses to internal and external triggers. Building on an analysis of how single-nucleotide polymorphisms (SNPs) influence gene expression in subsets of resting human CD4+ T cells, Schmiedel et al. used single-cell RNA sequencing to analyze relationships between SNPs and mRNA expression in activated CD4+ T cells. Expression of over 4000 genes by activated CD4+ T cells was affected by common SNPs including known disease-risk variants, with effects most prominent in specific T cell subsets. Activation of a subset of functionally important genes in CD4+ T cells was strongly influenced by biological sex. The new findings will provide a valuable resource for investigators interested in untangling the connections between genes, cell types, and genetic variants associated with the risk of specific immune-mediated diseases.",
        "publication_year": "2022",
        "authors": [
            "B. Schmiedel",
            "Cristian Gonz\u00e1lez-Col\u00edn",
            "Vicente Fajardo",
            "Job Rocha",
            "A. Madrigal",
            "C. Ram\u00edrez-Su\u00e1stegui",
            "Sourya Bhattacharyya",
            "Hayley Simon",
            "J. Greenbaum",
            "Bjoern Peters",
            "G. Seumois",
            "F. Ay",
            "Vivek Chandra",
            "P. Vijayanand"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "19",
        "reference_count": "102",
        "references": [
            "/paper/Integrative-single-cell-multiomics-analysis-of-a-in-Wang-Cheng/bc868ce9aa25e3ee4f6dcc8bd74f69c2e82d9753",
            "/paper/eQTL-Studies%3A-from-Bulk-Tissues-to-Single-Cells-Zhang-Zhao/64040e68278d9d4fb4e75bd3be29613821543bee",
            "/paper/Mapping-the-dynamic-genetic-regulatory-architecture-Kang-Shen/d26fa0beea05aa96754d1c9666e34e1c25dcb550",
            "/paper/Gene-expression-QTL-mapping-in-stimulated-provides-Panousis-Garwany/7ffd671d1132cb87da4b36bdfa902d60b196bd48",
            "/paper/Alternative-paths-to-immune-activation%3A-the-role-of-Voda-Correa/e4b1856234be45606881873ae48d98b40741ea26",
            "/paper/Mapping-the-functional-impact-of-non-coding-in-T-Catalinas-Ibarra-Soria/9e46bd9ae0eec5a7b8cba691bf1cbdfc4280d2be",
            "/paper/Cell-type-deconvolution-of-bulk-blood-RNA-Seq-to-of-Boltz-Schwarz/1d9e7cb412d10aad7295515827ace8142e1b4ff7",
            "/paper/Polygenic-Risk-Associated-with-Alzheimer%E2%80%99s-Disease-Dressman-Tasaki/7deaaba89e8245651ba39ea75cada71f6b17d39f",
            "/paper/Single-cell-genomics-meets-human-genetics.-Cuomo-Nathan/3bf875aa8b52b8390c30e30296ee0e6650298ea3",
            "/paper/The-missing-link-between-genetic-association-and-Connally-Nazeen/6a34c86d941566c29f05013f02e0f8a6e513e3e5",
            "/paper/Impact-of-Genetic-Polymorphisms-on-Human-Immune-Schmiedel-Singh/c29ae553d0bfc3981042899ce8b99b98f2c2bdbd",
            "/paper/Single-cell-RNA-sequencing-identifies-cell-and-QTLs-Wijst-Brugge/0561b397a20d09bbe3dca7c7d8785b9f25a38716",
            "/paper/17q21-asthma-risk-variants-switch-CTCF-binding-and-Schmiedel-Seumois/de3bd091e6f7daabf32b6956b15a77e9fb7643ec",
            "/paper/Innate-Immune-Activity-Conditions-the-Effect-of-Fairfax-Humburg/d3ebdd64aa62f4d92444aef8e6504b1e04fbe260",
            "/paper/Neonatal-genetics-of-gene-expression-reveal-origins-Huang-Tang/a7c4633e005a48136e49b8e38f34958f4881b888",
            "/paper/Intersection-of-population-variation-and-genetics-T-Ye-Feng/d9bb990b286de15102ae3edc7a4f72c098cfc644",
            "/paper/Promoter-interacting-expression-quantitative-trait-Chandra-Bhattacharyya/008ec8443a275fcf2e2cc24f5e4d74327ce253c6",
            "/paper/Leukocyte-specific-protein-1-regulates-T-cell-in-Hwang-Jung/f933350d8a188768a177f276dbac1e3c42b17eeb",
            "/paper/Genetic-Ancestry-and-Natural-Selection-Drive-in-to-N%C3%A9d%C3%A9lec-Sanz/96bb9a68802e73707cec6028e337674b4c61578a",
            "/paper/Common-Genetic-Variants-Modulate-Pathogen-Sensing-Lee-Ye/784bf92e04236605a0e6621d76566e34a0838358"
        ]
    },
    {
        "id": "f66476bb4dd3bb45d60be9165201f70f8a546027",
        "title": "Variable Step-Size $\\ell _{0}$-Norm Constraint NLMS Algorithms Based on Novel Mean Square Deviation Analyses",
        "abstract": "Simulations demonstrate that the proposed variable step-size algorithms have better performances than the existing algorithms in sparse system identification and acoustic echo cancellation scenarios. This paper proposes variable step-size <inline-formula><tex-math notation=\"LaTeX\">$\\ell _{0}$</tex-math></inline-formula>-norm constraint normalized least mean square (<inline-formula><tex-math notation=\"LaTeX\">$\\ell _{0}$</tex-math></inline-formula>-NLMS) algorithms for sparse channel identification. The mean square deviation of the <inline-formula><tex-math notation=\"LaTeX\">$\\ell _{0}$</tex-math></inline-formula>-NLMS algorithm is newly analyzed to obtain the optimal step size by reflecting the correlated property of the inputs. The mean square deviation estimations are derived in both the absence and presence of information on measurement noises. The variable step-size schemes are derived by minimizing the forthcoming mean square deviations. A reset algorithm is introduced to consider the sudden change in the unknown system in practical situations. Simulations demonstrate that the proposed variable step-size algorithms have better performances than the existing algorithms in sparse system identification and acoustic echo cancellation scenarios.",
        "publication_year": "2022",
        "authors": [
            "Minho Lee",
            "Taesu Park",
            "P. Park"
        ],
        "related_topics": [
            "Computer Science",
            "Engineering"
        ],
        "citation_count": "3",
        "reference_count": "76",
        "references": [
            "/paper/L0-norm-constraint-normalized-subband-adaptive-and-Liu-Zhao/9e31ceae5ada558541d1995e3f06d0166f79e37b",
            "/paper/l0-Norm-Based-Improved-Proportionate-Maximum-for-Saha-Patnaik/51fc2b5afe4aa541894a94cfc06a6cd1b007b401",
            "/paper/Study-of-L0-norm-constraint-normalized-subband-Liu-Zhao/7fff09b192d98b27e39a34aed9c6130c7c840da9",
            "/paper/L%E2%82%81-L%E2%82%82-Mode-Switching-Adaptive-Filter-Algorithm-on-Lee-Park/8bd38dfb052bd15beb9be2ba7d1cbfddac0b631d",
            "/paper/Adaptive-Algorithm-for-Sparse-System-Identification-Lee-Lee/e43bd55e097ac0b0c7d0c405b2f6a79c3c665712",
            "/paper/A-Variable-Step-Size-Robust-Saturation-Algorithm-Hur-Lee/96cb79c770ab30506c9dc178dd129eb27fc9853d",
            "/paper/Variable-step-size-widely-linear-complex-valued-and-Shi-Zhao/1b1d688ca1e130f496468511b479e14ae08c2777",
            "/paper/Variable-step-size-l0-norm-NLMS-algorithm-for-Nunoo-Chude-Okonkwo/9e2feabaa17f3019455082fbdfda1e7fa68f1324",
            "/paper/Block-Sparsity-Log-Sum-Induced-Adaptive-Filter-for-Zhang-Liu/a8f4acc0041feaad69abbfd63a509a41a081969c",
            "/paper/Robust-Variable-Step-Size-Reweighted-Least-Mean-for-Wang-Zhao/6e08add5629c51b78421e20053d348814da17f66",
            "/paper/A-p-norm-variable-step-size-LMS-algorithm-for-Aliyu-Alkassim/925afa0f1c978eefe334a022c69cb4c00e0b8124",
            "/paper/Convergence-analysis-of-the-zero-attracting-LMS-for-Jahromi-Salman/ba85f2786563dce6801534c78bc40802322a468d",
            "/paper/Reweighted-l1-norm-penalized-LMS-for-sparse-channel-Taheri-Vorobyov/e7ff64fe7e07aa36d7daee4b8030ac1fd7a19c42"
        ]
    },
    {
        "id": "5472fc060d6d22ed3b055732013ac767eb522fa4",
        "title": "Any-Shot Sequential Anomaly Detection in Surveillance Videos",
        "abstract": "This work proposes an online anomaly detection method for surveillance videos using transfer learning and any-shot learning, which in turn significantly reduces the training complexity and provides a mechanism which can detect anomalies using only a few labeled nominal examples. Anomaly detection in surveillance videos has been recently gaining attention. Even though the performance of state-of-the-art methods on publicly available data sets has been competitive, they demand a massive amount of training data. Also, they lack a concrete approach for continuously updating the trained model once new data is available. Furthermore, online decision making is an important but mostly neglected factor in this domain. Motivated by these research gaps, we propose an online anomaly detection method for surveillance videos using transfer learning and any-shot learning, which in turn significantly reduces the training complexity and provides a mechanism which can detect anomalies using only a few labeled nominal examples. Our proposed algorithm leverages the feature extraction power of neural network-based models for transfer learning, and the any-shot learning capability of statistical detection methods.",
        "publication_year": "2020",
        "authors": [
            "Keval Doshi",
            "Y. Yilmaz"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "49",
        "reference_count": "37",
        "references": [
            "/paper/Online-Anomaly-Detection-in-Surveillance-Videos-on-Doshi-Yilmaz/e0e25f7bc95afd3c7fa8097f8db7fb83238de243",
            "/paper/Deep-Learning-Based-Anomaly-Detection-in-Video-A-Duong-Le/2d26033ada57a73f7c8135195bdaaef2573c6917",
            "/paper/A-Critical-Study-on-the-Recent-Deep-Learning-Based-Baradaran-Bergevin/318abe78ac4df567e812ba43e49bb10bf0da17c9",
            "/paper/A-Modular-and-Unified-Framework-for-Detecting-and-Doshi-Y%C4%B1lmaz/d47ac61d72a8287b3d28441c4329c81e9ef5ccdd",
            "/paper/A-Survey-of-Deep-Learning-Solutions-for-Anomaly-in-Munyua-Wambugu/393302ba429287b6ebaba6e91b8013e0cf0141b6",
            "/paper/Object-Centric-and-Memory-Guided-Normality-for-Bergaoui-Naji/ad4355016b60c83ac585bff29b124ee1a9767d14",
            "/paper/Anomaly-Detection-in-Video-via-Self-Supervised-and-Georgescu-B%C4%83rb%C4%83l%C4%83u/57b2198f9a8df773425aa6cc88c9870cb07779e2",
            "/paper/UBnormal%3A-New-Benchmark-for-Supervised-Open-Set-Acsintoae-Florescu/495035ca18ceb82d13e5b42beece8eb633f6095c",
            "/paper/A-Novel-Unsupervised-Video-Anomaly-Detection-Based-Huang-Zhao/228273c1beb2f54a56dd19a650e73c10780044c5",
            "/paper/Multi-Task-Learning-based-Video-Anomaly-Detection-Baradaran-Bergevin/2c4194837fa408b63d52599b2b98f19b76ce6a67",
            "/paper/Real-World-Anomaly-Detection-in-Surveillance-Videos-Sultani-Chen/598fe25743f9492c5c1ba30274ea446f65426d85",
            "/paper/Adaptive-Sparse-Representations-for-Video-Anomaly-Mo-Monga/7534e966db99d449d75090d5c7f340b03c1de418",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Object-Centric-Auto-Encoders-and-Dummy-Anomalies-in-Ionescu-Khan/e7b7d97042ad2fdf3a7238a724c9dc3195537bea",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c",
            "/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429",
            "/paper/Joint-Detection-and-Recounting-of-Abnormal-Events-Hinami-Mei/094ac7510d1723cb9c2da01db47291322aa29025",
            "/paper/Online-detection-of-unusual-events-in-videos-via-Zhao-Fei-Fei/3262e77099cefe24cff1308f204e673cac832451",
            "/paper/Sparse-reconstruction-cost-for-abnormal-event-Cong-Yuan/ae37774ff871575b7799411bf87f42eb52634390",
            "/paper/Plug-and-Play-CNN-for-Crowd-Motion-Analysis%3A-An-in-Ravanbakhsh-Nabi/b9bdc61d63d75d82f24de21be26f61879df5a01b"
        ]
    },
    {
        "id": "496585f00f7f4dc066dfbcef433ae3192c1c9c69",
        "title": "Management of pain in patients with temporomandibular disorder (TMD): challenges and solutions",
        "abstract": "The treatment is structured in a multi-modal approach based on a biobehavioral approach that includes medical, physiotherapeutic, psychological, and dental treatments and a new biobeHavioral model regarding pain perception and motor behavior for the diagnosis and treatment of patients with painful TMD is proposed. Thanks to advances in neuroscience, biopsychosocial models for diagnostics and treatment (including physical, psychological, and pharmacological therapies) currently have more clinical support and scientific growth. At present, a conservative treatment approach prevails over surgery, given it is less aggressive and usually results in satisfactory clinical outcomes in mild\u2013moderate temporomandibular disorder (TMD). The aim of this review is to evaluate the recent evidence, identify challenges, and propose solutions from a clinical point of view for patients with craniofacial pain and TMD. The treatment we propose is structured in a multi-modal approach based on a biobehavioral approach that includes medical, physiotherapeutic, psychological, and dental treatments. We also propose a new biobehavioral model regarding pain perception and motor behavior for the diagnosis and treatment of patients with painful TMD.",
        "publication_year": "2018",
        "authors": [
            "A. Gil-Mart\u00ednez",
            "A. Paris\u2010Alemany",
            "I. L\u00f3pez-de-Uralde-Villanueva",
            "R. La Touche"
        ],
        "related_topics": [
            "Psychology",
            "Medicine"
        ],
        "citation_count": "127",
        "reference_count": "222",
        "references": [
            "/paper/Diagnosis-and-Treatment-of-Myogenous-Disorders%3A-A-Chan-Ip/5ef020fc4161e7b04f4df8717f80216ec0a1ea9d",
            "/paper/Modern-therapeutic-management-of-temporomandibular-Lazarescu-Balneoclimatology/9251c9006c14e578eb9ee64ea75459ed07a07944",
            "/paper/Temporomandibular-disorders%3A-improving-outcomes-a-Garrig%C3%B3s-Pedr%C3%B3n-Elizagaray-Garc%C3%ADa/fbcf387dd501ebdf16588136d54908f5e5ac6197",
            "/paper/Therapeutic-Agents-for-the-Treatment-of-Joint-and-Wu-Cai/76d0b8a7927d22a39a71b92d5914e2377e786f47",
            "/paper/Accurate-Diagnosis-and-Treatment-of-Painful-A-by-Garstka-Kozowska/40257e46141b0f0533ab8ac93c3c0dcbd632f105",
            "/paper/Effects-of-therapeutic-exercise-in-TMDs-with-pain-Moleirinho-Alves-Benzinho/7a5dc9c99dc7589aa3ae4fc5ce4848704099493c",
            "/paper/Physiotherapists-and-Osteopaths%E2%80%99-Attitudes%3A-in-of-Saran-Saccomanno/ca25dacb5c20fd4f02e93bfc5f2926389c9ce789",
            "/paper/Clinical-Reasoning-for-the-Examination-and-Physical-Fern%C3%A1ndez%E2%80%90de%E2%80%90las%E2%80%90Pe%C3%B1as-Piekartz/2f7029df33308e856b23570c8eb272162a3bea29",
            "/paper/Management-of-non-reducing-disc-derangement-in-a-Sabherwal-Tyagi/0a4366365962f3db61252f5d73bbda9f609b59c3",
            "/paper/Low-level-laser-therapy-in-temporomandibular-joint-Ahmad-Hasan/e82b3dfc8ee99783e9741aebe94f18a8f2558b8a",
            "/paper/Physical-therapy-for-temporomandibular-disorders-Sturdivant-Fricton/d0d5b7e7fb40501888e287cbe3f4158e9ea801a3",
            "/paper/Evaluation-of-the-Effectiveness-of-Biobehavioral-in-Orlando-Manfredini/dee153d1f6d1eedf618dc1efac91bb88eedaa4cf",
            "/paper/The-changing-field-of-temporomandibular-disorders%3A-Klasser-Greene/586b9e777e6ccf049d15e14c4be1709d2bfd7664",
            "/paper/Diagnosis-and-treatment-of-temporomandibular-Gauer-Semidey/0c6977c45884ec3e152d278202de5cc9c36292c6",
            "/paper/Pain-Related-Temporomandibular-Disorder-Current-and-Ghurye-McMillan/224d2e354d602e20f92f437daa08f7e92c711380",
            "/paper/Orofacial-pain-and-temporomandibular-disorders%3A-the-Conti-PINTO-FIAMENGUI/7920f8ef0b82c299851e99ac1b3a7ff3bac9f1e8",
            "/paper/Pharmacological-interventions-for-pain-in-patients-Mujakperuo-Watson/7b6ae33599e0503a6ee6cf84a1e334fd2fbd69fe",
            "/paper/Chronicity-factors-of-temporomandibular-disorders%3A-Soares-Rizzatti-Barbosa/e4cd1ed717da6a347343006347c1c63d87e05144",
            "/paper/A-comparison-of-treatment-modes-in-the-management-Crockett-Foreman/d4204637c7008b0e2f2f5bb77715d3a769ecec25",
            "/paper/Temporomandibular-disorders.-2.-Non-surgical-Dimitroulis-Gremillion/93368b064c69fefa30c7b07fb5a83632316cccf8"
        ]
    },
    {
        "id": "7525f81423bfbeaedf23b9f179a7447afbbce848",
        "title": "Genetic comparison of mouse lung telocytes with mesenchymal stem cells and fibroblasts",
        "abstract": "Gene expression profile of murine lung TCs demonstrates that TCs are functionally distinct interstitial cells with specific roles in cell signalling, tissue remodelling and angiogenesis. Telocytes (TCs) are interstitial cells with telopodes \u2013 very long prolongations that establish intercellular contacts with various types of cells. Telocytes have been found in many organs and various species and have been characterized ultrastructurally, immunophenotypically and electrophysiologically (www.telocytes.com). Telocytes are distributed through organ stroma forming a three\u2010dimensional network in close contacts with blood vessels, nerve bundles and cells of the local immune system. Moreover, it has been shown that TCs express a broad range of microRNAs, such as pro\u2010angiogenic and stromal\u2010specific miRs. In this study, the gene expression profile of murine lung TCs is compared with other differentiated interstitial cells (fibroblasts) and with stromal stem/progenitor cells. More than 2000 and 4000 genes were found up\u2010 or down\u2010regulated, respectively, in TCs as compared with either MSCs or fibroblasts. Several components or regulators of the vascular basement membrane are highly expressed in TCs, such as Nidogen, Collagen type IV and Tissue Inhibitor of Metalloproteinase 3 (TIMP3). Given that TCs locate in close vicinity of small vessels and capillaries, the data suggest the implication of TCs in vascular branching. Telocytes express also matrix metalloproteases Mmp3 and Mmp10, and thus could regulate extracellular matrix during vascular branching and de novo vessel formation. In conclusion, our data show that TCs are not fibroblasts, as the ultrastructure, immunocytochemistry and microRNA assay previously indicated. Gene expression profile demonstrates that TCs are functionally distinct interstitial cells with specific roles in cell signalling, tissue remodelling and angiogenesis.",
        "publication_year": "2013",
        "authors": [
            "Yonghua Zheng",
            "Miaomiao Zhang",
            "Mengjia Qian",
            "Lingyan Wang",
            "V. Cisma\u015fiu",
            "C. Bai",
            "L. Popescu",
            "Xiangdong Wang"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "124",
        "reference_count": "41",
        "references": [
            "/paper/Telocytes-in-regenerative-medicine-Bei-Wang/ac40123de90d564e110473a9ecb4f3b3f6a92daf",
            "/paper/Cardiac-Telocytes-and-Fibroblasts-in-Primary-and-Bei-Zhou/41f2b4efd222e50abf3af4bf13a92c962556faac",
            "/paper/Comparison-of-Chromosome-4-gene-expression-profile-Song-Cre%C8%9Boiu/daed12e232c9fadd083a9d58b2971ceb422560cf",
            "/paper/Skin-telocytes-versus-fibroblasts%3A-two-distinct-Kang-Zhu/952df44a2d1d94c833228ea70a22bbd883f0d2e5",
            "/paper/Telocytes-transfer-extracellular-vesicles-loaded-to-Cisma%C5%9Fiu-Popescu/f7340e226780484b45de88380fe8579781140d7e",
            "/paper/Telocytes%3A-An-Emerging-Component-of-Stem-Cell-Niche-Rosa-Marini/4ac60f2a8d82e1f55fa74bf5e8e2529c198fe660",
            "/paper/The-telopode-and-filopode-projecting-heterogeneous-Petrea-Cr%C4%83i%C5%A3oiu/0b7c01b1814949b7f6f7044bee3b4e84b29a4917",
            "/paper/A-Tale-of-Two-Cells%3A-Telocyte-and-Stem-Cell-Unique-Maadawi/2498b3c6fb8457270370f3a119b16400dfc9f122",
            "/paper/Identification-of-Myocardial-Telocytes-and-Bone-in-Zhong-Zheng/a9419034c02b66d28d125329d668be16ed545b93",
            "/paper/Potential-Role-of-Telocytes-in-Differentiation-of-Soliman/d70cd0ff16272ea64074da3af6dab306fbac60f4",
            "/paper/Esophageal-telocytes-and-hybrid-morphologies-Rusu-Nicolescu/ba1890e824bd6f2ea1cbd561c21cffafe36bf8c2",
            "/paper/Identification-of-telocytes-in-skeletal-muscle-for-Popescu-Manole/73bd1e8c8e9e9bf418e798c12180326411b43b21",
            "/paper/Potential-significance-of-telocytes-in-the-of-lung-Zheng-Bai/669077cd16ff48b18487ecb9a9facb63ed205e1b",
            "/paper/miR-193-expression-differentiates-telocytes-from-Cismasiu-Radu/e53e399dc18a9212fe8415869bfa38de0d8c4338",
            "/paper/Telocytes-in-human-skin-%E2%80%93-are-they-involved-in-skin-Ceafalan-Gherghiceanu/22bda2439a0f1b2929dbc069c5205896a48491ba",
            "/paper/Telocytes-and-putative-stem-cells-in-the-lungs%3A-and-Popescu-Gherghiceanu/ece27e349d815bb8d4fa286a0f6febb8431dc538",
            "/paper/Telocyte-morphologies-and-potential-roles-in-Zheng-Bai/790a7815964f4b4d9ab50dc7fd1cb2cb9fc236f5",
            "/paper/Telocytes%2C-a-distinct-type-of-cell-among-the-cells-Cre%C8%9Boiu-Cre%C8%9Boiu/1c818ec06ce4bca12dd1571099d2433e1718e58d",
            "/paper/Human-myometrium-%E2%80%93-the-ultrastructural-3D-network-Cre%C8%9Boiu-Cre%C8%9Boiu/3a733d169d4de7ad770bcfbbd9eb4496ad07b775",
            "/paper/Telocytes-and-Stem-Cells-Popescu-Nicolescu/0c17feadd55e3e0577e727a4dee4eae71c311d4b"
        ]
    },
    {
        "id": "4a980355c6e926b31a6c255f13f623b84792c0f8",
        "title": "Machine Learning and Its Application in Skin Cancer",
        "abstract": "The fundamentals of ML are discussed and its potential in assisting the diagnosis of skin cancer is discussed, including the use of deep convolutional neural networks. Artificial intelligence (AI) has wide applications in healthcare, including dermatology. Machine learning (ML) is a subfield of AI involving statistical models and algorithms that can progressively learn from data to predict the characteristics of new samples and perform a desired task. Although it has a significant role in the detection of skin cancer, dermatology skill lags behind radiology in terms of AI acceptance. With continuous spread, use, and emerging technologies, AI is becoming more widely available even to the general population. AI can be of use for the early detection of skin cancer. For example, the use of deep convolutional neural networks can help to develop a system to evaluate images of the skin to diagnose skin cancer. Early detection is key for the effective treatment and better outcomes of skin cancer. Specialists can accurately diagnose the cancer, however, considering their limited numbers, there is a need to develop automated systems that can diagnose the disease efficiently to save lives and reduce health and financial burdens on the patients. ML can be of significant use in this regard. In this article, we discuss the fundamentals of ML and its potential in assisting the diagnosis of skin cancer.",
        "publication_year": "2021",
        "authors": [
            "K. Das",
            "C. Cockerell",
            "A. Patil",
            "P. Pietkiewicz",
            "Mario Giulini",
            "S. Grabbe",
            "M. Goldust"
        ],
        "related_topics": [
            "Computer Science",
            "Medicine"
        ],
        "citation_count": "19",
        "reference_count": "49",
        "references": [
            "/paper/Clinical-Application-of-Artificial-Intelligence-for-Sanchez-Kamal/3e402735aa827797d2a52de9a9d7e37071edd33e",
            "/paper/Deep-Learning-based-and-Machine-Learning-based-in-Wang/77a98d49e435169a1e7a3d762a52a35f277214e4",
            "/paper/AI-Powered-Diagnosis-of-Skin-Cancer%3A-A-Contemporary-Melarkode-Srinivasan/164e14a497f49ce5694c48e1c04a3125aeabec6e",
            "/paper/Deep-learning-model-enhanced-skin-cancer-detection-Kolachina-Agada/0852ca8b92a957a016e88b380bf4445f88ae849b",
            "/paper/Evaluation-of-artificial-intelligence-techniques-in-Nia-Kaplanoglu/ff97adbdf7ba45c08c6abe277aba04b41e85e5b0",
            "/paper/Meta-Analysis-of-Human-Body-Diseases-with-the-of-Verma-Sharma/1d2a7d14e2573cf1015c43e8ff782f9491dad1a7",
            "/paper/An-Insight-into-Applications-of-Deep-Learning-in-Jyothi-Tejasvi/04e247b67e3579c5fc25f772555fe3fb6c3038ed",
            "/paper/Dhanvantari%3A-An-intelligent-diagnosis-tool-to-skin-Koundinya-Gowda/cad962b1c7e912fe5f727bfc37f7d884ff4ecfc2",
            "/paper/Application-of-non-negative-matrix-factorization-in-Hamamoto-Takasawa/c62fdc1881dd26001b8f7eff582b4d615762754f",
            "/paper/A-Melanoma-Skin-Cancer-Diagnosis-Using-Hybrid-MSVM-Shakya-Kumar/136173a55ffd15c8bc740b91fccf463ffa41571f",
            "/paper/Artificial-intelligence-based-image-classification-Goyal-Knackstedt/7e588ec59faf9736c9b981492c5293a2e8849858",
            "/paper/Machine-Learning-in-Dermatology%3A-Current-and-Chan-Reddy/588336811ef775391d45138d9c1684ab22632f53",
            "/paper/What-is-AI-Applications-of-artificial-intelligence-Du-Harpur-Watt/d3c787ccecad58b78c86530b780531dc7ee254b5",
            "/paper/Deep-learning-ensembles-for-melanoma-recognition-in-Codella-Nguyen/70ec156f7e6de0275c7e4e95e35f1bc1e92e29b3",
            "/paper/The-rise-of-artificial-intelligence-in-healthcare-Bohr-Memarzadeh/fd41c526ab65ef21a43dfd2b427f8eaeea6c35ce",
            "/paper/Artificial-Intelligence%2C-Machine-Learning%2C-Deep-and-Bini/846ff7afb7670d62f88b4a8cc99d306ffb81b075",
            "/paper/Artificial-Intelligence-in-Skin-Cancer-Diagnostics%3A-Jutzi-Krieghoff-Henning/d2e05b456fe3954e8965ebd8b12cc03e348cc23a",
            "/paper/Expert-Level-Diagnosis-of-Nonpigmented-Skin-Cancer-Tschandl-Rosendahl/f01b512314420d53fa4209d732aba1ed77977730",
            "/paper/Systematic-outperformance-of-112-dermatologists-in-Maron-Weichenthal/f5fbdbb31301263a6a5f67bd6dc485edaa3324e4",
            "/paper/Man-against-machine%3A-diagnostic-performance-of-a-in-Haenssle-Fink/546785490ac417be1f83ced6a8272e934934f411"
        ]
    },
    {
        "id": "c8ea6615e85e0df16cc52486bfdf725cc578ff59",
        "title": "Segmentation and Tracing of Single Neurons from 3D Confocal Microscope Images",
        "abstract": "Tree2Tree is developed, a robust automatic neuron segmentation and morphology generation algorithm that enables Tree2Tree to estimate bifurcations naturally, which is currently a challenge for current neuron tracing algorithms. In order to understand the brain, we need to first understand the morphology of neurons. In the neurobiology community, there have been recent pushes to analyze both neuron connectivity and the influence of structure on function. Currently, a technical roadblock that stands in the way of these studies is the inability to automatically trace neuronal structure from microscopy. On the image processing side, proposed tracing algorithms face difficulties in low contrast, indistinct boundaries, clutter, and complex branching structure. To tackle these difficulties, we develop Tree2Tree, a robust automatic neuron segmentation and morphology generation algorithm. Tree2Tree uses a local medial tree generation strategy in combination with a global tree linking to build a maximum likelihood global tree. Recasting the neuron tracing problem in a graph-theoretic context enables Tree2Tree to estimate bifurcations naturally, which is currently a challenge for current neuron tracing algorithms. Tests on cluttered confocal microscopy images of Drosophila neurons give results that correspond to ground truth within a margin of \u00b12.75% normalized mean absolute error.",
        "publication_year": "2013",
        "authors": [
            "S. Basu",
            "B. Condron",
            "A. Aksel",
            "S. Acton"
        ],
        "related_topics": [
            "Computer Science",
            "Biology"
        ],
        "citation_count": "36",
        "reference_count": "35",
        "references": [
            "/paper/Automated-neuron-tracing-using-probability-density-Radojevi%C4%87-Meijering/a96a1b0c8fae6947b6882423a59336fe0f0e7d30",
            "/paper/Tubularity-Flow-Field%E2%80%94A-Technique-for-Automatic-Mukherjee-Condron/76fd81e9b067c4f812cd0243af28a1aa1c796a49",
            "/paper/Neuron-segmentation-with-level-sets-Mukherjee-Condron/bb28df836398692ad3875919cf95604def38c9df",
            "/paper/Semi-automatic-3D-morphological-reconstruction-of-Zandt-Losneg%C3%A5rd/3a69abb6ab977c21ec869b68fd67cba60bb4828e",
            "/paper/Neuron-tracing-from-light-microscopy-images%3A-deep-Liu-Wang/6050d3b64eadae2ab87eaf9030cadf5ff871c929",
            "/paper/Crossover-Structure-Separation-With-Application-to-Guo-Liu/28b9191ee50438345b471a317a52ac25237283ca",
            "/paper/3D-Neuron-Microscopy-Image-Segmentation-via-the-and-Jiang-Chen/e11b2d143167d770e4c954bc6817d8f136898113",
            "/paper/Incorporate-Deep-Transfer-Learning-into-Automatic-Zheng-Hong/8bab0db8c7818ff6b1267e6e38798f650176ff6a",
            "/paper/An-automated-pipeline-for-bouton%2C-spine%2C-and-of-in-Xie-Chen/263f49bf19eb3a64a3dce130dac6d669eb5048ae",
            "/paper/A-Manual-Segmentation-Tool-for-Three-Dimensional-Magliaro-Callara/fd560852242413ba6999213f1f87b6057c021510",
            "/paper/Tree2Tree%3A-Neuron-segmentation-for-generation-of-Basu-Aksel/5550156fb39afd71919bff9a01faf21e3700fb6c",
            "/paper/Rapid-automated-three-dimensional-tracing-of-from-Al-Kofahi-Lasek/8c8c9c0ff996da9a2e8f8387788903e21a4c3668",
            "/paper/Neuron-tracing-in-perspective-Meijering/9c53d3569c141b2791b193e5dcc52fba8177710c",
            "/paper/Transmitted-light-brightfield-mosaic-microscopy-for-Oberlaender-Bruno/65524aea4b6f800ba79404b81ced89fddb887932",
            "/paper/Semi-Automated-Reconstruction-of-Neural-Processes-Lu-Fiala/d83930212ec8c55b806523c06757cf2a7e6fbecc",
            "/paper/Progress-in-functional-neuroanatomy%3A-precise-of-Evers-Schmitt/14b7c9ecc6a379b8cf7b6afc4b8499045ad2970d",
            "/paper/Automatic-segmentation-and-skeletonization-of-from-Dima-Scholz/4be7d188de85050f8b585b8bc661052462dde621",
            "/paper/Median-based-robust-algorithms-for-tracing-neurons-Al-Kofahi-Can/2b7902744b60319cadf7cecb14d3ab6a4bcdd1dc",
            "/paper/Automated-Algorithms-for-Multiscale-Morphometry-of-Weaver-Hof/58948de0c5462633e97d21cda696081062148b2d",
            "/paper/NeuronMetrics%3A-Software-for-semi-automated-of-Narro-Yang/b48c07298c5033fa94f2e76fb61f5ab835bd8b02"
        ]
    },
    {
        "id": "ac591dbf261777e05d89c27f9a7bcb06f88aab5a",
        "title": "Scalable Vision Transformers with Hierarchical Pooling",
        "abstract": "A Hierarchical Visual Transformer (HVT) is proposed which progressively pools visual tokens to shrink the sequence length and hence reduces the computational cost, analogous to the feature maps downsampling in Convolutional Neural Networks (CNNs). The recently proposed Visual image Transformers (ViT) with pure attention have achieved promising performance on image recognition tasks, such as image classification. However, the routine of the current ViT model is to maintain a full-length patch sequence during inference, which is redundant and lacks hierarchical representation. To this end, we propose a Hierarchical Visual Transformer (HVT) which progressively pools visual tokens to shrink the sequence length and hence reduces the computational cost, analogous to the feature maps downsampling in Convolutional Neural Networks (CNNs). It brings a great benefit that we can increase the model capacity by scaling dimensions of depth/width/resolution/patch size without introducing extra computational complexity due to the reduced sequence length. Moreover, we empirically find that the average pooled visual tokens contain more discriminative information than the single class token. To demonstrate the improved scalability of our HVT, we conduct extensive experiments on the image classification task. With comparable FLOPs, our HVT outperforms the competitive baselines on ImageNet and CIFAR-100 datasets. Code is available at https://github.com/MonashAI/HVT.",
        "publication_year": "2021",
        "authors": [
            "Zizheng Pan",
            "Bohan Zhuang",
            "Jing Liu",
            "Haoyu He",
            "Jianfei Cai"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "83",
        "reference_count": "48",
        "references": [
            "/paper/Unified-Visual-Transformer-Compression-Yu-Chen/4c69fdca6e8a1f10871ab9dc47f62c81ba7ead4a",
            "/paper/Less-is-More%3A-Pay-Less-Attention-in-Vision-Pan-Zhuang/a0964686d80e173529efca6377f47e6a1b2fe69a",
            "/paper/TransMCGC%3A-a-recast-vision-transformer-for-image-Xiang-Chen/fc9bafc76d2166ac6d3a393a867e2d32b835f9cc",
            "/paper/EfficientViT%3A-Enhanced-Linear-Attention-for-Visual-Cai-Gan/7d2a78a1f713b71c3a337247d042c5c2f0b2da84",
            "/paper/Dynamic-Spatial-Sparsification-for-Efficient-Vision-Rao-Liu/968f628c3d42dbfd16fd4516e61cfedc16612310",
            "/paper/Searching-for-Efficient-Multi-Stage-Vision-Liao-Karaman/97f26219c5258b5bef84fe02a511de43133c72b3",
            "/paper/Pruning-Self-attentions-into-Convolutional-Layers-He-Liu/5b5f5ece7e73317ff1d66a6a79372c66ea960a2e",
            "/paper/Efficient-Vision-Transformers-via-Fine-Grained-Jia-Han/c723187a2230749b1e706df2217e928c8271a660",
            "/paper/Multi-Tailed-Vision-Transformer-for-Efficient-Wang-Du/4c8e43451d239f43c83759f2f7e6ab678548ecd7",
            "/paper/Patch-level-Representation-Learning-for-Vision-Yun-Lee/6eece39036fe90ecc92725b9380edd165f6290c4",
            "/paper/Tokens-to-Token-ViT%3A-Training-Vision-Transformers-Yuan-Chen/dbe077f8521ecbe0a1477d6148c726d4f053d9c9",
            "/paper/Pyramid-Vision-Transformer%3A-A-Versatile-Backbone-Wang-Xie/3e398bad2d8636491a1034cc938a5e024c7aa881",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/Bottleneck-Transformers-for-Visual-Recognition-Srinivas-Lin/16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman/eb42cf88027de515750f230b23b1a057dc782108",
            "/paper/Feature-Pyramid-Networks-for-Object-Detection-Lin-Doll%C3%A1r/b9b4e05faa194e5022edd9eb9dd07e3d675c2b36",
            "/paper/On-the-Relationship-between-Self-Attention-and-Cordonnier-Loukas/1ce1d287e825c78d381a95c0134e080bf1310611",
            "/paper/Wider-or-Deeper%3A-Revisiting-the-ResNet-Model-for-Wu-Shen/3070a1bd503c3767def898bbd50c7eea2bbf29c9",
            "/paper/Axial-DeepLab%3A-Stand-Alone-Axial-Attention-for-Wang-Zhu/8eba733040b016e9c7ec5c3dc87cc1b28a5c2000"
        ]
    },
    {
        "id": "05dcdfece56d1869895f53ed581d8ad64118c05f",
        "title": "Sign Language Transformers: Joint End-to-End Sign Language Recognition and Translation",
        "abstract": "A novel transformer based architecture that jointly learns Continuous Sign Language Recognition and Translation while being trainable in an end-to-end manner is introduced by using a Connectionist Temporal Classification (CTC) loss to bind the recognition and translation problems into a single unified architecture. Prior work on Sign Language Translation has shown that having a mid-level sign gloss representation (effectively recognizing the individual signs) improves the translation performance drastically. In fact, the current state-of-the-art in translation requires gloss level tokenization in order to work. We introduce a novel transformer based architecture that jointly learns Continuous Sign Language Recognition and Translation while being trainable in an end-to-end manner. This is achieved by using a Connectionist Temporal Classification (CTC) loss to bind the recognition and translation problems into a single unified architecture. This joint approach does not require any ground-truth timing information, simultaneously solving two co-dependant sequence-to-sequence learning problems and leads to significant performance gains. We evaluate the recognition and translation performances of our approaches on the challenging RWTH-PHOENIX-Weather-2014T (PHOENIX14T) dataset. We report state-of-the-art sign language recognition and translation results achieved by our Sign Language Transformers. Our translation networks outperform both sign video to spoken language and gloss to spoken language translation models, in some cases more than doubling the performance (9.58 vs. 21.80 BLEU-4 Score). We also share new baseline translation results using transformer networks for several other text-to-text sign language translation tasks.",
        "publication_year": "2020",
        "authors": [
            "Necati Cihan Camg\u00f6z",
            "Oscar Koller",
            "Simon Hadfield",
            "R. Bowden"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "232",
        "reference_count": "77",
        "references": [
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2",
            "/paper/Improving-Sign-Language-Translation-with-Data-by-Zhou-Zhou/7811df11a75f58646d04b3132d35f0656e50a109",
            "/paper/Gloss-Free-End-to-End-Sign-Language-Translation-Lin-Wang/108c9f268b3a89d2570901b7997b683c8cbbe192",
            "/paper/Keypoint-based-Sign-Language-Translation-without-Kim-Kwak/dbffd748e6349bc87803f16999f958498e90a477",
            "/paper/Contrastive-Disentangled-Meta-Learning-for-Sign-Jin-Zhao/73a6b52896ff246f1278008f42858238e2814d2d",
            "/paper/A-Simple-Multi-Modality-Transfer-Learning-Baseline-Chen-Wei/33703b1bfecb918aea4dcc2644a759f1de37c940",
            "/paper/Frozen-Pretrained-Transformers-for-Neural-Sign-Coster-D'Oosterlinck/7cc9d291d947c3321e74a909a0984cb233a9f6e2",
            "/paper/Attention-is-All-You-Sign%3A-Sign-Language-with-Yin-Read/27d65e82cb4157a8d47fd8487c0dceefb00909ed",
            "/paper/Progressive-Transformers-for-End-to-End-Sign-Saunders-Camg%C3%B6z/5a65e6184d18cd93ccbaa4d940a27749358ef824",
            "/paper/ConSLT%3A-A-Token-level-Contrastive-Framework-for-Fu-Ye/3f8a2addbdab4fddc7455bbc699da0f432a61a4d",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/Sign-Language-Production-using-Neural-Machine-and-Stoll-Camg%C3%B6z/212d7af298a4bd9090b834293067d2f091a95cfc",
            "/paper/Text2Sign%3A-Towards-Sign-Language-Production-Using-Stoll-Camgoz/7f6231aae6e5eb5b62f85429f3ad8eaa96fee11e",
            "/paper/Neural-Sign-Language-Translation-based-on-Human-Ko-Kim/74669631d3f1fcc06d0e5e5daa7e4bfd5b6f6b59",
            "/paper/SubUNets%3A-End-to-End-Hand-Shape-and-Continuous-Sign-Camg%C3%B6z-Hadfield/a10cd29fec9dca66250dbde19db5e831f7ce6406",
            "/paper/Using-viseme-recognition-to-improve-a-sign-language-Schmidt-Koller/1eb596303ce1f90e8070090be02c768e91fd75ed",
            "/paper/Recurrent-Convolutional-Neural-Networks-for-Sign-by-Cui-Liu/a3c850001340266d4b2e7479f78387b5fda0815c",
            "/paper/Bridging-the-gap-between-sign-language-machine-and-Ebling-Huenerfauth/c4bc3e0586d998b791b75947d8e1135d2f7b1dda",
            "/paper/Re-Sign%3A-Re-Aligned-End-to-End-Sequence-Modelling-Koller-Zargaran/28b85543e8f12c3d2d2227dcc9f5e87c685535ea",
            "/paper/Video-based-Sign-Language-Recognition-without-Huang-Zhou/81a1660d57738347a04b22920571bc394dd97a9e"
        ]
    },
    {
        "id": "0a869336c65185f078ba473d7ca5b86a371ab929",
        "title": "MisGAN: Learning from Incomplete Data with Generative Adversarial Networks",
        "abstract": "The proposed GAN-based framework learns a complete data generator along with a mask generator that models the missing data distribution and demonstrates how to impute missing data by equipping the framework with an adversarially trained imputer. Generative adversarial networks (GANs) have been shown to provide an effective way to model complex distributions and have obtained impressive results on various challenging tasks. However, typical GANs require fully-observed data during training. In this paper, we present a GAN-based framework for learning from complex, high-dimensional incomplete data. The proposed framework learns a complete data generator along with a mask generator that models the missing data distribution. We further demonstrate how to impute missing data by equipping our framework with an adversarially trained imputer. We evaluate the proposed framework using a series of experiments with several types of missing data processes under the missing completely at random assumption.",
        "publication_year": "2019",
        "authors": [
            "Steven Cheng-Xian Li",
            "Bo Jiang",
            "Benjamin M Marlin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "123",
        "reference_count": "24",
        "references": [
            "/paper/A-Survey-of-Missing-Data-Imputation-Using-Networks-Kim-Tae/3539708f69ec8b7e59da278dcc8fd546e819782f",
            "/paper/ClueGAIN%3A-Application-of-Transfer-Learning-On-Nets-Zhao/93953d4fd1e9271912aae7dd6bc30389262b2690",
            "/paper/Learning-to-Rank-with-Missing-Data-via-Generative-Deng-Han/a9d209bcfc44676a17526f1b409d6385391b6f1a",
            "/paper/Imbalanced-Data-Learning-by-Minority-Class-using-Shamsolmoali-Zareapoor/6f14f7b9ae27b34a47c7f203537386ed31ab2295",
            "/paper/Multiple-Imputation-by-Generative-Adversarial-for-Vi-Nguyen/b8df63d57baceab4d7b26d49dd7f2775233aeb5a",
            "/paper/Sequential-Data-Imputation-with-Evolving-Generative-Chakraborty-Samanta/cbdea56fd2e2464633fdc1edfc683191bca6b2fb",
            "/paper/Generative-Adversarial-Networks-%3A-A-Survey-Kakkar-Singh/76826f8bbc707dcb0fcd2c52bd212b1b86299b60",
            "/paper/PC-GAIN%3A-Pseudo-label-Conditional-Generative-for-Wang-Li/22d8594c8776736f411928eb0989a050df3e7e6e",
            "/paper/IGANI%3A-Iterative-Generative-Adversarial-Networks-to-Kazemi-Meidani/28e66a4c817b772c248a434ae89cfd3eab9c5faa",
            "/paper/A-Review-on-Generative-Adversarial-Networks%3A-and-Gui-Sun/fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea",
            "/paper/AmbientGAN%3A-Generative-models-from-lossy-Bora-Price/b959d5655a3b2f92c2c1a8a7896fecafafea979d",
            "/paper/GAIN%3A-Missing-Data-Imputation-using-Generative-Nets-Yoon-Jordon/a89f0a78f86077864e108a1bd2c4e670c85907f8",
            "/paper/Improved-Training-of-Wasserstein-GANs-Gulrajani-Ahmed/edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "/paper/BEGAN%3A-Boundary-Equilibrium-Generative-Adversarial-Berthelot-Schumm/aa6f7ad0a06b52a8be89dbd8d056561418276ff2",
            "/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214",
            "/paper/Improved-Techniques-for-Training-GANs-Salimans-Goodfellow/571b0750085ae3d939525e62af510ee2cee9d5ea",
            "/paper/Wasserstein-Generative-Adversarial-Networks-Arjovsky-Chintala/acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "/paper/Tractable-Generative-Convolutional-Arithmetic-Sharir-Tamari/14362128953607e7fc8226ae9c4ec3e55b7e7653",
            "/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078",
            "/paper/Progressive-Growing-of-GANs-for-Improved-Quality%2C-Karras-Aila/744fe47157477235032f7bb3777800f9f2f45e52"
        ]
    },
    {
        "id": "89c6badea0d7bf834d4c069517116dd99c4cc0fd",
        "title": "PraNet: Parallel Reverse Attention Network for Polyp Segmentation",
        "abstract": "Quantitative and qualitative evaluations on five challenging datasets across six metrics show that the PraNet improves the segmentation accuracy significantly, and presents a number of advantages in terms of generalizability, and real-time segmentation efficiency. Colonoscopy is an effective technique for detecting colorectal polyps, which are highly related to colorectal cancer. In clinical practice, segmenting polyps from colonoscopy images is of great importance since it provides valuable information for diagnosis and surgery. However, accurate polyp segmentation is a challenging task, for two major reasons: (i) the same type of polyps has a diversity of size, color and texture; and (ii) the boundary between a polyp and its surrounding mucosa is not sharp. To address these challenges, we propose a parallel reverse attention network (PraNet) for accurate polyp segmentation in colonoscopy images. Specifically, we first aggregate the features in high-level layers using a parallel partial decoder (PPD). Based on the combined feature, we then generate a global map as the initial guidance area for the following components. In addition, we mine the boundary cues using the reverse attention (RA) module, which is able to establish the relationship between areas and boundary cues. Thanks to the recurrent cooperation mechanism between areas and boundaries, our PraNet is capable of calibrating some misaligned predictions, improving the segmentation accuracy. Quantitative and qualitative evaluations on five challenging datasets across six metrics show that our PraNet improves the segmentation accuracy significantly, and presents a number of advantages in terms of generalizability, and real-time segmentation efficiency (\\(\\varvec{\\sim }\\)50 fps).",
        "publication_year": "2020",
        "authors": [
            "Deng-Ping Fan",
            "Ge-Peng Ji",
            "Tao Zhou",
            "Geng Chen",
            "H. Fu",
            "Jianbing Shen",
            "Ling Shao"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "415",
        "reference_count": "40",
        "references": [
            "/paper/DilatedSegNet%3A-A-Deep-Dilated-Segmentation-Network-Tomar-Jha/31ead3efa990a3e7f7c46ba030f9a73ad80f1b20",
            "/paper/Pixel-Level-Anomaly-Detection-via-Uncertainty-aware-Huang-Liu/4c98fa39eb8a50db4afcef15f68f150194e3c6e6",
            "/paper/Dual-Consistency-Enabled-Weakly-and-Semi-Supervised-Meng-Zhang/75467e72821fdf303ec9b0bdfd0cc0b90268ea3b",
            "/paper/Lightweight-Real-Time-Polyp-Segmentation-Network-on-Yang-Yang/2f8e18dbc5dab7fb75b0f285a3f1f824b40c6bf2",
            "/paper/Deep-Gradient-Learning-for-Efficient-Camouflaged-Ji-Fan/0a75743c3cf6fd67d53930456eb1339daf2856a0",
            "/paper/ColonFormer%3A-An-Efficient-Transformer-Based-Method-Duc-Oanh/42f1d7d46b52d06dfb07060be65889a98b03cad1",
            "/paper/An-Efficient-Polyp-Segmentation-Network-Erol-Sarikaya/495ca7d0cdce89a287fa7d1ba3a48f9a70920405",
            "/paper/UACANet%3A-Uncertainty-Augmented-Context-Attention-Kim-Lee/40445de181e1f014d71afb0612df837b87837f00",
            "/paper/Concealed-Object-Detection-Fan-Ji/5a672eab7d11eefc1d9b5e4f2c6e3f97c88af157",
            "/paper/CRF-EfficientUNet%3A-an-improved-UNet-framework-for-Hong-Thanh/63c3b61c4cfd0f80df487267ec562fc05d590a40",
            "/paper/ResUNet%2B%2B%3A-An-Advanced-Architecture-for-Medical-Jha-Smedsrud/80f4c7c360d1150ba58c3bacf5c35718ebdd0c10",
            "/paper/Selective-Feature-Aggregation-Network-with-for-Fang-Chen/8cd4364347f647f2d2165953988c8895524dd8cc",
            "/paper/Road-Extraction-by-Deep-Residual-U-Net-Zhang-Liu/f06ff5f719eb9cd939dde8fc9b199b17adcbc75f",
            "/paper/WM-DOVA-maps-for-accurate-polyp-highlighting-in-vs.-Bernal-S%C3%A1nchez/cb9b38e3b6e2a90657b8a3285986761b598b7bdc",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/A-Benchmark-for-Endoluminal-Scene-Segmentation-of-V%C3%A1zquez-Bernal/8b008beb62007504aed4234980b5481edda644b0",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Camouflaged-Object-Detection-Fan-Ji/e5fb1c378086d072104b14f4fb2df9cf1da4b08c",
            "/paper/Bilateral-Attention-Network-for-RGB-D-Salient-Zhang-Lin/219cf4ff85056281f7b71c67513713d65d61c07a",
            "/paper/Inf-Net%3A-Automatic-COVID-19-Lung-Infection-From-CT-Fan-Zhou/22f4683316a6b4144d4fe025372dc4024d334148"
        ]
    },
    {
        "id": "c67332e7c0e83f77909b77c02263f8a5409c8ecd",
        "title": "Vestibular dose correlates with dizziness after radiosurgery for the treatment of vestibular schwannoma",
        "abstract": "The results reveal that 5\u00a0Gy and above minimum vestibular doses significantly worsened dizziness in patients with VS, and mean and maximum doses received by the vestibule were significantly lower in patients who had improved caloric function. Background Stereotactic radiosurgery (SRS) has been recognized as a first-line treatment option for small to moderate sized vestibular schwannoma (VS). Our aim is to evaluate the impact of SRS doses and other patient and disease characteristics on vestibular function in patients with VS. Methods Data on VS patients treated with single-fraction SRS to 12\u00a0Gy were retrospectively reviewed. No dose constraints were given to the vestibule during optimization in treatment planning. Patient and tumor characteristics, pre- and post-SRS vestibular examination results and patient-reported dizziness were assessed from patient records. Results Fifty-three patients were analyzed. Median follow-up was 32\u00a0months (range, 6\u201379). The median minimum, mean and maximum vestibular doses were 2.6\u2009\u00b1\u20091.6\u00a0Gy, 6.7\u2009\u00b1\u20092.8\u00a0Gy, and 11\u2009\u00b1\u20093.6\u00a0Gy, respectively. On univariate analysis, Koos grade ( p \u2009=\u20090.04; OR: 3.45; 95% CI 1.01\u201311.81), tumor volume (median 6.1\u00a0cm 3 ; range, 0.8\u201338; p \u2009=\u20090.01; OR: 4.85; 95% CI 1.43\u201316.49), presence of pre-SRS dizziness ( p \u2009=\u20090.02; OR: 3.98; 95% CI 1.19\u201313.24) and minimum vestibular dose ( p \u2009=\u20090.033; OR: 1.55; 95% CI 1.03\u20132.32) showed a significant association with patient-reported dizziness. On multivariate analysis, minimum vestibular dose remained significant ( p \u2009=\u20090.02; OR: 1.75; 95% CI 1.05\u20132.89). Patients with improved caloric function had received significantly lower mean (1.5\u2009\u00b1\u20090.7\u00a0Gy, p \u2009=\u20090.01) and maximum doses (4\u2009\u00b1\u20091.5\u00a0Gy, p \u2009=\u20090.01) to the vestibule. Conclusions Our results reveal that 5\u00a0Gy and above minimum vestibular doses significantly worsened dizziness. Additionally, mean and maximum doses received by the vestibule were significantly lower in patients who had improved caloric function. Further investigations are needed to determine dose-volume parameters and their effects on vestibular toxicity.",
        "publication_year": "2020",
        "authors": [
            "E. Ermi\u015f",
            "L. Anschuetz",
            "D. Leiser",
            "R. Poel",
            "A. Raabe",
            "P. Manser",
            "D. Aebersold",
            "M. Caversaccio",
            "G. Mantokoudis",
            "J. Abu-Isa",
            "F. Wagner",
            "E. Herrmann"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "4",
        "reference_count": "36",
        "references": [
            "/paper/Outcome-after-Radiotherapy-for-Vestibular-in-Tumor-K%C3%BCchler-Shafie/e31e7fcdcd0c35c08f16fb288abebd48088e044e",
            "/paper/Vestibulocochlear-Delineation-for-Vestibular-With-Restini-Brito/70e7673d36edb3adf9a0d7cb8c2a743457b72ed2",
            "/paper/Vestibular-Impairment-in-Patients-with-Vestibular-A-Pisani-Gioacchini/0b3a393c6dce8ad95bdf599953404b6f6c6cfa4d",
            "/paper/Diagnosis-and-Management-of-Vestibular-Schwannoma%3A-Nam/e57eee20b37edded7319f9a40e0b01ec44b8be17",
            "/paper/Functional-outcome-after-gamma-knife-treatment-in-Hempel-Hempel/ca00cf4fc31f1212c20fd1ed22a0eb73d9bf5df2",
            "/paper/Non-audiofacial-morbidity-after-Gamma-Knife-surgery-Sughrue-Yang/e3afdb6dab435adf5c307f05413d3ca370782b1d",
            "/paper/Radiosurgery-for-Vestibular-Schwannomas-Huang-Tu/a4b796d95cc86d8a6e74731ce466a29213809497",
            "/paper/Irradiation-of-cochlear-structures-during-and-Massager-Nissim/baa357e1e836c4b43aaf159e9f01e03af2f3e1d2",
            "/paper/Long-term-outcomes-of-Gamma-Knife-radiosurgery-in-Murphy-Barnett/8a6e08e9dc7d72bdeb969f9370f39f17feea752a",
            "/paper/Does-radiation-dose-to-the-vestibule-predict-change-Stavas-Carlson/288220febf1ea089f369f22672cc1d74689f9397",
            "/paper/Long-term-outcome-of-stereotactic-radiosurgery-in-Combs-Thilmann/e6a19c9d824c7091992e5ce461d197f4ac239940",
            "/paper/Gamma-Knife-radiosurgery-for-vestibular-schwannoma%3A-Boari-Bailo/c1073c3efc0a0dd873e7a6006d4eaef98a5d5434",
            "/paper/Long-term-Dizziness-Handicap-in-Patients-with-Carlson-Tveiten/36d95d2f8972d640c56cacb3704136255f55da0a",
            "/paper/Radiotherapy-for-vestibular-schwannomas%3A-a-critical-Murphy-Suh/5cf17e11bd4e5a17cf03356695f0c6c1f4680849"
        ]
    },
    {
        "id": "4942ef23503b2808982aa91db4fc96678e6ce46f",
        "title": "Joint optic disc and cup segmentation based on elliptical-like morphological feature and spatial geometry constraint",
        "abstract": "Semantic Scholar extracted view of \"Joint optic disc and cup segmentation based on elliptical-like morphological feature and spatial geometry constraint\" by Aidi Zhao et al.",
        "publication_year": "2023",
        "authors": [
            "Aidi Zhao",
            "H. Su",
            "C. She",
            "Xiao-Xi Huang",
            "Hui Li",
            "Huaiyu Qiu",
            "Zhihong Jiang",
            "Gao Huang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "28",
        "references": [
            "/paper/Joint-optic-disc-and-cup-segmentation-using-feature-Guo-Li/d8239a910afd9a6400d03dba7c50414c5f2d68ca",
            "/paper/Joint-Optic-Disc-and-Cup-Segmentation-Based-on-Deep-Fu-Cheng/83e1eb609e4267251a3bcb7ec47cc0754ae5f54b",
            "/paper/Cup-Segmentation-by-Gradient-Method-for-the-of-from-Ingle-Mishra/c924e9b0041d86fa8edbe5ee49bcdd218535773f",
            "/paper/JointRCNN%3A-A-Region-Based-Convolutional-Neural-for-Jiang-Duan/928d7e118bba3518dc3d40b182481655fcad15df",
            "/paper/Fully-Convolutional-Networks-for-Monocular-Retinal-Shankaranarayana-Ram/faf3f776a74dfbe18ac51cb424e9d1cbc1f514c5",
            "/paper/Mean-curvature-and-texture-constrained-composite-Panda-Puhan/68bc07327c3346f68f7fe4a101cd5dec62cad703",
            "/paper/Disc-Aware-Ensemble-Network-for-Glaucoma-Screening-Fu-Cheng/88b91fb2834432273b915a8fb63ccf017e1bc034",
            "/paper/Optic-disc-detection-and-segmentation-using-mask-in-Zaaboub-Sandid/d5993a9863b0eb95e974b745b02c0a2086193849",
            "/paper/Optic-disc-segmentation%3A-level-set-methods-and-Almazroa-Sun/d75eda1be14c7f784255d3b861c76a69868ee12e",
            "/paper/ORIGA-light%3A-An-online-retinal-fundus-image-for-and-Zhang-Yin/47ec115fb91adcd00716467fa038b0507ad6ac41"
        ]
    },
    {
        "id": "97f287a817355ec4f3f864edb18070dd5a5379ae",
        "title": "WiTransformer: A Novel Robust Gesture Recognition Sensing Model with WiFi",
        "abstract": "This work adopted the Body-coordinate Velocity Profile, a cross-domain WiFi signal feature derived from the channel state information, to reduce the threshold of the Transformers and proposed WiTransformer, a novel tactic based on pure Transformers to realize WiFi-based human gesture recognition models with task robustness. The past decade has demonstrated the potential of human activity recognition (HAR) with WiFi signals owing to non-invasiveness and ubiquity. Previous research has largely concentrated on enhancing precision through sophisticated models. However, the complexity of recognition tasks has been largely neglected. Thus, the performance of the HAR system is markedly diminished when tasked with increasing complexities, such as a larger classification number, the confusion of similar actions, and signal distortion To address this issue, we eliminated conventional convolutional and recurrent backbones and proposed WiTransformer, a novel tactic based on pure Transformers. Nevertheless, Transformer-like models are typically suited to large-scale datasets as pretraining models, according to the experience of the Vision Transformer. Therefore, we adopted the Body-coordinate Velocity Profile, a cross-domain WiFi signal feature derived from the channel state information, to reduce the threshold of the Transformers. Based on this, we propose two modified transformer architectures, united spatiotemporal Transformer (UST) and separated spatiotemporal Transformer (SST) to realize WiFi-based human gesture recognition models with task robustness. SST intuitively extracts spatial and temporal data features using two encoders, respectively. By contrast, UST can extract the same three-dimensional features with only a one-dimensional encoder, owing to its well-designed structure. We evaluated SST and UST on four designed task datasets (TDSs) with varying task complexities. The experimental results demonstrate that UST has achieved recognition accuracy of 86.16% on the most complex task dataset TDSs-22, outperforming the other popular backbones. Simultaneously, the accuracy decreases by at most 3.18% when the task complexity increases from TDSs-6 to TDSs-22, which is 0.14\u20130.2 times that of others. However, as predicted and analyzed, SST fails because of excessive lack of inductive bias and the limited scale of the training data.",
        "publication_year": "2023",
        "authors": [
            "Mingze Yang",
            "Hai Zhu",
            "Runzhe Zhu",
            "Fei Wu",
            "Ling Yin",
            "Yunchen Yang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "69",
        "references": [
            "/paper/WiFi-Based-Cross-Domain-Gesture-Recognition-via-Zhang-Tang/e9852705307b09b6b067c91973e836a182e68503",
            "/paper/STC-NLSTMNet%3A-An-Improved-Human-Activity-Method-CSI-Islam-Jannat/b867af7a73c0a20b725085266193d6892c24e96d",
            "/paper/Two-Stream-Convolution-Augmented-Transformer-for-Li-Cui/a3196e65467b80f4755968923b382e40c02ccb51",
            "/paper/WiGRUNT%3A-WiFi-Enabled-Gesture-Recognition-Using-Gu-Zhang/a3d66f25c9fe9c890d11ad1a216d64d3668d186c",
            "/paper/Learning-Gestures-From-WiFi%3A-A-Siamese-Recurrent-Yang-Zou/a6d087332d4cadd9a90c8c4aa2c122413033cd9d",
            "/paper/Environment-Robust-WiFi-Based-Human-Activity-Using-Shi-Cheng/3d43297ed9b6ce4df677a04491b745d1886a3c60",
            "/paper/Towards-CSI-based-diversity-activity-recognition-Guo-Zhang/21242acafa3cb57e4455bd23868f5598e1a6a804",
            "/paper/Widar3.0%3A-Zero-Effort-Cross-Domain-Gesture-With-Zhang-Zheng/635b079447ee46acc813a08305988e77dfe3d1dd",
            "/paper/WiHF%3A-Gesture-and-User-Recognition-With-WiFi-Li-Liu/8985bdeeea083d3ab6fd06f16e080535021ac62e",
            "/paper/Human-Action-Recognition-From-Various-Data-A-Review-Sun-Liu/29861616ecd74b59fffde138addd7326a2a2969a"
        ]
    },
    {
        "id": "af2bb4fa5fd18aa854cf5987c421fb9a1113d901",
        "title": "A Deep Generative Adversarial Network (GAN)-enabled Abnormal Pedestrian Behavior Detection at Grade Crossings",
        "abstract": "This paper presents a video processing pipeline based on a deep learning generative adversarial network (GAN) for detecting and localizing abnormal behaviors of pedestrians at grade crossings that can handle multiple pedestrians simultaneously presenting in a video frame by running a single model. This paper presents a video processing pipeline based on a deep learning generative adversarial network (GAN) for detecting and localizing abnormal behaviors of pedestrians at grade crossings. The skeleton detection and tracking algorithm captures pedestrian motion patterns of pedestrians and generates temporally-varying trajectories of posture key points for each pedestrian. The trajectories of only normal behaviors are learned by the GAN after being decomposed into local and global motion features. During the testing stage, anomalous behaviors can be readily observed as outliers of the learned features and trained models. Our pipeline can handle multiple pedestrians simultaneously presenting in a video frame by running a single model. It requires no specific location information or (minimal) model retraining, enhancing its robustness and extendibility to different grade crossings. In addition, the entire pipeline is also developed on an edge computing platform to enable salient field deployability of the technology. The experimental results demonstrate the prominent performance of the system in field tests.",
        "publication_year": "2023",
        "authors": [
            "Ge Song",
            "Yu Qian",
            "Yi Wang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "16",
        "references": [
            "/paper/NM-GAN%3A-Noise-modulated-generative-adversarial-for-Chen-Yue/91336c65cddd8546745f67a1b860c2595904ac15",
            "/paper/Surveillance-video-anomaly-detection-via-non-local-Zhang-Feng/58a9a798525969cdeeb610a52e6f58cb67b24186",
            "/paper/SVD-GAN-for-Real-Time-Unsupervised-Video-Anomaly-Samuel-Cuzzolin/2704402a722882afa89c033d68fe054d40921143",
            "/paper/Video-Anomaly-Detection-and-Localization-via-Fully-Fan-Wen/d880d303ee0bfdbc80fc34df0978088cd15ce861",
            "/paper/Spatial-Temporal-Cascade-Autoencoder-for-Video-in-Li-Chang/a2812bce010a0548688cd344330fe39a2f4d7381",
            "/paper/Residual-spatiotemporal-autoencoder-for-video-Deepak-Chandrakala/f750730710e0fd9632f86626ad554eb430fada77",
            "/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449",
            "/paper/Learning-Regularity-in-Skeleton-Trajectories-for-in-Morais-Le/db20d81d40243d66ff90f11b5c6f058d43d3701f",
            "/paper/OCGAN%3A-One-Class-Novelty-Detection-Using-GANs-With-Perera-Nallapati/599fd051c9438011ec5b581983c89e8922b4a5e6",
            "/paper/Representation-Learning-of-Temporal-Dynamics-for-Du-Fu/de420f342b15087515d9750a6fccec1909173d96"
        ]
    },
    {
        "id": "379d69eaa96d31e8add3a37477dcd1cfd153a3f5",
        "title": "Image-Signal Correlation Network for Textile Fiber Identification",
        "abstract": "Identifying fiber compositions is an important aspect of the textile industry. In recent decades, near-infrared spectroscopy has shown its potential in the automatic detection of fiber components. However, for plant fibers such as cotton and linen, the chemical compositions are the same and thus the absorption spectra are very similar, leading to the problem of \"different materials with the same spectrum, whereas the same material with different spectrums\" and it is difficult using a single mode of NIR signals to capture the effective features to distinguish these fibers. To solve this problem, textile experts under a microscope measure the cross-sectional or longitudinal characteristics of fibers to determine fiber contents with a destructive way. In this paper, we construct the first NIR signal-microscope image textile fiber composition dataset (NIRITFC). Based on the NIRITFC dataset, we propose an image-signal correlation network (ISiC-Net) and design image-signal correlation perception and image-signal correlation attention modules, respectively, to effectively integrate the visual features (esp. local texture details of fibers) with the finer absorption spectrum information of the NIR signal to capture the deep abstract features of bimodal data for nondestructive textile fiber identification. To better learn the spectral characteristics of the fiber components, the endmember vectors of the corresponding fibers are generated by embedding encoding, and the reconstruction loss is designed to guide the model to reconstruct the NIR signals of the corresponding fiber components by a nonlinear mapping. The quantitative and qualitative results are significantly improved compared to both single and bimodal approaches, indicating the great potential of combining microscopic images and NIR signals for textile fiber composition identification.",
        "publication_year": "2022",
        "authors": [
            "Bo Peng",
            "Liren He",
            "Yining Qiu",
            "Dong Wu",
            "M. Chi"
        ],
        "related_topics": [
            "Physics"
        ],
        "citation_count": 0,
        "reference_count": "39",
        "references": [
            "/paper/A-Multi-Signal-Perception-Network-for-Textile-Peng-He/f73d5edb86895698007538887e90fff001b2a9e8",
            "/paper/CU-Net%3A-Component-Unmixing-Network-for-Textile-Feng-Liang/8d3e71da2cb665118b6f6c4b4555781d43cd4f4e",
            "/paper/Qualitative-classification-of-waste-textiles-based-Liu-Li/3b568d829ff7302d58d884be3fed277631852a7c",
            "/paper/Identification-of-cotton-and-cotton-trash-by-Fortier-Rodgers/119975262d8d72d3ff0c958885cb0903642d2bff",
            "/paper/%5BStudy-of-nondestructive-and-fast-identification-of-Yuan-Chang/8ac7a6fca09c6d399f578df7655726712d2f9865",
            "/paper/Classifying-NIR-spectra-of-textile-products-with-Langeron-Doussot/efac96205126f6e823d23f242bab2f6644b41ae8",
            "/paper/Variables-selection-for-quantitative-determination-Sun-Zhou/f77beb721aa0b1735f75f2bddae4e70d8d5d76fc",
            "/paper/Nondestructive-measurement-of-fruit-and-vegetable-A-Nicolai-Beullens/a12f654b8eb486fec50b334f42781fa744cf99a3",
            "/paper/Hyperspectral-Unmixing-via-Deep-Convolutional-Zhang-Sun/b985aa61e82ff184a744e48016e37bf07892c351",
            "/paper/Deep-Texture-Recognition-via-Exploiting-Cross-Layer-Chen-Li/44ed782fe08688e2e788223d134a23dc518b3b61",
            "/paper/MTFNet%3A-Mutual-Transformer-Fusion-Network-for-RGB-D-Wang-Jiang/92480841e572e764eecefe4c1ff5e00bdf0a9709"
        ]
    },
    {
        "id": "dbb6c098c7adf0ecd8392ac4e9b70f8b2fa3502b",
        "title": "Machine learning-based jamming detection for IEEE 802.11: Design and experimental evaluation",
        "abstract": "This paper presents a jamming detection approach for 802.11 networks that uses metrics that are accessible through standard device drivers and performs detection via machine learning and achieves remarkably high detection rates in indoor and mobile outdoor scenarios even under challenging link conditions. Jamming is a well-known reliability threat for mass-market wireless networks. With the rise of safety-critical applications this is likely to become a constraining issue in the future. Thus, the design of accurate jamming detection algorithms becomes important to react to ongoing jamming attacks. With respect to experimental work, jamming detection has been mainly studied for sensor networks. However, many safety-critical applications are also likely to run over 802.11-based networks where the proposed approaches do not carry over. In this paper we present a jamming detection approach for 802.11 networks. It uses metrics that are accessible through standard device drivers and performs detection via machine learning. While it allows for stand-alone operation, it also enables cooperative detection. We experimentally show that our approach achieves remarkably high detection rates in indoor and mobile outdoor scenarios even under challenging link conditions.",
        "publication_year": "2014",
        "authors": [
            "Oscar Pu\u00f1al",
            "Ismet Aktas",
            "Cai-Julian Schnelke",
            "Gloria Abidin",
            "Klaus Wehrle",
            "J. Gross"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "75",
        "reference_count": "24",
        "references": [
            "/paper/Machine-Learning-based-Jamming-Detection-in-IoT-Upadhyaya-Sun/300b9bd202717193939fc972cb4c729049baa680",
            "/paper/Machine-Learning-Based-RF-Jamming-Classification-in-Kasturi-Jain/21034205ed183b3f1e8329842bf4344b75a0e218",
            "/paper/Jamming-attack-detection-in-a-pair-of-RF-vehicles-Karagiannis-Argyriou/00a120be6f039d6f84bf476a6e44af6351b98498",
            "/paper/Machine-Learning-based-RF-Jamming-Detection-in-Feng-Hua/24c8390c27230564a656b2cc24c94904ce374e50",
            "/paper/Detection-and-Classification-of-Radio-Frequency-Kasturi-Jain/643822a7309a44e81e705a31b3fd9a54b222af76",
            "/paper/A-Novel-Jamming-Attacks-Detection-Approach-Based-on-Arjoune-Salahdine/7d9c09efc488f8646536558449846ca554473827",
            "/paper/Analysis-on-Deep-Learning-Based-5G-Wireless-Jamming-Tyagi/366f54591cc3257bbc1d7704c683b95d71faecc8",
            "/paper/RF-Jamming-Classification-using-Relative-Speed-in-Kosmanos-Karagiannis/aedf0baeaac098103889deaa04b54f14570e126e",
            "/paper/A-Statistical-Approach-to-Detect-Jamming-Attacks-in-Osanaiye-Alfa/9deda5b03f9a4a40a64ae838e5b1873d7f891a4e",
            "/paper/An-Efficient-EVM-Based-Jamming-Detection-in-5G-%C3%96rnek-Kartal/a3d09eca39be938e9233ec40905ea52d8a1936f8",
            "/paper/A-Measurement-Driven-Anti-Jamming-System-for-802.11-Pelechrinis-Broustis/07d47634110a159688c1e3a1a3d4fa9714f322b5",
            "/paper/JamDetect%3A-A-system-to-detect-RAA-aware-jamming-in-Xu-Bagrodia/7e687d9244440e7ad76e1acecf7a5027a73bd65f",
            "/paper/MOJO%3A-a-distributed-physical-layer-anomaly-system-Sheth-Doerr/0e2234d74c15c519505f31f72b916bebc6c39ee8",
            "/paper/Detection-of-reactive-jamming-in-DSSS-based-Giustiniano-Lenders/076382e340e4f9b150d4309f917f3a323cd59e3d",
            "/paper/Improving-Reliability-of-Jamming-Attack-Detection-Thamilarasu-Mishra/7b70856db34688fac6a7030577814b8fbd0ee4bc",
            "/paper/Using-Channel-Hopping-to-Increase-802.11-Resilience-Navda-Bohra/0987796f4320193444ad7d343cdbf337a0befc23",
            "/paper/The-feasibility-of-launching-and-detecting-jamming-Xu-Trappe/2b7a0cb7ff419faaaec2a5c228c18ea1bd269dd6",
            "/paper/In-VANETs-we-trust%3A-characterizing-RF-jamming-in-Pu%C3%B1al-Aguiar/c695be04135501cac8e084253f78a5adba2258c9",
            "/paper/Performance-of-IEEE-802.11-based-WLAN-devices-under-Harjula-Pinola/5bfde75b19ed815dd5eef4d13166e32b0abe1501",
            "/paper/Denial-of-Service-Attacks-in-Wireless-Networks%3A-The-Pelechrinis-Iliofotou/f44ed06c868f97b24a28df856646a931318f67e9"
        ]
    },
    {
        "id": "a350f701176355fcdc1eeb7c65648092aa1567f4",
        "title": "Dynamic Filters in Graph Convolutional Neural Networks",
        "abstract": "A novel method to adapt the behaviour of a GCNN to the input is presented proposing two ways to perform spatial convolution on graphs using input-based filters which are dynamically generated. Over the last few years, we have seen increasing data generated from non-Euclidean domains, which are usually represented as graphs with complex relationships, and Graph Neural Networks (GNN) have gained a high interest because of their potential in processing graph-structured data. In particular, there is a strong interest in exploring the possibilities in performing convolution on graphs using an extension of the GNN architecture, generally referred to as Graph Convolutional Neural Networks (GCNN). Convolution on graphs has been achieved mainly in two forms: spectral and spatial convolutions. Due to the higher flexibility in exploring and exploiting the graph structure of data, recently, there is an increasing interest in investigating the possibilities that the spatial approach can offer. The idea of finding a way to adapt the network behaviour to the inputs they process to maximize the total performances has aroused much interest in the neural networks literature over the years. This paper presents a novel method to adapt the behaviour of a GCNN to the input proposing two ways to perform spatial convolution on graphs using input-based filters which are dynamically generated. Our model also investigates the problem of discovering and refining relations among nodes. The experimental assessment confirms the capabilities of the proposed approach, which achieves satisfying results using simple architectures with a low number of filters. \u2217This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 1 ar X iv :2 10 5. 10 37 7v 2 [ cs .L G ] 2 6 M ay 2 02 1",
        "publication_year": "2021",
        "authors": [
            "Andrea Apicella",
            "F. Isgr\u00f2",
            "Andrea Pollastro",
            "R. Prevete"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "46",
        "references": [
            "/paper/Anisotropic-SpiralNet-for-3D-Shape-Completion-and-Kim-Roh/f085bbf8561d40f230174348f6936ed09407366d",
            "/paper/A-Comprehensive-Survey-on-Graph-Neural-Networks-Wu-Pan/81a4fd3004df0eb05d6c1cef96ad33d5407820df",
            "/paper/Learning-graph-structure-via-graph-convolutional-Zhang-Chang/2c65aeb1ddb6edcf636e4548a7dcd76aac3dc48b",
            "/paper/A-Generalization-of-Convolutional-Neural-Networks-Hechtlinger-Chakravarti/7040c149b797506426177d23d5ab52d402fa0fd7",
            "/paper/CayleyNets%3A-Graph-Convolutional-Neural-Networks-Levie-Monti/b5007972c6f5a2294f83357c73e12664dd7c85b3",
            "/paper/Convolutional-Neural-Networks-on-Graphs-with-Fast-Defferrard-Bresson/c41eb895616e453dcba1a70c9b942c5063cc656c",
            "/paper/Dynamic-Edge-Conditioned-Filters-in-Convolutional-Simonovsky-Komodakis/1a39bb2caa151d15efd6718f3a80d9f4bff95af2",
            "/paper/Deep-Convolutional-Networks-on-Graph-Structured-Henaff-Bruna/e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "/paper/The-Graph-Neural-Network-Model-Scarselli-Gori/3efd851140aa28e95221b55fcc5659eea97b172d",
            "/paper/Learning-Convolutional-Neural-Networks-for-Graphs-Niepert-Ahmed/7c6de5a9e02a779e24504619050c6118f4eac181",
            "/paper/Adaptive-Graph-Convolutional-Neural-Networks-Li-Wang/51a2bc2e8fb8ed47a085df33dd965e57335080a0"
        ]
    },
    {
        "id": "34f0909c213546ca92c0dda262e0b98ae36564e5",
        "title": "End-to-End Pipeline for Uncertainty Quantification and Remaining Useful Life Estimation: An Application on Aircraft Engines",
        "abstract": "A technique for uncertainty quantification (UQ) based on Bayesian deep learning (BDL) is proposed and it is seen that with the proposed approach, it is possible to configure models for RUL estimation that exhibit better or comparable performance to the single-objective baseline when validated on the test sets. Estimating the remaining useful life (RUL) of an asset lies at the heart of prognostics and health management (PHM) of many operations-critical industries such as aviation. Modern methods of RUL estimation adopt techniques from deep learning (DL). However, most of these contemporary techniques deliver only single-point estimates for the RUL without reporting on the confidence of the prediction. This practice usually provides overly confident predictions that can have severe consequences in operational disruptions or even safety. To address this issue, we propose a technique for uncertainty quantification (UQ) based on Bayesian deep learning (BDL). The hyperparameters of the framework are tuned using a novel bi-objective Bayesian optimization method with objectives the predictive performance and predictive uncertainty. The method also integrates the data pre-processing steps into the hyperparameter optimization (HPO) stage, models the RUL as a Weibull distribution, and returns the survival curves of the monitored assets to allow informed decision-making. We validate this method on the widely used C-MAPSS dataset against a single-objective HPO baseline that aggregates the two objectives through the harmonic mean (HM). We demonstrate the existence of trade-offs between the predictive performance and the predictive uncertainty and observe that the bi-objective HPO returns a larger number of hyperparameter configurations compared to the single-objective baseline. Furthermore, we see that with the proposed approach, it is possible to configure models for RUL estimation that exhibit better or comparable performance to the single-objective baseline when validated on the test sets.",
        "publication_year": "2022",
        "authors": [
            "M. Kefalas",
            "B. Stein",
            "Mitra Baratchi",
            "A. Apostolidis",
            "T. Baeck"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "61",
        "references": [
            "/paper/A-Benchmark-on-Uncertainty-Quantification-for-Deep-Basora-Viens/e38cd95628bc2742d62a6111357481133b401f54",
            "/paper/Uncertainty-aware-Remaining-Useful-Life-predictor-Biggio-Wieland/2adaf7988fa991fb3b113925874967ad7031fefd",
            "/paper/Utilizing-uncertainty-information-in-remaining-life-Benker-Furtner/a48d185eac50e78ad9dadab7a5e8c69c4dd13e8d",
            "/paper/Automated-Machine-Learning-for-Remaining-Useful-of-Kefalas-Baratchi/8facb409b683ca952bf389391a995e9a51955eaf",
            "/paper/A-Bayesian-deep-learning-framework-for-interval-of-Kim-Liu/7ddf5423b45aa8f68f07e83f2aa43b286aac92d4",
            "/paper/Forecasting-remaining-useful-life%3A-Interpretable-Kraus-Feuerriegel/bd6cbb96c28a3cd179a5e77ce17a46069b42fb3e",
            "/paper/Probabilistic-Remaining-Useful-Life-Prediction-on-Zhao-Wu/3c281d64543749581b44b1f194dee10d437bd48b",
            "/paper/An-Uncertainty-Informed-Framework-for-Trustworthy-Zhou-Droguett/15d398cf7dc6b1f4df880e3d255d492176002305",
            "/paper/Multiobjective-Deep-Belief-Networks-Ensemble-for-in-Zhang-Lim/f0959b291381e15ecc31502af6bad4f22cdd41f5",
            "/paper/A-probabilistic-Bayesian-recurrent-neural-network-C%C3%A1ceres-Gonzalez/1ab930fc2c0b47cb7f24a7d0c9cc69f957b26579",
            "/paper/A-Bayesian-Deep-Learning-RUL-Framework-Integrating-Li-Yang/3baa130482983f44ed511071d2fdb76332c6653e"
        ]
    },
    {
        "id": "be6a7d3f90c6a9d2575bf42745a3e27fe17884ce",
        "title": "A unified probabilistic framework of robust and efficient color consistency correction for multiple images",
        "abstract": "Semantic Scholar extracted view of \"A unified probabilistic framework of robust and efficient color consistency correction for multiple images\" by Yinxuan Li et al.",
        "publication_year": "2022",
        "authors": [
            "Yinxuan Li",
            "Hongche Yin",
            "Jian Yao",
            "Hanyun Wang",
            "Li Li"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "41",
        "references": [
            "/paper/A-Comprehensive-Study-on-Object-Detection-in-Patel/efb0e6e7f4f5f7df3ecc59be5424753f19d5bd2e",
            "/paper/Voronoi-Centerline-Based-Seamline-Network-Method-Yuan-Cai/6700a65b221be9086551db34471a84b6128b4cce",
            "/paper/A-full-level-fused-cross-task-transfer-learning-for-Cao-Huang/efc9fbbc639521763903555b38ab0b2831484e48",
            "/paper/A-Sequential-Color-Correction-Approach-for-Texture-Dal%E2%80%99Col-Coelho/49c2f3de221ed0a688731b6812540cc11d5a0300",
            "/paper/Optimizing-Local-Alignment-along-the-Seamline-for-Yin-Li/c54b974580b29857d9b2591237deac6a5c3449ea",
            "/paper/Robust-Image-to-Image-Color-Transfer-Using-Optimal-Oskarsson/53c8bc7cf08bed28493237e5004dd202077fc59f",
            "/paper/Efficient-global-color-correction-for-large-scale-Yang-Liu/9868b1a123ec1fd2724f48380c35eb7e12c3ca4b",
            "/paper/Jointly-optimizing-global-and-local-color-for-image-Li-Menghan/cc752b73595183142f4d6b839fb2af06febbd6ee",
            "/paper/Color-Matching-Images-With-Unknown-Non-Linear-Rodr%C3%ADguez-Vazquez-Corral/6b6760b21c03cff3c7617598dd07e216419984c0",
            "/paper/A-closed-form-solution-for-multi-view-color-with-Xia-Yao/84a259fcb9268c82403a76e6db897d67e84c572d",
            "/paper/A-Feature-Descriptor-Based-on-Local-Normalized-for-Zhang-Zhang/0d60264bbb41ed188f852d96441f43909c3e60ee",
            "/paper/3Dlite%3A-towards-commodity-3D-scanning-for-content-Huang-Dai/22dd9a1d3cea23d8c0dc1e4837b844f7828799c4",
            "/paper/New-Insights-Into-the-Statistical-Properties-of-Dra%C5%A1kovi%C4%87-Pascal/5beb7de7df53bd0c67969c93191e2c8b180340c4",
            "/paper/Progressive-Color-Transfer-With-Dense-Semantic-He-Liao/95069a2d3bbfb885580c2ee08b5dd00c8bfa3539",
            "/paper/Color-Consistency-Correction-Based-on-Remapping-for-Xia-Yao/591dd6573403679ba82c0d4b12d058ae74af942c"
        ]
    },
    {
        "id": "bc868ce9aa25e3ee4f6dcc8bd74f69c2e82d9753",
        "title": "Integrative single cell multiomics analysis of human retina indicates a role for hierarchical transcription factors collaboration in genetic effects on gene regulation",
        "abstract": "The results suggest that among cell types sharing a similar lineage, cell type dependent genetic effect is primarily driven by trans-factors rather than cell type specific chromatin state of cis-elements. Background Systematic characterization of how genetic variation modulates gene regulation in a cell type specific context is essential for understanding complex traits. To address this question, we profiled gene expression and chromatin state of cells from healthy retinae of 20 human donors with a single-cell multiomics approach, and performed genomic sequencing. Results We mapped single-cell eQTL (sc-eQTLs), single-cell caQTL (sc-caQTL), single-cell allelic specific chromatin accessibility (sc-ASCA) and single-cell allelic specific expression (sc-ASE) in major retinal cell types. By integrating these results, we identified and characterized regulatory elements and genetic variants effective on gene regulation in individual cell types. Most of the sc-eQTLs and sc-caQTLs identified show cell type specific effects, while the cis-elements containing the genetic variants with cell type specific effects tend to be accessible in multiple cell types. Furthermore, the transcription factors with binding sites perturbed by genetic variants tend to have higher expression in the cell types, where the variants have effect, than the cell types where the variants do not have effect. Finally, we identified the enriched cell types, candidate causal variants and genes, and cell type specific regulatory mechanism underlying GWAS loci. Conclusions Overall, genetic effects on gene regulation are highly context dependent. Our results suggest that among cell types sharing a similar lineage, cell type dependent genetic effect is primarily driven by trans-factors rather than cell type specific chromatin state of cis-elements. Our findings indicate a role for hierarchical transcription factors collaboration in cell type specific effects of genetic variants on gene regulation.",
        "publication_year": "2022",
        "authors": [
            "Jun Wang",
            "Xuesen Cheng",
            "Q. Liang",
            "Leah A. Owen",
            "Meng Wang",
            "M. DeAngelis",
            "Yumei Li",
            "Rui Chen"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": 0,
        "reference_count": "82",
        "references": [
            "/paper/Mapping-genetic-effects-on-cell-type-specific-and-Benaglio-Newsome/361316a426dd8dc61ddf8ba3c99ad04f97f6282c",
            "/paper/Single-cell-chromatin-accessibility-reveals-of-Buenrostro-Wu/90ed15803987231feddb8de2271942a9690a265e",
            "/paper/Single-cell-eQTL-analysis-of-activated-T-cell-and-Schmiedel-Gonz%C3%A1lez-Col%C3%ADn/72d125f8bdfc38b4ddfcb2e5bae13563875479ae",
            "/paper/Cell-type%E2%80%93specific-genetic-regulation-of-gene-human-Kim-Hellmuth-Aguet/4478d67332fa216c135d671b179c1c0c790e73ee",
            "/paper/A-single-cell-atlas-of-chromatin-accessibility-in-Zhang-Hocker/2ebfa42ec2bc12d79abff5c0e1538470297ab1fd",
            "/paper/Population-scale-single-cell-RNA-seq-profiling-Jerber-Seaton/04f83707f82bb195bd978c3527782dea0945b75a",
            "/paper/Single-cell-eQTL-models-reveal-dynamic-T-cell-state-Nathan-Asgari/4725e2f7bae9d904e9664d72e0e03ae7d6e37401",
            "/paper/Mapping-the-cis-regulatory-architecture-of-the-in-Cherry-Yang/47fa4802b64d23c9ee389e9bb28d38afced374b2",
            "/paper/Cellular-deconvolution-of-GTEx-tissues-powers-of-Donovan-D%E2%80%99Antonio-Chronowska/3fe4a7c4366600b4dc2396edfcb0b10a9ab8f76d",
            "/paper/Single-cell-eQTL-mapping-identifies-cell-genetic-of-Yazar-Alquicira-Hern%C3%A1ndez/7f25d98a54560bf59bcf85e294194a2fd41a256b"
        ]
    },
    {
        "id": "51fc2b5afe4aa541894a94cfc06a6cd1b007b401",
        "title": "l0 Norm Based Improved Proportionate Maximum Correntropy Criterion Algorithm for Sparse System Identification",
        "abstract": "A l0-norm based IPMCC approach is presented that significantly enhances the convergence rate of the inactive coefficients which influence the sparse system and delivers a rapid convergence and lower steady-state error in contrast to the PMCC and l1-normbased IPMCC algorithm. To overcome the effect of impulsive noise on physical systems an algorithm was developed in the past using an improved proportionate maximum correntropy criterion (IPMCC) based on an adaptive filter incorporating l1-norm. This approach yielded satisfactory results for the identification of timevarying sparse physical systems but its execution is limited because it tends to draw the active and dominant coefficients to zero irrespective of their magnitude. To overcome the limitation of the l1-norm based IPMCC algorithm, this paper presents a l0-norm based IPMCC approach that significantly enhances the convergence rate of the inactive coefficients which influence the sparse system. Simulation findings prove that the suggested technique delivers a rapid convergence and lower steady-state error in contrast to the PMCC and l1-norm based IPMCC algorithm.",
        "publication_year": "2023",
        "authors": [
            "Soumili Saha",
            "Ansuman Patnaik",
            "S. Nanda"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "23",
        "references": [
            "/paper/Robust-proportionate-adaptive-filter-based-on-for-Ma-Zheng/6b69ecc44d66b7eacd0517a9cb880b739a8214fa",
            "/paper/Improved-proportionate-type-sparse-adaptive-under-Gogineni-Mula/b9be1e218961b1f8689074e01370d909ab95d202",
            "/paper/An-improved-proportionate-NLMS-algorithm-based-on-Paleologu-Benesty/cc43ec3aa1ff784934506864229e5398ce293013",
            "/paper/%24l_%7B0%7D%24-Norm-Constraint-LMS-Algorithm-for-Sparse-Gu-Jin/3498dce1e7a0c7d01ae2270b6aed21f9af2c7f4b",
            "/paper/Robust-Maximum-Correntropy-Criterion-Subband-Filter-Zhao-Liu/9b91b478c0965b6fe435492808d05fb3a4cf9266",
            "/paper/A-Novel-Normalized-Sign-Algorithm-for-System-Under-Lu-Zhao/2e5490adc436391104623dddeb4b5e66097fa955",
            "/paper/Modified-Least-Mean-Mixed-Norm-Algorithms-For-Under-Rakesh-Kumar/0e3213403fcc8e314aa2d7bc5168460110618303",
            "/paper/Variable-Step-Size-Affine-Projection-Maximum-Filter-Zhao-Liu/d137d41697acac1a93ad9d7e9bd48e9c141b592f",
            "/paper/An-Improved-Adaptive-System-Identification-Method-a-Rosalin-Rout/0077b9f8b5c494134848e9312ac3942f76792be6",
            "/paper/Filter-proportionate-normalized-least-mean-square-a-Rosalin-Rout/e2897370f871b2f403e048ed0886eddeeb250d16"
        ]
    },
    {
        "id": "e0e25f7bc95afd3c7fa8097f8db7fb83238de243",
        "title": "Online Anomaly Detection in Surveillance Videos with Asymptotic Bounds on False Alarm Rate",
        "abstract": "Semantic Scholar extracted view of \"Online Anomaly Detection in Surveillance Videos with Asymptotic Bounds on False Alarm Rate\" by Keval Doshi et al.",
        "publication_year": "2020",
        "authors": [
            "Keval Doshi",
            "Y. Yilmaz"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "39",
        "reference_count": "51",
        "references": [
            "/paper/A-Survey-of-Deep-Learning-Solutions-for-Anomaly-in-Munyua-Wambugu/393302ba429287b6ebaba6e91b8013e0cf0141b6",
            "/paper/An-Analysis-of-Artificial-Intelligence-Techniques-A-%C5%9Eeng%C3%B6n%C3%BCl-Samet/54a9bcf3edf88bbbb24159b09cfc5957cc7ae623",
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/Towards-Interpretable-Video-Anomaly-Detection-Doshi-Y%C4%B1lmaz/fcc6ab7340575dfb6db7a13225f9bea19bd02c10",
            "/paper/An-Efficient-Approach-for-Anomaly-Detection-in-Doshi-Y%C4%B1lmaz/46ecff6db6e08b7e610e392d7a07a0582d69e5bf",
            "/paper/A-Real-Time-Deep-Learning-Approach-for-Real-World-Petrocchi-Giorgi/9afbf2617e02d6bdd93137fd4b81a4edb8a4abb9",
            "/paper/Unsupervised-video-anomaly-detection-via-flows-with-Cho-Kim/e4b4349d19124be609622b75585d158055c1a0b3",
            "/paper/Attention-based-residual-autoencoder-for-video-Le-Kim/770c840fe25e4c09405529c639f1fcf0a1b245ea",
            "/paper/Generalized-Video-Anomaly-Event-Detection%3A-Taxonomy-Liu-Yang/bb51ca71833d42fa58f9adccb2296bdf665cc158",
            "/paper/Adversarial-Machine-Learning-Attacks-Against-Video-Mumcu-Doshi/3a5cba9420e8097218acf4e6772b63e469afdaa0",
            "/paper/Any-Shot-Sequential-Anomaly-Detection-in-Videos-Doshi-Yilmaz/5472fc060d6d22ed3b055732013ac767eb522fa4",
            "/paper/Continual-Learning-for-Anomaly-Detection-in-Videos-Doshi-Yilmaz/91e46a251a17088fcfebc85b999ed4d84ed5e4f3",
            "/paper/Online-growing-neural-gas-for-anomaly-detection-in-Sun-Liu/f36f8d32252679f4221c3d2afc2407a9f56b29a7",
            "/paper/A-Discriminative-Framework-for-Anomaly-Detection-in-Giorno-Bagnell/84f7f9e121c1285e15cefbfc44bcb3322f73b6aa",
            "/paper/Real-World-Anomaly-Detection-in-Surveillance-Videos-Sultani-Chen/598fe25743f9492c5c1ba30274ea446f65426d85",
            "/paper/Abnormal-Event-Detection-at-150-FPS-in-MATLAB-Lu-Shi/869b17632ed4f19f93b3b58dcaa9f0b8e92108f3",
            "/paper/Adaptive-Sparse-Representations-for-Video-Anomaly-Mo-Monga/7534e966db99d449d75090d5c7f340b03c1de418",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Online-detection-of-unusual-events-in-videos-via-Zhao-Fei-Fei/3262e77099cefe24cff1308f204e673cac832451",
            "/paper/Remembering-history-with-convolutional-LSTM-for-Luo-Liu/792250ae660b7c25f85eeea7dcae623e4301d97c"
        ]
    },
    {
        "id": "5ef020fc4161e7b04f4df8717f80216ec0a1ea9d",
        "title": "Diagnosis and Treatment of Myogenous Temporomandibular Disorders: A Clinical Update",
        "abstract": "An overview of the current understanding on a variety of diagnostic and treatment modalities for M-TMD patients is presented, and the benefits of multidisciplinary strategies have been noted for the effective management of myogenous TMD pain. Myogenous temporomandibular disorders (M-TMDs) are the most common chronic orofacial pain, affecting the masticatory muscles and, thus, jaw movement. While a concise diagnosis is crucial to formulate a rational treatment plan, the similarities in clinical presentations that M-TMDs share with other neuromuscular disorders affecting the temporomandibular joint (TMJ) could easily confuse physicians. In addition to the basics, such as thorough history taking and meticulous clinical examinations, different imaging techniques are useful adjuncts to facilitate the diagnostic process. This review presents an overview of the current understanding on a variety of diagnostic and treatment modalities for M-TMD patients. It is essential to highlight that there is not a single treatment for all, and the benefits of multidisciplinary strategies have been noted for the effective management of myogenous TMD pain. Treatment modalities ranging from conservative to minimally invasive options are discussed in this review.",
        "publication_year": "2022",
        "authors": [
            "Natalie Hoi Ying Chan",
            "Ching Kiu Ip",
            "D. Li",
            "Y. Leung"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "5",
        "reference_count": "147",
        "references": [
            "/paper/Myogenous-Temporomandibular-Disorders%3A-Diagnostic-Li-Li/4e31395a365db2efb7d80716faa7f57fb21778c8",
            "/paper/It-Is-Time-for-a-Multidisciplinary-Rehabilitation-A-Militi-Bonanno/d684e2637694146b08128e3d8863b786bd241298",
            "/paper/The-reliability-of-using-light-therapy-compared-in-Al-Quisi-Jamil/b23ea90748102a76482fbe7f6bff803e63bfdca0",
            "/paper/Botulinum-Toxin-and-Percutaneous-Needle-for-the-of-Gonz%C3%A1lez-P%C3%A9rez-Vera-Martin/8ddc5026471a2e0bc305b743b2946ee5feed795e",
            "/paper/Efficiency-of-occlusal-splint-therapy-on-orofacial-Orzeszek-Waliszewska-Pros%C3%B3%C5%82/374a454486b97053c1fa974d5966d3db58118424",
            "/paper/Temporomandibular-disorders%3A-a-review-of-current-in-Kapos-Exposto/4372f68a84938c5425138d480c994f74c8aae99b",
            "/paper/Temporomandibular-Disorders%3A-Current-Concepts-and-Li-Leung/b2c9335b9dc9d0e6888b7f4d7cf70867b1358cb4",
            "/paper/Management-of-pain-in-patients-with-disorder-(TMD)%3A-Gil-Mart%C3%ADnez-Paris%E2%80%90Alemany/496585f00f7f4dc066dfbcef433ae3192c1c9c69",
            "/paper/The-hierarchy-of-different-treatments-for-myogenous-Al-Moraissi-Conti/48109a656fc51824ebedadc175f7bc303d674540",
            "/paper/Therapeutic-Agents-for-the-Treatment-of-Joint-and-Wu-Cai/76d0b8a7927d22a39a71b92d5914e2377e786f47",
            "/paper/Conservative-management-of-temporomandibular-A-with-Butts-Dunning/3a0c040b409c77c7cd97a8b33384d5f94259e758",
            "/paper/Pharmacotherapy-in-Temporomandibular-Disorders%3A-A-Ouanounou-Goldberg/6984ab999a5f08bc98aafc9ce177d136b8ea801a",
            "/paper/Temporomandibular-disorders.-Part-3%3A-pain-and-Clarke-Oluwajana/22deac6c5b5bcaba0d859f61d6dbf6f86ca4101a",
            "/paper/Use-of-botulinum-toxin-type-a-in-temporomandibular-Huamani-Moreira/e39e063f4e4c88cc0cf89f6a398f25f5f653fe3b",
            "/paper/Management-of-temporomandibular-disorders-in-the-Thambar-Kulkarni/0e942f1d6f80515afaa23ff0c97352067f0ed874"
        ]
    },
    {
        "id": "ac40123de90d564e110473a9ecb4f3b3f6a92daf",
        "title": "Telocytes in regenerative medicine",
        "abstract": "This review focuses on the latest progresses regarding TCs in the repair and regeneration of different tissues and organs, including heart, lung, skeletal muscle, skin, meninges and choroid plexus, eye, liver, uterus and urinary system. Telocytes (TCs) are a distinct type of interstitial cells characterized by a small cell body and extremely long and thin telopodes (Tps). The presence of TCs has been documented in many tissues and organs (go to http://www.telocytes.com). Functionally, TCs form a three\u2010dimensional (3D) interstitial network by homocellular and heterocellular communication and are involved in the maintenance of tissue homeostasis. As important interstitial cells to guide or nurse putative stem and progenitor cells in stem cell niches in a spectrum of tissues and organs, TCs contribute to tissue repair and regeneration. This review focuses on the latest progresses regarding TCs in the repair and regeneration of different tissues and organs, including heart, lung, skeletal muscle, skin, meninges and choroid plexus, eye, liver, uterus and urinary system. By targeting TCs alone or in tandem with stem cells, we might promote regeneration and prevent the evolution to irreversible tissue damage. Exploring pharmacological or non\u2010pharmacological methods to enhance the growth of TCs would be a novel therapeutic strategy besides exogenous transplantation for many diseased disorders.",
        "publication_year": "2015",
        "authors": [
            "Yihua Bei",
            "Fei Wang",
            "Chang-qing Yang",
            "Junjie Xiao"
        ],
        "related_topics": [
            "Biology",
            "Medicine"
        ],
        "citation_count": "125",
        "reference_count": "158",
        "references": [
            "/paper/Telocytes-in-cardiac-regeneration-and-repair.-Bei-Zhou/1f4a9d02cd9f8810f1045164e46553a53be958e8",
            "/paper/Telocytes%3A-An-Emerging-Component-of-Stem-Cell-Niche-Rosa-Marini/4ac60f2a8d82e1f55fa74bf5e8e2529c198fe660",
            "/paper/Telocyte-implications-in-human-pathology%3A-An-Ibba%E2%80%90Manneschi-Rosa/948cf15cc59b0003d582e6197f05b5ae491806e8",
            "/paper/The-History-of-Telocyte-Discovery-and-Wang-Jin/dad41d953bc82e5e38bca2ededd88414d526d7bd",
            "/paper/A-cellular-regulator-of-the-niche%3A-telocyte.-Babadag-%C3%87elebi-Saltik/7768e813356ac9a0e46fe020e02ecf3c676e8028",
            "/paper/Telocytes-in-skeletal%2C-cardiac-and-smooth-muscle-Marini-Rosa/38b7651bf34fd342e3979d9fd57189c3d62ba773",
            "/paper/Potential-Role-of-Telocytes-in-Differentiation-of-Soliman/d70cd0ff16272ea64074da3af6dab306fbac60f4",
            "/paper/A-Tale-of-Two-Cells%3A-Telocyte-and-Stem-Cell-Unique-Maadawi/2498b3c6fb8457270370f3a119b16400dfc9f122",
            "/paper/A-review-of-telocytes-in-cardiovascular-tissue-and-Ongidi-Abdulsalaam/c341919b50e590124f19f479a5329d209254f93f",
            "/paper/Dermal-Telocytes%3A-A-Different-Viewpoint-of-Skin-and-Manole-Gherghiceanu/f53b8a4c645cd4cbefbe2eb7342e9154b82db41b",
            "/paper/Genetic-comparison-of-mouse-lung-telocytes-with-and-Zheng-Zhang/7525f81423bfbeaedf23b9f179a7447afbbce848",
            "/paper/Telocytes-revisited-Cre%C8%9Boiu-Popescu/f559a5a09de67821d9c77b3613fdacc32d672664",
            "/paper/Identification-of-telocytes-in-skeletal-muscle-for-Popescu-Manole/73bd1e8c8e9e9bf418e798c12180326411b43b21",
            "/paper/Telocytes-transfer-extracellular-vesicles-loaded-to-Cisma%C5%9Fiu-Popescu/f7340e226780484b45de88380fe8579781140d7e",
            "/paper/Telocyte-morphologies-and-potential-roles-in-Zheng-Bai/790a7815964f4b4d9ab50dc7fd1cb2cb9fc236f5",
            "/paper/Telocytes-in-liver-regeneration%3A-possible-roles-Wang-Song/74dfb0fc01b7988a1df21343b961c59444db0df0",
            "/paper/Telocytes-and-Stem-Cells-Popescu-Nicolescu/0c17feadd55e3e0577e727a4dee4eae71c311d4b",
            "/paper/Telocytes-accompanying-cardiomyocyte-in-primary-two-Zhou-Zhang/aeb7e745eed1ffd7680f664a395e65d606a22618",
            "/paper/Telocytes-and-stem-cells-in-limbus-and-uvea-of-eye-Luesma-Gherghiceanu/1678fbf33156eacdde78cc3767d9755b90aac36e",
            "/paper/Potential-significance-of-telocytes-in-the-of-lung-Zheng-Bai/669077cd16ff48b18487ecb9a9facb63ed205e1b"
        ]
    },
    {
        "id": "3e402735aa827797d2a52de9a9d7e37071edd33e",
        "title": "Clinical Application of Artificial Intelligence for Non-melanoma Skin Cancer",
        "abstract": "For ultimate success, dermatologists must not be wary of AI as a potential replacement for their expertise, but as a new tool to complement their diagnostic acumen and extend patient care. The development and implementation of artificial intelligence is beginning to impact the care of dermatology patients. Although the clinical application of AI in dermatology to date has largely focused on melanoma, the prevalence of non-melanoma skin cancers, including basal cell and squamous cell cancers, is a critical application for this technology. The need for a timely diagnosis and treatment of skin cancers makes finding more time efficient diagnostic methods a top priority, and AI may help improve dermatologists\u2019 performance and facilitate care in the absence of dermatology expertise. Beyond diagnosis, for more severe cases, AI may help in predicting therapeutic response and replacing or reinforcing input from multidisciplinary teams. AI may also help in designing novel therapeutics. Despite this potential, enthusiasm in AI must be tempered by realistic expectations regarding performance. AI can only perform as well as the information that is used to train it, and development and implementation of new guidelines to improve transparency around training and performance of algorithms is key for promoting confidence in new systems. Special emphasis should be placed on the role of dermatologists in curating high-quality datasets that reflect a range of skin tones, diagnoses, and clinical scenarios. For ultimate success, dermatologists must not be wary of AI as a potential replacement for their expertise, but as a new tool to complement their diagnostic acumen and extend patient care.",
        "publication_year": "2023",
        "authors": [
            "Katherine Sanchez",
            "K. Kamal",
            "P. Manjaly",
            "Sophia Ly",
            "A. Mostaghimi"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": 0,
        "reference_count": "24",
        "references": [
            "/paper/Machine-Learning-and-Its-Application-in-Skin-Cancer-Das-Cockerell/4a980355c6e926b31a6c255f13f623b84792c0f8",
            "/paper/The-potential-of-using-artificial-intelligence-to-Willingham-Spencer/c1c9cc40c806014421efe7dd4637998cfef3146e",
            "/paper/Improving-Skin-cancer-Management-with-ARTificial-a-Felmingham-MacNamara/6181fb5b6a97b0c955f0f73ad916c8e79c017902",
            "/paper/Application-of-explainable-artificial-intelligence-Meena-Hasija/52a9875e9640daaf0640cdf6b59eeca310be1207",
            "/paper/Characterizing-the-Role-of-Dermatologists-in-AI-for-Zakhem-Fakhoury/d81ac9bdd9e0ad2bfa81852a5daeae50cf7e262e",
            "/paper/Explainable-artificial-intelligence%C2%A0in-skin-cancer-Hauser-Kurz/8ff1430cb39605dcc10963a087777dd885e98b1a",
            "/paper/Artificial-Intelligence-for-Skin-Cancer-Detection%3A-Takiddin-Schneider/8de503479da7bc414a907bfcd683f8a966b8177a",
            "/paper/Current-state-of-machine-learning-for-non-melanoma-Sharma-Shwe/7b83fc957f50ff836003c27024d52c52395536c7",
            "/paper/Artificial-intelligence-image-recognition-of-and-in-Aggarwal-Papay/5d3397e1d7ffa82c808e9f5f06ed68dbe54f99ed",
            "/paper/Patient-Perspectives-on-the-Use-of-Artificial-for-A-Nelson-Perez-Chada/84c97789ff901f53af68d4f7b843802c5e588940"
        ]
    },
    {
        "id": "a96a1b0c8fae6947b6882423a59336fe0f0e7d30",
        "title": "Automated neuron tracing using probability hypothesis density filtering",
        "abstract": "Results of experiments on 2D and 3D fluorescence microscopy image datasets of real neurons indicate the proposed neuron tracing method performs comparably or even better than the state of the art. Motivation: The functionality of neurons and their role in neuronal networks is tightly connected to the cell morphology. A fundamental problem in many neurobiological studies aiming to unravel this connection is the digital reconstruction of neuronal cell morphology from microscopic image data. Many methods have been developed for this, but they are far from perfect, and better methods are needed. Results: Here we present a new method for tracing neuron centerlines needed for full reconstruction. The method uses a fundamentally different approach than previous methods by considering neuron tracing as a Bayesian multi\u2010object tracking problem. The problem is solved using probability hypothesis density filtering. Results of experiments on 2D and 3D fluorescence microscopy image datasets of real neurons indicate the proposed method performs comparably or even better than the state of the art. Availability and Implementation: Software implementing the proposed neuron tracing method was written in the Java programming language as a plugin for the ImageJ platform. Source code is freely available for non\u2010commercial use at https://bitbucket.org/miroslavradojevic/phd. Contact: meijering@imagescience.org Supplementary information: Supplementary data are available at Bioinformatics online.",
        "publication_year": "2017",
        "authors": [
            "M. Radojevi\u0107",
            "E. Meijering"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "34",
        "reference_count": "66",
        "references": [
            "/paper/Neuron-reconstruction-from-fluorescence-microscopy-Radojevi%C4%87-Meijering/12e4e2819964d184081454051b4b85c3fe747f80",
            "/paper/Hidden-Markov-modeling-for-maximum-probability-Athey-Tward/753da2666ac57b11fd153bdc62ef10ff443754f9",
            "/paper/Neuron-tracing-from-light-microscopy-images%3A-deep-Liu-Wang/6050d3b64eadae2ab87eaf9030cadf5ff871c929",
            "/paper/Hidden-Markov-Modeling-for-Maximum-Likelihood-Athey-Tward/e10cf0f28cf60b3a8e43f2a78a2b71d226173192",
            "/paper/Automated-3D-Neuron-Tracing-with-Precise-Branch-and-Liu-Zhang/49dda61386b9ec5e0dbeaa5cc0122f4cb9c2bfbb",
            "/paper/PAT%E2%80%94Probabilistic-Axon-Tracking-for-Densely-Labeled-Skibbe-Reisert/d2137dd7e50febf59beb4ad6f32d914282437770",
            "/paper/TraceMontage%3A-A-method-for-merging-multiple-traces-Dizaji-Walker/4d5bfda90546e3088c1d726f6bb8a14e45f8ec45",
            "/paper/Automatic-3D-Single-Neuron-Reconstruction-with-Tang-Zhang/70f4ff56aedf755c88cb52faf4cf17069ee5dd28",
            "/paper/Weakly-Supervised-Learning-of-3D-Deep-Network-for-Huang-Chen/589e66d5a2a67892512de83ca64319521223f079",
            "/paper/Minimizing-Probability-Graph-Connectivity-Cost-for-Huang-Cao/1eb37076cf79015eed7b9330bd75679ba2385aca",
            "/paper/Segmentation-and-Tracing-of-Single-Neurons-from-3D-Basu-Condron/c8ea6615e85e0df16cc52486bfdf725cc578ff59",
            "/paper/APP2%3A-automatic-tracing-of-3D-neuron-morphology-on-Xiao-Peng/01fb4e77850f0c82167143ae98f428dd0bf29e28",
            "/paper/Neuron-tracing-in-perspective-Meijering/9c53d3569c141b2791b193e5dcc52fba8177710c",
            "/paper/Neurite-Tracing-With-Object-Process-Basu-Ooi/8dbc6e8c610c6af4fb3af1b46d0d5f091b93a4fe",
            "/paper/Three-dimensional-neuron-tracing-by-voxel-scooping-Rodriguez-Ehlenberger/a2be6165009778af6489d71d5f6d8d52ba6a7e49",
            "/paper/Active-learning-of-neuron-morphology-for-accurate-Gala-Chapeton/c374df35ea0a85328871b24895c8af8b6438c01f",
            "/paper/Automatic-3D-neuron-tracing-using-all-path-pruning-Peng-Long/dd612ad3e77153265b925821c9f8e4502b787d8d",
            "/paper/Rivulet%3A-3D-Neuron-Morphology-Tracing-with-Liu-Zhang/964f6b9d1bc925afcd307f128305831e1b34f49b",
            "/paper/Neuron-anatomy-structure-reconstruction-based-on-a-Luo-Sui/3af36f12b586be7b2d4fcbde077f1f80f5cca342",
            "/paper/Automatic-Reconstruction-of-Neural-Morphologies-Choroma%C5%84ska-Chang/2b027d3d60dc211139e9909ad945ae7cd8a323f3"
        ]
    },
    {
        "id": "4c69fdca6e8a1f10871ab9dc47f62c81ba7ead4a",
        "title": "Unified Visual Transformer Compression",
        "abstract": "This paper proposes a unified ViT compression framework that seamlessly assembles three effective techniques: pruning, layer skipping, and knowledge distillation, and formulate a budget-constrained, end-to-end optimization framework. Vision transformers (ViTs) have gained popularity recently. Even without customized image operators such as convolutions, ViTs can yield competitive performance when properly trained on massive data. However, the computational overhead of ViTs remains prohibitive, due to stacking multi-head self-attention modules and else. Compared to the vast literature and prevailing success in compressing convolutional neural networks, the study of Vision Transformer compression has also just emerged, and existing works focused on one or two aspects of compression. This paper proposes a unified ViT compression framework that seamlessly assembles three effective techniques: pruning, layer skipping, and knowledge distillation. We formulate a budget-constrained, end-to-end optimization framework, targeting jointly learning model weights, layer-wise pruning ratios/masks, and skip configurations, under a distillation loss. The optimization problem is then solved using the primal-dual algorithm. Experiments are conducted with several ViT variants, e.g. DeiT and T2T-ViT backbones on the ImageNet dataset, and our approach consistently outperforms recent competitors. For example, DeiT-Tiny can be trimmed down to 50\\% of the original FLOPs almost without losing accuracy. Codes are available online:~\\url{https://github.com/VITA-Group/UVC}.",
        "publication_year": "2022",
        "authors": [
            "Shixing Yu",
            "Tianlong Chen",
            "Jiayi Shen",
            "Huan Yuan",
            "Jianchao Tan",
            "Sen Yang",
            "Ji Liu",
            "Zhangyang Wang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "28",
        "reference_count": "78",
        "references": [
            "/paper/X-Pruner%3A-eXplainable-Pruning-for-Vision-Yu-Xiang/e60b6836b45ad0ae02a5fa663c8c31119f0c0a94",
            "/paper/COMCAT%3A-Towards-Efficient-Compression-and-of-Vision-Xiao-Yin/113793840434696080208b9dd6034944fd6efd61",
            "/paper/Voting-from-Nearest-Tasks%3A-Meta-Vote-Pruning-of-for-Zhao-Zhou/59c53a0e49743b247ad99129d92d545f7a506863",
            "/paper/Pruning-Self-attentions-into-Convolutional-Layers-He-Liu/5b5f5ece7e73317ff1d66a6a79372c66ea960a2e",
            "/paper/HeatViT%3A-Hardware-Efficient-Adaptive-Token-Pruning-Dong-Sun/ec68079f15b620a8a7ad19b3477f895e2ecf193d",
            "/paper/TinyViT%3A-Fast-Pretraining-Distillation-for-Small-Wu-Zhang/2fe71acc2c3f1e75b6149dea72838f0b594ad013",
            "/paper/Boost-Vision-Transformer-with-GPU-Friendly-Sparsity-Yu-Chen/07be590365e7fb76680be4ed67a5505763ec2d96",
            "/paper/Distilling-Token-Pruned-Pose-Transformer-for-2D-Ren/db7afc888e499edbd2946269a13073db752208b2",
            "/paper/Attention-Map-Guided-Transformer-Pruning-for-Edge-Mao-Yao/15ea393d47239a8bf672ffd59e9364f83ea59228",
            "/paper/MaskedKD%3A-Efficient-Distillation-of-Vision-with-Son-Lee/b6ffd0b74620ceff699df661a7bccc56d0e932d9",
            "/paper/Patch-Slimming-for-Efficient-Vision-Transformers-Tang-Han/33fd56e5067a1e8a9713378af3e1c1c08d5ce93b",
            "/paper/Do-Vision-Transformers-See-Like-Convolutional-Raghu-Unterthiner/39b492db00faead70bc3f4fb4b0364d94398ffdb",
            "/paper/Chasing-Sparsity-in-Vision-Transformers%3A-An-Chen-Cheng/efbe9f591090018f78b42c84613c8afda9292fdb",
            "/paper/Tokens-to-Token-ViT%3A-Training-Vision-Transformers-Yuan-Chen/dbe077f8521ecbe0a1477d6148c726d4f053d9c9",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "/paper/Pre-Trained-Image-Processing-Transformer-Chen-Wang/43cb4886a8056d5005702edbc51be327542b2124",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/Reducing-Transformer-Depth-on-Demand-with-Dropout-Fan-Grave/f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
            "/paper/Apprentice%3A-Using-Knowledge-Distillation-Techniques-Mishra-Marr/cf8c44a703350ebc5df46a861c76db9f0e49457b",
            "/paper/Attention-is-All-you-Need-Vaswani-Shazeer/204e3073870fae3d05bcbc2f6a8e263d9b72e776"
        ]
    },
    {
        "id": "364574aeb179196e1ef9155e1034ad385ddd9db2",
        "title": "Better Sign Language Translation with STMC-Transformer",
        "abstract": "The video-to-text translation of the STMC-Transformer outperforms translation of GT glosses and contradicts previous claims that GT gloss translation acts as an upper bound for SLT performance and reveals that glosses are an inefficient representation of sign language. Sign Language Translation (SLT) first uses a Sign Language Recognition (SLR) system to extract sign language glosses from videos. Then, a translation system generates spoken language translations from the sign language glosses. This paper focuses on the translation system and introduces the STMC-Transformer which improves on the current state-of-the-art by over 5 and 7 BLEU respectively on gloss-to-text and video-to-text translation of the PHOENIX-Weather 2014T dataset. On the ASLG-PC12 corpus, we report an increase of over 16 BLEU. We also demonstrate the problem in current methods that rely on gloss supervision. The video-to-text translation of our STMC-Transformer outperforms translation of GT glosses. This contradicts previous claims that GT gloss translation acts as an upper bound for SLT performance and reveals that glosses are an inefficient representation of sign language. For future SLT research, we therefore suggest an end-to-end training of the recognition and translation models, or using a different sign language annotation scheme.",
        "publication_year": "2020",
        "authors": [
            "Kayo Yin",
            "Jesse Read"
        ],
        "related_topics": [
            "Computer Science",
            "Linguistics"
        ],
        "citation_count": "66",
        "reference_count": "53",
        "references": [
            "/paper/Machine-Translation-from-Signed-to-Spoken-State-of-Coster-Shterionov/7366fe7b4e7756dd13220d29077142ff802b41b3",
            "/paper/Stochastic-Transformer-Networks-with-Linear-Units%3A-Voskou-Panousis/9e890135a6e2034518a31be9b3e69a1a34ef2706",
            "/paper/Prior-Knowledge-and-Memory-Enriched-Transformer-for-Jin-Zhao/d715a0fc2d6a9752a2e0fc647a0756ae6b5d3311",
            "/paper/Pipeline-Signed-Japanese-Translation-Focusing-on-a-Yano-Utsumi/ffa8f901372d67bd6e4b4f8c0f89f264fcdddce7",
            "/paper/Explore-More-Guidance%3A-A-Task-aware-Instruction-for-Cao-Li/9b234fd1357b552f2a5eeca1bfb5f0cbe6db595d",
            "/paper/Approaching-Sign-Language-Gloss-Translation-as-a-Zhang-Duh/78185ca44944e23c89ae165f5b83d420d5e36661",
            "/paper/Sign-Language-Translation-from-Instructional-Videos-Tarr'es-G%C3%A1llego/06c8cdd8c517e45adcbb519d77c897aaa6766282",
            "/paper/A-Simple-Multi-Modality-Transfer-Learning-Baseline-Chen-Wei/33703b1bfecb918aea4dcc2644a759f1de37c940",
            "/paper/Neural-Sign-Language-Translation-with-Yin-Tao/f67770b66c198168cd71ada5e1204879e5350ad7",
            "/paper/STFE-Net%3A-A-Spatial-Temporal-Feature-Extraction-for-Hu-Liu/1e3a1583e85df9fe27948e7d21c6d84f42e30566",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/Neural-Sign-Language-Translation-by-Learning-Orbay-Akarun/4e39e59f41a480f68c934cc38eb874a25ceb5073",
            "/paper/Translation-of-Sign-Language-Glosses-to-Text-Using-Arvanitis-Constantinopoulos/5607802968e594aecd9885813adb16c78fa5b602",
            "/paper/Neural-Sign-Language-Translation-based-on-Human-Ko-Kim/74669631d3f1fcc06d0e5e5daa7e4bfd5b6f6b59",
            "/paper/English-ASL-Gloss-Parallel-Corpus-2012%3A-ASLG-PC12-Othman-Jemni/473fffb95c3db24938a21346ecd117a8a9204404",
            "/paper/Recurrent-Continuous-Translation-Models-Kalchbrenner-Blunsom/944a1cfd79dbfb6fef460360a0765ba790f4027a",
            "/paper/Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "/paper/Improving-Continuous-Sign-Language-Recognition%3A-and-Forster-Koller/91e4220449ea1d7ed2b49c916dd89af850c69b26",
            "/paper/Effective-Approaches-to-Attention-based-Neural-Luong-Pham/93499a7c7f699b6630a86fad964536f9423bb6d0"
        ]
    },
    {
        "id": "3539708f69ec8b7e59da278dcc8fd546e819782f",
        "title": "A Survey of Missing Data Imputation Using Generative Adversarial Networks",
        "abstract": "The architecture, objective of a generator and a discriminator, training method and loss function, and what improvements have been made to each model are looked at. Recently, many deep learning models for missing data imputation have been studied. One of the most popular models is Generative Adversarial Networks (GANs), which generate plausible fake data through adversarial training. In this paper, we take a look at the architecture, objective of a generator and a discriminator, training method and loss function. After that, we can see what improvements have been made to each model. Moreover, we can easily compare several GAN-based models for missing data imputation.",
        "publication_year": "2020",
        "authors": [
            "Jaeyoon Kim",
            "Donghyun Tae",
            "J. Seok"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "15",
        "reference_count": "9",
        "references": [
            "/paper/Learning-to-Rank-with-Missing-Data-via-Generative-Deng-Han/a9d209bcfc44676a17526f1b409d6385391b6f1a",
            "/paper/Ensemble-Generative-Adversarial-Imputation-Network-Li-Dogan/6828db066a894ee61c92ab719cbbd03b8d741a5e",
            "/paper/Differentiable-and-Scalable-Generative-Adversarial-Wu-Wang/0d37a47e67b8b3aed896390b3596fbec77f620d1",
            "/paper/Extended-missing-data-imputation-via-GANs-for-Deng-Han/8db3ff84fec281f73029e8f5c02d9df00316de05",
            "/paper/A-Survey-of-Missing-Value-Imputation-for-Gene-Data-Kim-Seok/2a28c18c0343e96336bb0f864b2a02a54415db72",
            "/paper/Missing-value-estimation-of-microarray-data-using-Pati-Gupta/8fe648cb9580707e6f8da2bb2b1cebe45e2e63b9",
            "/paper/Merits-of-Bayesian-networks-in-overcoming-small-a-Ameur-Njah/4ccb4008270a772e4bc0083d79cc22d545811adc",
            "/paper/A-Review-of-Deep-Learning-Methods-for-Irregularly-Sun-Qiao/ae27afd8505feb4db0e018645a6cb3c4672e660b",
            "/paper/Attention-Based-Sequence-to-Sequence-Model-for-Time-Li-Du/92f7dcc20f0abc0d2bb8e5d694c3b884f917766d",
            "/paper/Bayesian-Network-for-Base-Station-Energy-Data-Tan-Li/2e401ca63088e9e32a9fec06de68b9df8239034f",
            "/paper/Improving-Missing-Data-Imputation-with-Deep-Models-Camino-Hammerschmidt/3cd6941ffd95d58461d8b3e9b52660a43d8d9833",
            "/paper/MisGAN%3A-Learning-from-Incomplete-Data-with-Networks-Li-Jiang/0a869336c65185f078ba473d7ca5b86a371ab929",
            "/paper/GAIN%3A-Missing-Data-Imputation-using-Generative-Nets-Yoon-Jordon/a89f0a78f86077864e108a1bd2c4e670c85907f8",
            "/paper/CollaGAN%3A-Collaborative-GAN-for-Missing-Image-Data-Lee-Kim/e8f442574299f068e2c8c685dcb6d18668e386f5",
            "/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214",
            "/paper/Generative-Image-Inpainting-with-Contextual-Yu-Lin/6b0bbf3e7df725cc3b781d2648e41782cb3d8539",
            "/paper/Globally-and-locally-consistent-image-completion-Iizuka-Simo-Serra/d21ebaab3f715dc7178966ff146711882e6a6fee",
            "/paper/Free-Form-Image-Inpainting-With-Gated-Convolution-Yu-Lin/a997f1ecd85e1467d11252741d188fac8db22722"
        ]
    },
    {
        "id": "31ead3efa990a3e7f7c46ba030f9a73ad80f1b20",
        "title": "DilatedSegNet: A Deep Dilated Segmentation Network for Polyp Segmentation",
        "abstract": "The results on the publicly available Kvasir-SEG and BKAI-IGH datasets suggest that DilatedSegNet can give real-time feedback while retaining a high \\ac{DSC}, indicating high potential for using such models in real clinical settings in the near future. Colorectal cancer (CRC) is the second leading cause of cancer-related death worldwide. Excision of polyps during colonoscopy helps reduce mortality and morbidity for CRC. Powered by deep learning, computer-aided diagnosis (CAD) systems can detect regions in the colon overlooked by physicians during colonoscopy. Lacking high accuracy and real-time speed are the essential obstacles to be overcome for successful clinical integration of such systems. While literature is focused on improving accuracy, the speed parameter is often ignored. Toward this critical need, we intend to develop a novel real-time deep learning-based architecture, DilatedSegNet, to perform polyp segmentation on the fly. DilatedSegNet is an encoder-decoder network that uses pre-trained ResNet50 as the encoder from which we extract four levels of feature maps. Each of these feature maps is passed through a dilated convolution pooling (DCP) block. The outputs from the DCP blocks are concatenated and passed through a series of four decoder blocks that predicts the segmentation mask. The proposed method achieves a real-time operation speed of 33.68 frames per second with an average dice coefficient of 0.90 and mIoU of 0.83. Additionally, we also provide heatmap along with the qualitative results that shows the explanation for the polyp location, which increases the trustworthiness of the method. The results on the publicly available Kvasir-SEG and BKAI-IGH datasets suggest that DilatedSegNet can give real-time feedback while retaining a high \\ac{DSC}, indicating high potential for using such models in real clinical settings in the near future. The GitHub link of the source code can be found here: \\url{https://github.com/nikhilroxtomar/DilatedSegNet}.",
        "publication_year": "2022",
        "authors": [
            "Nikhil Kumar Tomar",
            "Debesh Jha",
            "U. Bagci"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "22",
        "references": [
            "/paper/Selecting-the-Best-Optimizers-for-Deep-Learning-Mortazi-%C3%87i%C3%A7ek/918ca934a4d1c36caa136b5fb95755aa30245887",
            "/paper/DDANet%3A-Dual-Decoder-Attention-Network-for-Polyp-Tomar-Jha/41d96e594de2ab2d3c041227db255794debe2f11",
            "/paper/PraNet%3A-Parallel-Reverse-Attention-Network-for-Fan-Ji/89c6badea0d7bf834d4c069517116dd99c4cc0fd",
            "/paper/Automatic-Polyp-Segmentation-via-Multi-scale-Zhao-Zhang/f36ff155a741f4c404fcac9de1d47e53aa99e71b",
            "/paper/ResUNet%2B%2B%3A-An-Advanced-Architecture-for-Medical-Jha-Smedsrud/80f4c7c360d1150ba58c3bacf5c35718ebdd0c10",
            "/paper/NeoUNet%3A-Towards-accurate-colon-polyp-segmentation-Lan-An/ba4a1a82cf7fca1f28436468778f5a6b2757f1dd",
            "/paper/Real-Time-Polyp-Detection%2C-Localization-and-in-Deep-Jha-Ali/9c0032a7e3a3a7dcd6f5caa9780ffbb7ffe5a237",
            "/paper/UNet%2B%2B%3A-A-Nested-U-Net-Architecture-for-Medical-Zhou-Siddiquee/a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "/paper/CaraNet%3A-context-axial-reverse-attention-network-of-Lou-Guan/97326c0468e4e412630b4db7cea9d0f8ac4dc475",
            "/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "/paper/Kvasir-SEG%3A-A-Segmented-Polyp-Dataset-Jha-Smedsrud/349461d60b4d3d34dc97147e4b9ec2b9bd611be8"
        ]
    },
    {
        "id": "e31e7fcdcd0c35c08f16fb288abebd48088e044e",
        "title": "Outcome after Radiotherapy for Vestibular Schwannomas (VS)\u2014Differences in Tumor Control, Symptoms and Quality of Life after Radiotherapy with Photon versus Proton Therapy",
        "abstract": "SRS/HFSRT, FRT and FPT for VS show similar overall clinical and functional outcomes, and facial and trigeminal nerve affection after RT occurred as mild symptoms with highest toxicity rate in FPT patients. Simple Summary The standard of care for radiotherapy of symptomatic or progressive vestibular schwannomas (VS) is photon beam single-dose radiosurgery (applying 1 \u00d7 12 Gy) or (hypo)fractionated radiotherapy (applying 3 \u00d7 6 Gy up to 32 \u00d7 1.8 Gy). Only few centers also enable irradiation with protons. Proton therapy offers unique physical properties whereby healthy tissue around the tumor can be protected although a very high dose is applied to the target lesion. In patients with benign brain tumors such as vestibular schwannomas reduction of treatment-related side effects is very important. Few data comparing photon vs. proton beam radiotherapy for patients with VS are available. Thus, a detailed evaluation of differences in tumor control, symptoms and quality of life in patients with VS after photon beam vs. proton beam radiotherapy is needed. Abstract Background: To evaluate differences in local tumor control (LC), symptoms and quality of life (QOL) of 261 patients with VS after stereotactic radiosurgery/hypofractionated stereotactic radiotherapy (SRS/HFSRT) vs. fractionated radiotherapy (FRT) vs. fractionated proton therapy (FPT) were studied. Methods: For SRS/HFSRT (n = 149), the median fraction dose applied was 12 Gy. For FRT (n = 87) and FPT (n = 25), the median cumulative doses applied were 57.6 Gy and 54 Gy (RBE), respectively. FRT and FPT used single median doses of 1.8 Gy/Gy (RBE). Median follow-up was 38 months. We investigated dosimetry for organs at risk and analyzed toxicity and QOL by sending out a questionnaire. Results: LC was 99.5% at 12 months after RT with no statistical difference between treatment groups (p = 0.19). LC was significantly lower in NF2 patients (p = 0.004) and in patients with higher tumor extension grade (p = 0.039). The hearing preservation rate was 97% at 12 months after RT with no statistical difference between treatment groups (p = 0.31). Facial and trigeminal nerve affection after RT occurred as mild symptoms with highest toxicity rate in FPT patients. Conclusion: SRS/HFSRT, FRT and FPT for VS show similar overall clinical and functional outcomes. Cranial nerve impairment rates vary, potentially due to selection bias with larger VS in the FRT and FPT group.",
        "publication_year": "2022",
        "authors": [
            "Maike K\u00fcchler",
            "R. E. El Shafie",
            "S. Adeberg",
            "K. Herfarth",
            "L. K\u00f6nig",
            "K. Lang",
            "J. H\u00f6rner-Rieber",
            "P. Plinkert",
            "W. Wick",
            "F. Sahm",
            "S. Sprengel",
            "J. Debus",
            "D. Bernhardt"
        ],
        "related_topics": [
            "Medicine",
            "Physics"
        ],
        "citation_count": "4",
        "reference_count": "39",
        "references": [
            "/paper/Proton-Radiotherapy-for-Vestibular-Schwannomas-in-A-Douwes-Koetsier/f9fd516b24c951c78ffd98b6c51afc8a2c94173b",
            "/paper/Radiation-for-Sporadic-Vestibular-Schwannoma%3A-An-on-Woodson/21db66a912d65b66f5c9e9a2fcfd52b3aa170e72",
            "/paper/The-role-of-particle-radiotherapy-in-the-treatment-Iannalfi-Riva/038919abc3ddccf19ecfb0b70ee1e7d5d638c665",
            "/paper/Vestibulocochlear-Delineation-for-Vestibular-With-Restini-Brito/70e7673d36edb3adf9a0d7cb8c2a743457b72ed2",
            "/paper/Hearing-preservation-after-radiotherapy-for-is-to-a-Combs-Welzel/ddeb309ccc1d8d5297b58583b2d39ab23244325d",
            "/paper/Clinical-outcomes-and-toxicity-of-proton-for-a-Koetsier-Hensen/c20237f711f8b980a8d1a77ad40430fcaa313170",
            "/paper/Differences-in-clinical-results-after-LINAC-based-Combs-Welzel/5718395ce2b6a6d607091b64e65ad0b0ce9feab4",
            "/paper/Outcome-and-Toxicity-of-Proton-Therapy-for-A-Cohort-Koetsier-Hensen/a657b6d3bc46b482b7c0ea2dec886d954a6de1ee",
            "/paper/Radiotherapy-in-patients-with-vestibular-schwannoma-Wagner-Welzel/6de23b615d730dc160d2cc0426e2cc45e681424d",
            "/paper/Proton-Beam-Radiosurgery-for-Vestibular-Schwannoma%3A-Weber-Chan/1d4908ec144224b4b3340a54e20568453e92f8c9",
            "/paper/Radiotherapy-for-vestibular-schwannomas%3A-a-critical-Murphy-Suh/5cf17e11bd4e5a17cf03356695f0c6c1f4680849",
            "/paper/Vestibular-dose-correlates-with-dizziness-after-for-Ermi%C5%9F-Anschuetz/c67332e7c0e83f77909b77c02263f8a5409c8ecd",
            "/paper/Long-term-outcome-after-highly-advanced-single-dose-Combs-Engelhard/76deff0777011b15cc4588b78a522f25e4e22f7d",
            "/paper/Stereotactic-Radiosurgery-for-Vestibular-Reducing-Dupic-Urcissin/f885e7a048dcf690325773aceb0adff169042c59"
        ]
    },
    {
        "id": "c924e9b0041d86fa8edbe5ee49bcdd218535773f",
        "title": "Cup Segmentation by Gradient Method for the Assessment of Glaucoma from Retinal Image",
        "abstract": "An automatic cup region segmentation method based on gradient method is presented and results show effectiveness in segmentation of the cup in the process of glaucoma assessment. Automatic analysis of retinal images is emerging as an important tool for early detection of eye diseases. Glaucoma is one of the main causes of blindness in recent times. Deformation of Optic Disk (OD) and the Cup (inside the Optic Disk) is important parameter for glaucoma detection. The detection of OD manually by experts is a standard procedure for this. There have been efforts for OD segmentation but very few methods for the cup segmentation. Finding the cup region helps in finding the cup-to-disk (CDR) which is also an important property for identifying the disease. In this paper, we present an automatic cup region segmentation method based on gradient method. The method has been evaluated on dataset of images taken from random images from different sources. The segmentation results obtained shows consistency on handling photometric and geometric variations found across the dataset. Overall, the obtained result show effectiveness in segmentation of the cup in the process of glaucoma assessment. Keywords\u2014 Cup, glaucoma, gradient, optic disk(OD), retinal",
        "publication_year": "2013",
        "authors": [
            "R. Ingle",
            "P. Mishra"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "16",
        "reference_count": "16",
        "references": [
            "/paper/Optic-Disc-and-Cup-Segmentation-in-Fundus-Retinal-Priyadharsini-Beulah/77e46b45cd6a62f431bfe384baaf1171e00b596c",
            "/paper/Optic-Disc-Boundary-Detection-and-Cup-Segmentation-Rajaiah-Britto/c8f95d660709209f6c5e882a0952752ecdf1c7cc",
            "/paper/Optic-Disc-and-Optic-Cup-Segmentation-Methodologies-Almazroa-Burman/ae32cc948e196ab3dd9f8e01a5cd0cb128d92e72",
            "/paper/OPTIC-CUP-SEGMENTATION-USING-MANUAL-THRESHOLDING-Elseid-Elmanna/e9478bb7d9ddf0bd963b073dcb9355bcfa808a46",
            "/paper/Optic-cup-segmentation-based-on-extracting-blood-Almazroa-Alodhayb/773e5aba749ce2054222b938255944a998639ea3",
            "/paper/Optic-cup-segmentation%3A-type-II-fuzzy-thresholding-Almazroa-Alodhayb/4475dfe75c659cc64b5d6f053c4e79ac442223d4",
            "/paper/Joint-optic-disc-and-cup-segmentation-based-on-and-Zhao-Su/4942ef23503b2808982aa91db4fc96678e6ce46f",
            "/paper/Optic-Cup-Segmentation-using-U-Net-Architecture-on-Prastyo-Sumi/d5959436da53a7bde79b4a17e0b184dbd4559ccf",
            "/paper/Detection-of-glaucoma-using-Neuroretinal-Rim-Das-Nirmala/73a07c0e1691665a5b376475c4a8355eba8f05f8",
            "/paper/Detection-of-glaucoma-using-retinal-fundus-images%3A-Shabbir-Rasheed/f9a11d8186840c9be16e997f2abc9e8975164479",
            "/paper/Automated-detection-of-kinks-from-blood-vessels-for-Wong-Liu/cd41ede9f3125c6647041d1bcf57fe815d461995",
            "/paper/ARGALI%3A-an-automatic-cup-to-disc-ratio-measurement-Liu-Wong/134dbba5a7f34cd1feedc49615adc3a699fbeb62",
            "/paper/Retinal-image-analysis-for-automated-glaucoma-risk-Ny%C3%BAl/246e6977cd6efbcb8abcc9ac3505bff2bd9b0133",
            "/paper/Effects-of-Preprocessing-Eye-Fundus-Images-on-Based-Meier-Bock/0312ea54c4fc9d82ff62c5f699808273be2bf78a",
            "/paper/Classifying-Glaucoma-with-Image-Based-Features-from-Bock-Meier/051db34f73eef42c1e969d4bf852b1f61ee66986",
            "/paper/Glaucoma-risk-index%3A-%C2%A0Automated-glaucoma-detection-Bock-Meier/3cf06f1704d94e733dd5174bdfc2485ea7c7a4f2",
            "/paper/Determination-of-cup-to-disc-ratio-of-optical-nerve-Muramatsu-Nakagawa/b94d7ea64bd7f43fe59daf2ed2357374d3f2be38",
            "/paper/Optic-disk-feature-extraction-via-modified-model-Xu-Chutatape/4fa6b41e4b9b61c45c069d51b691a7c5fedeb8b4",
            "/paper/Automated-optic-nerve-analysis-for-diagnostic-in-Yu-Abidi/c821600ee830105c296cd131626c13ccaaf8d7f1",
            "/paper/Measurement-of-the-glaucomatous-cup-using-acquired-Guesalaga-Irarrazabal/499158d3bdca16a06e0a03f49a4b83e779a6dd96"
        ]
    },
    {
        "id": "e9852705307b09b6b067c91973e836a182e68503",
        "title": "WiFi-Based Cross-Domain Gesture Recognition via Modified Prototypical Networks",
        "abstract": "A WiFi-based cross-domain gesture recognition system (WiGr) which has a domain-transferable mapping to construct an embedding space where the representations of samples from the same class are clustered, and those from different classes are separated, and the key insight of WiGr is using the similarity between the query sample representation and the class prototypes in theembedding space to perform the gesture classification. Numerous deep learning studies have achieved remarkable advances in WiFi-based human gesture recognition (HGR) using channel state information (CSI). However, since the CSI patterns of the same gesture change across domains (i.e., users, environments, locations, and orientations), recognition accuracy might degrade significantly when applying the trained model to new domains. To overcome this problem, we propose a WiFi-based cross-domain gesture recognition system (WiGr) which has a domain-transferable mapping to construct an embedding space where the representations of samples from the same class are clustered, and those from different classes are separated. The key insight of WiGr is using the similarity between the query sample representation and the class prototypes in the embedding space to perform the gesture classification, which can avoid the influence of the cross-domain CSI patterns change. Meanwhile, we present a dual-path prototypical network (Dual-Path PN) which consists of a deep feature extractor and a dual-path (i.e., Path-A and Path-B substructures) recognizer. The trained feature extractor can extract the gesture-related domain-independent features from CSI, namely, the domain-transferable mapping. In addition, WiGr implements the cross-domain HGR based on only a pair of WiFi devices without retraining in the new domain. We conduct comprehensive experiments on three data sets, one is built by ourselves and the others are public data sets. The evaluation suggests that WiGr achieves 86.8%\u201392.7% in-domain recognition accuracy and 83.5%\u201393% cross-domain accuracy under the four-shot condition.",
        "publication_year": "2022",
        "authors": [
            "Xie Zhang",
            "Chengpei Tang",
            "Kang Yin",
            "Qingqian Ni"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "10",
        "reference_count": 0,
        "references": [
            "/paper/AirFi%3A-Empowering-WiFi-based-Passive-Human-Gesture-Wang-Yang/e939719b2a66bbaddd74ed139970e5a7e0b5f3cd",
            "/paper/WiTransformer%3A-A-Novel-Robust-Gesture-Recognition-Yang-Zhu/97f287a817355ec4f3f864edb18070dd5a5379ae",
            "/paper/Cross-Domain-WiFi-Sensing-with-Channel-State-A-Chen-Zhou/53955e1959b8a7d8d356c2c04ceaec8ce1194850",
            "/paper/Gesture-recognition-method-based-on-misalignment-KL-Tian-Zhuang/d1d6dfe9bfc8969bdf99b08e48603d9eacc33c20",
            "/paper/Deep-Learning-and-Its-Applications-to-WiFi-Human-A-Yang-Chen/7a9057c5e91e7fe3611b80df10f4911ba0e56b87",
            "/paper/SenseFi%3A-A-library-and-benchmark-on-WiFi-human-Yang-Chen/3aadb6c7e584e4f4a281f7d9053b8d4a369c23f8",
            "/paper/A-lightweight-attention-deep-learning-method-for-on-Song-Zhu/e378372dfbf45acbf478188a7a88ee5a2654094e",
            "/paper/Wi-LADL%3A-A-Wireless-Based-Lightweight-Attention-for-Song-Lou/ddde7dd799e478e5ebfb6463a58d223cccc02367",
            "/paper/RFCam%3A-Uncertainty-aware-Fusion-of-Camera-and-Wi-Fi-Chen-Munir/97e6ed97b31d177c5b1d4a218f1912d8378d053e",
            "/paper/Wi-Monitor%3A-Daily-Activity-Monitoring-Using-Wi-Fi-Zhou-Guo/46ac1c0dcfca48ae34d01b9017516da3ab4ac096"
        ]
    },
    {
        "id": "58a9a798525969cdeeb610a52e6f58cb67b24186",
        "title": "Surveillance video anomaly detection via non-local U-Net frame prediction",
        "abstract": "An unsupervised anomaly detection method for surveillance video based on frame prediction based on Generative Adversarial Network is implemented and has better accuracy in surveillance videos than some other state-of-the-art anomaly detection algorithms. Anomaly detection of surveillance video has become a critical concern in computer vision. It can be used for real-time monitoring and the timely generation of alarms and is widely applied in transportation systems and security systems. An unsupervised anomaly detection method for surveillance video based on frame prediction is implemented in this paper. Generative Adversarial Network (GAN) is used to generate the high-quality frame. Two generators are designed to predict the next future frame. Non-local U-Net is proposed as Generator 1 for frame prediction to predict the global information. Generator 2 obtains more related past frame features and large contour information. The predicted frame and the ground truth are compared to determine anomalies. We take spatial constraints during generative adversarial training, including gradient loss and intensity loss, and time constraints, such as optical flow loss, into account. We experimentally verify that the proposed method has better accuracy in surveillance videos than some other state-of-the-art anomaly detection algorithms.",
        "publication_year": "2022",
        "authors": [
            "Qianqian Zhang",
            "Guorui Feng",
            "Hanzhou Wu"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "10",
        "reference_count": "50",
        "references": [
            "/paper/Deep-Crowd-Anomaly-Detection-by-Fusing-and-Networks-Sharif-Jiao/c6a3c11da0e45e5a18539752d42751f2a5e63d91",
            "/paper/A-Deep-Generative-Adversarial-Network-(GAN)-enabled-Song-Qian/af2bb4fa5fd18aa854cf5987c421fb9a1113d901",
            "/paper/Future-frame-prediction-based-on-generative-network-Li-Li/32c82fa3e438521d010e7c7b95a7c01d61f2ceff",
            "/paper/Fast-anomaly-detection-in-video-surveillance-system-Kotkar-Sucharita/2e1e7e972023a9f320b5de2504a07fb6834a734f",
            "/paper/Generalized-Video-Anomaly-Event-Detection%3A-Taxonomy-Liu-Yang/bb51ca71833d42fa58f9adccb2296bdf665cc158",
            "/paper/Self-Supervised-Traffic-Advisors%3A-Distributed%2C-for-Sun-Kousik/5dff8ba275384e6091dce0d16774e9ef2b2a04b9",
            "/paper/An-intelligent-unsupervised-anomaly-detection-in-Modi-Parikh/e182aff269bcc02f6a6f94ad0b9f691a42774825",
            "/paper/Anomaly-detection-with-dual-stream-memory-network-Wang-Chen/a03aa9703dcccf927786e5b55768e648527392d7",
            "/paper/Prediction-of-Temperature-Abnormality-based-on-LSTM-Si-Kim/ff36fed36d72df96282ec12c5537b66cb24184b1",
            "/paper/Texture-classification-based-feature-processing-for-Mohamed-Alqahtani/ea487c5920ea18d23df7bedf6dff0fb7fe8d440c",
            "/paper/Enhanced-Adversarial-Learning-Based-Video-Anomaly-Yang-Fu/4bf8cb1dedf3f780af4f750ea3f03abf71425396",
            "/paper/Dual-Discriminator-Generative-Adversarial-Network-Dong-Zhang/e37daeaa20bc8cd68db07641201faf1db3b8c31d",
            "/paper/Unsupervised-Anomaly-Detection-and-Localization-on-Ganokratanaa-Aramvith/de4df9cd002f7ac04c260b657a8ba91c00ca8bfd",
            "/paper/Video-Prediction-and-Anomaly-Detection-Algorithm-On-Fan-Meng/9ce175a3837f2420878caddbd1aab0892e253ae4",
            "/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "/paper/Anomaly-Detection-in-Surveillance-Videos-Bhakat-Ramakrishnan/34a51fe1bbfbc2c347e706e139ffb2a49f9ba70a",
            "/paper/Spatio-Temporal-Unity-Networking-for-Video-Anomaly-Li-Cai/1be10a34f619e203651036d2609fc0d9780525c5",
            "/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d",
            "/paper/Deep-and-Sparse-features-For-Anomaly-Detection-and-Sabzalian-Marvi/4e6bde2c3cec5e2f5e5bfb2f227a166a2a2ce5d8",
            "/paper/A-Deep-Learning-Based-Technique-for-Anomaly-in-Singh-Pankajakshan/f7268a1948372b5dea1bfd13761373cfe8c46247"
        ]
    },
    {
        "id": "f73d5edb86895698007538887e90fff001b2a9e8",
        "title": "A Multi-Signal Perception Network for Textile Composition Identification",
        "abstract": "Semantic Scholar extracted view of \"A Multi-Signal Perception Network for Textile Composition Identification\" by Bo Peng et al.",
        "publication_year": "2023",
        "authors": [
            "Bo Peng",
            "Liren He",
            "Dong Wu",
            "M. Chi",
            "Jintao Chen"
        ],
        "related_topics": "",
        "citation_count": 0,
        "reference_count": "18",
        "references": [
            "/paper/Image-Signal-Correlation-Network-for-Textile-Fiber-Peng-He/379d69eaa96d31e8add3a37477dcd1cfd153a3f5",
            "/paper/A-Progressive-and-Multi-Prior-Guided-Network-for-Peng-Qiu/f79c45c04a3a88794d9ab2e76872ca870d01feee",
            "/paper/Non-IID-federated-learning-via-random-exchange-of-Peng-Chi/1b064b6b9999958060f762809be695b777324943",
            "/paper/Attention-Bottlenecks-for-Multimodal-Fusion-Nagrani-Yang/f1902f99c53781601061d794d957f77982753352",
            "/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "/paper/Qualitative-classification-of-waste-textiles-based-Liu-Li/3b568d829ff7302d58d884be3fed277631852a7c",
            "/paper/Deep-Auto-Encoders-With-Sequential-Learning-for-Nguyen-Nguyen/7cc24c750663d9a9d0c08857fa16d0fc9303abcc",
            "/paper/CIS-Net%3A-A-Novel-CNN-Model-for-Spatial-Image-via-Wu-Zhong/43535cbf700222b6eec8b7fdafe0a70b026b8a7d",
            "/paper/Deep-Learning-for-EEG-motor-imagery-classification-Amin-Alsulaiman/902d37e8602d8020d4d29d2c0bf1b140c130c46a",
            "/paper/CU-Net%3A-Component-Unmixing-Network-for-Textile-Feng-Liang/8d3e71da2cb665118b6f6c4b4555781d43cd4f4e"
        ]
    },
    {
        "id": "300b9bd202717193939fc972cb4c729049baa680",
        "title": "Machine Learning-based Jamming Detection in Wireless IoT Networks",
        "abstract": "This paper proposes to develop a passive, non node-centric, low-overhead network jamming detection mechanism, and proposes to use the multi-path profile information forJamming detection. Jamming is a well known threat to the wireless community which is becoming a crucial issue with the rise of security-critical applications. The design of a jamming detection mechanism is paramount to current networks to counteract smart jamming attacks, where the attacker stealthily jams the network at different time intervals to cause a significant performance degradation in wireless networks. Current detection mechanisms generally employ the nodes in the network to collect information about the network, hence incurring overhead and communication cost on the nodes. In this paper, we propose to address this issue by using machine learning algorithms to develop a passive, non node-centric, low-overhead network jamming detection mechanism. A number of dedicated nodes, referred as anchor nodes are deployed to collect the network information for jamming detection. We first consider the radio signal strength information for jamming detection and validate with simulated and real network data. With 5 anchor nodes, the proposed detection algorithms report accuracy of 98% and 89.7% respectively for simulated and real network data. We then propose to use the multi-path profile information for jamming detection. With more features, the accuracy is improved significantly over the signal strength-based detection, with 99.01% achieved with simulated data with 5 anchor nodes. Future work will include testing and enhancing the performance of multipath profile-based detection using real network data.",
        "publication_year": "2019",
        "authors": [
            "Bikalpa Upadhyaya",
            "Sumei Sun",
            "B. Sikdar"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "14",
        "reference_count": "13",
        "references": [
            "/paper/Jamming-Detection-in-IoT-Wireless-Networks%3A-An-Hussain-Abughanam/73876321f30ea5f736ecb320bd9d4724bcae5eec",
            "/paper/Real-time-Machine-Learning-Based-on-Hoeffding-Trees-Arjoune-Faruque/915d2d4580d65620b149e0688dd5dc42bdaed662",
            "/paper/JADE%3A-Data-Driven-Automated-Jammer-Detection-for-Kilinc-Marina/1f65e5679b872ef490357a3664f95218ede56935",
            "/paper/Security-Threats-and-Artificial-Intelligence-Based-Zaman-Alhazmi/40742d4f47c0ad0ceef59033d5a3b3900ab6f3a2",
            "/paper/Detection-of-Stealthy-Jamming-for-UAV-Assisted-An-Zhang-Zhang/cb26dd9b5629b6d420a5c7cb9940794bc1c1b3b6",
            "/paper/Reactive-Jamming-Detection-Based-on-Hidden-Markov-Zhang-Mao/1815b4b3850f6382d77b3bdfc628298737d91b3a",
            "/paper/eSWORD%3A-Implementation-of-Wireless-Jamming-Attacks-Robinson-Bonati/168139d218b21e233505b32d396a7db4d40e978e",
            "/paper/FOLPETTI%3A-A-Novel-Multi-Armed-Bandit-Smart-Attack-Bout-Brighente/5afdaf0a5d2beb14e3ac7964e73a5ced4c0de7e2",
            "/paper/Jamming-Detection-and-Classification-in-OFDM-Based-Li-Pawlak/2ed5fff879598474e33e875e3eb5565529498e0e",
            "/paper/A-General-Security-Approach-for-Soft-information-Ercan-Galligan/8352936716bba1f0d5f87f923dcfed134f033fa9",
            "/paper/Machine-learning-based-jamming-detection-for-IEEE-Pu%C3%B1al-Aktas/dbb6c098c7adf0ecd8392ac4e9b70f8b2fa3502b",
            "/paper/Detection-of-jamming-style-DoS-attack-in-Wireless-Manju-Kumar/12220a63d1f4d2a2c00a06f18d753755255d6038",
            "/paper/Detection-of-reactive-jamming-in-sensor-networks-Strasser-Danev/1cda3472ac6af5b8b0647a4f1f769ed17cceca85",
            "/paper/The-feasibility-of-launching-and-detecting-jamming-Xu-Trappe/2b7a0cb7ff419faaaec2a5c228c18ea1bd269dd6",
            "/paper/Deep-Learning-for-Launching-and-Mitigating-Wireless-Erpek-Sagduyu/b2ff78b76a302b005ab65ad0d404373a70f3d5ee",
            "/paper/Jamming-attacks-on-wireless-networks%3A-A-taxonomic-Vadlamani-Eksioglu/9703fbf0cfcfc063351ae20153b2757dec63e452",
            "/paper/Exploiting-Jamming-Caused-Neighbor-Changes-for-Liu-Liu/30edce3852af366d0eddfb1159da419341217813",
            "/paper/Two-Dimensional-Antijamming-Mobile-Communication-on-Xiao-Jiang/7a1086892e266f19f81fa19eeed47a0b0e2afae3",
            "/paper/Game-Theoretic-Modeling-of-Jamming-Attacks-in-Ad-Thamilarasu-Sridhar/9f8f858d9ac497af60a9d5c2afa3e6c4d6c3fdd8",
            "/paper/Anti-Jamming-Underwater-Transmission-With-Mobility-Xiao-Donghua/3b029260bbb6d7aec04609970c5853a96f0f875f"
        ]
    },
    {
        "id": "f085bbf8561d40f230174348f6936ed09407366d",
        "title": "Anisotropic SpiralNet for 3D Shape Completion and Denoising",
        "abstract": "A novel 3D mesh completion and denoising system with a deep learning framework that reconstructs a high-quality mesh structure from input mesh data with several holes and various types of noise is proposed by using a variational deep autoencoder with anisotropic filters that apply different convolutional filters to each vertex of the3D mesh. Three-dimensional mesh post-processing is an important task because low-precision hardware and a poor capture environment will inevitably lead to unordered point clouds with unwanted noise and holes that should be suitably corrected while preserving the original shapes and details. Although many 3D mesh data-processing approaches have been proposed over several decades, the resulting 3D mesh often has artifacts that must be removed and loses important original details that should otherwise be maintained. To address these issues, we propose a novel 3D mesh completion and denoising system with a deep learning framework that reconstructs a high-quality mesh structure from input mesh data with several holes and various types of noise. We build upon SpiralNet by using a variational deep autoencoder with anisotropic filters that apply different convolutional filters to each vertex of the 3D mesh. Experimental results show that the proposed method enhances the reconstruction quality and achieves better accuracy compared to previous neural network systems.",
        "publication_year": "2022",
        "authors": [
            "S. Kim",
            "Jihyun Roh",
            "Hyeonseung Im",
            "Jongmin Kim"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "42",
        "references": [
            "/paper/Deformable-Shape-Completion-with-Graph-Autoencoders-Litany-Bronstein/66bc2f209dfa9b547b0523311dd69f8aaafda971",
            "/paper/Learning-Local-Neighboring-Structure-for-Robust-3D-Gao-Zhai/153d5f337920b214389f87aa53492e93fbd7e270",
            "/paper/FeaStNet%3A-Feature-Steered-Graph-Convolutions-for-3D-Verma-Boyer/dd6f75f8a5e17e69338310d9457010560f73ef71",
            "/paper/Neural-3D-Morphable-Models%3A-Spiral-Convolutional-3D-Bouritsas-Bokhnyak/840bdc32643b434556a800ae20caf63e25d1e3af",
            "/paper/A-Simple-Approach-to-Intrinsic-Correspondence-on-3D-Lim-Dielen/b31e6f81bbe8456398e098045a19d7618815837c",
            "/paper/PointNet%3A-Deep-Learning-on-Point-Sets-for-3D-and-Qi-Su/d997beefc0922d97202789d2ac307c55c2c52fba",
            "/paper/Generating-3D-faces-using-Convolutional-Mesh-Ranjan-Bolkart/ccb7ad8ea38991798172c33aee83f4d68a45d376",
            "/paper/Deep-Learning-on-Point-Sets-for-3-D-Classification-Qi/8d62db434a5fec66c85153a8109509ff786dd29a",
            "/paper/SpiralNet%2B%2B%3A-A-Fast-and-Highly-Efficient-Mesh-Gong-Chen/5969da915e121e2e2001e119f5962a1c413e44c1",
            "/paper/Feature-preserving-mesh-denoising-via-bilateral-Lee-Wang/bae97241a21c9354f1f542cc9edb5dcdecb3011e"
        ]
    },
    {
        "id": "e38cd95628bc2742d62a6111357481133b401f54",
        "title": "A Benchmark on Uncertainty Quantification for Deep Learning Prognostics",
        "abstract": "Surprisingly, HNN can achieve strong results without the added training complexity and extra parameters of the BNN, and DE and MCD generally provide more conservative predictive uncertainty than BNN. Reliable uncertainty quantification on RUL prediction is crucial for informative decision-making in predictive maintenance. In this context, we assess some of the latest developments in the field of uncertainty quantification for prognostics deep learning. This includes the state-of-the-art variational inference algorithms for Bayesian neural networks (BNN) as well as popular alternatives such as Monte Carlo Dropout (MCD), deep ensembles (DE) and heteroscedastic neural networks (HNN). All the inference techniques share the same inception deep learning architecture as a functional model. We performed hyperparameter search to optimize the main variational and learning parameters of the algorithms. The performance of the methods is evaluated on a subset of the large NASA NCMAPSS dataset for aircraft engines. The assessment includes RUL prediction accuracy, the quality of predictive uncertainty, and the possibility to break down the total predictive uncertainty into its aleatoric and epistemic parts. The results show no method clearly outperforms the others in all the situations. Although all methods are close in terms of accuracy, we find differences in the way they estimate uncertainty. Thus, DE and MCD generally provide more conservative predictive uncertainty than BNN. Surprisingly, HNN can achieve strong results without the added training complexity and extra parameters of the BNN. For tasks like active learning where a separation of epistemic and aleatoric uncertainty is required, radial BNN and MCD seem the best options.",
        "publication_year": "2023",
        "authors": [
            "Luis Basora",
            "Arthur Viens",
            "Manuel Arias Chao",
            "X. Olive"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "77",
        "references": [
            "/paper/A-Bayesian-Deep-Learning-RUL-Framework-Integrating-Li-Yang/3baa130482983f44ed511071d2fdb76332c6653e",
            "/paper/Utilizing-uncertainty-information-in-remaining-life-Benker-Furtner/a48d185eac50e78ad9dadab7a5e8c69c4dd13e8d",
            "/paper/Bayesian-Deep-Learning-Based-Health-Prognostics-Peng-Ye/414a0e226aea2a77a2514e4c87f67853b5f642fa",
            "/paper/Controlling-the-accuracy-and-uncertainty-trade-off-Deng-Bucchianico/c5a3ca067f3e43357bc26df2bcd7b23bf417717e",
            "/paper/End-to-End-Pipeline-for-Uncertainty-Quantification-Kefalas-Stein/34f0909c213546ca92c0dda262e0b98ae36564e5",
            "/paper/A-probabilistic-Bayesian-recurrent-neural-network-C%C3%A1ceres-Gonzalez/1ab930fc2c0b47cb7f24a7d0c9cc69f957b26579",
            "/paper/Probabilistic-Remaining-Useful-Life-Prediction-on-Zhao-Wu/3c281d64543749581b44b1f194dee10d437bd48b",
            "/paper/Simple-and-Scalable-Predictive-Uncertainty-using-Lakshminarayanan-Pritzel/802168a81571dde28f5ddb94d84677bc007afa7b",
            "/paper/Bayesian-Neural-Network-Based-Method-of-Remaining-Huang-Bai/76ec122179ee55dff6fe3d4493681566d1543d7b",
            "/paper/Uncertainty-Aware-Prognosis-via-Deep-Gaussian-Biggio-Wieland/090d132ca927a9500de1563eb6cae8af85bda03e"
        ]
    },
    {
        "id": "efb0e6e7f4f5f7df3ecc59be5424753f19d5bd2e",
        "title": "A Comprehensive Study on Object Detection Techniques in Unconstrained Environments",
        "abstract": "A comprehensive study of object detection techniques in unconstrained environments, including various challenges, datasets, and state-of-the-art approaches, and a comparative analysis of the methods are presented. Object detection is a crucial task in computer vision that aims to identify and localize objects in images or videos. The recent advancements in deep learning and Convolutional Neural Networks (CNNs) have significantly improved the performance of object detection techniques. This paper presents a comprehensive study of object detection techniques in unconstrained environments, including various challenges, datasets, and state-of-the-art approaches. Additionally, we present a comparative analysis of the methods and highlight their strengths and weaknesses. Finally, we provide some future research directions to further improve object detection in unconstrained environments.",
        "publication_year": "2023",
        "authors": [
            "Hrishitva Patel"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "19",
        "references": [
            "/paper/Object-Detection-and-Classification-from-a-Video-Feroz-Sultana/6457559e182ff2eabf50f5b734cd6ba11c655b1d",
            "/paper/Object-detection-using-YOLO%3A-challenges%2C-datasets-Diwan-Anirudh/d8adfa796b1666e0332d3715c9708a0d8d85097a",
            "/paper/Object-detection-and-recognition-using-contour-edge-Rani-Ghai/12f08d59d9105b75a76da6ae62576e945d5ce487",
            "/paper/A-Page-Object-Detection-Method-Based-on-Mask-R-CNN-Xu-Shi/08e00d0468b47cbc125e3b08a7e979880a51b961",
            "/paper/LNFCOS%3A-Efficient-Object-Detection-through-Deep-on-Hwang-Lee/a4bcedee3f50a419527d8a1c7d3fc019591a2561",
            "/paper/The-Effect-of-Improving-Annotation-Quality-on-A-Ma-Ushiku/2e3da016401b06d15a64032c8c8a49485d0d8aad",
            "/paper/A-Multi-Object-Tracking-Algorithm-With-Center-Based-Cao-Li/56eb4436c6f2630c1f01fd5c047bba83ad4e7a3b",
            "/paper/Detecting-Object-Level-Scene-Changes-in-Images-with-Doi-Hamaguchi/0f4facfac57a4752ecbac34dd4256c69db2437a4",
            "/paper/From-handcrafted-to-deep-local-invariant-features-Csurka-Humenberger/b822dd68cd1a30ee1c60e912df88e8b52d4c96a5",
            "/paper/Study-of-object-detection-based-on-Faster-R-CNN-Liu-Zhao/1cd786770e7a3c7014e77a1d2469089b51542d51"
        ]
    },
    {
        "id": "361316a426dd8dc61ddf8ba3c99ad04f97f6282c",
        "title": "Mapping genetic effects on cell type-specific chromatin accessibility and annotating complex trait variants using single nucleus ATAC-seq",
        "abstract": "The utility of snATAC-seq for mapping genetic effects on accessible chromatin in specific cell types and provide a resource for annotating complex immune trait loci are highlighted. Gene regulation is highly cell type-specific and understanding the function of non-coding genetic variants associated with complex traits requires molecular phenotyping at cell type resolution. In this study we performed single nucleus ATAC-seq (snATAC-seq) and genotyping in peripheral blood mononuclear cells from 10 individuals. Clustering chromatin accessibility profiles of 66,843 total nuclei identified 14 immune cell types and sub-types. We mapped chromatin accessibility QTLs (caQTLs) in each immune cell type and sub-type which identified 6,248 total caQTLs, including those obscured from assays of bulk tissue such as with divergent effects on different cell types. For 3,379 caQTLs we further annotated putative target genes of variant activity using single cell co-accessibility, and caQTL variants were significantly correlated with the accessibility level of linked gene promoters. We fine-mapped loci associated with 16 complex immune traits and identified immune cell caQTLs at 517 candidate causal variants, including those with cell type-specific effects. At the 6q15 locus associated with type 1 diabetes, in line with previous reports, variant rs72928038 was a na\u00efve CD4+ T cell caQTL linked to BACH2 and we validated the allelic effects of this variant on regulatory activity in Jurkat T cells. These results highlight the utility of snATAC-seq for mapping genetic effects on accessible chromatin in specific cell types and provide a resource for annotating complex immune trait loci.",
        "publication_year": "2020",
        "authors": [
            "P. Benaglio",
            "Jacklyn M Newsome",
            "Jee Yun Han",
            "Joshua Chiou",
            "Anthony Aylward",
            "Sierra Corban",
            "Mei-Lin Okino",
            "Jaspreet Kaur",
            "D. Gorkin",
            "Kyle J. Gaulton"
        ],
        "related_topics": [
            "Biology"
        ],
        "citation_count": "8",
        "reference_count": "58",
        "references": [
            "/paper/Integrative-single-cell-multiomics-analysis-of-a-in-Wang-Cheng/bc868ce9aa25e3ee4f6dcc8bd74f69c2e82d9753",
            "/paper/Fine-mapping%2C-trans-ancestral%2C-and-genomic-analyses-Robertson-Inshaw/e41e3ba0695f1da1b7c897ccfd64b223b9963243",
            "/paper/Single-nucleus-chromatin-accessibility-profiling-of-Turner-Hu/161db3769b64d90e3250202b9442daa900067132",
            "/paper/Cell-specific-chromatin-landscape-of-human-coronary-Turner-Hu/9f3a69c10d8a5d7581ec2542d7d46df548a00a00",
            "/paper/scDALI%3A-Modelling-allelic-heterogeneity-of-DNA-in-Heinen-Secchia/3c86c86c06dbc1f9cbb34258b21397be66a9dbba",
            "/paper/Revisiting-genetic-artifacts-on-DNA-methylation-Jim%C3%A9nez-Kayser/a567bdf50c06f14365a8c866162b73e04bfb4ea7",
            "/paper/scDALI%3A-modeling-allelic-heterogeneity-in-single-Heinen-Secchia/ab962e6623575e2d5ce40df50854f73411bf2a94",
            "/paper/scDALI%3A-modeling-allelic-heterogeneity-in-single-Heinen-Secchia/2a61757544761da0545dbe86765bcd6abc1771f4",
            "/paper/Single-cell-RNA-sequencing-identifies-cell-and-QTLs-Wijst-Brugge/0561b397a20d09bbe3dca7c7d8785b9f25a38716",
            "/paper/Genetic-Control-of-Chromatin-States-in-Humans-Local-Grubert-Zaugg/003d69d3273ff38c80e16dd584951b6a7e22c284",
            "/paper/Cell-type%E2%80%93specific-genetic-regulation-of-gene-human-Kim-Hellmuth-Aguet/4478d67332fa216c135d671b179c1c0c790e73ee",
            "/paper/DNaseI-sensitivity-QTLs-are-a-major-determinant-of-Degner-Pai/230f57422b47cbeb95af7ce383a2aa414fa2b8e1",
            "/paper/Fine-mapping-cellular-QTLs-with-RASQUAL-and-Kumasaka-Knights/2b483c7293261972dcf76a99ea42d8af72ad14eb",
            "/paper/Single-cell-chromatin-accessibility-reveals-islet-Chiou-Zeng/b72942b0069fc35514c87123f8eb61abee7bf314",
            "/paper/Genetic-Drivers-of-Epigenetic-and-Transcriptional-Chen-Ge/bcc975b156e421a37d5e6e29c22971a2a658216f",
            "/paper/Type-2-Diabetes%E2%80%93Associated-Genetic-Variants-in-Khetan-Kursawe/243dc93778b4bbae004aed057ec0c54d97880eb2",
            "/paper/RNA-splicing-is-a-primary-link-between-genetic-and-Li-Geijn/726c847bcddca4d1be6cde804c35eb5af14999fa",
            "/paper/Genetic-mapping-of-cell-type-specificity-for-traits-Watanabe-Mirkov/ff7f38df49f3a9dde8f32fe48c05404ad0d2404c"
        ]
    },
    {
        "id": "6b69ecc44d66b7eacd0517a9cb880b739a8214fa",
        "title": "Robust proportionate adaptive filter based on maximum correntropy criterion for sparse system identification in impulsive noise environments",
        "abstract": "Simulation results in sparse system identification and echo cancellation applications are presented, which demonstrate that the proposed proportionate MCC exhibits outstanding performance under the impulsive noise environments. Proportionate-type adaptive filtering (PtAF) algorithms have been successfully applied to sparse system identification. The major drawback of the traditional PtAF algorithms based on the mean square error (MSE) criterion show poor robustness in the presence of impulsive noises or abrupt changes because MSE is only valid and rational under Gaussian assumption. However, this assumption is not satisfied in most real-world applications. To improve its robustness under non-Gaussian environments, we incorporate the maximum correntropy criterion (MCC) into the update equation of the PtAF to develop proportionate MCC (PMCC) algorithm. The mean and mean square convergence performance analysis are also performed. Simulation results in sparse system identification and echo cancellation applications are presented, which demonstrate that the proposed PMCC exhibits outstanding performance under the impulsive noise environments.",
        "publication_year": "2018",
        "authors": [
            "Wentao Ma",
            "Dongqiao Zheng",
            "Zhiyu Zhang",
            "Jiandong Duan",
            "Badong Chen"
        ],
        "related_topics": [
            "Engineering",
            "Computer Science"
        ],
        "citation_count": "29",
        "reference_count": "36",
        "references": [
            "/paper/Improved-proportionate-type-sparse-adaptive-under-Gogineni-Mula/b9be1e218961b1f8689074e01370d909ab95d202",
            "/paper/l0-Norm-Based-Improved-Proportionate-Maximum-for-Saha-Patnaik/51fc2b5afe4aa541894a94cfc06a6cd1b007b401",
            "/paper/Recursive-MCC-Algorithm-with-Proportionate-Update-Ma-Qiu/9536d501d6ed8f42e08f88559835b1c3e3bbd008",
            "/paper/Adaptive-Combination-of-Proportionate-Recursive-and-Qin-Tao/90b6aca99b596f1a16a2fba3095ce824c7304135",
            "/paper/Sparse-Aware-Bias-Compensated-Adaptive-Filtering-Ma-Zheng/82f0aa91c775c2a05e1d9383e658280e0cdd1fe0",
            "/paper/Noise-Free-Maximum-Correntropy-Criterion-Algorithm-Shi-Li/4f239d919fc77d038873d2d7d18dae27b6b5d0ff",
            "/paper/An-Adaptive-Channel-Estimation-Based-on-Fixed-Point-Yue-Qu/eefdb7f68326ce6ad182c6d455b9fe36c4e6dda6",
            "/paper/Recursive-Constrained-Maximum-Correntropy-Criterion-Qian-Ning/fc8b3068f537f402065c738d741d1f903303724f",
            "/paper/A-Proportionate-Normalized-Maximum-Correntropy-with-Li-Wang/543ddfb15f41f24e6f48837f992800af615e0ac9",
            "/paper/Bias-compensated-normalized-least-mean-fourth-with-Wentao-Jinzhe/7a6771fce7b0b926bb4d7f462411139fcbb9615c",
            "/paper/Maximum-correntropy-criterion-based-sparse-adaptive-Ma-Qu/329a79805ec179708da630ee3e6948362885a41c",
            "/paper/Proportionate-Minimum-Error-Entropy-Algorithm-for-Wu-Peng/efd7081faa234f50491837ebfe847bcd8dd494db",
            "/paper/Diffusion-maximum-correntropy-criterion-algorithms-Ma-Chen/0721fcba6ed52ada464bfb1f513711aef334dde8",
            "/paper/A-normalized-robust-mixed-norm-adaptive-algorithm-Papoulis-Stathaki/bb8d48bb370e3443f9dee01ee7423db66e86601b",
            "/paper/Robust-adaptive-filtering-algorithms-for-spl-alpha-Aydin-Arikan/f72677cbfa9d206e89fac02b795ab0e41fad7904",
            "/paper/Robust-Adaptive-Filtering-Algorithms-for-Stable-Aydin-Arikan/3734d2d5471b642cb4046e8ac005d39d6985d227",
            "/paper/Enhancing-the-tracking-capability-of-recursive-via-Zhang-Zhang/4c75d8dfdecbbb0b9f25a9861058d48bfe77896a",
            "/paper/%24l_%7B0%7D%24-Norm-Constraint-LMS-Algorithm-for-Sparse-Gu-Jin/3498dce1e7a0c7d01ae2270b6aed21f9af2c7f4b",
            "/paper/Steady-State-Mean-Square-Error-Analysis-for-under-Chen-Xing/6b84f7867979d00611dcc6351d15ad75ff68b8d0",
            "/paper/Proportionate-adaptive-algorithms-for-network-echo-Deng-Doroslova%C4%8Dki/dfdea532ac8a5c4ee364f14199643709969b20c3"
        ]
    },
    {
        "id": "393302ba429287b6ebaba6e91b8013e0cf0141b6",
        "title": "A Survey of Deep Learning Solutions for Anomaly Detection in Surveillance Videos",
        "abstract": "This review attempts to provide holistic benchmarking of the published deep learning solutions for videos anomaly detection since 2016 by identifying, the learning technique, datasets used and the overall model accuracy. Deep learning has proven to be a landmark computing approach to the computer vision domain. Hence, it has been widely applied to solve complex cognitive tasks like the detection of anomalies in surveillance videos. Anomaly detection in this case is the identification of abnormal events in the surveillance videos which can be deemed as security incidents or threats. Deep learning solutions for anomaly detection has outperformed other traditional machine learning solutions. This review attempts to provide holistic benchmarking of the published deep learning solutions for videos anomaly detection since 2016. The paper identifies, the learning technique, datasets used and the overall model accuracy. Reviewed papers were organised into five deep learning methods namely; autoencoders, continual learning, transfer learning, reinforcement learning and ensemble learning. Current and emerging trends are discussed as well.",
        "publication_year": "2021",
        "authors": [
            "John Gatara Munyua",
            "G. Wambugu",
            "Stephen Thiiru Njenga"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "4",
        "reference_count": "59",
        "references": [
            "/paper/An-Analysis-of-Artificial-Intelligence-Techniques-A-%C5%9Eeng%C3%B6n%C3%BCl-Samet/54a9bcf3edf88bbbb24159b09cfc5957cc7ae623",
            "/paper/A-Survey-on-Video-Anomaly-Detection-Yadav-Kumar/5c3744df2175166aa5070ea17cff045075000246",
            "/paper/Inflated-3D-Convolution-Network-for-Detecting-in-Yadav-Kumar/5556fe60cec7fad2fa2a7e500d09f2d0e4be6394",
            "/paper/An-intelligent-unsupervised-anomaly-detection-in-Modi-Parikh/e182aff269bcc02f6a6f94ad0b9f691a42774825",
            "/paper/Leveraging-Deep-Learning-for-Anomaly-Detection-in-Kavikuil-Amudha/3d138ca6e72f2983d7186634550919e83958714d",
            "/paper/Continual-Learning-for-Anomaly-Detection-in-Videos-Doshi-Yilmaz/91e46a251a17088fcfebc85b999ed4d84ed5e4f3",
            "/paper/Improved-anomaly-detection-in-surveillance-videos-a-Khaleghi-Moin/1a5c917ec7763c2ff9619e6f19d02d2f254d236a",
            "/paper/Unsupervised-deep-learning-system-for-local-anomaly-Ramchandran-Sangaiah/f917e526b7b0a0ab318344f39435fc68adeeff54",
            "/paper/Application-of-Deep-Learning-for-Crowd-Anomaly-from-Pawar-Attar/659af4508e03e2f38978a7fb1692f9e37414c5ae",
            "/paper/Deep-Reinforcement-Learning-for-Real-world-Anomaly-Aberkane-Elarbi/7061fd3afa86d4a0f4ef23b95c0503d3271d34af",
            "/paper/Any-Shot-Sequential-Anomaly-Detection-in-Videos-Doshi-Yilmaz/5472fc060d6d22ed3b055732013ac767eb522fa4",
            "/paper/Ensemble-Learning-Using-Bagging-And-Inception-V3-In-Zahid-Tahir/f2db30ce2596e36a97111247e58937f9feb610f5",
            "/paper/Exploring-Background-bias-for-Anomaly-Detection-in-Liu-Ma/e1e5fbf1440850bdea40aeee99956cb6e01e2e22",
            "/paper/Deep-anomaly-detection-through-visual-attention-in-Nasaruddin-Muchtar/a9542b88c6c792e9f0bc3cad671d88a53b81aa8b"
        ]
    },
    {
        "id": "4e31395a365db2efb7d80716faa7f57fb21778c8",
        "title": "Myogenous Temporomandibular Disorders: Diagnostic Concepts and Prospective Pilot Study on Extracorporeal Shockwave Therapy",
        "abstract": "Although significant differences were not seen between groups, this prospective pilot study provided preliminary evidence that ESWT is safe and potentially beneficial in the treatment of M-TMD. The aims of this article are to discuss the current, and potential future directions, in the diagnosis of myogenous temporomandibular disorders (M-TMD), as well as to report a pilot study to investigate the feasibility and clinical outcomes of extracorporeal shockwave therapy (ESWT) in the treatment of M-TMD. Forty-one adult patients presented with M-TMD were recruited into the study and randomized into two groups: Group 1 received ESWT treatment, whereas Group 2 received placebo treatment. The variables investigated were pain, measured by a numerical rating scale (NRS) and mouth opening. Twenty-six patients (Group 1: n = 14, mean age = 45.3 (16.7) years; Group 2: n = 12, mean age = 46.8 (19.7) years) completed 1-year follow up and were included into the final analysis. In both groups, reduction in pain and increase in MO (unassisted maximum, assisted maximum, and pain-free) were seen at post-treatment 1 year. There were more reduction in pain and increase in all MO in Group 1 than Group 2, but statistical significance was not detected. No major complications were encountered in this study. Although significant differences were not seen between groups, this prospective pilot study provided preliminary evidence that ESWT is safe and potentially beneficial in the treatment of M-TMD.",
        "publication_year": "2022",
        "authors": [
            "D. Li",
            "K. Li",
            "Y. Leung"
        ],
        "related_topics": [
            "Medicine",
            "Psychology"
        ],
        "citation_count": 0,
        "reference_count": "50",
        "references": [
            "/paper/Treatment-of-Temporomandibular-Joint-Disorders-by-A-Li-Wu/7cd686bd8e51b86e163d738d7ee1568c8ffc1fdc",
            "/paper/Diagnosis-and-Treatment-of-Myogenous-Disorders%3A-A-Chan-Ip/5ef020fc4161e7b04f4df8717f80216ec0a1ea9d",
            "/paper/The-hierarchy-of-different-treatments-for-myogenous-Al-Moraissi-Conti/48109a656fc51824ebedadc175f7bc303d674540",
            "/paper/%5BMuscular-physiotherapy-in-patients-with-disorders.-Michelotti-Parisini/605ac60364dbf64fa584c997e664d4de4932b540",
            "/paper/Diagnosis-and-treatment-of-temporomandibular-Gauer-Semidey/0c6977c45884ec3e152d278202de5cc9c36292c6",
            "/paper/Botulinum-Toxin-for-Treating-Temporomandibular-What-Delcanho-Val/6db852ca97b91f01d3e9d720be026e3f3103eb01",
            "/paper/Extracorporeal-shock-wave-therapy-is-effective-in-Sun-Gao/51c3214dfcb13382534c32531b59c3685ec6ed45",
            "/paper/Acupuncture-therapy-in-the-management-of-the-for-Wu-Zhang/b8c10d82992021e03c985e5dbe4efa9f99472a83",
            "/paper/Low-level-laser-therapy-in-the-treatment-of-(TMD)%3A-Conti/b1e77efcc61c200149d6d4c43f70757c74cc2bcb",
            "/paper/Temporomandibular-Disorders%3A-Current-Concepts-and-Li-Leung/b2c9335b9dc9d0e6888b7f4d7cf70867b1358cb4"
        ]
    },
    {
        "id": "1f4a9d02cd9f8810f1045164e46553a53be958e8",
        "title": "Telocytes in cardiac regeneration and repair.",
        "abstract": "Semantic Scholar extracted view of \"Telocytes in cardiac regeneration and repair.\" by Yihua Bei et al.",
        "publication_year": "2016",
        "authors": [
            "Yihua Bei",
            "Qiulian Zhou",
            "Qi Sun",
            "Junjie Xiao"
        ],
        "related_topics": [
            "Biology",
            "Medicine"
        ],
        "citation_count": "34",
        "reference_count": "129",
        "references": [
            "/paper/Telocytes-in-skeletal%2C-cardiac-and-smooth-muscle-Marini-Rosa/38b7651bf34fd342e3979d9fd57189c3d62ba773",
            "/paper/Cardiac-Telocyte-Derived-Exosomes-and-Their-in-Marini-Ibba%E2%80%90Manneschi/58173beb19d18638375bb367bd7bacdfbe068c6f",
            "/paper/A-comprehensive-guide-to-telocytes-and-their-great-Kucyba%C5%82a-Janas/6d8f862a86f90fc1f8eb0603ec6f98ab37d5a425",
            "/paper/Telocytes-in-Fibrosis-Diseases%3A-From-Current-to-Wei-Chen/a63a1a6219106269bb91b6c6e5c82e34cd16b4c7",
            "/paper/Roles-and-distribution-of-telocytes-in-tissue-in-Condrat-Barbu/5fd543170a4545bcacdcd34ccfc81ddc2c06c0ad",
            "/paper/Dynamic-Involvement-of-Telocytes-in-Modulating-in-Cucu-Nicolescu/153f8e0b45d56a125064b3e055fc9828b3bd2f4c",
            "/paper/Telocytes%3A-New-Connecting-Devices-in-the-Stromal-of-Cre%C8%9Boiu-Vannucchi/0817ee2c0e2feeb034726580b35804a8a285ec31",
            "/paper/Ultrastructure-of-telocytes%2C-a-new-type-of-cells-in-Ge-Ye/08f11349594797b7339278de0c9a8130d4320d2d",
            "/paper/The-Non-cardiomyocyte-Cells-of-the-Heart.-Their-in-Varga-Kyselovi%C4%8D/7cdfba42d080acec80e4d058facb0621723b9a5a",
            "/paper/Cardiac-Telocytes-16-Years-on%E2%80%94What-Have-We-Learned-Klein-Cs%C3%B6b%C3%B6nyeiov%C3%A1/6135c582439438e1b43f04ac784bbee69a0a037d",
            "/paper/Telocytes-in-regenerative-medicine-Bei-Wang/ac40123de90d564e110473a9ecb4f3b3f6a92daf",
            "/paper/Identification-of-telocytes-in-skeletal-muscle-for-Popescu-Manole/73bd1e8c8e9e9bf418e798c12180326411b43b21",
            "/paper/Cardiac-Telocytes-and-Fibroblasts-in-Primary-and-Bei-Zhou/41f2b4efd222e50abf3af4bf13a92c962556faac",
            "/paper/Telocytes-in-liver-regeneration%3A-possible-roles-Wang-Song/74dfb0fc01b7988a1df21343b961c59444db0df0",
            "/paper/Heterocellular-communication-in-the-heart%3A-electron-Gherghiceanu-Popescu/72cdae9adc9e4af060e899877c3deed57a51e991",
            "/paper/Telocytes-accompanying-cardiomyocyte-in-primary-two-Zhou-Zhang/aeb7e745eed1ffd7680f664a395e65d606a22618",
            "/paper/The-secretome-of-myocardial-telocytes-modulates-the-Albulescu-Tanase/649023407a61c212071504be3db57410803c2ef4",
            "/paper/Multiple-immunophenotypes-of-cardiac-telocytes.-Chang-Li/93862ecaa611d6be395d182bfa1020aab7b17f2c",
            "/paper/Telocytes-transfer-extracellular-vesicles-loaded-to-Cisma%C5%9Fiu-Popescu/f7340e226780484b45de88380fe8579781140d7e",
            "/paper/Telocytes-revisited-Cre%C8%9Boiu-Popescu/f559a5a09de67821d9c77b3613fdacc32d672664"
        ]
    },
    {
        "id": "c1c9cc40c806014421efe7dd4637998cfef3146e",
        "title": "The potential of using artificial intelligence to improve skin cancer diagnoses in Hawai'i's multiethnic population.",
        "abstract": "The combined results of the artificial intelligence with those of the dermatologists support the use of artificial intelligence as an efficient lesion assessment strategy to reduce time and expense in diagnoses to reduce delays in treatment. Skin cancer remains the most commonly diagnosed cancer in the USA with more than 1 million new cases each year. Melanomas account for about 1% of all skin cancers and most skin cancer deaths. Multiethnic individuals whose skin is pigmented underestimate their risk for skin cancers and melanomas and may delay seeking a diagnosis. The use of artificial intelligence may help improve the diagnostic precision of dermatologists/physicians to identify malignant lesions. To validate our artificial intelligence's efficiency in distinguishing between images, we utilized 50 images obtained from our International Skin Imaging Collaboration dataset (n\u2009=\u200925) and pathologically confirmed lesions (n\u2009=\u200925). We compared the ability of our artificial intelligence to visually diagnose these 50 skin cancer lesions with a panel of three dermatologists. The artificial intelligence model better differentiated between melanoma vs. nonmelanoma with an area under the curve of 0.948. The three-panel member dermatologists correctly diagnosed a similar number of images (n\u2009=\u200935) as the artificial intelligence program (n\u2009=\u200934). Fleiss' kappa (\u0138) score for the raters and artificial intelligence indicated fair (0.247) agreement. However, the combined result of the dermatologists panel with the artificial intelligence assessments correctly identified 100% of the images from the test data set. Our artificial intelligence platform was able to utilize visual images to discriminate melanoma from nonmelanoma, using de-identified images. The combined results of the artificial intelligence with those of the dermatologists support the use of artificial intelligence as an efficient lesion assessment strategy to reduce time and expense in diagnoses to reduce delays in treatment.",
        "publication_year": "2021",
        "authors": [
            "M. Willingham",
            "Shane Y P K Spencer",
            "Christopher Lum",
            "Janira M Navarro Sanchez",
            "Terrilea Burnett",
            "J. Shepherd",
            "Kevin D. Cassel"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "2",
        "reference_count": 0,
        "references": [
            "/paper/Clinical-Application-of-Artificial-Intelligence-for-Sanchez-Kamal/3e402735aa827797d2a52de9a9d7e37071edd33e",
            "/paper/Mapping-intellectual-structures-and-research-in-the-Lyu-Wang/ff2ea93072488f2b0e93446e894d226bb6ceabd3"
        ]
    },
    {
        "id": "6181fb5b6a97b0c955f0f73ad916c8e79c017902",
        "title": "Improving Skin cancer Management with ARTificial Intelligence (SMARTI): protocol for a preintervention/postintervention trial of an artificial intelligence system used as a diagnostic aid for skin cancer management in a specialist dermatology setting",
        "abstract": "The impact of the AI algorithm on diagnostic and management decisions will be evaluated by comparing the initial management decision of the registrar with their AI-assisted decision and comparing the benign to malignant ratio (for lesions biopsied) between the preintervention and postintervention periods. Introduction Convolutional neural networks (CNNs) can diagnose skin cancers with impressive accuracy in experimental settings, however, their performance in the real-world clinical setting, including comparison to teledermatology services, has not been validated in prospective clinical studies. Methods and analysis Participants will be recruited from dermatology clinics at the Alfred Hospital and Skin Health Institute, Melbourne. Skin lesions will be imaged using a proprietary dermoscopic camera. The artificial intelligence (AI) algorithm, a CNN developed by MoleMap Ltd and Monash eResearch, classifies lesions as benign, malignant or uncertain. This is a preintervention/postintervention study. In the preintervention period, treating doctors are blinded to AI lesion assessment. In the postintervention period, treating doctors review the AI lesion assessment in real time, and have the opportunity to then change their diagnosis and management. Any skin lesions of concern and at least two benign lesions will be selected for imaging. Each participant\u2019s lesions will be examined by a registrar, the treating consultant dermatologist and later by a teledermatologist. At the conclusion of the preintervention period, the safety of the AI algorithm will be evaluated in a primary analysis by measuring its sensitivity, specificity and agreement with histopathology where available, or the treating consultant dermatologists\u2019 classification. At trial completion, AI classifications will be compared with those of the teledermatologist, registrar, treating dermatologist and histopathology. The impact of the AI algorithm on diagnostic and management decisions will be evaluated by: (1) comparing the initial management decision of the registrar with their AI-assisted decision and (2) comparing the benign to malignant ratio (for lesions biopsied) between the preintervention and postintervention periods. Ethics and dissemination Human Research Ethics Committee (HREC) approval received from the Alfred Hospital Ethics Committee on 14 February 2019 (HREC/48865/Alfred-2018). Findings from this study will be disseminated through peer-reviewed publications, non-peer reviewed media and conferences. Trial registration number NCT04040114.",
        "publication_year": "2022",
        "authors": [
            "C. Felmingham",
            "Samantha MacNamara",
            "W. Cranwell",
            "Narelle Williams",
            "M. Wada",
            "N. Adler",
            "Z. Ge",
            "Alastair Sharfe",
            "Adrian Bowling",
            "M. Haskett",
            "R. Wolfe",
            "V. Mar"
        ],
        "related_topics": [
            "Medicine"
        ],
        "citation_count": "6",
        "reference_count": "33",
        "references": [
            "/paper/Clinical-Application-of-Artificial-Intelligence-for-Sanchez-Kamal/3e402735aa827797d2a52de9a9d7e37071edd33e",
            "/paper/Challenging-Patterns-of-Atypical-Dermatofibromas-of-Orzan-Doroban%C8%9Bu/e64892c66ebae3beaa0f166e898f3cc8e6e3b619",
            "/paper/The-role-of-mobile-teledermoscopy-in-skin-cancer-Lee-Witkowski/b9141ece8735b52f8ebc98e03546cb8427efda21",
            "/paper/The-Artificial-Intelligence-in-Teledermatology%3A-A-Giansanti/2b9f3a09ec649022e46ea9435a2a983606d70bd9",
            "/paper/Service-System-Design-of-New-Media-Information-and-Sun/fac33a76365e1b78ab170e81755bce2672f0e1fb",
            "/paper/Skin-cancer-risk-self-assessment-using-AI-as-a-mass-Ukharov-Shlivko/54f6a729c321d78b00b79efe869e43442149e811",
            "/paper/Expert-Level-Diagnosis-of-Nonpigmented-Skin-Cancer-Tschandl-Rosendahl/f01b512314420d53fa4209d732aba1ed77977730",
            "/paper/Deep-neural-networks-are-superior-to-dermatologists-Brinker-Hekler/c1c4fb5b8653b8730988e4c8df5ff5184edb1782",
            "/paper/Results-of-the-2016-International-Skin-Imaging-on-Marchetti-Codella/7a28816ccfa2c7608ccba437d38d1e69de1f428e",
            "/paper/Acral-melanoma-detection-using-a-convolutional-for-Yu-Yang/2286b53045dda4309a7f4da297e7d1974b1cb0d4",
            "/paper/Man-against-machine-reloaded%3A-performance-of-a-in-a-Haenssle-Fink/0a135bca2100eca70768c2fddbb62d516b3cef1c",
            "/paper/Dermatologist-level-classification-of-skin-cancer-Esteva-Kuprel/e1ec11a1cb3d9745fb18d3bf74247f95a6663d08",
            "/paper/Comparison-of-the-accuracy-of-human-readers-versus-Tschandl-Codella/4e50a8356f6e8239e08418b260bc6cbe640a512c",
            "/paper/Man-against-machine%3A-diagnostic-performance-of-a-in-Haenssle-Fink/546785490ac417be1f83ced6a8272e934934f411",
            "/paper/What-is-AI-Applications-of-artificial-intelligence-Du-Harpur-Watt/d3c787ccecad58b78c86530b780531dc7ee254b5",
            "/paper/Classification-of-the-Clinical-Images-for-Benign-a-Han-Kim/561af930ceb87cc54677e16e7d4451b8ad646771"
        ]
    },
    {
        "id": "e10cf0f28cf60b3a8e43f2a78a2b71d226173192",
        "title": "Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction",
        "abstract": "This paper presents a probabilistic method which combines a hidden Markov state process that encodes neuron geometric properties with a random field appearance model of the flourescence process, and utilizes dynamic programming to efficiently compute the global maximizers of what is called the \u201cmost probable\u201d neuron path. Recent advances in brain clearing and imaging have made it possible to image entire mammalian brains at sub-micron resolution. These images offer the potential to assemble brain-wide atlases of projection neuron morphology, but manual neuron reconstruction remains a bottleneck. In this paper we present a probabilistic method which combines a hidden Markov state process that encodes neuron geometric properties with a random field appearance model of the flourescence process. Our method utilizes dynamic programming to efficiently compute the global maximizers of what we call the \u201cmost probable\u201d neuron path. We applied our algorithm to the output of image segmentation models where false negatives severed neuronal processes, and showed that it can follow axons in the presence of noise or nearby neurons. Our method has the potential to be integrated into a semi or fully automated reconstruction pipeline. Additionally, it creates a framework for conditioning the probability to fixed start and endpoints through which users can intervene with hard constraints to, for example, rule out certain reconstructions, or assign axons to particular cell bodies. E-mail addresses: tathey1@jhu.edu, DTward@mednet.ucla.edu, umuelle3@jhmi.edu, mim@cis.jhu.edu. Date: August 9, 2021. 1 ar X iv :2 10 6. 02 70 1v 2 [ cs .C V ] 5 A ug 2 02 1 2 T. L. ATHEY, D. TWARD, U. MUELLER, AND M. I. MILLER",
        "publication_year": "2021",
        "authors": [
            "Thomas L. Athey",
            "D. Tward",
            "Ulrich Mueller",
            "M. Miller"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "50",
        "references": [
            "/paper/Automated-neuron-tracing-using-probability-density-Radojevi%C4%87-Meijering/a96a1b0c8fae6947b6882423a59336fe0f0e7d30",
            "/paper/Anisotropic-path-searching-for-automatic-neuron-Xie-Zhao/4d401caf33b963b921c6c03d789a982ae24bfaf5",
            "/paper/DeepNeuron%3A-an-open-deep-learning-toolbox-for-Zhou-Kuo/0d895cdf6c93e2464fd7ed9bdf9865dad4c4c416",
            "/paper/Automatic-Reconstruction-of-Neural-Morphologies-Choroma%C5%84ska-Chang/2b027d3d60dc211139e9909ad945ae7cd8a323f3",
            "/paper/Automated-Neuron-Tracing-Methods%3A-An-Updated-Acciai-Soda/04b69b22f6d7f730e08778acfd8c7beafb076d7d",
            "/paper/APP2%3A-automatic-tracing-of-3D-neuron-morphology-on-Xiao-Peng/01fb4e77850f0c82167143ae98f428dd0bf29e28",
            "/paper/Deep-Learning-Segmentation-of-Optical-Microscopy-Li-Zeng/7cf541ec0692b55c24dc81e111ba693b74e7beaa",
            "/paper/Mapping-mesoscale-axonal-projections-in-the-mouse-a-Friedmann-Pun/f755126b06d843e8ce6ec24c805f3071178ae204",
            "/paper/FMST%3A-an-Automatic-Neuron-Tracing-Method-Based-on-Yang-Hao/103c372c1086935be6717e393c67463a255d56b2",
            "/paper/Reconstruction-of-1%2C000-Projection-Neurons-Reveals-Winnubst-Bas/0f644f606f582133bcd654bb93b8ccd3a2c69d45"
        ]
    },
    {
        "id": "59c53a0e49743b247ad99129d92d545f7a506863",
        "title": "Voting from Nearest Tasks: Meta-Vote Pruning of Pre-trained Models for Downstream Tasks",
        "abstract": "A simple but effective ''Meta-Vote Pruning (MVP)'' method that significantly reduces the pruning iterations for a new task by initializing a sub-network from the pruned models of its nearest tasks. As a few large-scale pre-trained models become the major choices of various applications, new challenges arise for model pruning, e.g., can we avoid pruning the same model from scratch for every downstream task? How to reuse the pruning results of previous tasks to accelerate the pruning for a new task? To address these challenges, we create a small model for a new task from the pruned models of similar tasks. We show that a few fine-tuning steps on this model suffice to produce a promising pruned-model for the new task. We study this ''meta-pruning'' from nearest tasks on two major classes of pre-trained models, convolutional neural network (CNN) and vision transformer (ViT), under a limited budget of pruning iterations. Our study begins by investigating the overlap of pruned models for similar tasks and how the overlap changes over different layers and blocks. Inspired by these discoveries, we develop a simple but effective ''Meta-Vote Pruning (MVP)'' method that significantly reduces the pruning iterations for a new task by initializing a sub-network from the pruned models of its nearest tasks. In experiments, we demonstrate MVP's advantages in accuracy, efficiency, and generalization through extensive empirical studies and comparisons with popular pruning methods over several datasets.",
        "publication_year": "2023",
        "authors": [
            "Haiyan Zhao",
            "Tianyi Zhou",
            "Guodong Long",
            "Jing Jiang",
            "Chengqi Zhang"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "41",
        "references": [
            "/paper/Pruning-Convolutional-Neural-Networks-for-Resource-Molchanov-Tyree/3db8730c203f88d7f08a6a99e8c02a077dc9b011",
            "/paper/Towards-Efficient-Model-Compression-via-Learned-Chin-Ding/282eda4516e0d4d7e6a462814fae6d48126f9c8f",
            "/paper/Model-Agnostic-Meta-Learning-for-Fast-Adaptation-of-Finn-Abbeel/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518",
            "/paper/Accelerating-Convolutional-Networks-via-Global-%26-Lin-Ji/e8262c9a0a63c765fd0529a6429f3b92cb7ad1b0",
            "/paper/MetaPruning%3A-Meta-Learning-for-Automatic-Neural-Liu-Mu/bd3df472bc848083068a76e9ce2b2ab49543dc78",
            "/paper/Learning-Efficient-Convolutional-Networks-through-Liu-Li/90a16f34d109b63d95ab4da2d491cbe3a1c8b656",
            "/paper/Learning-both-Weights-and-Connections-for-Efficient-Han-Pool/1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "/paper/Exploring-Simple-Siamese-Representation-Learning-Chen-He/0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d",
            "/paper/Winning-the-Lottery-with-Continuous-Sparsification-Savarese-Silva/54b8fcf4cc95c0eee93910052018d6286dc78ad9",
            "/paper/Training-data-efficient-image-transformers-%26-Touvron-Cord/ad7ddcc14984caae308c397f1a589aae75d4ab71"
        ]
    },
    {
        "id": "d715a0fc2d6a9752a2e0fc647a0756ae6b5d3311",
        "title": "Prior Knowledge and Memory Enriched Transformer for Sign Language Translation",
        "abstract": "This paper proposes a novel method called Prior knowledge and memory Enriched Transformer (PET) for SLT, which incorporates the auxiliary information into vanilla transformer, and designs a multi-stream memory structure to obtain higher-quality translations. This paper attacks the challenging problem of sign language translation (SLT), which involves not only visual and textual understanding but also additional prior knowledge learning (i.e. performing style, syntax). However, the majority of existing methods with vanilla encoder-decoder structures fail to sufficiently explore all of them. Based on this concern, we propose a novel method called Prior knowledge and memory Enriched Transformer (PET) for SLT, which incorporates the auxiliary information into vanilla transformer. Concretely, we develop gated interactive multi-head attention which associates the multimodal representation and global signing style with adaptive gated functions. One Part-of-Speech (POS) sequence generator relies on the associated information to predict the global syntactic structure, which is thereafter leveraged to guide the sentence generation. Besides, considering that the visual-textual context information, and additional auxiliary knowledge of a word may appear in more than one video, we design a multi-stream memory structure to obtain higher-quality translations, which stores the detailed correspondence between a word and its various relevant information, leading to a more comprehensive understanding for each word. We conduct extensive empirical studies on RWTH-PHOENIX-Weather-2014 dataset with both signer-dependent and signer-independent conditions. The quantitative and qualitative experimental results comprehensively reveal the effectiveness of PET.",
        "publication_year": "2022",
        "authors": [
            "Tao Jin",
            "Zhou Zhao",
            "Meng Zhang",
            "Xingshan Zeng"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": "5",
        "reference_count": "26",
        "references": [
            "/paper/Gloss-Free-End-to-End-Sign-Language-Translation-Lin-Wang/108c9f268b3a89d2570901b7997b683c8cbbe192",
            "/paper/MC-SLT%3A-Towards-Low-Resource-Signer-Adaptive-Sign-Jin-Zhao/951aec8bb6ef4114a69a4cf5b7d49f3f78c09c58",
            "/paper/SLTUNET%3A-A-Simple-Unified-Model-for-Sign-Language-Zhang-Muller/3bbc8841012fdb5971d1c86dff528edd8590f1b8",
            "/paper/OpenSR%3A-Open-Modality-Speech-Recognition-via-Cheng-Jin/abac1f1f876d2cc332830bdf705ba5e8d7f92313",
            "/paper/Machine-Translation-from-Signed-to-Spoken-State-of-Coster-Shterionov/7366fe7b4e7756dd13220d29077142ff802b41b3",
            "/paper/Contrastive-Disentangled-Meta-Learning-for-Sign-Jin-Zhao/73a6b52896ff246f1278008f42858238e2814d2d",
            "/paper/Connectionist-Temporal-Fusion-for-Sign-Language-Wang-Guo/33e309f993023a0384221733dd884e2b891c8311",
            "/paper/Sign-Language-Transformers%3A-Joint-End-to-End-Sign-Camg%C3%B6z-Koller/05dcdfece56d1869895f53ed581d8ad64118c05f",
            "/paper/Neural-Sign-Language-Translation-by-Learning-Orbay-Akarun/4e39e59f41a480f68c934cc38eb874a25ceb5073",
            "/paper/Better-Sign-Language-Translation-with-Yin-Read/364574aeb179196e1ef9155e1034ad385ddd9db2",
            "/paper/Stochastic-Transformer-Networks-with-Linear-Units%3A-Voskou-Panousis/9e890135a6e2034518a31be9b3e69a1a34ef2706",
            "/paper/TSPNet%3A-Hierarchical-Feature-Learning-via-Temporal-Li-Xu/16091f0821502b70294ef66671183dadd1afcdc0",
            "/paper/Neural-Sign-Language-Translation-Camg%C3%B6z-Hadfield/644602c65a5d8f30e62be027eb7b47f7c335191a",
            "/paper/SBAT%3A-Video-Captioning-with-Sparse-Boundary-Aware-Jin-Huang/884be34dd5d2ea78940da96d2813be7768933857",
            "/paper/Memory-Attended-Recurrent-Network-for-Video-Pei-Zhang/b12124f7bbdd3a99d6b392024806d0f3124380ac"
        ]
    },
    {
        "id": "0d37a47e67b8b3aed896390b3596fbec77f620d1",
        "title": "Differentiable and Scalable Generative Adversarial Models for Data Imputation",
        "abstract": "An effective scalable imputation system named SCIS is proposed to significantly speed up the training of the differentiable generative adversarial imputation models under accuracyguarantees for large-scale incomplete data. Data imputation has been extensively explored to solve the missing data problem. The dramatically increasing volume of incomplete data makes the imputation models computationally infeasible in many real-life applications. In this paper, we propose an effective scalable imputation system named SCIS to significantly speed up the training of the differentiable generative adversarial imputation models under accuracyguarantees for large-scale incomplete data. SCIS consists of two modules, differentiable imputation modeling (DIM) and sample size estimation (SSE). DIM leverages a new masking Sinkhorn divergence function to make an arbitrary generative adversarial imputation model differentiable, while for such a differentiable imputation model, SSE can estimate an appropriate sample size to ensure the user-specified imputation accuracy of the final model. Extensive experiments upon several real-life large-scale datasets demonstrate that, our proposed system can accelerate the generative adversarial model training by 7.1x. Using around 7.6% samples, SCIS yields competitive accuracy with the stateof-the-art imputation methods in much shorter computation time.",
        "publication_year": "2022",
        "authors": [
            "Yangyang Wu",
            "Jun Wang",
            "Xiaoye Miao",
            "Wenjia Wang",
            "Jianwei Yin"
        ],
        "related_topics": [
            "Computer Science"
        ],
        "citation_count": 0,
        "reference_count": "46",
        "references": [
            "/paper/GAIN%3A-Missing-Data-Imputation-using-Generative-Nets-Yoon-Jordon/a89f0a78f86077864e108a1bd2c4e670c85907f8",
            "/paper/A-Survey-of-Missing-Data-Imputation-Using-Networks-Kim-Tae/3539708f69ec8b7e59da278dcc8fd546e819782f",
            "/paper/Missing-Data-Imputation-with-Adversarially-trained-Spinelli-Scardapane/fb7ebf11df671d556e14501e63f61370c4ccf84c",
            "/paper/Generative-Semi-supervised-Learning-for-Time-Series-Miao-Wu/1fe4590e1807c61fc416612966010123036db3e7",
            "/paper/%22Deep%22-Learning-for-Missing-Value-Imputationin-with-Biessmann-Salinas/06e43829f9862f62ea38192a06e0f010737a07df",
            "/paper/Multiple-Imputation-Using-Deep-Denoising-Gondara-Wang/e3445d7de264269ef3a00aacc803cf360ea9192b",
            "/paper/Variational-Autoencoders-for-Missing-Data-with-to-a-McCoy-Kroon/7badf468b881a006b6d33f4d031f9506e64c0bf6",
            "/paper/MIWAE%3A-Deep-Generative-Modelling-and-Imputation-of-Mattei-Frellsen/47143b310dfa81e62db1c91b121efd74372e7271",
            "/paper/DataWig%3A-Missing-Value-Imputation-for-Tables-Biessmann-Rukat/d774b0c2462f7620f9055d0b1a6d9465e38c2b16",
            "/paper/Learning-Individual-Models-for-Imputation-Zhang-Song/f407419ca725e68fb5accd2413c8a30783922f0e"
        ]
    }
]